{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f1cb61-da00-4cea-93a9-b38e021cc485",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation of Libraries & User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6009177-87e7-4732-9f9c-8037206b4bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:44.783607Z",
     "iopub.status.busy": "2025-06-11T04:29:44.783291Z",
     "iopub.status.idle": "2025-06-11T04:29:47.555300Z",
     "shell.execute_reply": "2025-06-11T04:29:47.554545Z",
     "shell.execute_reply.started": "2025-06-11T04:29:44.783587Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install Necessary Libraries\n",
    "#!pip install -- upgrade pip --q\n",
    "!pip install openai --q\n",
    "!pip install openpyxl --q\n",
    "#!pip install pandas --q\n",
    "#!pip install numpy --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abb5c0c-1ad8-44f4-a4b4-c5805440f219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:47.557353Z",
     "iopub.status.busy": "2025-06-11T04:29:47.556679Z",
     "iopub.status.idle": "2025-06-11T04:29:48.480816Z",
     "shell.execute_reply": "2025-06-11T04:29:48.480284Z",
     "shell.execute_reply.started": "2025-06-11T04:29:47.557318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import necessary modules and set default settings as required\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import threading\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75301a15-1445-4d10-a2a5-a8c5370b0802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:48.481836Z",
     "iopub.status.busy": "2025-06-11T04:29:48.481430Z",
     "iopub.status.idle": "2025-06-11T04:29:48.484834Z",
     "shell.execute_reply": "2025-06-11T04:29:48.484335Z",
     "shell.execute_reply.started": "2025-06-11T04:29:48.481816Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ede763-3118-4043-aa0d-63de4c94b419",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc83145-e39c-486a-a642-c7230b38ec08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:48.486006Z",
     "iopub.status.busy": "2025-06-11T04:29:48.485666Z",
     "iopub.status.idle": "2025-06-11T04:29:48.489925Z",
     "shell.execute_reply": "2025-06-11T04:29:48.489453Z",
     "shell.execute_reply.started": "2025-06-11T04:29:48.485988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initializing openai api key\n",
    "openai.api_key = 'sk-proj-4aZNVQQU2553UKazDKGYT3BlbkFJjISCNXbbMhMb1c0FO6Ly'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f3b6e-dcdd-4c89-beaa-adc09bac488a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b81846-e902-4574-9fb9-59e183a71b99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UDF for review word count & buckets tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb2ea65-d2e9-4759-824d-c25a6d4ec1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:49.262810Z",
     "iopub.status.busy": "2025-06-11T04:29:49.262474Z",
     "iopub.status.idle": "2025-06-11T04:29:49.266391Z",
     "shell.execute_reply": "2025-06-11T04:29:49.265849Z",
     "shell.execute_reply.started": "2025-06-11T04:29:49.262788Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word_count(comment):\n",
    "    return len(comment.split())\n",
    "\n",
    "#Function to categorize word count into buckets\n",
    "def categorize_word_count(count):\n",
    "    if count <= 4:\n",
    "        return '1-4'\n",
    "    elif count <= 15:\n",
    "        return '5-15'\n",
    "    elif count <= 30:\n",
    "        return '16-30'\n",
    "    elif count <= 60:\n",
    "        return '31-60'\n",
    "    elif count <= 100:\n",
    "        return '61-100'\n",
    "    else:\n",
    "        return '>100'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e876b8-3bba-450e-a4ad-03dbd6fec6fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to assign values based on the presence of the topic in positive or negative keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5476664c-f2e6-45fb-8896-7d91f9a5f2aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:50.388818Z",
     "iopub.status.busy": "2025-06-11T04:29:50.388498Z",
     "iopub.status.idle": "2025-06-11T04:29:50.392191Z",
     "shell.execute_reply": "2025-06-11T04:29:50.391586Z",
     "shell.execute_reply.started": "2025-06-11T04:29:50.388798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_value(topic, positive, negative):\n",
    "    if topic in positive:\n",
    "        return 1\n",
    "    elif topic in negative:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef33b8-2be4-4aa7-8410-f87144f3e063",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UDF for Dynamic output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce15d9b-fd5b-4843-ae3b-4718105bc89a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:51.302937Z",
     "iopub.status.busy": "2025-06-11T04:29:51.302607Z",
     "iopub.status.idle": "2025-06-11T04:29:51.307207Z",
     "shell.execute_reply": "2025-06-11T04:29:51.306679Z",
     "shell.execute_reply.started": "2025-06-11T04:29:51.302916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function for dynamic message\n",
    "def print_dynamic_message(full_counter,key_counter,subcounter, full_total, key_total,subtotal, start_time, stop_event): #new addition - subcounter & subtotal\n",
    "    while not stop_event.is_set():\n",
    "        clear_output(wait=True)\n",
    "        elapsed_time_sec = time.time() - start_time\n",
    "        elapsed_time = time.strftime('%H:%M:%S', time.gmtime(elapsed_time_sec))\n",
    "        print(f\"Overall - Executing {full_counter[0]} of {full_total}\")\n",
    "        print(f\"Key - Executing {key_counter} of {key_total}\") #new addition\n",
    "        print(f\"Loop within Key - Executing {subcounter[0]} of {int(subtotal)}\", end=' ') #Replacement - subcounter & subtotal to counter & total\n",
    "        print(f\"\\nElapsed time: {elapsed_time}\")\n",
    "        for _ in range(3):  # Number of dots in the animation\n",
    "            if stop_event.is_set():\n",
    "                break\n",
    "            print('.', end='', flush=True)\n",
    "            time.sleep(0.5)  # Time delay between dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21189474-fc0f-48f3-acd0-53fe58855bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:51.883048Z",
     "iopub.status.busy": "2025-06-11T04:29:51.882733Z",
     "iopub.status.idle": "2025-06-11T04:29:51.886618Z",
     "shell.execute_reply": "2025-06-11T04:29:51.886056Z",
     "shell.execute_reply.started": "2025-06-11T04:29:51.883029Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function for dynamic message\n",
    "def print_dynamic_message_keyword(counter, total, stop_event):\n",
    "    while not stop_event.is_set():\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Executing loop {counter[0]} out of {int(total)}\", end=' ')\n",
    "        for _ in range(3):  # Number of dots in the animation\n",
    "            if stop_event.is_set():\n",
    "                break\n",
    "            print('.', end='', flush=True)\n",
    "            time.sleep(0.5)  # Time delay between dots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3d6e8-ed47-4f2c-bec4-7575302de73a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to query the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ea4aa5-e738-4fbe-9b23-4a61dc7c9c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:53.043194Z",
     "iopub.status.busy": "2025-06-11T04:29:53.042891Z",
     "iopub.status.idle": "2025-06-11T04:29:53.046675Z",
     "shell.execute_reply": "2025-06-11T04:29:53.046071Z",
     "shell.execute_reply.started": "2025-06-11T04:29:53.043173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_openai(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4o-2024-08-06',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=4095\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    completion_tokens = response.usage.completion_tokens\n",
    "    prompt_tokens = response.usage.prompt_tokens\n",
    "    \n",
    "    return content, prompt_tokens, completion_tokens    \n",
    "\n",
    "#gpt-4o-2024-05-13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871ea3a-845c-43df-b07a-b72684dab2bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UDF-Sentiment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ff2f1cf-67f7-412a-8faa-a30a9951f96d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:54.174223Z",
     "iopub.status.busy": "2025-06-11T04:29:54.173739Z",
     "iopub.status.idle": "2025-06-11T04:29:54.179927Z",
     "shell.execute_reply": "2025-06-11T04:29:54.179451Z",
     "shell.execute_reply.started": "2025-06-11T04:29:54.174200Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to initialize the Sentiment Scoring context with OpenAI\n",
    "#        - 'Others': Others refer to customer comments on topics other than 'Product Quality & OLD Gold Jewellery Exchange'.\n",
    "\n",
    "def score_sentiments_jul(reviews_df):\n",
    "    reviews_list = []\n",
    "    for index, row in reviews_df.iterrows():\n",
    "        review = row['review_text']\n",
    "        reviewer = row['Name']\n",
    "        reviews_list.append({\"review\": review, \"reviewer\": reviewer})\n",
    "            \n",
    "    prompt = f\"\"\"\n",
    "    You have been given a list of Commentor Names & Customer comments for analysis.\n",
    "    Instructions:\n",
    "    1. Read & analyze each of the comment for sentiment('positive' or 'negative').  \n",
    "    2. Categorize each of the comment into below defined topics.\n",
    "        Topic & Definitions:\n",
    "        - 'Trust':Trust refers to customers' trust in the brand.\n",
    "        - 'Store Experience': Store Experience refers to the customers' feeling on the overall shopping experience.\n",
    "        - 'Store Staff': Store Staff refers to customers feeling on how the sales person or staff interacts with the customer when providing assistance before, during, and after a purchase. A Good Store staff means he has good Knowledge on products & process and is able to explain clearly, very polite & hospitable, makes the customer feel heard, valued, and satisfied with the service & hospitality provided.\n",
    "        - 'Product Design': Product Design refers to the presence of any of these words 'DESIGN','CRAFTSMANSHIP','WORKMANSHIP' in the comment. The comment may also describe these in the product.\n",
    "        - 'Product Variety': Product Variety refers to the range of different products or collections available. A good variety means the customer feels there are many options to choose from.\n",
    "        - 'Discount': Discount refers to offers or deals. A comment on good Discount refers to customers' feeling that they have received a good deal or offer through a sale or discount.\n",
    "        - 'Making Charge': Making charge refers to the customers comments on whether they feel making charges are reasonable, high or low.\n",
    "        - 'Price': Price refers to the overall pricing of the products. Customer comments on whether the products are affordable, expensive, or value for money.        \n",
    "        - 'Product Quality': Product Quality refers to customers comments on Quality, Strength, Durability & Reliability of the product. The comment must include one of the words 'Quality', 'Strength', 'Durability' or 'Reliable' with reference to product quality to qualify as comment on Product Quality. \n",
    "        - 'OLD Gold Jewellery Exchange': OLD Gold Jewellery Exchange refers to customers comments on Old Gold Jewellery Exchange Policy, ease of exchanging their old gold & the value they get out of it. The comment must include one of the words 'Exchange', 'Exchange Policy' or 'old gold exchange' to qualify as comment on OLD Gold Jewellery Exchange. \n",
    "    3. Present the analysis for each of the comments ONLY in JSON format as shown in the below example. The output must strictly adhere to the JSON format provided in the example. Any additional text, explanations, summaries, or interpretations outside of this format is not required and should be omitted. \n",
    "        Example:\n",
    "            {{\n",
    "              \"Commentor Name\": \n",
    "              [\n",
    "                {{\n",
    "                  \"positive\": \"Trust,Store Experience,Store Staff,Product Quality\",\n",
    "                  \"negative\": \"Discount,Price\"\n",
    "                }}\n",
    "              ],\n",
    "              \"Commentor Name\": \n",
    "              [\n",
    "                {{\n",
    "                  \"positive\": \"OLD Gold Jewellery Exchange,Trust,Store Staff\",\n",
    "                  \"negative\": \"Product Quality\"\n",
    "                }}\n",
    "              ]\n",
    "            }}\n",
    "\n",
    "    Customer Comments: \n",
    "    {json.dumps(reviews_list)}\n",
    "\"\"\"    \n",
    "    #encoding = tiktoken.encoding_for_model(\"gpt-4-1106-preview\")  \n",
    "    #input_token = len(encoding.encode(prompt))\n",
    "    api_response, input_token, output_token = query_openai(prompt)\n",
    "    #output_token = len(encoding.encode(api_response))\n",
    "        \n",
    "    return api_response, input_token, output_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1fb0d-b3a6-466a-811e-291ce9984804",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to assign values based on the presence of the topic in positive or negative keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59c53ff-5af0-417f-95fe-161fd270e172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:55.143193Z",
     "iopub.status.busy": "2025-06-11T04:29:55.142844Z",
     "iopub.status.idle": "2025-06-11T04:29:55.146359Z",
     "shell.execute_reply": "2025-06-11T04:29:55.145803Z",
     "shell.execute_reply.started": "2025-06-11T04:29:55.143171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_value(topic, positive, negative):\n",
    "    if topic in positive:\n",
    "        return 1\n",
    "    elif topic in negative:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fea4c-ae23-4b5a-bed8-167b022a4d9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UDF for Keywords extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa165b9-8e46-4453-a6ac-ba310f6d178f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:55.973519Z",
     "iopub.status.busy": "2025-06-11T04:29:55.973217Z",
     "iopub.status.idle": "2025-06-11T04:29:55.978129Z",
     "shell.execute_reply": "2025-06-11T04:29:55.977570Z",
     "shell.execute_reply.started": "2025-06-11T04:29:55.973498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positive_keywords(reviews,topic):\n",
    "    prompt = f\"\"\"\n",
    "    You have been provided with a list of customer comments of a jewellery shop that has a positive sentiment for the topic {topic}. \n",
    "    \n",
    "    Your task is to follow the steps as below:\n",
    "    1. Read through each of the comments.  \n",
    "    2. Check the relevancy of each of the comments with the {topic}.\n",
    "    3. Identify the Positive keywords & Positive phrases with relevance to {topic} in each of the comments.\n",
    "    4. Consolidate all the Positive keywords & Positive phrases.\n",
    "    5. Strictly give only the top 5 Positive keywords & the top 5 Positive phrases along with their frequencies.\n",
    "    \n",
    "    Strictly follow the instructions as below while executing the task:\n",
    "    a. The keywords & phrases that you are listing down should be strictly relevant to the {topic} & should be in the same keywords as in customer comments.\n",
    "        For example: if the topic is 'Product Quality', relevant keywords might include 'durable', 'good quality', 'quality product','excellent quality' but not  'beautiful designs','Exquisite Workmanship', 'great service', 'good service', 'nice collection', 'friendly staff' or 'quick service', as these are related to Design, collection & Customer Service, not product quality.\n",
    "    b. Note that keywords can be either a single word or a combination of two words.\n",
    "        For example: 'Trustable', 'Reliable', 'Durable' are single word keywords while 'Good Quality', 'excellent variety', 'wide range', 'good designs' are two word keywords.  \n",
    "    c. The order of keywords & phrases that are listed must be in the descending order of their frequencies.\n",
    "    d. Strictly omit keywords & phrases that are not relevant to the {topic}.\n",
    "    e. Strictly ensure the keywords are mapped to keywords & phrases are mapped to phrases.\n",
    "    f. Strictly ensure that the keywords must not be mapped in phrases & phrases must not be mapped in keywords.\n",
    "    g. If there are no relevant positive keywords & phrases in comments for {topic}, give the output as \"No relevant positive keywords/ phrases\".\n",
    "    h. Strictly follow the below structure for the output. An example output is also given for your reference.\n",
    "    \n",
    "        Structure:\n",
    "        {{\n",
    "            \"{topic}\":  \n",
    "            [\n",
    "            {{\n",
    "              \"keywords\": \"<str>\",\n",
    "              \"phrases\": \"<str>\"\n",
    "            }}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "\n",
    "        Example Output:\n",
    "        {{\n",
    "            \"Trust\": \n",
    "            [\n",
    "            {{\n",
    "              \"keywords\": \"Genuine Service :5, Trust :4 , Reliable Option : 3 ,Honest :3\",\n",
    "              \"phrases\": \"Trustworthy place to buy :1, Our all time trusted place :1, Most trustworthy brand name :1\"\n",
    "            }}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "    The output should strictly be only in a JSON format.\n",
    "    Strictly start the output with {{.\n",
    "    Strictly do not start with ```json & end with  ``` in the output you give.\n",
    "    Strictly do not start with```json.\n",
    "    Strictly ensure that your output can be decoded by json.loads().\n",
    "\n",
    "Remember, The ultimate goal is to provide the business team with what delights the customer in our {topic} through positive keywords & phrases along with their frequencies in the comments.\n",
    "This helps them improve and better meet the needs of their customers.\n",
    "\n",
    "Here are the customer comments to work with:\n",
    "{reviews}\n",
    "\"\"\"    \n",
    "\n",
    "    \n",
    "    #encoding = tiktoken.encoding_for_model(\"gpt-4-1106-preview\")  \n",
    "    #input_token_count = len(encoding.encode(prompt))\n",
    "    #print(f\"Input tokens = {token_count}\")\n",
    "    \n",
    "    api_response,input_token_count,output_token_count = query_openai(prompt)\n",
    "    \n",
    "    #results = json.loads(api_response) # Assuming the API response is in valid JSON format \n",
    "    #output_token_count = len(encoding.encode(api_response))\n",
    "    #print(f\"Output tokens = {output_token}\")\n",
    "    \n",
    "    return api_response, input_token_count, output_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c4bb5e-b518-4053-9a4d-d6de3dc1fb17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:56.513586Z",
     "iopub.status.busy": "2025-06-11T04:29:56.513055Z",
     "iopub.status.idle": "2025-06-11T04:29:56.518023Z",
     "shell.execute_reply": "2025-06-11T04:29:56.517514Z",
     "shell.execute_reply.started": "2025-06-11T04:29:56.513562Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def negative_keywords(reviews,topic):\n",
    "    prompt = f\"\"\"\n",
    "    You have been provided with a list of customer comments of a jewellery shop that has a negative sentiment for the topic {topic}. \n",
    "    \n",
    "    Your task is to follow the steps as below:\n",
    "    1. Read through each of the comments.  \n",
    "    2. Check the relevancy of each of the comments with the {topic}.\n",
    "    3. Identify the negative keywords & negative phrases with relevance to {topic} in each of the comments.\n",
    "    4. Consolidate all the negative keywords & negative phrases.\n",
    "    5. Strictly give only the top 5 negative keywords & the top 5 negative phrases along with their frequencies.\n",
    "    \n",
    "    Strictly follow the instructions as below while executing the task:\n",
    "    a. The keywords & phrases that you are listing down should be strictly relevant to the {topic} & should be in the same keywords as in customer comments.\n",
    "        For example, if the topic is 'Product Quality', relevant words might include 'broke immediately', 'very weak', 'poor quality','bad quality' but not  'poor designs','rude service', 'bad service', 'low collection', 'unfriendly staff' or 'slow service', as these are related to Design, product variety & Customer Service, not product quality.\n",
    "    b. Note that keywords can be either a single word or a combination of two words.\n",
    "        For example: 'unhappy', 'painful', 'waiting' are single word keywords while 'poor designs', 'very weak', 'bad quality', 'rude service' are two word keywords.  \n",
    "    c. The order of keywords & phrases that are listed must be in the descending order of their frequencies.\n",
    "    d. Strictly omit keywords & phrases that are not relevant to the {topic}.\n",
    "    e. Strictly ensure the keywords are mapped to keywords & phrases are mapped to phrases.\n",
    "    f. Strictly ensure that the keywords must not be mapped in phrases & phrases must not be mapped in keywords.\n",
    "    g. If there are no relevant negative keywords & phrases in comments for {topic}, give the output as \"No relevant negative keywords/ phrases\".\n",
    "    h. Strictly follow the below structure for the output. An example output is also given for your reference.\n",
    "    \n",
    "        Structure:\n",
    "        {{\n",
    "            \"{topic}\":  \n",
    "            [\n",
    "            {{\n",
    "              \"keywords\": \"<str>\",\n",
    "              \"phrases\": \"<str>\"\n",
    "            }}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "\n",
    "        Example Output:\n",
    "        {{\n",
    "            \"Customer Service\": \n",
    "            [\n",
    "            {{\n",
    "              \"keywords\": \"Poor Service :5, rude behaviour :4 , unfriendly staff : 3 , didnt respond well :3, lousy behaviour:1\",\n",
    "              \"phrases\": \"The staff didnt bother to ask us what we wanted  :2, Didn't have product knowledge  :1\"\n",
    "            }}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "    The output should strictly be only in a JSON format.\n",
    "    Strictly start the output with {{.\n",
    "    Strictly do not start with ```json & end with  ``` in the output you give.\n",
    "    Strictly do not start with```json.\n",
    "    Strictly ensure that your output can be decoded by json.loads().\n",
    "\n",
    "Remember, The ultimate goal is to provide the business team with what pain points of the customer in our {topic} through negative words & phrases along with their frequencies in the comments.\n",
    "This helps them improve and better meet the needs of their customers.\n",
    "\n",
    "Here are the customer comments to work with:\n",
    "{reviews}\n",
    "\"\"\"    \n",
    "\n",
    "    \n",
    "    #encoding = tiktoken.encoding_for_model(\"gpt-4-1106-preview\")  \n",
    "    #input_token_count = len(encoding.encode(prompt))\n",
    "    #print(f\"Input tokens = {token_count}\")\n",
    "    \n",
    "    api_response,input_token_count,output_token_count = query_openai(prompt)\n",
    "    \n",
    "    #results = json.loads(api_response) # Assuming the API response is in valid JSON format \n",
    "    #output_token_count = len(encoding.encode(api_response))\n",
    "    #print(f\"Output tokens = {output_token}\")\n",
    "    \n",
    "    return api_response, input_token_count, output_token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a00297-305d-4e66-8c44-a419450bff1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UDF for Combining Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b27e3ed-a340-4e48-914d-92c07dd7ecd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:57.037927Z",
     "iopub.status.busy": "2025-06-11T04:29:57.037615Z",
     "iopub.status.idle": "2025-06-11T04:29:57.041319Z",
     "shell.execute_reply": "2025-06-11T04:29:57.040763Z",
     "shell.execute_reply.started": "2025-06-11T04:29:57.037907Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to combine keywords\n",
    "def combine_keywords(cell_content):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the following keywords and their frequencies:\n",
    "    \n",
    "    {cell_content}\n",
    "\n",
    "    Please perform the following tasks:\n",
    "    1. Group together keywords that has an overall similar meanings(those with closely related meanings, e.g., \"Trusted\", \"Trustworthy\", \"Reliable\") under a common term.\n",
    "    2. Correct any spelling mistakes (e.g., lowercase variations, incorrect spellings) but ensure that the meaning is not changed.\n",
    "    3. Sum up the frequencies of the grouped keywords.\n",
    "    4. There can be upto 10 grouped keywords in the descending order of the summed up frequncies.\n",
    "    \n",
    "    Strictly follow the below structure for the output. Dont give any additional explanation\n",
    "    \n",
    "        Structure:\n",
    "        {{\n",
    "        <str>:frequency, <str>:frequency \n",
    "        }}\n",
    "    \"\"\"\n",
    "\n",
    "    api_response,input_token_count,output_token_count = query_openai(prompt)\n",
    "\n",
    "    return api_response, input_token_count, output_token_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c487861f-080e-496c-8809-e32631fb9011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:57.743598Z",
     "iopub.status.busy": "2025-06-11T04:29:57.743282Z",
     "iopub.status.idle": "2025-06-11T04:29:57.747076Z",
     "shell.execute_reply": "2025-06-11T04:29:57.746505Z",
     "shell.execute_reply.started": "2025-06-11T04:29:57.743578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to combine phrases\n",
    "def combine_phrases(cell_content):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the following phrases and their frequencies:\n",
    "    \n",
    "    {cell_content}\n",
    "\n",
    "    Please perform the following tasks:\n",
    "    1. Group together similar phrases that convey the same or closely related meaning (e.g., \"most trustworthy people\" and \"very trustworthy\").\n",
    "    2. Correct any minor spelling or phrasing issues (e.g., capitalization, common typos), ensuring that the original meaning of the phrase is not changed.\n",
    "    3. Sum up the frequencies of the grouped phrases.\n",
    "    4. There can be upto 10 grouped phrases in the descending order of the summed up frequncies.  \n",
    "\n",
    "    Strictly follow the below structure for the output. Dont give any additional explanation\n",
    "    \n",
    "        Structure:\n",
    "        {{\n",
    "        <str>:frequency, <str>:frequency \n",
    "        }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    api_response,input_token_count,output_token_count = query_openai(prompt)\n",
    "\n",
    "    return api_response, input_token_count, output_token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118881b-3ddb-4102-a393-461c0a979f5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Reading & Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f88306-569b-4d38-9380-4cf7d4c4a8f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading data scraped from APIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e4e6fa-f54d-4efe-9e6f-1c4ec7245906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:29:58.422949Z",
     "iopub.status.busy": "2025-06-11T04:29:58.422641Z",
     "iopub.status.idle": "2025-06-11T04:30:05.661661Z",
     "shell.execute_reply": "2025-06-11T04:30:05.661137Z",
     "shell.execute_reply.started": "2025-06-11T04:29:58.422929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (8481, 10)\n"
     ]
    }
   ],
   "source": [
    "#Define the folder path\n",
    "folder_path = 'scraped_data/uae_us'\n",
    "\n",
    "#List of required columns\n",
    "required_columns = [\n",
    "                    \"address\", \"name\", \"publishedAtDate\", \"reviewsCount\", \"stars\", \n",
    "                    \"text\", \"textTranslated\", \"title\", \"totalScore\",\"url\"\n",
    "                    ]\n",
    "\n",
    "#Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "#Loop through all files in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    #Check if it's a file and has a valid extension (CSV or Excel)\n",
    "    if os.path.isfile(file_path) and file.endswith(('.csv', '.xlsx')):\n",
    "        try:\n",
    "            #Read CSV or Excel\n",
    "            if file.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path, usecols=lambda col: col in required_columns, encoding='utf-8')\n",
    "            elif file.endswith('.xlsx'):\n",
    "                df = pd.read_excel(file_path, usecols=lambda col: col in required_columns, engine='openpyxl')\n",
    "            \n",
    "            #Append to list if it's not empty\n",
    "            if not df.empty:\n",
    "                dfs.append(df)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "#Combine all dataframes\n",
    "if dfs:\n",
    "    combined_df_competitors = pd.concat(dfs, ignore_index=True)\n",
    "    print(\"Combined DataFrame shape:\", combined_df_competitors.shape)\n",
    "    \n",
    "    #Display the final dataframe\n",
    "    combined_df_competitors.head()\n",
    "else:\n",
    "    print(\"No valid files found or no data in the specified columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05247c5-066d-4726-9854-8abf73557da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.663081Z",
     "iopub.status.busy": "2025-06-11T04:30:05.662735Z",
     "iopub.status.idle": "2025-06-11T04:30:05.672310Z",
     "shell.execute_reply": "2025-06-11T04:30:05.671775Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.663052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8479, 10)\n"
     ]
    }
   ],
   "source": [
    "combined_df_competitors = combined_df_competitors.dropna(how='all')\n",
    "print(combined_df_competitors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a70593-0015-40db-9b4a-2ded56343671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.673299Z",
     "iopub.status.busy": "2025-06-11T04:30:05.672978Z",
     "iopub.status.idle": "2025-06-11T04:30:05.686874Z",
     "shell.execute_reply": "2025-06-11T04:30:05.686331Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.673274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>reviewsCount</th>\n",
       "      <th>title</th>\n",
       "      <th>totalScore</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>publishedAtDate</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>textTranslated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Garden State Plaza, Paramus, NJ 07652</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Tiffany &amp; Co.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     address  reviewsCount          title  \\\n",
       "0  One Garden State Plaza, Paramus, NJ 07652         103.0  Tiffany & Co.   \n",
       "\n",
       "   totalScore                                                url name  \\\n",
       "0         4.1  https://www.google.com/maps/search/?api=1&quer...  NaN   \n",
       "\n",
       "  publishedAtDate  stars text textTranslated  \n",
       "0             NaN    NaN  NaN            NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_competitors.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d4e61c-20d3-495a-844a-aac24531b6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.688403Z",
     "iopub.status.busy": "2025-06-11T04:30:05.688184Z",
     "iopub.status.idle": "2025-06-11T04:30:05.692894Z",
     "shell.execute_reply": "2025-06-11T04:30:05.692429Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.688387Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combining title & address columns to create a primary key to map store name\n",
    "combined_df_competitors['title-address'] = combined_df_competitors['title']+\"-\"+combined_df_competitors['address'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6399c-f408-497d-9cc3-fc3736f0cbf5",
   "metadata": {},
   "source": [
    "combined_df_competitors.to_excel(\"temp.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "264476b6-f6e8-44f1-a394-7ff67a986ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.693895Z",
     "iopub.status.busy": "2025-06-11T04:30:05.693580Z",
     "iopub.status.idle": "2025-06-11T04:30:05.701936Z",
     "shell.execute_reply": "2025-06-11T04:30:05.701472Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.693875Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "store_name_mapping = {\n",
    "\"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)-Meena Bazar - Al Fahidi St - Bur Dubai - Al Fahidi - Dubai - United Arab Emirates\": \"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)\",\n",
    "\"Bhima Jewellers - Al Karama - Dubai-karama Center - Shop No. 16 16th St - Al Karama - Dubai - United Arab Emirates\": \"Bhima Jewellers - Al Karama\",\n",
    "\"Bhindi Jewelers-1070 Oak Tree Rd, Decatur, GA 30033\": \"Bhindi Jewellers-Decatur, GA\",\n",
    "\"Evermark Jewelry-3170 Peachtree Pkwy, Johns Creek, GA 30024\": \"Evermark Jewelry-Johns Creek, GA\",\n",
    "\"Jared Jewelers-1016 Illinois Rte 59, Aurora, IL 60504\": \"Jared-Aurora, IL\",\n",
    "\"Jared Jewelers-1504 Randall Rd, Algonquin, IL 60102\": \"Jared-Algonquin, IL\",\n",
    "\"Jared Jewelers-15341 LaGrange Rd, Orland Park, IL 60462\": \"Jared-Orland Park, IL\",\n",
    "\"Jared Jewelers-1700 Woodfield Rd, Schaumburg, IL 60173, United States\": \"Jared-Schaumburg, IL\",\n",
    "\"Jared Jewelers-2370 Fountain Square Dr, Lombard, IL 60148\": \"Jared-Lombard, IL\",\n",
    "\"Jared Jewelers-567 E Townline Rd, Vernon Hills, IL 60061, United States\": \"Jared-Vernon Hills, IL\",\n",
    "\"Jared Jewelers-693 E Boughton Rd, Bolingbrook, IL 60440\": \"Jared-Bolingbrook, IL\",\n",
    "\"Joyalukkas Jewellery Al Barsha-4684+QX2 Lulu Hypermarket - Al Barsha Rd - Al Barsha - Al Barsha 1 - Dubai - United Arab Emirates\": \"Joyalukkas Jewellery - Al Barsha\",\n",
    "\"Joyalukkas Jewellery Karama-Karama Centre, Kuwait Road - Dubai - United Arab Emirates\": \"Joyalukkas Jewellery - Al Karama\",\n",
    "\"Joyalukkas Jewellery-3155 Peachtree Pkwy, Suwanee, GA 30024\": \"Joyalukkas Jewellery-Suwanee, GA\",\n",
    "\"Joyalukkas Jewellery-7055 Preston Rd, Frisco, TX 75034\": \"Joyalukkas Jewellery-Frisco, TX\",\n",
    "\"Joyalukkas Jewellery-Al Fahidi St - Bur Dubai - Al Fahidi - Dubai - United Arab Emirates\": \"Joyalukkas Jewellery - Al Fahidi st - Al Fahidi\",\n",
    "\"Joyalukkas Jewellery-Dalma Plaza - Hamdan Bin Mohammed St - Abu Dhabi - United Arab Emirates\": \"Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi\",\n",
    "\"Joyalukkas Jewellery-Madinat Zayed Shopping Centre - Sultan Bin Zayed The First St - Zone 1 - Abu Dhabi - United Arab Emirates\": \"Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi\",\n",
    "\"Joyalukkas Jewellery-Shabia - Musaffah - Abu Dhabi - United Arab Emirates\": \"Joyalukkas Jewellery - Shabia - Abu Dhabi\",\n",
    "\"Joyalukkas Jewelry-2642 W Devon Ave, Chicago, IL 60659\": \"Joyalukkas Jewellery-Chicago, IL\",\n",
    "\"Joyalukkas Jewelry-5901 Hillcroft Ave Suite C7-A, Houston, TX 77036, United States\": \"Joyalukkas Jewellery-Houston, TX\",\n",
    "\"Kanz Jewels Meena Bazaar-19 50B St - Al Fahidi - Dubai - United Arab Emirates\": \"Kanz Jewellers\",\n",
    "\"Malabar Gold & Diamonds - Iselin - New Jersey-1348 Oak Tree Rd, Iselin, NJ 08830\": \"Malabar Gold & Diamonds-Iselin, NJ\",\n",
    "\"Malabar Gold & Diamonds - Silicon Central Mall-Central - Ground Floor, Shop No C03 & C04 - Dubai Silicon Oasis - Dubai - United Arab Emirates\": \"Malabar Gold & Diamonds - Silicon Oasis Central\",\n",
    "\"Malabar Gold and Diamonds - Al Barsha - Dubai-Level 2, Lulu Hypermarket, Al Barsha - Dubai - United Arab Emirates\": \"Malabar Gold and Diamonds - Al Barsha - Dubai\",\n",
    "\"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)-BurDubai - Al Fahidi St - Al Souq Al Kabeer - Dubai - United Arab Emirates\": \"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)\",\n",
    "\"Malabar Gold and Diamonds - Al Karama - Dubai-Karama Center, karama Center - Shop no: B66 - Kuwait St - Al Karama - Dubai - United Arab Emirates\": \"Malabar Gold and Diamonds - Al Karama - Dubai\",\n",
    "\"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi-Ground Floor, Al Wahda Mall - Hazza ' Bin Zayed The First St - Al Nahyan - Zone 1 - Abu Dhabi - United Arab Emirates\": \"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi\",\n",
    "\"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi-Dalma Mall - First Floor - Abu Dhabi Industrial City - ICAD I - Abu Dhabi - United Arab Emirates\": \"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi\",\n",
    "\"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)-Omeir Bin Yousaf Building, Behind New UAE Exchange - Hamdan Bin Mohammed St - Abu Dhabi - United Arab Emirates\": \"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)\",\n",
    "\"Malabar Gold and Diamonds - Hamdan Street (Branch 2)-3 Hamdan Bin Mohammed St - opp. ahalia hospital - Al Danah - Zone 1 - Abu Dhabi - United Arab Emirates\": \"Malabar Gold and Diamonds - Hamdan Street (Branch 2)\",\n",
    "\"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed-Lulu Hypermarket, Madinat Zayed Shopping Centre - Abu Dhabi - United Arab Emirates\": \"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed\",\n",
    "\"Malabar Gold and Diamonds - Meena Bazar - Dubai-Meena Bazar Cosmos Lane, Near Dubai Museum - Dubai - United Arab Emirates\": \"Malabar Gold and Diamonds - Meena Bazar - Dubai\",\n",
    "\"Malabar Gold and Diamonds - Shabia Musaffah-G Floor,Building # C125,ME-11 Mussafah Shabia Opp Al Ansari Exchange 106916 - Abu Dhabi - United Arab Emirates\": \"Malabar Gold and Diamonds - Shabia Musaffah\",\n",
    "\"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)-Shop No: - 01 Al Fahidi St - opp. Habib Bank AG Zurich - Bur Dubai - Al Souq Al Kabeer - Dubai - United Arab Emirates\": \"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)\",\n",
    "\"Malabar Gold and Diamonds Chicago-2652 W Devon Ave, Chicago, IL 60659\": \"Malabar Gold & Diamonds-Chicago, IL\",\n",
    "\"Malabar Gold and Diamonds- Dallas-5811 Preston Rd, Frisco, TX 75034\": \"Malabar Gold & Diamonds-Frisco, TX\",\n",
    "\"Malabar Gold and Diamonds Naperville-1568 Ogden Ave, Naperville, IL 60540\": \"Malabar Gold & Diamonds-Naperville, IL\",\n",
    "\"Malani Jewelers-300 Central Expy, Richardson, TX 75080\": \"Malani Jewellers-Richardson, TX\",\n",
    "\"May Jewelers-8032 Leesburg Pike, Tysons, VA 22182, United States\": \"May Jewelers-Vienna, VA\",\n",
    "\"Meena Jewellers-Meena Bazar Cosmos Lane - 14 50B St - near Dubai Museum - Al Fahidi - Dubai - United Arab Emirates\": \"Meena Jewellers - Meena Bazar\",\n",
    "\"Mint Jewels | Sell Gold in Dubai | Buy Gold Bars in Dubai-karama Center - 22 Kuwait St - Al Karama - Dubai - United Arab Emirates\": \"Mint Jewels - Al Karama\",\n",
    "\"Sona Jewelers-6 Marconi Ave, Iselin, NJ 08830, United States\": \"Sona Jewelers-Iselin, NJ\",\n",
    "\"Tiffany & Co.-1 American Dream Wy E201, East Rutherford, NJ 07073, United States\": \"Tiffany & Co-East Rutherford, NJ\",\n",
    "\"Tiffany & Co.-101 Riverside Square Mall Suite 184A, Hackensack, NJ 07601\": \"Tiffany & Co-Hackensack, NJ\",\n",
    "\"Tiffany & Co.-105 Broad St, Red Bank, NJ 07701\": \"Tiffany & Co-Red Bank, NJ\",\n",
    "\"Tiffany & Co.-1158 Northbrook Ct, Northbrook, IL 60062\": \"Tiffany & Co-Northbrook, IL\",\n",
    "\"Tiffany & Co.-1200 Morris Tpke, Short Hills, NJ 07078\": \"Tiffany & Co-Short Hills, NJ\",\n",
    "\"Tiffany & Co.-4999 Old Orchard Shopping Ctr, Skokie, IL 60077\": \"Tiffany & Co-Skokie, IL\",\n",
    "\"Tiffany & Co.-730 Michigan Ave, Chicago, IL 60611\": \"Tiffany & Co-Chicago, IL\",\n",
    "\"Tiffany & Co.-8045 Leesburg Pike, Vienna, VA 22182\": \"Tiffany & Co-Vienna, VA\",\n",
    "\"Tiffany & Co.-9200 Stony Point Pkwy, Richmond, VA 23235, United States\": \"Tiffany & Co-Richmond, VA\",\n",
    "\"Tiffany & Co.-One Garden State Plaza, Paramus, NJ 07652\": \"Tiffany & Co-Paramus, NJ\",\n",
    "\"VBJ (Vummidi Bangaru Jewellers)-7100 Stonebrook Pkwy, Frisco, TX 75034\": \"VBJ Jewellers-Frisco, TX\"\n",
    "}\n",
    "\n",
    "#Create a new column 'store_name' by mapping the values of 'title-address' using the dictionary\n",
    "combined_df_competitors['store_name'] = combined_df_competitors['title-address'].map(store_name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b33cf622-49c9-4bc6-b121-895c04519818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.702875Z",
     "iopub.status.busy": "2025-06-11T04:30:05.702555Z",
     "iopub.status.idle": "2025-06-11T04:30:05.713755Z",
     "shell.execute_reply": "2025-06-11T04:30:05.713301Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.702850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>reviewsCount</th>\n",
       "      <th>title</th>\n",
       "      <th>totalScore</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>publishedAtDate</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>textTranslated</th>\n",
       "      <th>title-address</th>\n",
       "      <th>store_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Garden State Plaza, Paramus, NJ 07652</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Tiffany &amp; Co.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiffany &amp; Co.-One Garden State Plaza, Paramus,...</td>\n",
       "      <td>Tiffany &amp; Co-Paramus, NJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     address  reviewsCount          title  \\\n",
       "0  One Garden State Plaza, Paramus, NJ 07652         103.0  Tiffany & Co.   \n",
       "\n",
       "   totalScore                                                url name  \\\n",
       "0         4.1  https://www.google.com/maps/search/?api=1&quer...  NaN   \n",
       "\n",
       "  publishedAtDate  stars text textTranslated  \\\n",
       "0             NaN    NaN  NaN            NaN   \n",
       "\n",
       "                                       title-address                store_name  \n",
       "0  Tiffany & Co.-One Garden State Plaza, Paramus,...  Tiffany & Co-Paramus, NJ  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_competitors.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3e5bb0-0b36-437a-8773-bb6ec528798d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.714528Z",
     "iopub.status.busy": "2025-06-11T04:30:05.714314Z",
     "iopub.status.idle": "2025-06-11T04:30:05.719981Z",
     "shell.execute_reply": "2025-06-11T04:30:05.719544Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.714513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is mapped correctly\n"
     ]
    }
   ],
   "source": [
    "if((len(combined_df_competitors['title-address'].unique().tolist())) == (len(combined_df_competitors['store_name'].unique().tolist()))):\n",
    "    print(\"Data is mapped correctly\")\n",
    "else:\n",
    "    print(\"Revisit Store Name Mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f00c88c3-b146-47be-babd-01ce2a16a3e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.720937Z",
     "iopub.status.busy": "2025-06-11T04:30:05.720681Z",
     "iopub.status.idle": "2025-06-11T04:30:05.725728Z",
     "shell.execute_reply": "2025-06-11T04:30:05.725261Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.720913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tiffany & Co-Paramus, NJ',\n",
       " 'Joyalukkas Jewellery - Shabia - Abu Dhabi',\n",
       " 'Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed',\n",
       " 'Malabar Gold & Diamonds-Naperville, IL',\n",
       " 'Sona Jewelers-Iselin, NJ',\n",
       " 'Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi',\n",
       " 'Malabar Gold & Diamonds-Chicago, IL',\n",
       " 'Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi',\n",
       " 'Tiffany & Co-Northbrook, IL',\n",
       " 'Jared-Lombard, IL',\n",
       " 'Bhima Jewellers - Al Karama',\n",
       " 'Malabar Gold and Diamonds - Al Barsha - Dubai',\n",
       " 'Malabar Gold and Diamonds - Hamdan Street ( Branch 1)',\n",
       " 'Jared-Schaumburg, IL',\n",
       " 'Tiffany & Co-Chicago, IL',\n",
       " 'Tiffany & Co-Richmond, VA',\n",
       " 'Malabar Gold and Diamonds - Meena Bazar - Dubai',\n",
       " 'Tiffany & Co-Skokie, IL',\n",
       " 'Joyalukkas Jewellery-Chicago, IL',\n",
       " 'Mint Jewels - Al Karama',\n",
       " 'Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)',\n",
       " 'May Jewelers-Vienna, VA',\n",
       " 'Tiffany & Co-Red Bank, NJ',\n",
       " 'Kanz Jewellers',\n",
       " 'Malabar Gold & Diamonds - Silicon Oasis Central',\n",
       " 'Malani Jewellers-Richardson, TX',\n",
       " 'Malabar Gold and Diamonds - Al Karama - Dubai',\n",
       " 'Bhindi Jewellers-Decatur, GA',\n",
       " 'Joyalukkas Jewellery-Frisco, TX',\n",
       " 'Evermark Jewelry-Johns Creek, GA',\n",
       " 'Tiffany & Co-East Rutherford, NJ',\n",
       " 'Jared-Bolingbrook, IL',\n",
       " 'Joyalukkas Jewellery - Al Barsha',\n",
       " 'Jared-Vernon Hills, IL',\n",
       " 'Joyalukkas Jewellery - Al Karama',\n",
       " 'Malabar Gold and Diamonds - Shabia Musaffah',\n",
       " 'Malabar Gold & Diamonds-Iselin, NJ',\n",
       " 'Joyalukkas Jewellery - Al Fahidi st - Al Fahidi',\n",
       " 'Tiffany & Co-Short Hills, NJ',\n",
       " 'Meena Jewellers - Meena Bazar',\n",
       " 'Joyalukkas Jewellery-Houston, TX',\n",
       " 'Tiffany & Co-Hackensack, NJ',\n",
       " 'Malabar Gold and Diamonds - Hamdan Street (Branch 2)',\n",
       " 'Malabar Gold & Diamonds-Frisco, TX',\n",
       " 'Jared-Aurora, IL',\n",
       " 'Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)',\n",
       " 'Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)',\n",
       " 'Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi',\n",
       " 'Tiffany & Co-Vienna, VA',\n",
       " 'VBJ Jewellers-Frisco, TX',\n",
       " 'Joyalukkas Jewellery-Suwanee, GA',\n",
       " 'Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi',\n",
       " 'Jared-Algonquin, IL',\n",
       " 'Jared-Orland Park, IL']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_competitors['store_name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fa7b5e1-d8e0-4cbf-8376-2622cfec0665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:05.726600Z",
     "iopub.status.busy": "2025-06-11T04:30:05.726323Z",
     "iopub.status.idle": "2025-06-11T04:30:07.317698Z",
     "shell.execute_reply": "2025-06-11T04:30:07.317185Z",
     "shell.execute_reply.started": "2025-06-11T04:30:05.726555Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_df_competitors.to_excel('temp/combined_df_competitors.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31d7db94-911e-464f-a272-c06ea53c0c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:07.319246Z",
     "iopub.status.busy": "2025-06-11T04:30:07.318979Z",
     "iopub.status.idle": "2025-06-11T04:30:07.326155Z",
     "shell.execute_reply": "2025-06-11T04:30:07.325728Z",
     "shell.execute_reply.started": "2025-06-11T04:30:07.319227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_required = ['name','publishedAtDate','stars','text', 'textTranslated','totalScore','store_name'] \n",
    "combined_df_competitors= combined_df_competitors[columns_required].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0806790-a4f0-49f8-9e3d-6a07aa7bf32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:07.563020Z",
     "iopub.status.busy": "2025-06-11T04:30:07.562768Z",
     "iopub.status.idle": "2025-06-11T04:30:07.566763Z",
     "shell.execute_reply": "2025-06-11T04:30:07.566257Z",
     "shell.execute_reply.started": "2025-06-11T04:30:07.563001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'publishedAtDate',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'textTranslated',\n",
       " 'totalScore',\n",
       " 'store_name']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_competitors.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59284dbe-dada-4517-8fe2-453e52690e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:10.162365Z",
     "iopub.status.busy": "2025-06-11T04:30:10.162048Z",
     "iopub.status.idle": "2025-06-11T04:30:10.171342Z",
     "shell.execute_reply": "2025-06-11T04:30:10.170803Z",
     "shell.execute_reply.started": "2025-06-11T04:30:10.162343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>publishedAtDate</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>textTranslated</th>\n",
       "      <th>totalScore</th>\n",
       "      <th>store_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Tiffany &amp; Co-Paramus, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Evermark Jewelry-Johns Creek, GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name publishedAtDate  stars text textTranslated  totalScore  \\\n",
       "0     NaN             NaN    NaN  NaN            NaN         4.1   \n",
       "4424  NaN             NaN    NaN  NaN            NaN         5.0   \n",
       "\n",
       "                            store_name  \n",
       "0             Tiffany & Co-Paramus, NJ  \n",
       "4424  Evermark Jewelry-Johns Creek, GA  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_drop = combined_df_competitors[combined_df_competitors['stars'].isna()]\n",
    "rows_to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3bbead0-1bc7-4ffd-b6fd-0dbc88c97218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:11.103233Z",
     "iopub.status.busy": "2025-06-11T04:30:11.102927Z",
     "iopub.status.idle": "2025-06-11T04:30:11.109615Z",
     "shell.execute_reply": "2025-06-11T04:30:11.109021Z",
     "shell.execute_reply.started": "2025-06-11T04:30:11.103214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_name\n",
       "Joyalukkas Jewellery - Al Fahidi st - Al Fahidi                               1102\n",
       "Malabar Gold and Diamonds - Hamdan Street (Branch 2)                           789\n",
       "Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed                   701\n",
       "Malabar Gold and Diamonds - Al Karama - Dubai                                  511\n",
       "Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi                             421\n",
       "Joyalukkas Jewellery - Al Karama                                               412\n",
       "Malabar Gold & Diamonds-Iselin, NJ                                             360\n",
       "Malabar Gold & Diamonds-Naperville, IL                                         352\n",
       "Malabar Gold and Diamonds - Meena Bazar - Dubai                                337\n",
       "Malabar Gold & Diamonds-Frisco, TX                                             333\n",
       "Malabar Gold and Diamonds - Al Barsha - Dubai                                  321\n",
       "Malabar Gold & Diamonds-Chicago, IL                                            265\n",
       "Malabar Gold and Diamonds - Hamdan Street ( Branch 1)                          257\n",
       "Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)            256\n",
       "Mint Jewels - Al Karama                                                        245\n",
       "Joyalukkas Jewellery-Frisco, TX                                                229\n",
       "Malabar Gold and Diamonds - Shabia Musaffah                                    223\n",
       "Joyalukkas Jewellery-Suwanee, GA                                               191\n",
       "Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)     156\n",
       "Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi                          128\n",
       "Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi               118\n",
       "Joyalukkas Jewellery-Houston, TX                                               111\n",
       "Joyalukkas Jewellery-Chicago, IL                                               105\n",
       "Malabar Gold & Diamonds - Silicon Oasis Central                                 95\n",
       "Joyalukkas Jewellery - Al Barsha                                                71\n",
       "Malani Jewellers-Richardson, TX                                                 62\n",
       "Joyalukkas Jewellery - Shabia - Abu Dhabi                                       61\n",
       "Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi                                  58\n",
       "VBJ Jewellers-Frisco, TX                                                        54\n",
       "Bhima Jewellers - Al Karama                                                     30\n",
       "Jared-Algonquin, IL                                                             21\n",
       "Kanz Jewellers                                                                  18\n",
       "Jared-Schaumburg, IL                                                            13\n",
       "Jared-Bolingbrook, IL                                                           10\n",
       "Meena Jewellers - Meena Bazar                                                    9\n",
       "Sona Jewelers-Iselin, NJ                                                         8\n",
       "Jared-Aurora, IL                                                                 7\n",
       "Tiffany & Co-Chicago, IL                                                         6\n",
       "Jared-Vernon Hills, IL                                                           5\n",
       "Jared-Orland Park, IL                                                            4\n",
       "Tiffany & Co-Vienna, VA                                                          3\n",
       "Tiffany & Co-Hackensack, NJ                                                      3\n",
       "Tiffany & Co-East Rutherford, NJ                                                 3\n",
       "Jared-Lombard, IL                                                                3\n",
       "Tiffany & Co-Skokie, IL                                                          2\n",
       "Bhindi Jewellers-Decatur, GA                                                     2\n",
       "May Jewelers-Vienna, VA                                                          1\n",
       "Tiffany & Co-Richmond, VA                                                        1\n",
       "Tiffany & Co-Northbrook, IL                                                      1\n",
       "Tiffany & Co-Paramus, NJ                                                         1\n",
       "Tiffany & Co-Red Bank, NJ                                                        1\n",
       "Evermark Jewelry-Johns Creek, GA                                                 1\n",
       "Tiffany & Co-Short Hills, NJ                                                     1\n",
       "Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_competitors['store_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65f09a4d-4ef5-4c60-a3b9-1e1e84dfc04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:12.403055Z",
     "iopub.status.busy": "2025-06-11T04:30:12.402731Z",
     "iopub.status.idle": "2025-06-11T04:30:12.409600Z",
     "shell.execute_reply": "2025-06-11T04:30:12.409063Z",
     "shell.execute_reply.started": "2025-06-11T04:30:12.403034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dropping records having Null Values in stars \n",
    "combined_df_competitors = combined_df_competitors.dropna(subset=['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23ec2d40-9863-4753-ac64-018b64d31445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:13.183729Z",
     "iopub.status.busy": "2025-06-11T04:30:13.183412Z",
     "iopub.status.idle": "2025-06-11T04:30:13.187674Z",
     "shell.execute_reply": "2025-06-11T04:30:13.187156Z",
     "shell.execute_reply.started": "2025-06-11T04:30:13.183708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8477"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df_competitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453059be-6856-4cc6-a660-8a46faa60d67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Competitor Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9f325a1-5fba-4bb4-9f96-fc5967813e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:15.163288Z",
     "iopub.status.busy": "2025-06-11T04:30:15.162974Z",
     "iopub.status.idle": "2025-06-11T04:30:15.221415Z",
     "shell.execute_reply": "2025-06-11T04:30:15.220941Z",
     "shell.execute_reply.started": "2025-06-11T04:30:15.163268Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating review_text column\n",
    "combined_df_competitors['review_text'] = combined_df_competitors.apply(\n",
    "                                                                        lambda row: row['text'] if pd.isna(row['textTranslated']) or row['textTranslated'].strip() == '' else row['textTranslated'], \n",
    "                                                                        axis=1\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a42ea4e-13a5-44e0-8656-5474ecbb1478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:15.828893Z",
     "iopub.status.busy": "2025-06-11T04:30:15.828560Z",
     "iopub.status.idle": "2025-06-11T04:30:15.844397Z",
     "shell.execute_reply": "2025-06-11T04:30:15.843867Z",
     "shell.execute_reply.started": "2025-06-11T04:30:15.828872Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert 'publishedAtDate' to datetime format\n",
    "combined_df_competitors['publishedAtDate'] = pd.to_datetime(combined_df_competitors['publishedAtDate'])\n",
    "\n",
    "#Extracting Year and month\n",
    "combined_df_competitors['year'] = combined_df_competitors['publishedAtDate'].dt.year\n",
    "combined_df_competitors['month'] = combined_df_competitors['publishedAtDate'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89d82d2a-af21-4347-8706-ddb4c21fad88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:16.703687Z",
     "iopub.status.busy": "2025-06-11T04:30:16.703376Z",
     "iopub.status.idle": "2025-06-11T04:30:16.713534Z",
     "shell.execute_reply": "2025-06-11T04:30:16.713068Z",
     "shell.execute_reply.started": "2025-06-11T04:30:16.703667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['May-2025', 'Apr-2025', 'Jun-2025'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group by 'store_name' and calculate min & max dates\n",
    "store_date_summary = combined_df_competitors.groupby('store_name')['publishedAtDate'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "#Format dates as 'MMM-YYYY'\n",
    "store_date_summary['min_date'] = store_date_summary['min'].dt.strftime('%b-%Y')\n",
    "store_date_summary['max_date'] = store_date_summary['max'].dt.strftime('%b-%Y')\n",
    "\n",
    "#Drop the original min/max date columns\n",
    "store_date_summary = store_date_summary.drop(columns=['min', 'max'])\n",
    "\n",
    "#Display the final result\n",
    "store_date_summary['min_date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a186f-481a-4409-baa9-ec1dfaca18c2",
   "metadata": {},
   "source": [
    "#### Filtering comments greater than Dec 31, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b0c1a-f2f3-4543-8b2e-9129fd7a4250",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Define the cutoff date\n",
    "cutoff_date = pd.Timestamp('2025-01-01', tz='UTC')  # Convert cutoff_date to UTC\n",
    "\n",
    "#Filter the dataframe to keep only records after December 31, 2024\n",
    "combined_df_competitors = combined_df_competitors[combined_df_competitors['publishedAtDate'] > cutoff_date].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec1e2ecc-6bf0-415f-b6ff-6e569b762a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:19.303339Z",
     "iopub.status.busy": "2025-06-11T04:30:19.303019Z",
     "iopub.status.idle": "2025-06-11T04:30:19.309040Z",
     "shell.execute_reply": "2025-06-11T04:30:19.308574Z",
     "shell.execute_reply.started": "2025-06-11T04:30:19.303317Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dropping the repetitive columns\n",
    "combined_df_competitors.drop(columns=['text','textTranslated'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea5fea60-c51d-4de7-b170-140997842b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:19.863542Z",
     "iopub.status.busy": "2025-06-11T04:30:19.863240Z",
     "iopub.status.idle": "2025-06-11T04:30:19.867172Z",
     "shell.execute_reply": "2025-06-11T04:30:19.866694Z",
     "shell.execute_reply.started": "2025-06-11T04:30:19.863521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Adding 'store_code' column to competitors and filling with 'NA'\n",
    "combined_df_competitors['store_code'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c3cdb6c-8a88-4840-9826-78cd40f6ca1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:20.663023Z",
     "iopub.status.busy": "2025-06-11T04:30:20.662714Z",
     "iopub.status.idle": "2025-06-11T04:30:20.666850Z",
     "shell.execute_reply": "2025-06-11T04:30:20.666222Z",
     "shell.execute_reply.started": "2025-06-11T04:30:20.663005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dictionary mapping to standard column names in rest of the code\n",
    "std_column_names_comp = {\n",
    "                            'name': 'Name',\n",
    "                            'review_text': 'review_text',\n",
    "                            'publishedAtDate': 'Published At Date',\n",
    "                            'stars': 'Stars',\n",
    "                            'store_name':'Store Name',\n",
    "                            'totalScore':'Total Score',\n",
    "                            'store_code':'Store Code Cleaned',\n",
    "                            'year':'year', \n",
    "                            'month':'month'\n",
    "                        }\n",
    "\n",
    "\n",
    "#Renaming the columns\n",
    "combined_df_competitors.rename(columns=std_column_names_comp, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cfa4b99-7f0d-4f0a-90eb-60726bbea62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:21.163220Z",
     "iopub.status.busy": "2025-06-11T04:30:21.162924Z",
     "iopub.status.idle": "2025-06-11T04:30:21.167926Z",
     "shell.execute_reply": "2025-06-11T04:30:21.167435Z",
     "shell.execute_reply.started": "2025-06-11T04:30:21.163199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df_competitors['Store Name'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ed413c9-24fa-4983-b817-29ac7579e19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:21.763463Z",
     "iopub.status.busy": "2025-06-11T04:30:21.763160Z",
     "iopub.status.idle": "2025-06-11T04:30:21.767158Z",
     "shell.execute_reply": "2025-06-11T04:30:21.766673Z",
     "shell.execute_reply.started": "2025-06-11T04:30:21.763444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8477"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df_competitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c2cab2b-1160-4703-b480-5a2f1bf79213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:22.502887Z",
     "iopub.status.busy": "2025-06-11T04:30:22.502556Z",
     "iopub.status.idle": "2025-06-11T04:30:23.834965Z",
     "shell.execute_reply": "2025-06-11T04:30:23.834371Z",
     "shell.execute_reply.started": "2025-06-11T04:30:22.502867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Remove timezone to make datetime timezone-naive\n",
    "combined_df_competitors['Published At Date'] = combined_df_competitors['Published At Date'].dt.tz_localize(None)\n",
    "\n",
    "#Now save to Excel\n",
    "combined_df_competitors.to_excel(\"temp/raw_file_combined_df_competitors.xlsx\", index=False)\n",
    "\n",
    "print(\"File saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d13ea2e-e4c0-4d15-a6fd-06052e8a1f99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:23.836121Z",
     "iopub.status.busy": "2025-06-11T04:30:23.835831Z",
     "iopub.status.idle": "2025-06-11T04:30:23.844983Z",
     "shell.execute_reply": "2025-06-11T04:30:23.844523Z",
     "shell.execute_reply.started": "2025-06-11T04:30:23.836100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Published At Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>Store Name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Store Code Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suyel Khan</td>\n",
       "      <td>2025-06-09 10:54:58.711</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Joyalukkas Jewellery - Shabia - Abu Dhabi</td>\n",
       "      <td>Thank for jeeshan❤️</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hidayat Afridi</td>\n",
       "      <td>2025-06-09 08:08:12.093</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Joyalukkas Jewellery - Shabia - Abu Dhabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name       Published At Date  Stars  Total Score  \\\n",
       "2      Suyel Khan 2025-06-09 10:54:58.711    5.0          4.6   \n",
       "3  Hidayat Afridi 2025-06-09 08:08:12.093    5.0          4.6   \n",
       "\n",
       "                                  Store Name          review_text  year  \\\n",
       "2  Joyalukkas Jewellery - Shabia - Abu Dhabi  Thank for jeeshan❤️  2025   \n",
       "3  Joyalukkas Jewellery - Shabia - Abu Dhabi                  NaN  2025   \n",
       "\n",
       "   month Store Code Cleaned  \n",
       "2      6                 NA  \n",
       "3      6                 NA  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_competitors.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173aa75f-caf2-4849-8d32-4d30315e18cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading Tanishq Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064df222-799e-4a6e-bd6b-5b81dd550ba1",
   "metadata": {},
   "source": [
    "<span style = \"color:darkgreen\">**Prerequisites before reading in python notebook**</span>\n",
    "\n",
    "This code works where all the data are combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe0209e-b70f-464b-9839-e8f4c08c88cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "file_path = 'scraped_data/tanishq/scraped_data_tanishq.xlsx'\n",
    "\n",
    "#Load all the sheets into a dictionary of DataFrames\n",
    "sheets_dict = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "#Combine all the DataFrames into a single DataFrame\n",
    "combined_df_tq = pd.concat(sheets_dict.values(), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a302c6dc-611f-4862-ac12-2a95c2f5218d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:26.043792Z",
     "iopub.status.busy": "2025-06-11T04:30:26.043110Z",
     "iopub.status.idle": "2025-06-11T04:30:29.869913Z",
     "shell.execute_reply": "2025-06-11T04:30:29.869358Z",
     "shell.execute_reply.started": "2025-06-11T04:30:26.043755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screenname</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Business Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santhoshkumar Sathian</td>\n",
       "      <td>So happy with good services specially Mrs chai...</td>\n",
       "      <td>2024-04-09 17:55:36</td>\n",
       "      <td>5</td>\n",
       "      <td>Lulu ,Sharjah Central, A-06, Ground Floor Shei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kusum Devrani</td>\n",
       "      <td>Exceptional service from Tanishq and their sta...</td>\n",
       "      <td>2024-04-12 20:07:01</td>\n",
       "      <td>5</td>\n",
       "      <td>G-01, TAJ DUBAI, BURJ-KHALIFA STREET, BUSINESS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Screenname                                            Content  \\\n",
       "0  Santhoshkumar Sathian  So happy with good services specially Mrs chai...   \n",
       "1          Kusum Devrani  Exceptional service from Tanishq and their sta...   \n",
       "\n",
       "                  Date  Ratings  \\\n",
       "0  2024-04-09 17:55:36        5   \n",
       "1  2024-04-12 20:07:01        5   \n",
       "\n",
       "                                   Business Location  \n",
       "0  Lulu ,Sharjah Central, A-06, Ground Floor Shei...  \n",
       "1  G-01, TAJ DUBAI, BURJ-KHALIFA STREET, BUSINESS...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Data and share it \n",
    "combined_df_tq = pd.read_excel('scraped_data/tanishq/scraped_data_tanishq.xlsx', usecols=['Screenname', 'Chatter', 'Post Created Date','Ratings','Location'])\n",
    "\n",
    "combined_df_tq.rename(columns={\n",
    "                                'Screenname': 'Screenname',\n",
    "                                'Chatter': 'Content',\n",
    "                                'Post Created Date':'Date',\n",
    "                                'Ratings':'Ratings',\n",
    "                                'Location':'Business Location'\n",
    "                                }, inplace=True)\n",
    "\n",
    "combined_df_tq.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108f237-2176-4c66-9d95-b642557889f7",
   "metadata": {},
   "source": [
    "### Tanishq Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "131f33a8-360f-4256-bf17-1f2c154ecdb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:29.871279Z",
     "iopub.status.busy": "2025-06-11T04:30:29.870979Z",
     "iopub.status.idle": "2025-06-11T04:30:29.875098Z",
     "shell.execute_reply": "2025-06-11T04:30:29.874578Z",
     "shell.execute_reply.started": "2025-06-11T04:30:29.871258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Screenname', 'Content', 'Date', 'Ratings', 'Business Location'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_tq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0e1998e-9c83-4d74-bc74-c3474539288f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:30.983387Z",
     "iopub.status.busy": "2025-06-11T04:30:30.983074Z",
     "iopub.status.idle": "2025-06-11T04:30:30.987002Z",
     "shell.execute_reply": "2025-06-11T04:30:30.986359Z",
     "shell.execute_reply.started": "2025-06-11T04:30:30.983366Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating a seperate dataframe\n",
    "working_combined_tq = combined_df_tq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c617d815-b6e6-4238-876f-5e3cc814f259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:32.043684Z",
     "iopub.status.busy": "2025-06-11T04:30:32.043380Z",
     "iopub.status.idle": "2025-06-11T04:30:32.948646Z",
     "shell.execute_reply": "2025-06-11T04:30:32.947863Z",
     "shell.execute_reply.started": "2025-06-11T04:30:32.043666Z"
    }
   },
   "outputs": [],
   "source": [
    "working_combined_tq.to_excel('temp/combined_tq.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5434cd4c-f7ec-4319-a43d-57278ed90569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:32.949831Z",
     "iopub.status.busy": "2025-06-11T04:30:32.949556Z",
     "iopub.status.idle": "2025-06-11T04:30:32.955310Z",
     "shell.execute_reply": "2025-06-11T04:30:32.954811Z",
     "shell.execute_reply.started": "2025-06-11T04:30:32.949811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(working_combined_tq[\"Business Location\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "454a7e73-42e0-4fbb-ac08-2e583f0a293c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:33.498632Z",
     "iopub.status.busy": "2025-06-11T04:30:33.498276Z",
     "iopub.status.idle": "2025-06-11T04:30:33.504889Z",
     "shell.execute_reply": "2025-06-11T04:30:33.504354Z",
     "shell.execute_reply.started": "2025-06-11T04:30:33.498609Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "location_to_store_name = {\n",
    "                            \"1429 Oak Tree Rd\" : \"Tanishq-New Jersey, NJ\",\n",
    "                            \"2335 Post Oak Blvd\" : \"Tanishq-Houston, TX\",\n",
    "                            \"2809 Preston Rd #1200\" : \"Tanishq-Frisco, TX\",\n",
    "                            \"3406 El Camino Real\" : \"Tanishq-Santa Clara, CA\",\n",
    "                            \"4300 E New York St\" : \"Tanishq-Chicago, IL\",\n",
    "                            \"580 Peachtree Pkwy\" : \"Tanishq-Atlanta, GA\",\n",
    "                            \"7325 166th Avenue Northeast suite F155\" : \"Tanishq-Redmond Seattle, WA\",\n",
    "                            \"Al Dana Tower, Rolla Square, Al Ghuwair Al Gharb\" : \"Tanishq Jewellers-Rolla, SH\",\n",
    "                            \"C-19&amp;20, Ground Floor Silicon Central, Silicon Oasis Dubai\" : \"Tanishq Jewellers-Silicon Central, DB\",\n",
    "                            \"Dubai Gold souk, AL Hind Plaza 1 - Deira - Al Ras\" : \"Tanishq Jewellers-Gold Souk, DB\",\n",
    "                            \"F33 A, Oman Avenues Mall, Baushar\" : \"Tanishq Jewellers-Avenues Mall, OM\",\n",
    "                            \"G-01, TAJ DUBAI, BURJ-KHALIFA STREET, BUSINESS BAY\" : \"Tanishq Jewellers-Taj, DB\",\n",
    "                            \"Ground Floor, Al Wahda Mall - Hazza ' Bin Zayed The First St - Al Nahyan -  Zone 1\" : \"Mia-Al Wahda Mall, AD\",\n",
    "                            \"Johara Al Mana WLL, Lulu Hypermarket , Shop No 6 Lulu, D Ring\" : \"Tanishq Jewellers-Lulu Hypermarket, QA\",\n",
    "                            \"Lulu ,Sharjah Central, A-06, Ground Floor Sheikh Rashid Bin Saqr Al Qasimi St - Halwan Suburb - Samnan - Sharjah\" : \"Tanishq Jewellers-Sharjah Central, SH\",\n",
    "                            \"Shop 20, Ground Floor, Lulu Hypermarket شارع أم سقيم البرشاء\" : \"Tanishq Jewellers-Al Barsha, DB\",\n",
    "                            \"Shop No 17-20, Ground Floor Karama Center Shopping Mall, Al Kuwait Street\" : \"Tanishq Jewellers-Al Karama, DB\",\n",
    "                            \"Shop No:1, Plot No:312-294 Al Souq Al Kabeer, Fahidi Road Bur Dubai\" : \"Tanishq Jewellers-Al Fahidi, DB\",\n",
    "                            \"Shop Number 1 &amp; 2 Ground Floor, UW Mall 39 11B St - Al Mankhool\" : \"Tanishq Jewellers-UW Mall Al Mankhool, DB\",\n",
    "                            \"Showroom No. 3, Plot 312/177, Al Souq Al Kabeer, Meena Bazar, Cosmos Lane, Near Dubai Museum Bur Dubai- 90320\" : \"Tanishq Jewellers-Meena Bazar, DB\",\n",
    "                            \"Showroom No:3, Plot No:C-7 Sector No:E-8, Al Saman Tower\" : \"Tanishq Jewellers-Hamdan Bin Mohammed Street, AD\",\n",
    "                            \"Tanishq Jewellery Johara Al Mana WLL Doha Festival City, Store GE138, Bawabat Al Shamal\" : \"Tanishq Jewellers-Festival City, QA\",\n",
    "                            \"Unit 1025, Level 1, Burjuman Center, Opposite Starbucks, Khalid Bin Al Waleed Street,\" : \"Mia-Burjuman, DB\"\n",
    "                        }\n",
    "\n",
    "#Map the 'location' to 'Store Name'\n",
    "working_combined_tq['store_name'] = working_combined_tq['Business Location'].map(location_to_store_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "727cd0ca-7f71-496e-b0d3-367f7d1d0229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:34.284605Z",
     "iopub.status.busy": "2025-06-11T04:30:34.284286Z",
     "iopub.status.idle": "2025-06-11T04:30:34.289438Z",
     "shell.execute_reply": "2025-06-11T04:30:34.288930Z",
     "shell.execute_reply.started": "2025-06-11T04:30:34.284585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(working_combined_tq['store_name'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cdb3934-5cef-400b-b615-b4ff32aab1bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:35.163494Z",
     "iopub.status.busy": "2025-06-11T04:30:35.163175Z",
     "iopub.status.idle": "2025-06-11T04:30:35.169338Z",
     "shell.execute_reply": "2025-06-11T04:30:35.168791Z",
     "shell.execute_reply.started": "2025-06-11T04:30:35.163475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_name\n",
       "Tanishq Jewellers-Al Fahidi, DB                     1781\n",
       "Tanishq Jewellers-Al Barsha, DB                     1029\n",
       "Tanishq Jewellers-Gold Souk, DB                     1016\n",
       "Tanishq-Frisco, TX                                   778\n",
       "Tanishq Jewellers-Meena Bazar, DB                    683\n",
       "Tanishq Jewellers-Silicon Central, DB                681\n",
       "Tanishq Jewellers-Al Karama, DB                      488\n",
       "Mia-Burjuman, DB                                     408\n",
       "Tanishq Jewellers-Hamdan Bin Mohammed Street, AD     390\n",
       "Tanishq-Atlanta, GA                                  373\n",
       "Tanishq Jewellers-Sharjah Central, SH                319\n",
       "Tanishq-Houston, TX                                  248\n",
       "Tanishq-New Jersey, NJ                               231\n",
       "Tanishq Jewellers-Rolla, SH                          223\n",
       "Tanishq-Chicago, IL                                  203\n",
       "Tanishq Jewellers-Taj, DB                            154\n",
       "Tanishq Jewellers-Lulu Hypermarket, QA               145\n",
       "Tanishq-Redmond Seattle, WA                          133\n",
       "Tanishq Jewellers-Avenues Mall, OM                    82\n",
       "Tanishq-Santa Clara, CA                               63\n",
       "Tanishq Jewellers-UW Mall Al Mankhool, DB             30\n",
       "Tanishq Jewellers-Festival City, QA                   29\n",
       "Mia-Al Wahda Mall, AD                                 27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_combined_tq['store_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5501b5a3-3ed9-4e2c-b251-c210ad94c568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:35.798827Z",
     "iopub.status.busy": "2025-06-11T04:30:35.798504Z",
     "iopub.status.idle": "2025-06-11T04:30:35.804754Z",
     "shell.execute_reply": "2025-06-11T04:30:35.804189Z",
     "shell.execute_reply.started": "2025-06-11T04:30:35.798806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "location_to_store_code = {\n",
    "                            \"1429 Oak Tree Rd\" : \"XNJ\",\n",
    "                            \"2335 Post Oak Blvd\" : \"XTH\",\n",
    "                            \"2809 Preston Rd #1200\" : \"XTD\",\n",
    "                            \"3406 El Camino Real\" : \"XBA\",\n",
    "                            \"4300 E New York St\" : \"XCG\",\n",
    "                            \"580 Peachtree Pkwy\" : \"XAC\",\n",
    "                            \"7325 166th Avenue Northeast suite F155\" : \"XWS\",\n",
    "                            \"Al Dana Tower, Rolla Square, Al Ghuwair Al Gharb\" : \"XSR\",\n",
    "                            \"C-19&amp;20, Ground Floor Silicon Central, Silicon Oasis Dubai\" : \"XDS\",\n",
    "                            \"Dubai Gold souk, AL Hind Plaza 1 - Deira - Al Ras\" : \"XDG\",\n",
    "                            \"F33 A, Oman Avenues Mall, Baushar\" : \"XOM\",\n",
    "                            \"G-01, TAJ DUBAI, BURJ-KHALIFA STREET, BUSINESS BAY\" : \"XDT\",\n",
    "                            \"Ground Floor, Al Wahda Mall - Hazza ' Bin Zayed The First St - Al Nahyan -  Zone 1\" : \"XAW\",\n",
    "                            \"Johara Al Mana WLL, Lulu Hypermarket , Shop No 6 Lulu, D Ring\" : \"XQD\",\n",
    "                            \"Lulu ,Sharjah Central, A-06, Ground Floor Sheikh Rashid Bin Saqr Al Qasimi St - Halwan Suburb - Samnan - Sharjah\" : \"XSL\",\n",
    "                            \"Shop 20, Ground Floor, Lulu Hypermarket شارع أم سقيم البرشاء\" : \"XDB\",\n",
    "                            \"Shop No 17-20, Ground Floor Karama Center Shopping Mall, Al Kuwait Street\" : \"XDK\",\n",
    "                            \"Shop No:1, Plot No:312-294 Al Souq Al Kabeer, Fahidi Road Bur Dubai\" : \"XDF\",\n",
    "                            \"Shop Number 1 &amp; 2 Ground Floor, UW Mall 39 11B St - Al Mankhool\" : \"XDX\",\n",
    "                            \"Showroom No. 3, Plot 312/177, Al Souq Al Kabeer, Meena Bazar, Cosmos Lane, Near Dubai Museum Bur Dubai- 90320\" : \"XDM\",\n",
    "                            \"Showroom No:3, Plot No:C-7 Sector No:E-8, Al Saman Tower\" : \"XAH\",\n",
    "                            \"Tanishq Jewellery Johara Al Mana WLL Doha Festival City, Store GE138, Bawabat Al Shamal\" : \"XQF\",\n",
    "                            \"Unit 1025, Level 1, Burjuman Center, Opposite Starbucks, Khalid Bin Al Waleed Street,\" : \"XDJ\"\n",
    "                            }\n",
    "\n",
    "#Map the 'location' to 'Store Code'\n",
    "working_combined_tq['store_code'] = working_combined_tq['Business Location'].map(location_to_store_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52c29f2b-b1fc-4eb1-a31e-177680dfb012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:36.703182Z",
     "iopub.status.busy": "2025-06-11T04:30:36.702865Z",
     "iopub.status.idle": "2025-06-11T04:30:36.707646Z",
     "shell.execute_reply": "2025-06-11T04:30:36.707147Z",
     "shell.execute_reply.started": "2025-06-11T04:30:36.703160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(working_combined_tq['store_code'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9090dbc8-7e8f-421f-bb7c-a74e13ed4e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:37.652269Z",
     "iopub.status.busy": "2025-06-11T04:30:37.651922Z",
     "iopub.status.idle": "2025-06-11T04:30:37.659098Z",
     "shell.execute_reply": "2025-06-11T04:30:37.658590Z",
     "shell.execute_reply.started": "2025-06-11T04:30:37.652249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address & Store Name number matches\n",
      "Store code also matches\n"
     ]
    }
   ],
   "source": [
    "if(len(working_combined_tq[\"Business Location\"].unique().tolist()) == len(working_combined_tq['store_name'].unique().tolist())):\n",
    "    print(\"Address & Store Name number matches\")\n",
    "    if(len(working_combined_tq[\"Business Location\"].unique().tolist()) == len(working_combined_tq['store_code'].unique().tolist())):\n",
    "        print(\"Store code also matches\")\n",
    "    else:\n",
    "        print(\"Store code number doesnt match\")\n",
    "else:\n",
    "    print(\"Store Name doesnt match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae6aac47-e1cf-4370-90d2-736f0da910ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:39.522862Z",
     "iopub.status.busy": "2025-06-11T04:30:39.522526Z",
     "iopub.status.idle": "2025-06-11T04:30:39.527393Z",
     "shell.execute_reply": "2025-06-11T04:30:39.526795Z",
     "shell.execute_reply.started": "2025-06-11T04:30:39.522843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan_store_code_locations = working_combined_tq[working_combined_tq['store_code'].isna()]['Business Location'].unique().tolist()\n",
    "print(nan_store_code_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abe6c6cf-b9fd-40bd-8a40-7762d3a92695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:42.283728Z",
     "iopub.status.busy": "2025-06-11T04:30:42.283418Z",
     "iopub.status.idle": "2025-06-11T04:30:42.289219Z",
     "shell.execute_reply": "2025-06-11T04:30:42.288705Z",
     "shell.execute_reply.started": "2025-06-11T04:30:42.283708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating the dictionary for avg_rating\n",
    "store_code_to_avg_rating = {\n",
    "                            \"XSL\" : 4.9,\n",
    "                            \"XDT\" : 4.9,\n",
    "                            \"XDS\" : 4.9,\n",
    "                            \"XDF\" : 5,\n",
    "                            \"XDK\" : 4.9,\n",
    "                            \"XDM\" : 4.9,\n",
    "                            \"XDJ\" : 4.9,\n",
    "                            \"XDB\" : 4.9,\n",
    "                            \"XAH\" : 5,\n",
    "                            \"XQD\" : 4.9,\n",
    "                            \"XOM\" : 4.7,\n",
    "                            \"XQF\" : 4.9,\n",
    "                            \"XDG\" : 5,\n",
    "                            \"XSR\" : 5,\n",
    "                            \"XDX\" : 4.9,\n",
    "                            \"XAW\" : 5,\n",
    "                            \"XTD\" : 4.9,\n",
    "                            \"XCG\" : 4.8,\n",
    "                            \"XNJ\" : 4.7,\n",
    "                            \"XTH\" : 4.8,\n",
    "                            \"XAC\" : 4.9,\n",
    "                            \"XWS\" : 4.8,\n",
    "                            \"XBA\" : 4.5\n",
    "                            }\n",
    "\n",
    "working_combined_tq['Total Score'] = working_combined_tq['store_code'].map(store_code_to_avg_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d962a1c3-124f-489a-9dce-0c0037477d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:43.242983Z",
     "iopub.status.busy": "2025-06-11T04:30:43.242386Z",
     "iopub.status.idle": "2025-06-11T04:30:43.247265Z",
     "shell.execute_reply": "2025-06-11T04:30:43.246751Z",
     "shell.execute_reply.started": "2025-06-11T04:30:43.242948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.9, 5.0, 4.7, 4.8, 4.5]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_combined_tq['Total Score'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5eeb9d5-5f3d-4f8c-bcfd-b5bcd1031f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:44.302892Z",
     "iopub.status.busy": "2025-06-11T04:30:44.302553Z",
     "iopub.status.idle": "2025-06-11T04:30:44.310823Z",
     "shell.execute_reply": "2025-06-11T04:30:44.310336Z",
     "shell.execute_reply.started": "2025-06-11T04:30:44.302868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract year and month\n",
    "working_combined_tq['Date'] = pd.to_datetime(working_combined_tq['Date'])\n",
    "working_combined_tq['year'] = working_combined_tq['Date'].dt.year\n",
    "working_combined_tq['month'] = working_combined_tq['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b7e8afe-bf61-417b-8758-97bceeed8e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:45.383276Z",
     "iopub.status.busy": "2025-06-11T04:30:45.382740Z",
     "iopub.status.idle": "2025-06-11T04:30:45.388234Z",
     "shell.execute_reply": "2025-06-11T04:30:45.387669Z",
     "shell.execute_reply.started": "2025-06-11T04:30:45.383256Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dropping the repetitive columns\n",
    "working_combined_tq.drop(columns=['Business Location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "869d3ded-3950-4c16-9f4a-2a9684cdc998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:52.497850Z",
     "iopub.status.busy": "2025-06-11T04:30:52.497528Z",
     "iopub.status.idle": "2025-06-11T04:30:52.501878Z",
     "shell.execute_reply": "2025-06-11T04:30:52.501393Z",
     "shell.execute_reply.started": "2025-06-11T04:30:52.497830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Screenname', 'Content', 'Date', 'Ratings', 'store_name', 'store_code',\n",
       "       'Total Score', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_combined_tq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d304c8f-4c69-46a3-9a0e-73552f968efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:53.403655Z",
     "iopub.status.busy": "2025-06-11T04:30:53.403332Z",
     "iopub.status.idle": "2025-06-11T04:30:53.407291Z",
     "shell.execute_reply": "2025-06-11T04:30:53.406794Z",
     "shell.execute_reply.started": "2025-06-11T04:30:53.403633Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dictionary mapping to standard column names in rest of the code\n",
    "std_column_names_tq = {\n",
    "                        'Screenname': 'Name',\n",
    "                        'Content': 'review_text',\n",
    "                        'Date': 'Published At Date',\n",
    "                        'Ratings': 'Stars',\n",
    "                        'store_name':'Store Name',\n",
    "                        'Total Score':'Total Score',\n",
    "                        'store_code':'Store Code Cleaned',\n",
    "                        'year':'year', \n",
    "                        'month':'month'\n",
    "                    }\n",
    "\n",
    "\n",
    "#Renaming the columns\n",
    "working_combined_tq.rename(columns=std_column_names_tq, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8372dea9-ed15-438e-b730-4570b2556f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:30:58.503577Z",
     "iopub.status.busy": "2025-06-11T04:30:58.503257Z",
     "iopub.status.idle": "2025-06-11T04:30:58.510633Z",
     "shell.execute_reply": "2025-06-11T04:30:58.510044Z",
     "shell.execute_reply.started": "2025-06-11T04:30:58.503556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store Code Cleaned\n",
       "XAC    4.9\n",
       "XAH    5.0\n",
       "XAW    5.0\n",
       "XBA    4.5\n",
       "XCG    4.8\n",
       "XDB    4.9\n",
       "XDF    5.0\n",
       "XDG    5.0\n",
       "XDJ    4.9\n",
       "XDK    4.9\n",
       "XDM    4.9\n",
       "XDS    4.9\n",
       "XDT    4.9\n",
       "XDX    4.9\n",
       "XNJ    4.7\n",
       "XOM    4.7\n",
       "XQD    4.9\n",
       "XQF    4.9\n",
       "XSL    4.9\n",
       "XSR    5.0\n",
       "XTD    4.9\n",
       "XTH    4.8\n",
       "XWS    4.8\n",
       "Name: Total Score, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_combined_tq.groupby('Store Code Cleaned')['Total Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca6763d0-ad7f-4d90-9fe0-2da1ec30bfee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:06.543118Z",
     "iopub.status.busy": "2025-06-11T04:31:06.542792Z",
     "iopub.status.idle": "2025-06-11T04:31:08.085265Z",
     "shell.execute_reply": "2025-06-11T04:31:08.084676Z",
     "shell.execute_reply.started": "2025-06-11T04:31:06.543097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Remove timezone to make datetime timezone-naive\n",
    "working_combined_tq['Published At Date'] = working_combined_tq['Published At Date'].dt.tz_localize(None)\n",
    "\n",
    "#Now save to Excel\n",
    "working_combined_tq.to_excel(\"temp/raw_file_combined_tq.xlsx\", index=False)\n",
    "\n",
    "print(\"File saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c4f74-9826-4337-9709-04e714dbb4b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combining Tanishq & Competitor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0814a31-57c3-4800-9736-2691ff8fdfc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:12.043040Z",
     "iopub.status.busy": "2025-06-11T04:31:12.042709Z",
     "iopub.status.idle": "2025-06-11T04:31:12.047074Z",
     "shell.execute_reply": "2025-06-11T04:31:12.046602Z",
     "shell.execute_reply.started": "2025-06-11T04:31:12.043020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'review_text', 'Published At Date', 'Stars', 'Store Name',\n",
       "       'Store Code Cleaned', 'Total Score', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_combined_tq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33d008fa-ad4a-4823-b669-0fe3a1ccdfb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:13.362967Z",
     "iopub.status.busy": "2025-06-11T04:31:13.362658Z",
     "iopub.status.idle": "2025-06-11T04:31:13.367190Z",
     "shell.execute_reply": "2025-06-11T04:31:13.366640Z",
     "shell.execute_reply.started": "2025-06-11T04:31:13.362946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Published At Date', 'Stars', 'Total Score', 'Store Name',\n",
       "       'review_text', 'year', 'month', 'Store Code Cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_competitors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7324c11-1ca8-4f32-a34b-0dfac16938d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:15.023131Z",
     "iopub.status.busy": "2025-06-11T04:31:15.022773Z",
     "iopub.status.idle": "2025-06-11T04:31:15.028808Z",
     "shell.execute_reply": "2025-06-11T04:31:15.028332Z",
     "shell.execute_reply.started": "2025-06-11T04:31:15.023109Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "combined_df = pd.concat([working_combined_tq, combined_df_competitors], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dba29297-5cd9-45e0-b68d-0b78b5ea97a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:16.023428Z",
     "iopub.status.busy": "2025-06-11T04:31:16.023120Z",
     "iopub.status.idle": "2025-06-11T04:31:16.030627Z",
     "shell.execute_reply": "2025-06-11T04:31:16.029992Z",
     "shell.execute_reply.started": "2025-06-11T04:31:16.023409Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Desired column order\n",
    "desired_order = ['Store Name', 'Name', 'Published At Date', 'Stars', 'Total Score',\n",
    "                 'year', 'month', 'review_text','Store Code Cleaned']\n",
    "#Reordering the columns\n",
    "combined_df = combined_df[desired_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3336ed7e-c25d-4433-96c2-5888660021bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:17.288581Z",
     "iopub.status.busy": "2025-06-11T04:31:17.288265Z",
     "iopub.status.idle": "2025-06-11T04:31:17.297541Z",
     "shell.execute_reply": "2025-06-11T04:31:17.296982Z",
     "shell.execute_reply.started": "2025-06-11T04:31:17.288560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>Published At Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>review_text</th>\n",
       "      <th>Store Code Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Sharjah Central, SH</td>\n",
       "      <td>Santhoshkumar Sathian</td>\n",
       "      <td>2024-04-09 17:55:36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>So happy with good services specially Mrs chai...</td>\n",
       "      <td>XSL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Store Name                   Name  \\\n",
       "0  Tanishq Jewellers-Sharjah Central, SH  Santhoshkumar Sathian   \n",
       "\n",
       "    Published At Date  Stars  Total Score  year  month  \\\n",
       "0 2024-04-09 17:55:36    5.0          4.9  2024      4   \n",
       "\n",
       "                                         review_text Store Code Cleaned  \n",
       "0  So happy with good services specially Mrs chai...                XSL  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f53df277-f897-4a83-95b4-99c0003ad59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:20.503539Z",
     "iopub.status.busy": "2025-06-11T04:31:20.503230Z",
     "iopub.status.idle": "2025-06-11T04:31:23.421377Z",
     "shell.execute_reply": "2025-06-11T04:31:23.420748Z",
     "shell.execute_reply.started": "2025-06-11T04:31:20.503520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Remove timezone to make datetime timezone-naive\n",
    "# working_combined_tq['Published At Date'] = working_combined_tq['Published At Date'].dt.tz_localize(None)\n",
    "\n",
    "#Now save to Excel\n",
    "combined_df.to_excel(\"temp/raw_file_combined.xlsx\", index=False)\n",
    "\n",
    "print(\"File saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd4fba-613d-4967-820c-e8010965a230",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa668c-2ea3-401d-b93b-aef63149784f",
   "metadata": {},
   "source": [
    "> There are certain stores that are not considered due to non availability of tangible data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f585206e-5c61-4ec9-9307-5dad6ae05fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:31.982295Z",
     "iopub.status.busy": "2025-06-11T04:31:31.981975Z",
     "iopub.status.idle": "2025-06-11T04:31:31.988521Z",
     "shell.execute_reply": "2025-06-11T04:31:31.987895Z",
     "shell.execute_reply.started": "2025-06-11T04:31:31.982274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Store Name'].unique().tolist()\n",
    "combined_df['Store Name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2bbded7-fa89-40e3-9f42-68cb0daac25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:32.502876Z",
     "iopub.status.busy": "2025-06-11T04:31:32.502518Z",
     "iopub.status.idle": "2025-06-11T04:31:32.508836Z",
     "shell.execute_reply": "2025-06-11T04:31:32.508338Z",
     "shell.execute_reply.started": "2025-06-11T04:31:32.502855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Store Code Cleaned'].unique().tolist()\n",
    "combined_df['Store Code Cleaned'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9e84a8e-b780-415b-85dc-2642869a2939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:32.703564Z",
     "iopub.status.busy": "2025-06-11T04:31:32.703252Z",
     "iopub.status.idle": "2025-06-11T04:31:32.708662Z",
     "shell.execute_reply": "2025-06-11T04:31:32.708168Z",
     "shell.execute_reply.started": "2025-06-11T04:31:32.703543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Store Name'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59ef4484-432e-4878-8635-8c1b89eb9489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:33.163247Z",
     "iopub.status.busy": "2025-06-11T04:31:33.162926Z",
     "iopub.status.idle": "2025-06-11T04:31:33.169325Z",
     "shell.execute_reply": "2025-06-11T04:31:33.168856Z",
     "shell.execute_reply.started": "2025-06-11T04:31:33.163224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tanishq Jewellers-Sharjah Central, SH',\n",
       " 'Tanishq Jewellers-Taj, DB',\n",
       " 'Tanishq Jewellers-Silicon Central, DB',\n",
       " 'Tanishq Jewellers-Al Fahidi, DB',\n",
       " 'Tanishq Jewellers-Al Karama, DB',\n",
       " 'Tanishq Jewellers-Meena Bazar, DB',\n",
       " 'Mia-Burjuman, DB',\n",
       " 'Tanishq Jewellers-Al Barsha, DB',\n",
       " 'Tanishq Jewellers-Hamdan Bin Mohammed Street, AD',\n",
       " 'Tanishq Jewellers-Lulu Hypermarket, QA',\n",
       " 'Tanishq Jewellers-Avenues Mall, OM',\n",
       " 'Tanishq Jewellers-Festival City, QA',\n",
       " 'Tanishq Jewellers-Gold Souk, DB',\n",
       " 'Tanishq Jewellers-Rolla, SH',\n",
       " 'Tanishq Jewellers-UW Mall Al Mankhool, DB',\n",
       " 'Mia-Al Wahda Mall, AD',\n",
       " 'Tanishq-Frisco, TX',\n",
       " 'Tanishq-Chicago, IL',\n",
       " 'Tanishq-New Jersey, NJ',\n",
       " 'Tanishq-Houston, TX',\n",
       " 'Tanishq-Atlanta, GA',\n",
       " 'Tanishq-Redmond Seattle, WA',\n",
       " 'Tanishq-Santa Clara, CA',\n",
       " 'Joyalukkas Jewellery - Shabia - Abu Dhabi',\n",
       " 'Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed',\n",
       " 'Malabar Gold & Diamonds-Naperville, IL',\n",
       " 'Sona Jewelers-Iselin, NJ',\n",
       " 'Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi',\n",
       " 'Malabar Gold & Diamonds-Chicago, IL',\n",
       " 'Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi',\n",
       " 'Tiffany & Co-Northbrook, IL',\n",
       " 'Jared-Lombard, IL',\n",
       " 'Bhima Jewellers - Al Karama',\n",
       " 'Malabar Gold and Diamonds - Al Barsha - Dubai',\n",
       " 'Malabar Gold and Diamonds - Hamdan Street ( Branch 1)',\n",
       " 'Jared-Schaumburg, IL',\n",
       " 'Tiffany & Co-Chicago, IL',\n",
       " 'Tiffany & Co-Richmond, VA',\n",
       " 'Malabar Gold and Diamonds - Meena Bazar - Dubai',\n",
       " 'Tiffany & Co-Skokie, IL',\n",
       " 'Joyalukkas Jewellery-Chicago, IL',\n",
       " 'Mint Jewels - Al Karama',\n",
       " 'Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)',\n",
       " 'May Jewelers-Vienna, VA',\n",
       " 'Tiffany & Co-Red Bank, NJ',\n",
       " 'Kanz Jewellers',\n",
       " 'Malabar Gold & Diamonds - Silicon Oasis Central',\n",
       " 'Malani Jewellers-Richardson, TX',\n",
       " 'Malabar Gold and Diamonds - Al Karama - Dubai',\n",
       " 'Bhindi Jewellers-Decatur, GA',\n",
       " 'Joyalukkas Jewellery-Frisco, TX',\n",
       " 'Tiffany & Co-East Rutherford, NJ',\n",
       " 'Jared-Bolingbrook, IL',\n",
       " 'Joyalukkas Jewellery - Al Barsha',\n",
       " 'Jared-Vernon Hills, IL',\n",
       " 'Joyalukkas Jewellery - Al Karama',\n",
       " 'Malabar Gold and Diamonds - Shabia Musaffah',\n",
       " 'Malabar Gold & Diamonds-Iselin, NJ',\n",
       " 'Joyalukkas Jewellery - Al Fahidi st - Al Fahidi',\n",
       " 'Tiffany & Co-Short Hills, NJ',\n",
       " 'Meena Jewellers - Meena Bazar',\n",
       " 'Joyalukkas Jewellery-Houston, TX',\n",
       " 'Tiffany & Co-Hackensack, NJ',\n",
       " 'Malabar Gold and Diamonds - Hamdan Street (Branch 2)',\n",
       " 'Malabar Gold & Diamonds-Frisco, TX',\n",
       " 'Jared-Aurora, IL',\n",
       " 'Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)',\n",
       " 'Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)',\n",
       " 'Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi',\n",
       " 'Tiffany & Co-Vienna, VA',\n",
       " 'VBJ Jewellers-Frisco, TX',\n",
       " 'Joyalukkas Jewellery-Suwanee, GA',\n",
       " 'Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi',\n",
       " 'Jared-Algonquin, IL',\n",
       " 'Jared-Orland Park, IL']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Store Name'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0d0710c-330f-4e6b-9bfb-eb4149e6086e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:33.433676Z",
     "iopub.status.busy": "2025-06-11T04:31:33.433382Z",
     "iopub.status.idle": "2025-06-11T04:31:33.439797Z",
     "shell.execute_reply": "2025-06-11T04:31:33.439255Z",
     "shell.execute_reply.started": "2025-06-11T04:31:33.433657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create individual dataframes \n",
    "mappings = {\"agd_mb\" : \"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)\",\n",
    "            \"bhi_ak\" : \"Bhima Jewellers - Al Karama\",\n",
    "            \"bhi_dec_ga\" : \"Bhindi Jewellers-Decatur, GA\",\n",
    "            \"eve_joh_ga\" : \"Evermark Jewelry-Johns Creek, GA\",\n",
    "            \"jar_alg_il\" : \"Jared-Algonquin, IL\",\n",
    "            \"jar_aur_il\" : \"Jared-Aurora, IL\",\n",
    "            \"jar_bol_il\" : \"Jared-Bolingbrook, IL\",\n",
    "            \"jar_lom_il\" : \"Jared-Lombard, IL\",\n",
    "            \"jar_orl_il\" : \"Jared-Orland Park, IL\",\n",
    "            \"jar_sch_il\" : \"Jared-Schaumburg, IL\",\n",
    "            \"jar_ver_il\" : \"Jared-Vernon Hills, IL\",\n",
    "            \"joy_ab\" : \"Joyalukkas Jewellery - Al Barsha\",\n",
    "            \"joy_ak\" : \"Joyalukkas Jewellery - Al Karama\",\n",
    "            \"joy_chi_il\" : \"Joyalukkas Jewellery-Chicago, IL\",\n",
    "            \"joy_dm_ad\" : \"Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi\",\n",
    "            \"joy_fri_tx\" : \"Joyalukkas Jewellery-Frisco, TX\",\n",
    "            \"joy_hou_tx\" : \"Joyalukkas Jewellery-Houston, TX\",\n",
    "            \"joy_mz_ad\" : \"Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi\",\n",
    "            \"joy_sh_ad\" : \"Joyalukkas Jewellery - Shabia - Abu Dhabi\",\n",
    "            \"joy_st_af\" : \"Joyalukkas Jewellery - Al Fahidi st - Al Fahidi\",\n",
    "            \"joy_suw_ga\" : \"Joyalukkas Jewellery-Suwanee, GA\",\n",
    "            \"kan_mb\" : \"Kanz Jewellers\",\n",
    "            \"mal_ab\" : \"Malabar Gold and Diamonds - Al Barsha - Dubai\",\n",
    "            \"mal_ak\" : \"Malabar Gold and Diamonds - Al Karama - Dubai\",\n",
    "            \"mal_aw_ad\" : \"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi\",\n",
    "            \"mal_b1_ad\" : \"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)\",\n",
    "            \"mal_b1_af\" : \"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)\",\n",
    "            \"mal_b2_ad\" : \"Malabar Gold and Diamonds - Hamdan Street (Branch 2)\",\n",
    "            \"mal_b2_af\" : \"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)\",\n",
    "            \"mal_chi_il\" : \"Malabar Gold & Diamonds-Chicago, IL\",\n",
    "            \"mal_dm_ad\" : \"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi\",\n",
    "            \"mal_fri_tx\" : \"Malabar Gold & Diamonds-Frisco, TX\",\n",
    "            \"mal_ise_nj\" : \"Malabar Gold & Diamonds-Iselin, NJ\",\n",
    "            \"mal_lu_ad\" : \"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed\",\n",
    "            \"mal_mb\" : \"Malabar Gold and Diamonds - Meena Bazar - Dubai\",\n",
    "            \"mal_nap_il\" : \"Malabar Gold & Diamonds-Naperville, IL\",\n",
    "            \"mal_ric_tx\" : \"Malani Jewellers-Richardson, TX\",\n",
    "            \"mal_sc\" : \"Malabar Gold & Diamonds - Silicon Oasis Central\",\n",
    "            \"mal_sh_ad\" : \"Malabar Gold and Diamonds - Shabia Musaffah\",\n",
    "            \"may_vie_va\" : \"May Jewelers-Vienna, VA\",\n",
    "            \"mia_awm_ad\" : \"Mia-Al Wahda Mall, AD\",\n",
    "            \"mia_bur_db\" : \"Mia-Burjuman, DB\",\n",
    "            \"min_ak\" : \"Mint Jewels - Al Karama\",\n",
    "            \"mna_mb\" : \"Meena Jewellers - Meena Bazar\",\n",
    "            \"son_ise_nj\" : \"Sona Jewelers-Iselin, NJ\",\n",
    "            \"tan_am_om\" : \"Tanishq Jewellers-Avenues Mall, OM\",\n",
    "            \"tan_atl_ga\" : \"Tanishq-Atlanta, GA\",\n",
    "            \"tan_bar_db\" : \"Tanishq Jewellers-Al Barsha, DB\",\n",
    "            \"tan_chi_il\" : \"Tanishq-Chicago, IL\",\n",
    "            \"tan_fah_db\" : \"Tanishq Jewellers-Al Fahidi, DB\",\n",
    "            \"tan_fc_qa\" : \"Tanishq Jewellers-Festival City, QA\",\n",
    "            \"tan_fri_tx\" : \"Tanishq-Frisco, TX\",\n",
    "            \"tan_gs_db\" : \"Tanishq Jewellers-Gold Souk, DB\",\n",
    "            \"tan_ham_ad\" : \"Tanishq Jewellers-Hamdan Bin Mohammed Street, AD\",\n",
    "            \"tan_hou_tx\" : \"Tanishq-Houston, TX\",\n",
    "            \"tan_kar_db\" : \"Tanishq Jewellers-Al Karama, DB\",\n",
    "            \"tan_lul_qa\" : \"Tanishq Jewellers-Lulu Hypermarket, QA\",\n",
    "            \"tan_mank_db\" : \"Tanishq Jewellers-UW Mall Al Mankhool, DB\",\n",
    "            \"tan_mee_db\" : \"Tanishq Jewellers-Meena Bazar, DB\",\n",
    "            \"tan_new_nj\" : \"Tanishq-New Jersey, NJ\",\n",
    "            \"tan_rol_sh\" : \"Tanishq Jewellers-Rolla, SH\",\n",
    "            \"tan_rse_wa\" : \"Tanishq-Redmond Seattle, WA\",\n",
    "            \"tan_sc_ca\" : \"Tanishq-Santa Clara, CA\",\n",
    "            \"tan_sc_sh\" : \"Tanishq Jewellers-Sharjah Central, SH\",\n",
    "            \"tan_sil_db\" : \"Tanishq Jewellers-Silicon Central, DB\",\n",
    "            \"tan_taj_db\" : \"Tanishq Jewellers-Taj, DB\",\n",
    "            \"tif_chi_il\" : \"Tiffany & Co-Chicago, IL\",\n",
    "            \"tif_eas_nj\" : \"Tiffany & Co-East Rutherford, NJ\",\n",
    "            \"tif_hac_nj\" : \"Tiffany & Co-Hackensack, NJ\",\n",
    "            \"tif_nor_il\" : \"Tiffany & Co-Northbrook, IL\",\n",
    "            \"tif_par_nj\" : \"Tiffany & Co-Paramus, NJ\",\n",
    "            \"tif_red_nj\" : \"Tiffany & Co-Red Bank, NJ\",\n",
    "            \"tif_ric_va\" : \"Tiffany & Co-Richmond, VA\",\n",
    "            \"tif_sho_nj\" : \"Tiffany & Co-Short Hills, NJ\",\n",
    "            \"tif_sko_il\" : \"Tiffany & Co-Skokie, IL\",\n",
    "            \"tif_vie_va\" : \"Tiffany & Co-Vienna, VA\",\n",
    "            \"vbj_fri_tx\" : \"VBJ Jewellers-Frisco, TX\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0bc65ac3-3748-4ecf-871e-63486b7059b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:33.908888Z",
     "iopub.status.busy": "2025-06-11T04:31:33.908573Z",
     "iopub.status.idle": "2025-06-11T04:31:34.051603Z",
     "shell.execute_reply": "2025-06-11T04:31:34.050947Z",
     "shell.execute_reply.started": "2025-06-11T04:31:33.908868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty dictionary to store your dataframes\n",
    "dataframes = {}\n",
    "\n",
    "#Loop through the mappings and filter combined_df_21to23 for each title\n",
    "for df_name, title in mappings.items():\n",
    "    filtered_df = combined_df[combined_df['Store Name'] == title].reset_index(drop=True)\n",
    "    dataframes[df_name] = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc480dfb-84b9-471d-9ee4-5d9744455e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:34.202831Z",
     "iopub.status.busy": "2025-06-11T04:31:34.202521Z",
     "iopub.status.idle": "2025-06-11T04:31:34.206824Z",
     "shell.execute_reply": "2025-06-11T04:31:34.206285Z",
     "shell.execute_reply.started": "2025-06-11T04:31:34.202810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "845295ec-a6e2-4158-9f5a-7f5c0d638967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:34.603136Z",
     "iopub.status.busy": "2025-06-11T04:31:34.602825Z",
     "iopub.status.idle": "2025-06-11T04:31:34.669465Z",
     "shell.execute_reply": "2025-06-11T04:31:34.668984Z",
     "shell.execute_reply.started": "2025-06-11T04:31:34.603117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize two new dictionaries to store the non-null and null dataframes\n",
    "nonnull_dataframes = {}\n",
    "null_dataframes = {}\n",
    "\n",
    "#Loop through the previously created 'dataframes' dictionary\n",
    "for df_name, df in dataframes.items():\n",
    "    #Filter the dataframe for non-null 'review_text' and reset the index\n",
    "    nonnull_dataframes[f\"{df_name}_nonnull\"] = df[df['review_text'].notnull()].reset_index(drop=True)\n",
    "    \n",
    "    #Filter the dataframe for null 'review_text' and reset the index\n",
    "    null_dataframes[f\"{df_name}_null\"] = df[df['review_text'].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c7ccc253-37d2-4a54-b5f3-8479e31b50ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:36.103018Z",
     "iopub.status.busy": "2025-06-11T04:31:36.102697Z",
     "iopub.status.idle": "2025-06-11T04:31:36.176667Z",
     "shell.execute_reply": "2025-06-11T04:31:36.176157Z",
     "shell.execute_reply.started": "2025-06-11T04:31:36.102999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df_name, df in nonnull_dataframes.items():\n",
    "    # Filter the dataframe for non-null 'review_text' and reset the index\n",
    "    nonnull_dataframes[df_name]['word_count'] = nonnull_dataframes[df_name]['review_text'].apply(word_count)\n",
    "    nonnull_dataframes[df_name]['count_buckets'] = nonnull_dataframes[df_name]['word_count'].apply(categorize_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "181bb8dd-34cd-4dbe-86cd-4ba71dccd43a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:39.054328Z",
     "iopub.status.busy": "2025-06-11T04:31:39.053902Z",
     "iopub.status.idle": "2025-06-11T04:31:39.060848Z",
     "shell.execute_reply": "2025-06-11T04:31:39.060290Z",
     "shell.execute_reply.started": "2025-06-11T04:31:39.054309Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define bucket ranges\n",
    "buckets = ['1-4', '5-15', '16-30', '31-60', '61-100', '>100']\n",
    "\n",
    "agd_mb_nonnull_buckets = {}\n",
    "bhi_ak_nonnull_buckets = {}\n",
    "bhi_dec_ga_nonnull_buckets = {}\n",
    "jar_alg_il_nonnull_buckets = {}\n",
    "jar_aur_il_nonnull_buckets = {}\n",
    "jar_bol_il_nonnull_buckets = {}\n",
    "jar_lom_il_nonnull_buckets = {}\n",
    "jar_orl_il_nonnull_buckets = {}\n",
    "jar_sch_il_nonnull_buckets = {}\n",
    "jar_ver_il_nonnull_buckets = {}\n",
    "joy_ab_nonnull_buckets = {}\n",
    "joy_st_af_nonnull_buckets = {}\n",
    "joy_ak_nonnull_buckets = {}\n",
    "joy_dm_ad_nonnull_buckets = {}\n",
    "joy_mz_ad_nonnull_buckets = {}\n",
    "joy_sh_ad_nonnull_buckets = {}\n",
    "joy_chi_il_nonnull_buckets = {}\n",
    "joy_fri_tx_nonnull_buckets = {}\n",
    "joy_hou_tx_nonnull_buckets = {}\n",
    "joy_suw_ga_nonnull_buckets = {}\n",
    "kan_mb_nonnull_buckets = {}\n",
    "mal_sc_nonnull_buckets = {}\n",
    "mal_chi_il_nonnull_buckets = {}\n",
    "mal_fri_tx_nonnull_buckets = {}\n",
    "mal_ise_nj_nonnull_buckets = {}\n",
    "mal_nap_il_nonnull_buckets = {}\n",
    "mal_ab_nonnull_buckets = {}\n",
    "mal_b1_af_nonnull_buckets = {}\n",
    "mal_ak_nonnull_buckets = {}\n",
    "mal_aw_ad_nonnull_buckets = {}\n",
    "mal_dm_ad_nonnull_buckets = {}\n",
    "mal_b1_ad_nonnull_buckets = {}\n",
    "mal_b2_ad_nonnull_buckets = {}\n",
    "mal_lu_ad_nonnull_buckets = {}\n",
    "mal_mb_nonnull_buckets = {}\n",
    "mal_sh_ad_nonnull_buckets = {}\n",
    "mal_b2_af_nonnull_buckets = {}\n",
    "mal_ric_tx_nonnull_buckets = {}\n",
    "may_vie_va_nonnull_buckets = {}\n",
    "mna_mb_nonnull_buckets = {}\n",
    "mia_awm_ad_nonnull_buckets = {}\n",
    "mia_bur_db_nonnull_buckets = {}\n",
    "min_ak_nonnull_buckets = {}\n",
    "son_ise_nj_nonnull_buckets = {}\n",
    "tan_bar_db_nonnull_buckets = {}\n",
    "tan_fah_db_nonnull_buckets = {}\n",
    "tan_kar_db_nonnull_buckets = {}\n",
    "tan_am_om_nonnull_buckets = {}\n",
    "tan_fc_qa_nonnull_buckets = {}\n",
    "tan_gs_db_nonnull_buckets = {}\n",
    "tan_ham_ad_nonnull_buckets = {}\n",
    "tan_lul_qa_nonnull_buckets = {}\n",
    "tan_mee_db_nonnull_buckets = {}\n",
    "tan_rol_sh_nonnull_buckets = {}\n",
    "tan_sc_sh_nonnull_buckets = {}\n",
    "tan_sil_db_nonnull_buckets = {}\n",
    "tan_taj_db_nonnull_buckets = {}\n",
    "tan_mank_db_nonnull_buckets = {}\n",
    "tan_atl_ga_nonnull_buckets = {}\n",
    "tan_chi_il_nonnull_buckets = {}\n",
    "tan_fri_tx_nonnull_buckets = {}\n",
    "tan_hou_tx_nonnull_buckets = {}\n",
    "tan_new_nj_nonnull_buckets = {}\n",
    "tan_rse_wa_nonnull_buckets = {}\n",
    "tan_sc_ca_nonnull_buckets = {}\n",
    "tif_chi_il_nonnull_buckets = {}\n",
    "tif_eas_nj_nonnull_buckets = {}\n",
    "tif_hac_nj_nonnull_buckets = {}\n",
    "tif_nor_il_nonnull_buckets = {}\n",
    "tif_red_nj_nonnull_buckets = {}\n",
    "tif_ric_va_nonnull_buckets = {}\n",
    "tif_sho_nj_nonnull_buckets = {}\n",
    "tif_sko_il_nonnull_buckets = {}\n",
    "tif_vie_va_nonnull_buckets = {}\n",
    "vbj_fri_tx_nonnull_buckets = {}\n",
    "tif_par_nj_nonnull_buckets = {}\n",
    "eve_joh_ga_nonnull_buckets = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80cae72c-facd-48fd-9f6c-c1608db3204f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:40.659083Z",
     "iopub.status.busy": "2025-06-11T04:31:40.658773Z",
     "iopub.status.idle": "2025-06-11T04:31:40.948795Z",
     "shell.execute_reply": "2025-06-11T04:31:40.948188Z",
     "shell.execute_reply.started": "2025-06-11T04:31:40.659063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define bucket ranges\n",
    "buckets = ['1-4', '5-15', '16-30', '31-60', '61-100', '>100']\n",
    "\n",
    "#Loop through the bucket ranges and create DataFrames\n",
    "for bucket in buckets:\n",
    "    agd_mb_filtered_df = nonnull_dataframes['agd_mb_nonnull'][nonnull_dataframes['agd_mb_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    bhi_ak_filtered_df = nonnull_dataframes['bhi_ak_nonnull'][nonnull_dataframes['bhi_ak_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    bhi_dec_ga_filtered_df = nonnull_dataframes['bhi_dec_ga_nonnull'][nonnull_dataframes['bhi_dec_ga_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    jar_alg_il_filtered_df = nonnull_dataframes['jar_alg_il_nonnull'][nonnull_dataframes['jar_alg_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    jar_aur_il_filtered_df = nonnull_dataframes['jar_aur_il_nonnull'][nonnull_dataframes['jar_aur_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    jar_bol_il_filtered_df = nonnull_dataframes['jar_bol_il_nonnull'][nonnull_dataframes['jar_bol_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    jar_lom_il_filtered_df = nonnull_dataframes['jar_lom_il_nonnull'][nonnull_dataframes['jar_lom_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    jar_orl_il_filtered_df = nonnull_dataframes['jar_orl_il_nonnull'][nonnull_dataframes['jar_orl_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    jar_sch_il_filtered_df = nonnull_dataframes['jar_sch_il_nonnull'][nonnull_dataframes['jar_sch_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    jar_ver_il_filtered_df = nonnull_dataframes['jar_ver_il_nonnull'][nonnull_dataframes['jar_ver_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_ab_filtered_df = nonnull_dataframes['joy_ab_nonnull'][nonnull_dataframes['joy_ab_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_st_af_filtered_df = nonnull_dataframes['joy_st_af_nonnull'][nonnull_dataframes['joy_st_af_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_ak_filtered_df = nonnull_dataframes['joy_ak_nonnull'][nonnull_dataframes['joy_ak_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_dm_ad_filtered_df = nonnull_dataframes['joy_dm_ad_nonnull'][nonnull_dataframes['joy_dm_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_mz_ad_filtered_df = nonnull_dataframes['joy_mz_ad_nonnull'][nonnull_dataframes['joy_mz_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_sh_ad_filtered_df = nonnull_dataframes['joy_sh_ad_nonnull'][nonnull_dataframes['joy_sh_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_chi_il_filtered_df = nonnull_dataframes['joy_chi_il_nonnull'][nonnull_dataframes['joy_chi_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_fri_tx_filtered_df = nonnull_dataframes['joy_fri_tx_nonnull'][nonnull_dataframes['joy_fri_tx_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_hou_tx_filtered_df = nonnull_dataframes['joy_hou_tx_nonnull'][nonnull_dataframes['joy_hou_tx_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    joy_suw_ga_filtered_df = nonnull_dataframes['joy_suw_ga_nonnull'][nonnull_dataframes['joy_suw_ga_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    kan_mb_filtered_df = nonnull_dataframes['kan_mb_nonnull'][nonnull_dataframes['kan_mb_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_sc_filtered_df = nonnull_dataframes['mal_sc_nonnull'][nonnull_dataframes['mal_sc_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_chi_il_filtered_df = nonnull_dataframes['mal_chi_il_nonnull'][nonnull_dataframes['mal_chi_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_fri_tx_filtered_df = nonnull_dataframes['mal_fri_tx_nonnull'][nonnull_dataframes['mal_fri_tx_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_ise_nj_filtered_df = nonnull_dataframes['mal_ise_nj_nonnull'][nonnull_dataframes['mal_ise_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_nap_il_filtered_df = nonnull_dataframes['mal_nap_il_nonnull'][nonnull_dataframes['mal_nap_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_ab_filtered_df = nonnull_dataframes['mal_ab_nonnull'][nonnull_dataframes['mal_ab_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_b1_af_filtered_df = nonnull_dataframes['mal_b1_af_nonnull'][nonnull_dataframes['mal_b1_af_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_ak_filtered_df = nonnull_dataframes['mal_ak_nonnull'][nonnull_dataframes['mal_ak_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_aw_ad_filtered_df = nonnull_dataframes['mal_aw_ad_nonnull'][nonnull_dataframes['mal_aw_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_dm_ad_filtered_df = nonnull_dataframes['mal_dm_ad_nonnull'][nonnull_dataframes['mal_dm_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_b1_ad_filtered_df = nonnull_dataframes['mal_b1_ad_nonnull'][nonnull_dataframes['mal_b1_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_b2_ad_filtered_df = nonnull_dataframes['mal_b2_ad_nonnull'][nonnull_dataframes['mal_b2_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_lu_ad_filtered_df = nonnull_dataframes['mal_lu_ad_nonnull'][nonnull_dataframes['mal_lu_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_mb_filtered_df = nonnull_dataframes['mal_mb_nonnull'][nonnull_dataframes['mal_mb_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_sh_ad_filtered_df = nonnull_dataframes['mal_sh_ad_nonnull'][nonnull_dataframes['mal_sh_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_b2_af_filtered_df = nonnull_dataframes['mal_b2_af_nonnull'][nonnull_dataframes['mal_b2_af_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mal_ric_tx_filtered_df = nonnull_dataframes['mal_ric_tx_nonnull'][nonnull_dataframes['mal_ric_tx_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    may_vie_va_filtered_df = nonnull_dataframes['may_vie_va_nonnull'][nonnull_dataframes['may_vie_va_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mna_mb_filtered_df = nonnull_dataframes['mna_mb_nonnull'][nonnull_dataframes['mna_mb_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mia_awm_ad_filtered_df = nonnull_dataframes['mia_awm_ad_nonnull'][nonnull_dataframes['mia_awm_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    mia_bur_db_filtered_df = nonnull_dataframes['mia_bur_db_nonnull'][nonnull_dataframes['mia_bur_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    min_ak_filtered_df = nonnull_dataframes['min_ak_nonnull'][nonnull_dataframes['min_ak_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    son_ise_nj_filtered_df = nonnull_dataframes['son_ise_nj_nonnull'][nonnull_dataframes['son_ise_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_bar_db_filtered_df = nonnull_dataframes['tan_bar_db_nonnull'][nonnull_dataframes['tan_bar_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_fah_db_filtered_df = nonnull_dataframes['tan_fah_db_nonnull'][nonnull_dataframes['tan_fah_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_kar_db_filtered_df = nonnull_dataframes['tan_kar_db_nonnull'][nonnull_dataframes['tan_kar_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_am_om_filtered_df = nonnull_dataframes['tan_am_om_nonnull'][nonnull_dataframes['tan_am_om_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_fc_qa_filtered_df = nonnull_dataframes['tan_fc_qa_nonnull'][nonnull_dataframes['tan_fc_qa_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_gs_db_filtered_df = nonnull_dataframes['tan_gs_db_nonnull'][nonnull_dataframes['tan_gs_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_ham_ad_filtered_df = nonnull_dataframes['tan_ham_ad_nonnull'][nonnull_dataframes['tan_ham_ad_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_lul_qa_filtered_df = nonnull_dataframes['tan_lul_qa_nonnull'][nonnull_dataframes['tan_lul_qa_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_mee_db_filtered_df = nonnull_dataframes['tan_mee_db_nonnull'][nonnull_dataframes['tan_mee_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_rol_sh_filtered_df = nonnull_dataframes['tan_rol_sh_nonnull'][nonnull_dataframes['tan_rol_sh_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_sc_sh_filtered_df = nonnull_dataframes['tan_sc_sh_nonnull'][nonnull_dataframes['tan_sc_sh_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_sil_db_filtered_df = nonnull_dataframes['tan_sil_db_nonnull'][nonnull_dataframes['tan_sil_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_taj_db_filtered_df = nonnull_dataframes['tan_taj_db_nonnull'][nonnull_dataframes['tan_taj_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_mank_db_filtered_df = nonnull_dataframes['tan_mank_db_nonnull'][nonnull_dataframes['tan_mank_db_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_atl_ga_filtered_df = nonnull_dataframes['tan_atl_ga_nonnull'][nonnull_dataframes['tan_atl_ga_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_chi_il_filtered_df = nonnull_dataframes['tan_chi_il_nonnull'][nonnull_dataframes['tan_chi_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_fri_tx_filtered_df = nonnull_dataframes['tan_fri_tx_nonnull'][nonnull_dataframes['tan_fri_tx_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_hou_tx_filtered_df = nonnull_dataframes['tan_hou_tx_nonnull'][nonnull_dataframes['tan_hou_tx_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_new_nj_filtered_df = nonnull_dataframes['tan_new_nj_nonnull'][nonnull_dataframes['tan_new_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_rse_wa_filtered_df = nonnull_dataframes['tan_rse_wa_nonnull'][nonnull_dataframes['tan_rse_wa_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tan_sc_ca_filtered_df = nonnull_dataframes['tan_sc_ca_nonnull'][nonnull_dataframes['tan_sc_ca_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_chi_il_filtered_df = nonnull_dataframes['tif_chi_il_nonnull'][nonnull_dataframes['tif_chi_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_eas_nj_filtered_df = nonnull_dataframes['tif_eas_nj_nonnull'][nonnull_dataframes['tif_eas_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_hac_nj_filtered_df = nonnull_dataframes['tif_hac_nj_nonnull'][nonnull_dataframes['tif_hac_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_nor_il_filtered_df = nonnull_dataframes['tif_nor_il_nonnull'][nonnull_dataframes['tif_nor_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_red_nj_filtered_df = nonnull_dataframes['tif_red_nj_nonnull'][nonnull_dataframes['tif_red_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_ric_va_filtered_df = nonnull_dataframes['tif_ric_va_nonnull'][nonnull_dataframes['tif_ric_va_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_sho_nj_filtered_df = nonnull_dataframes['tif_sho_nj_nonnull'][nonnull_dataframes['tif_sho_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_sko_il_filtered_df = nonnull_dataframes['tif_sko_il_nonnull'][nonnull_dataframes['tif_sko_il_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_vie_va_filtered_df = nonnull_dataframes['tif_vie_va_nonnull'][nonnull_dataframes['tif_vie_va_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    vbj_fri_tx_filtered_df = nonnull_dataframes['vbj_fri_tx_nonnull'][nonnull_dataframes['vbj_fri_tx_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    tif_par_nj_filtered_df = nonnull_dataframes['tif_par_nj_nonnull'][nonnull_dataframes['tif_par_nj_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "    eve_joh_ga_filtered_df = nonnull_dataframes['eve_joh_ga_nonnull'][nonnull_dataframes['eve_joh_ga_nonnull']['count_buckets'] == bucket].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    agd_mb_nonnull_buckets[f'agd_mb_nonnull_{bucket.replace(\">\", \"greater_\")}'] = agd_mb_filtered_df\n",
    "    bhi_ak_nonnull_buckets[f'bhi_ak_nonnull_{bucket.replace(\">\", \"greater_\")}'] = bhi_ak_filtered_df\n",
    "    bhi_dec_ga_nonnull_buckets[f'bhi_dec_ga_nonnull_{bucket.replace(\">\", \"greater_\")}'] = bhi_dec_ga_filtered_df\n",
    "    jar_alg_il_nonnull_buckets[f'jar_alg_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = jar_alg_il_filtered_df\n",
    "    jar_aur_il_nonnull_buckets[f'jar_aur_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = jar_aur_il_filtered_df\n",
    "    jar_bol_il_nonnull_buckets[f'jar_bol_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = jar_bol_il_filtered_df\n",
    "    jar_lom_il_nonnull_buckets[f'jar_lom_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = jar_lom_il_filtered_df\n",
    "    jar_orl_il_nonnull_buckets[f'jar_orl_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = jar_orl_il_filtered_df\n",
    "    jar_sch_il_nonnull_buckets[f'jar_sch_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = jar_sch_il_filtered_df\n",
    "    jar_ver_il_nonnull_buckets[f'jar_ver_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = jar_ver_il_filtered_df\n",
    "    joy_ab_nonnull_buckets[f'joy_ab_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_ab_filtered_df\n",
    "    joy_st_af_nonnull_buckets[f'joy_st_af_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_st_af_filtered_df\n",
    "    joy_ak_nonnull_buckets[f'joy_ak_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_ak_filtered_df\n",
    "    joy_dm_ad_nonnull_buckets[f'joy_dm_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_dm_ad_filtered_df\n",
    "    joy_mz_ad_nonnull_buckets[f'joy_mz_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_mz_ad_filtered_df\n",
    "    joy_sh_ad_nonnull_buckets[f'joy_sh_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_sh_ad_filtered_df\n",
    "    joy_chi_il_nonnull_buckets[f'joy_chi_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_chi_il_filtered_df\n",
    "    joy_fri_tx_nonnull_buckets[f'joy_fri_tx_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_fri_tx_filtered_df\n",
    "    joy_hou_tx_nonnull_buckets[f'joy_hou_tx_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_hou_tx_filtered_df\n",
    "    joy_suw_ga_nonnull_buckets[f'joy_suw_ga_nonnull_{bucket.replace(\">\", \"greater_\")}'] = joy_suw_ga_filtered_df\n",
    "    kan_mb_nonnull_buckets[f'kan_mb_nonnull_{bucket.replace(\">\", \"greater_\")}'] = kan_mb_filtered_df\n",
    "    mal_sc_nonnull_buckets[f'mal_sc_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_sc_filtered_df\n",
    "    mal_chi_il_nonnull_buckets[f'mal_chi_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_chi_il_filtered_df\n",
    "    mal_fri_tx_nonnull_buckets[f'mal_fri_tx_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_fri_tx_filtered_df\n",
    "    mal_ise_nj_nonnull_buckets[f'mal_ise_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_ise_nj_filtered_df\n",
    "    mal_nap_il_nonnull_buckets[f'mal_nap_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_nap_il_filtered_df\n",
    "    mal_ab_nonnull_buckets[f'mal_ab_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_ab_filtered_df\n",
    "    mal_b1_af_nonnull_buckets[f'mal_b1_af_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_b1_af_filtered_df\n",
    "    mal_ak_nonnull_buckets[f'mal_ak_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_ak_filtered_df\n",
    "    mal_aw_ad_nonnull_buckets[f'mal_aw_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_aw_ad_filtered_df\n",
    "    mal_dm_ad_nonnull_buckets[f'mal_dm_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_dm_ad_filtered_df\n",
    "    mal_b1_ad_nonnull_buckets[f'mal_b1_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_b1_ad_filtered_df\n",
    "    mal_b2_ad_nonnull_buckets[f'mal_b2_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_b2_ad_filtered_df\n",
    "    mal_lu_ad_nonnull_buckets[f'mal_lu_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_lu_ad_filtered_df\n",
    "    mal_mb_nonnull_buckets[f'mal_mb_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_mb_filtered_df\n",
    "    mal_sh_ad_nonnull_buckets[f'mal_sh_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_sh_ad_filtered_df\n",
    "    mal_b2_af_nonnull_buckets[f'mal_b2_af_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_b2_af_filtered_df\n",
    "    mal_ric_tx_nonnull_buckets[f'mal_ric_tx_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mal_ric_tx_filtered_df\n",
    "    may_vie_va_nonnull_buckets[f'may_vie_va_nonnull_{bucket.replace(\">\", \"greater_\")}'] = may_vie_va_filtered_df\n",
    "    mna_mb_nonnull_buckets[f'mna_mb_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mna_mb_filtered_df\n",
    "    mia_awm_ad_nonnull_buckets[f'mia_awm_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mia_awm_ad_filtered_df\n",
    "    mia_bur_db_nonnull_buckets[f'mia_bur_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = mia_bur_db_filtered_df\n",
    "    min_ak_nonnull_buckets[f'min_ak_nonnull_{bucket.replace(\">\", \"greater_\")}'] = min_ak_filtered_df\n",
    "    son_ise_nj_nonnull_buckets[f'son_ise_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = son_ise_nj_filtered_df\n",
    "    tan_bar_db_nonnull_buckets[f'tan_bar_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_bar_db_filtered_df\n",
    "    tan_fah_db_nonnull_buckets[f'tan_fah_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_fah_db_filtered_df\n",
    "    tan_kar_db_nonnull_buckets[f'tan_kar_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_kar_db_filtered_df\n",
    "    tan_am_om_nonnull_buckets[f'tan_am_om_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_am_om_filtered_df\n",
    "    tan_fc_qa_nonnull_buckets[f'tan_fc_qa_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_fc_qa_filtered_df\n",
    "    tan_gs_db_nonnull_buckets[f'tan_gs_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_gs_db_filtered_df\n",
    "    tan_ham_ad_nonnull_buckets[f'tan_ham_ad_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_ham_ad_filtered_df\n",
    "    tan_lul_qa_nonnull_buckets[f'tan_lul_qa_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_lul_qa_filtered_df\n",
    "    tan_mee_db_nonnull_buckets[f'tan_mee_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_mee_db_filtered_df\n",
    "    tan_rol_sh_nonnull_buckets[f'tan_rol_sh_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_rol_sh_filtered_df\n",
    "    tan_sc_sh_nonnull_buckets[f'tan_sc_sh_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_sc_sh_filtered_df\n",
    "    tan_sil_db_nonnull_buckets[f'tan_sil_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_sil_db_filtered_df\n",
    "    tan_taj_db_nonnull_buckets[f'tan_taj_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_taj_db_filtered_df\n",
    "    tan_mank_db_nonnull_buckets[f'tan_mank_db_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_mank_db_filtered_df\n",
    "    tan_atl_ga_nonnull_buckets[f'tan_atl_ga_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_atl_ga_filtered_df\n",
    "    tan_chi_il_nonnull_buckets[f'tan_chi_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_chi_il_filtered_df\n",
    "    tan_fri_tx_nonnull_buckets[f'tan_fri_tx_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_fri_tx_filtered_df\n",
    "    tan_hou_tx_nonnull_buckets[f'tan_hou_tx_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_hou_tx_filtered_df\n",
    "    tan_new_nj_nonnull_buckets[f'tan_new_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_new_nj_filtered_df\n",
    "    tan_rse_wa_nonnull_buckets[f'tan_rse_wa_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_rse_wa_filtered_df\n",
    "    tan_sc_ca_nonnull_buckets[f'tan_sc_ca_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tan_sc_ca_filtered_df\n",
    "    tif_chi_il_nonnull_buckets[f'tif_chi_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_chi_il_filtered_df\n",
    "    tif_eas_nj_nonnull_buckets[f'tif_eas_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_eas_nj_filtered_df\n",
    "    tif_hac_nj_nonnull_buckets[f'tif_hac_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_hac_nj_filtered_df\n",
    "    tif_nor_il_nonnull_buckets[f'tif_nor_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_nor_il_filtered_df\n",
    "    tif_red_nj_nonnull_buckets[f'tif_red_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_red_nj_filtered_df\n",
    "    tif_ric_va_nonnull_buckets[f'tif_ric_va_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_ric_va_filtered_df\n",
    "    tif_sho_nj_nonnull_buckets[f'tif_sho_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_sho_nj_filtered_df\n",
    "    tif_sko_il_nonnull_buckets[f'tif_sko_il_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_sko_il_filtered_df\n",
    "    tif_vie_va_nonnull_buckets[f'tif_vie_va_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_vie_va_filtered_df\n",
    "    vbj_fri_tx_nonnull_buckets[f'vbj_fri_tx_nonnull_{bucket.replace(\">\", \"greater_\")}'] = vbj_fri_tx_filtered_df\n",
    "    tif_par_nj_nonnull_buckets[f'tif_par_nj_nonnull_{bucket.replace(\">\", \"greater_\")}'] = tif_par_nj_filtered_df\n",
    "    eve_joh_ga_nonnull_buckets[f'eve_joh_ga_nonnull_{bucket.replace(\">\", \"greater_\")}'] = eve_joh_ga_filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66eae4ad-df37-4942-95b6-ac4999b83236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:41.570364Z",
     "iopub.status.busy": "2025-06-11T04:31:41.569870Z",
     "iopub.status.idle": "2025-06-11T04:31:41.597548Z",
     "shell.execute_reply": "2025-06-11T04:31:41.597000Z",
     "shell.execute_reply.started": "2025-06-11T04:31:41.570340Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_agd_mb = [\n",
    "    agd_mb_nonnull_buckets['agd_mb_nonnull_1-4'],\n",
    "    agd_mb_nonnull_buckets['agd_mb_nonnull_5-15'],\n",
    "    agd_mb_nonnull_buckets['agd_mb_nonnull_16-30'],\n",
    "    agd_mb_nonnull_buckets['agd_mb_nonnull_31-60'],\n",
    "    agd_mb_nonnull_buckets['agd_mb_nonnull_61-100'],\n",
    "    agd_mb_nonnull_buckets['agd_mb_nonnull_greater_100']\n",
    "]\n",
    "\n",
    "dataframes_bhi_ak = [bhi_ak_nonnull_buckets['bhi_ak_nonnull_1-4'],bhi_ak_nonnull_buckets['bhi_ak_nonnull_5-15'],bhi_ak_nonnull_buckets['bhi_ak_nonnull_16-30'],bhi_ak_nonnull_buckets['bhi_ak_nonnull_31-60'],bhi_ak_nonnull_buckets['bhi_ak_nonnull_61-100'],bhi_ak_nonnull_buckets['bhi_ak_nonnull_greater_100']]\n",
    "dataframes_bhi_dec_ga = [bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_1-4'],bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_5-15'],bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_16-30'],bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_31-60'],bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_61-100'],bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_greater_100']]\n",
    "dataframes_jar_alg_il = [jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_1-4'],jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_5-15'],jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_16-30'],jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_31-60'],jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_61-100'],jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_greater_100']]\n",
    "dataframes_jar_aur_il = [jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_1-4'],jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_5-15'],jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_16-30'],jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_31-60'],jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_61-100'],jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_greater_100']]\n",
    "dataframes_jar_bol_il = [jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_1-4'],jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_5-15'],jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_16-30'],jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_31-60'],jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_61-100'],jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_greater_100']]\n",
    "dataframes_jar_lom_il = [jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_1-4'],jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_5-15'],jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_16-30'],jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_31-60'],jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_61-100'],jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_greater_100']]\n",
    "dataframes_jar_orl_il = [jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_1-4'],jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_5-15'],jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_16-30'],jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_31-60'],jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_61-100'],jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_greater_100']]\n",
    "dataframes_jar_sch_il = [jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_1-4'],jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_5-15'],jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_16-30'],jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_31-60'],jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_61-100'],jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_greater_100']]\n",
    "dataframes_jar_ver_il = [jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_1-4'],jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_5-15'],jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_16-30'],jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_31-60'],jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_61-100'],jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_greater_100']]\n",
    "dataframes_joy_ab = [joy_ab_nonnull_buckets['joy_ab_nonnull_1-4'],joy_ab_nonnull_buckets['joy_ab_nonnull_5-15'],joy_ab_nonnull_buckets['joy_ab_nonnull_16-30'],joy_ab_nonnull_buckets['joy_ab_nonnull_31-60'],joy_ab_nonnull_buckets['joy_ab_nonnull_61-100'],joy_ab_nonnull_buckets['joy_ab_nonnull_greater_100']]\n",
    "dataframes_joy_st_af = [joy_st_af_nonnull_buckets['joy_st_af_nonnull_1-4'],joy_st_af_nonnull_buckets['joy_st_af_nonnull_5-15'],joy_st_af_nonnull_buckets['joy_st_af_nonnull_16-30'],joy_st_af_nonnull_buckets['joy_st_af_nonnull_31-60'],joy_st_af_nonnull_buckets['joy_st_af_nonnull_61-100'],joy_st_af_nonnull_buckets['joy_st_af_nonnull_greater_100']]\n",
    "dataframes_joy_ak = [joy_ak_nonnull_buckets['joy_ak_nonnull_1-4'],joy_ak_nonnull_buckets['joy_ak_nonnull_5-15'],joy_ak_nonnull_buckets['joy_ak_nonnull_16-30'],joy_ak_nonnull_buckets['joy_ak_nonnull_31-60'],joy_ak_nonnull_buckets['joy_ak_nonnull_61-100'],joy_ak_nonnull_buckets['joy_ak_nonnull_greater_100']]\n",
    "dataframes_joy_dm_ad = [joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_1-4'],joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_5-15'],joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_16-30'],joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_31-60'],joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_61-100'],joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_greater_100']]\n",
    "dataframes_joy_mz_ad = [joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_1-4'],joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_5-15'],joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_16-30'],joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_31-60'],joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_61-100'],joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_greater_100']]\n",
    "dataframes_joy_sh_ad = [joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_1-4'],joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_5-15'],joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_16-30'],joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_31-60'],joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_61-100'],joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_greater_100']]\n",
    "dataframes_joy_chi_il = [joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_1-4'],joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_5-15'],joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_16-30'],joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_31-60'],joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_61-100'],joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_greater_100']]\n",
    "dataframes_joy_fri_tx = [joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_1-4'],joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_5-15'],joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_16-30'],joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_31-60'],joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_61-100'],joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_greater_100']]\n",
    "dataframes_joy_hou_tx = [joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_1-4'],joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_5-15'],joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_16-30'],joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_31-60'],joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_61-100'],joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_greater_100']]\n",
    "dataframes_joy_suw_ga = [joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_1-4'],joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_5-15'],joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_16-30'],joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_31-60'],joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_61-100'],joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_greater_100']]\n",
    "dataframes_kan_mb = [kan_mb_nonnull_buckets['kan_mb_nonnull_1-4'],kan_mb_nonnull_buckets['kan_mb_nonnull_5-15'],kan_mb_nonnull_buckets['kan_mb_nonnull_16-30'],kan_mb_nonnull_buckets['kan_mb_nonnull_31-60'],kan_mb_nonnull_buckets['kan_mb_nonnull_61-100'],kan_mb_nonnull_buckets['kan_mb_nonnull_greater_100']]\n",
    "dataframes_mal_sc = [mal_sc_nonnull_buckets['mal_sc_nonnull_1-4'],mal_sc_nonnull_buckets['mal_sc_nonnull_5-15'],mal_sc_nonnull_buckets['mal_sc_nonnull_16-30'],mal_sc_nonnull_buckets['mal_sc_nonnull_31-60'],mal_sc_nonnull_buckets['mal_sc_nonnull_61-100'],mal_sc_nonnull_buckets['mal_sc_nonnull_greater_100']]\n",
    "dataframes_mal_chi_il = [mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_1-4'],mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_5-15'],mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_16-30'],mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_31-60'],mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_61-100'],mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_greater_100']]\n",
    "dataframes_mal_fri_tx = [mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_1-4'],mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_5-15'],mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_16-30'],mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_31-60'],mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_61-100'],mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_greater_100']]\n",
    "dataframes_mal_ise_nj = [mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_1-4'],mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_5-15'],mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_16-30'],mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_31-60'],mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_61-100'],mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_greater_100']]\n",
    "dataframes_mal_nap_il = [mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_1-4'],mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_5-15'],mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_16-30'],mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_31-60'],mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_61-100'],mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_greater_100']]\n",
    "dataframes_mal_ab = [mal_ab_nonnull_buckets['mal_ab_nonnull_1-4'],mal_ab_nonnull_buckets['mal_ab_nonnull_5-15'],mal_ab_nonnull_buckets['mal_ab_nonnull_16-30'],mal_ab_nonnull_buckets['mal_ab_nonnull_31-60'],mal_ab_nonnull_buckets['mal_ab_nonnull_61-100'],mal_ab_nonnull_buckets['mal_ab_nonnull_greater_100']]\n",
    "dataframes_mal_b1_af = [mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_1-4'],mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_5-15'],mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_16-30'],mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_31-60'],mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_61-100'],mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_greater_100']]\n",
    "dataframes_mal_ak = [mal_ak_nonnull_buckets['mal_ak_nonnull_1-4'],mal_ak_nonnull_buckets['mal_ak_nonnull_5-15'],mal_ak_nonnull_buckets['mal_ak_nonnull_16-30'],mal_ak_nonnull_buckets['mal_ak_nonnull_31-60'],mal_ak_nonnull_buckets['mal_ak_nonnull_61-100'],mal_ak_nonnull_buckets['mal_ak_nonnull_greater_100']]\n",
    "dataframes_mal_aw_ad = [mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_1-4'],mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_5-15'],mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_16-30'],mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_31-60'],mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_61-100'],mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_greater_100']]\n",
    "dataframes_mal_dm_ad = [mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_1-4'],mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_5-15'],mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_16-30'],mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_31-60'],mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_61-100'],mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_greater_100']]\n",
    "dataframes_mal_b1_ad = [mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_1-4'],mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_5-15'],mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_16-30'],mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_31-60'],mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_61-100'],mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_greater_100']]\n",
    "dataframes_mal_b2_ad = [mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_1-4'],mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_5-15'],mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_16-30'],mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_31-60'],mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_61-100'],mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_greater_100']]\n",
    "dataframes_mal_lu_ad = [mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_1-4'],mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_5-15'],mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_16-30'],mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_31-60'],mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_61-100'],mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_greater_100']]\n",
    "dataframes_mal_mb = [mal_mb_nonnull_buckets['mal_mb_nonnull_1-4'],mal_mb_nonnull_buckets['mal_mb_nonnull_5-15'],mal_mb_nonnull_buckets['mal_mb_nonnull_16-30'],mal_mb_nonnull_buckets['mal_mb_nonnull_31-60'],mal_mb_nonnull_buckets['mal_mb_nonnull_61-100'],mal_mb_nonnull_buckets['mal_mb_nonnull_greater_100']]\n",
    "dataframes_mal_sh_ad = [mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_1-4'],mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_5-15'],mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_16-30'],mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_31-60'],mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_61-100'],mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_greater_100']]\n",
    "dataframes_mal_b2_af = [mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_1-4'],mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_5-15'],mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_16-30'],mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_31-60'],mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_61-100'],mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_greater_100']]\n",
    "dataframes_mal_ric_tx = [mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_1-4'],mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_5-15'],mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_16-30'],mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_31-60'],mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_61-100'],mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_greater_100']]\n",
    "dataframes_may_vie_va = [may_vie_va_nonnull_buckets['may_vie_va_nonnull_1-4'],may_vie_va_nonnull_buckets['may_vie_va_nonnull_5-15'],may_vie_va_nonnull_buckets['may_vie_va_nonnull_16-30'],may_vie_va_nonnull_buckets['may_vie_va_nonnull_31-60'],may_vie_va_nonnull_buckets['may_vie_va_nonnull_61-100'],may_vie_va_nonnull_buckets['may_vie_va_nonnull_greater_100']]\n",
    "dataframes_mna_mb = [mna_mb_nonnull_buckets['mna_mb_nonnull_1-4'],mna_mb_nonnull_buckets['mna_mb_nonnull_5-15'],mna_mb_nonnull_buckets['mna_mb_nonnull_16-30'],mna_mb_nonnull_buckets['mna_mb_nonnull_31-60'],mna_mb_nonnull_buckets['mna_mb_nonnull_61-100'],mna_mb_nonnull_buckets['mna_mb_nonnull_greater_100']]\n",
    "dataframes_mia_awm_ad = [mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_1-4'],mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_5-15'],mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_16-30'],mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_31-60'],mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_61-100'],mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_greater_100']]\n",
    "dataframes_mia_bur_db = [mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_1-4'],mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_5-15'],mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_16-30'],mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_31-60'],mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_61-100'],mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_greater_100']]\n",
    "dataframes_min_ak = [min_ak_nonnull_buckets['min_ak_nonnull_1-4'],min_ak_nonnull_buckets['min_ak_nonnull_5-15'],min_ak_nonnull_buckets['min_ak_nonnull_16-30'],min_ak_nonnull_buckets['min_ak_nonnull_31-60'],min_ak_nonnull_buckets['min_ak_nonnull_61-100'],min_ak_nonnull_buckets['min_ak_nonnull_greater_100']]\n",
    "dataframes_son_ise_nj = [son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_1-4'],son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_5-15'],son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_16-30'],son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_31-60'],son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_61-100'],son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_greater_100']]\n",
    "dataframes_tan_bar_db = [tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_1-4'],tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_5-15'],tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_16-30'],tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_31-60'],tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_61-100'],tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_greater_100']]\n",
    "dataframes_tan_fah_db = [tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_1-4'],tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_5-15'],tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_16-30'],tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_31-60'],tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_61-100'],tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_greater_100']]\n",
    "dataframes_tan_kar_db = [tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_1-4'],tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_5-15'],tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_16-30'],tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_31-60'],tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_61-100'],tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_greater_100']]\n",
    "dataframes_tan_am_om = [tan_am_om_nonnull_buckets['tan_am_om_nonnull_1-4'],tan_am_om_nonnull_buckets['tan_am_om_nonnull_5-15'],tan_am_om_nonnull_buckets['tan_am_om_nonnull_16-30'],tan_am_om_nonnull_buckets['tan_am_om_nonnull_31-60'],tan_am_om_nonnull_buckets['tan_am_om_nonnull_61-100'],tan_am_om_nonnull_buckets['tan_am_om_nonnull_greater_100']]\n",
    "dataframes_tan_fc_qa = [tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_1-4'],tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_5-15'],tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_16-30'],tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_31-60'],tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_61-100'],tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_greater_100']]\n",
    "dataframes_tan_gs_db = [tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_1-4'],tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_5-15'],tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_16-30'],tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_31-60'],tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_61-100'],tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_greater_100']]\n",
    "dataframes_tan_ham_ad = [tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_1-4'],tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_5-15'],tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_16-30'],tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_31-60'],tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_61-100'],tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_greater_100']]\n",
    "dataframes_tan_lul_qa = [tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_1-4'],tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_5-15'],tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_16-30'],tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_31-60'],tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_61-100'],tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_greater_100']]\n",
    "dataframes_tan_mee_db = [tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_1-4'],tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_5-15'],tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_16-30'],tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_31-60'],tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_61-100'],tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_greater_100']]\n",
    "dataframes_tan_rol_sh = [tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_1-4'],tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_5-15'],tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_16-30'],tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_31-60'],tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_61-100'],tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_greater_100']]\n",
    "dataframes_tan_sc_sh = [tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_1-4'],tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_5-15'],tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_16-30'],tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_31-60'],tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_61-100'],tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_greater_100']]\n",
    "dataframes_tan_sil_db = [tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_1-4'],tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_5-15'],tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_16-30'],tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_31-60'],tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_61-100'],tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_greater_100']]\n",
    "dataframes_tan_taj_db = [tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_1-4'],tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_5-15'],tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_16-30'],tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_31-60'],tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_61-100'],tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_greater_100']]\n",
    "dataframes_tan_mank_db = [tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_1-4'],tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_5-15'],tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_16-30'],tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_31-60'],tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_61-100'],tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_greater_100']]\n",
    "dataframes_tan_atl_ga = [tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_1-4'],tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_5-15'],tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_16-30'],tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_31-60'],tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_61-100'],tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_greater_100']]\n",
    "dataframes_tan_chi_il = [tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_1-4'],tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_5-15'],tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_16-30'],tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_31-60'],tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_61-100'],tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_greater_100']]\n",
    "dataframes_tan_fri_tx = [tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_1-4'],tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_5-15'],tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_16-30'],tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_31-60'],tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_61-100'],tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_greater_100']]\n",
    "dataframes_tan_hou_tx = [tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_1-4'],tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_5-15'],tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_16-30'],tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_31-60'],tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_61-100'],tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_greater_100']]\n",
    "dataframes_tan_new_nj = [tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_1-4'],tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_5-15'],tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_16-30'],tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_31-60'],tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_61-100'],tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_greater_100']]\n",
    "dataframes_tan_rse_wa = [tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_1-4'],tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_5-15'],tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_16-30'],tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_31-60'],tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_61-100'],tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_greater_100']]\n",
    "dataframes_tan_sc_ca = [tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_1-4'],tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_5-15'],tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_16-30'],tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_31-60'],tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_61-100'],tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_greater_100']]\n",
    "dataframes_tif_chi_il = [tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_1-4'],tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_5-15'],tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_16-30'],tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_31-60'],tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_61-100'],tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_greater_100']]\n",
    "dataframes_tif_eas_nj = [tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_1-4'],tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_5-15'],tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_16-30'],tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_31-60'],tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_61-100'],tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_greater_100']]\n",
    "dataframes_tif_hac_nj = [tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_1-4'],tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_5-15'],tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_16-30'],tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_31-60'],tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_61-100'],tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_greater_100']]\n",
    "dataframes_tif_nor_il = [tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_1-4'],tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_5-15'],tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_16-30'],tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_31-60'],tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_61-100'],tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_greater_100']]\n",
    "dataframes_tif_red_nj = [tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_1-4'],tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_5-15'],tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_16-30'],tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_31-60'],tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_61-100'],tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_greater_100']]\n",
    "dataframes_tif_ric_va = [tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_1-4'],tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_5-15'],tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_16-30'],tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_31-60'],tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_61-100'],tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_greater_100']]\n",
    "dataframes_tif_sho_nj = [tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_1-4'],tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_5-15'],tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_16-30'],tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_31-60'],tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_61-100'],tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_greater_100']]\n",
    "dataframes_tif_sko_il = [tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_1-4'],tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_5-15'],tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_16-30'],tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_31-60'],tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_61-100'],tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_greater_100']]\n",
    "dataframes_tif_vie_va = [tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_1-4'],tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_5-15'],tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_16-30'],tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_31-60'],tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_61-100'],tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_greater_100']]\n",
    "dataframes_vbj_fri_tx = [vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_1-4'],vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_5-15'],vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_16-30'],vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_31-60'],vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_61-100'],vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_greater_100']]\n",
    "dataframes_tif_par_nj = [tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_1-4'],tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_5-15'],tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_16-30'],tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_31-60'],tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_61-100'],tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_greater_100']]\n",
    "dataframes_eve_joh_ga = [eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_1-4'],eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_5-15'],eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_16-30'],eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_31-60'],eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_61-100'],eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_greater_100']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2186aa0-66b9-494a-a345-ef6e2c0a90fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:31:44.389362Z",
     "iopub.status.busy": "2025-06-11T04:31:44.389040Z",
     "iopub.status.idle": "2025-06-11T04:31:44.480865Z",
     "shell.execute_reply": "2025-06-11T04:31:44.480359Z",
     "shell.execute_reply.started": "2025-06-11T04:31:44.389341Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_agd_mb = pd.concat(dataframes_agd_mb, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_bhi_ak = pd.concat(dataframes_bhi_ak, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_bhi_dec_ga = pd.concat(dataframes_bhi_dec_ga, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_jar_alg_il = pd.concat(dataframes_jar_alg_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_jar_aur_il = pd.concat(dataframes_jar_aur_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_jar_bol_il = pd.concat(dataframes_jar_bol_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_jar_lom_il = pd.concat(dataframes_jar_lom_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_jar_orl_il = pd.concat(dataframes_jar_orl_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_jar_sch_il = pd.concat(dataframes_jar_sch_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_jar_ver_il = pd.concat(dataframes_jar_ver_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_ab = pd.concat(dataframes_joy_ab, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_st_af = pd.concat(dataframes_joy_st_af, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_ak = pd.concat(dataframes_joy_ak, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_dm_ad = pd.concat(dataframes_joy_dm_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_mz_ad = pd.concat(dataframes_joy_mz_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_sh_ad = pd.concat(dataframes_joy_sh_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_chi_il = pd.concat(dataframes_joy_chi_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_fri_tx = pd.concat(dataframes_joy_fri_tx, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_hou_tx = pd.concat(dataframes_joy_hou_tx, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_joy_suw_ga = pd.concat(dataframes_joy_suw_ga, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_kan_mb = pd.concat(dataframes_kan_mb, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_sc = pd.concat(dataframes_mal_sc, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_chi_il = pd.concat(dataframes_mal_chi_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_fri_tx = pd.concat(dataframes_mal_fri_tx, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_ise_nj = pd.concat(dataframes_mal_ise_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_nap_il = pd.concat(dataframes_mal_nap_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_ab = pd.concat(dataframes_mal_ab, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_b1_af = pd.concat(dataframes_mal_b1_af, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_ak = pd.concat(dataframes_mal_ak, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_aw_ad = pd.concat(dataframes_mal_aw_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_dm_ad = pd.concat(dataframes_mal_dm_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_b1_ad = pd.concat(dataframes_mal_b1_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_b2_ad = pd.concat(dataframes_mal_b2_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_lu_ad = pd.concat(dataframes_mal_lu_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_mb = pd.concat(dataframes_mal_mb, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_sh_ad = pd.concat(dataframes_mal_sh_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_b2_af = pd.concat(dataframes_mal_b2_af, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mal_ric_tx = pd.concat(dataframes_mal_ric_tx, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_may_vie_va = pd.concat(dataframes_may_vie_va, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mna_mb = pd.concat(dataframes_mna_mb, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mia_awm_ad = pd.concat(dataframes_mia_awm_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_mia_bur_db = pd.concat(dataframes_mia_bur_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_min_ak = pd.concat(dataframes_min_ak, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_son_ise_nj = pd.concat(dataframes_son_ise_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_bar_db = pd.concat(dataframes_tan_bar_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_fah_db = pd.concat(dataframes_tan_fah_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_kar_db = pd.concat(dataframes_tan_kar_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_am_om = pd.concat(dataframes_tan_am_om, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_fc_qa = pd.concat(dataframes_tan_fc_qa, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_gs_db = pd.concat(dataframes_tan_gs_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_ham_ad = pd.concat(dataframes_tan_ham_ad, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_lul_qa = pd.concat(dataframes_tan_lul_qa, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_mee_db = pd.concat(dataframes_tan_mee_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_rol_sh = pd.concat(dataframes_tan_rol_sh, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_sc_sh = pd.concat(dataframes_tan_sc_sh, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_sil_db = pd.concat(dataframes_tan_sil_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_taj_db = pd.concat(dataframes_tan_taj_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_mank_db = pd.concat(dataframes_tan_mank_db, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_atl_ga = pd.concat(dataframes_tan_atl_ga, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_chi_il = pd.concat(dataframes_tan_chi_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_fri_tx = pd.concat(dataframes_tan_fri_tx, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_hou_tx = pd.concat(dataframes_tan_hou_tx, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_new_nj = pd.concat(dataframes_tan_new_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_rse_wa = pd.concat(dataframes_tan_rse_wa, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tan_sc_ca = pd.concat(dataframes_tan_sc_ca, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_chi_il = pd.concat(dataframes_tif_chi_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_eas_nj = pd.concat(dataframes_tif_eas_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_hac_nj = pd.concat(dataframes_tif_hac_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_nor_il = pd.concat(dataframes_tif_nor_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_red_nj = pd.concat(dataframes_tif_red_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_ric_va = pd.concat(dataframes_tif_ric_va, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_sho_nj = pd.concat(dataframes_tif_sho_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_sko_il = pd.concat(dataframes_tif_sko_il, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_vie_va = pd.concat(dataframes_tif_vie_va, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_vbj_fri_tx = pd.concat(dataframes_vbj_fri_tx, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_tif_par_nj = pd.concat(dataframes_tif_par_nj, ignore_index=True).reset_index(drop=True)\n",
    "combined_df_eve_joh_ga = pd.concat(dataframes_eve_joh_ga, ignore_index=True).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a93f98-7cb1-4927-be67-17ab07792966",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sentiment Scoring for Null reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3dd16fb5-0558-4e51-a0f7-6c4af543eb28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:34:52.023562Z",
     "iopub.status.busy": "2025-06-11T04:34:52.023234Z",
     "iopub.status.idle": "2025-06-11T04:34:52.026726Z",
     "shell.execute_reply": "2025-06-11T04:34:52.026145Z",
     "shell.execute_reply.started": "2025-06-11T04:34:52.023529Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#List of new columns to add with a default value of 0\n",
    "column_names = [\"Trust\",\n",
    "                \"Store Experience\",\n",
    "                \"Store Staff\",\n",
    "                \"Product Design\",\n",
    "                \"Product Variety\",\n",
    "                \"Discount\",\n",
    "                \"Making Charge\",\n",
    "                \"Price\",\n",
    "                \"Product Quality\",\n",
    "                \"OLD Gold Jewellery Exchange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1242b47-ed4d-4212-8ee8-8fb0a12cd154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:34:55.348377Z",
     "iopub.status.busy": "2025-06-11T04:34:55.347792Z",
     "iopub.status.idle": "2025-06-11T04:34:55.466782Z",
     "shell.execute_reply": "2025-06-11T04:34:55.466197Z",
     "shell.execute_reply.started": "2025-06-11T04:34:55.348351Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loop through each DataFrame in 'null_dataframes' dictionary\n",
    "for df_name, df in null_dataframes.items():\n",
    "    # Add 'Commentor Name' column by copying values from 'name' column\n",
    "    df['Commentor Name'] = df['Name']\n",
    "\n",
    "#Loop through each DataFrame in the 'null_dataframes' dictionary\n",
    "for df_name, df in null_dataframes.items():\n",
    "    # Add each column from 'column_names' with a default value of 0\n",
    "    for column in column_names:\n",
    "        df[column] = 0\n",
    "\n",
    "# Now, each DataFrame in 'null_dataframes' has the new columns with values initialized to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f297a8-88a0-4692-81c1-35b7594d14fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sentiment Scoring for reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01db33-44ff-4b30-99e8-d7c27d0eee23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Competitors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1449f-dc0a-4148-aa4e-1f4102633ab3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### bhi_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33a588b9-8a0f-41f3-8332-453149ca5837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:40:59.719954Z",
     "iopub.status.busy": "2025-06-11T04:40:59.719650Z",
     "iopub.status.idle": "2025-06-11T04:41:18.783192Z",
     "shell.execute_reply": "2025-06-11T04:41:18.782634Z",
     "shell.execute_reply.started": "2025-06-11T04:40:59.719934Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:19\n",
      "Total Input Tokens - 4067\n",
      "Total Input Cost = 0.04\n",
      "Total Output Tokens - 732\n",
      "Total Output Cost = 0.02\n",
      "Total Cost = 0.06\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(bhi_ak_nonnull_buckets['bhi_ak_nonnull_1-4'])/25)+math.ceil(len(bhi_ak_nonnull_buckets['bhi_ak_nonnull_5-15'])/25)+math.ceil(len(bhi_ak_nonnull_buckets['bhi_ak_nonnull_16-30'])/25)+math.ceil(len(bhi_ak_nonnull_buckets['bhi_ak_nonnull_31-60'])/25)+math.ceil(len(bhi_ak_nonnull_buckets['bhi_ak_nonnull_61-100'])/25)+math.ceil(len(bhi_ak_nonnull_buckets['bhi_ak_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(bhi_ak_nonnull_buckets.keys())\n",
    "bhi_ak_nonnull_api = []\n",
    "input_tokens_bhi_ak_nonnull=0\n",
    "output_tokens_bhi_ak_nonnull=0\n",
    "start_time_bhi_ak = time.time()\n",
    "\n",
    "for key in bhi_ak_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = bhi_ak_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_bhi_ak, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        bhi_ak_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_bhi_ak_nonnull+=input_tokens\n",
    "    output_tokens_bhi_ak_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_bhi_ak = time.time() - start_time_bhi_ak\n",
    "formatted_time_bhi_ak = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_bhi_ak))\n",
    "input_token_cost_bhi_ak = round((0.01/1000) * input_tokens_bhi_ak_nonnull, 2)\n",
    "output_token_cost_bhi_ak = round((0.03/1000) * output_tokens_bhi_ak_nonnull, 2)\n",
    "total_cost_bhi_ak = round(input_token_cost_bhi_ak + output_token_cost_bhi_ak, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_bhi_ak}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_bhi_ak_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_bhi_ak}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_bhi_ak_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_bhi_ak}\")\n",
    "print(f\"Total Cost = {total_cost_bhi_ak}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc4da71c-d38c-4bf2-8b61-fa1a812dfc97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:41:24.512803Z",
     "iopub.status.busy": "2025-06-11T04:41:24.512450Z",
     "iopub.status.idle": "2025-06-11T04:41:24.517106Z",
     "shell.execute_reply": "2025-06-11T04:41:24.516524Z",
     "shell.execute_reply.started": "2025-06-11T04:41:24.512778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"Binu Pillai\": [\\n    {\\n      \"positive\": \"Store Staff\",\\n      \"negative\": \"\"\\n    }\\n  ],\\n  \"Sajani Manikandan\": [\\n    {\\n      \"positive\": \"Store Staff\",\\n      \"negative\": \"\"\\n    }\\n  ],\\n  \"ameen sb\": [\\n    {\\n      \"positive\": \"Product Variety\",\\n      \"negative\": \"\"\\n    }\\n  ],\\n  \"Parthibarajan s\": [\\n    {\\n      \"positive\": \"\",\\n      \"negative\": \"\"\\n    }\\n  ],\\n  \"Jacob Plackan\": [\\n    {\\n      \"positive\": \"Store Staff\",\\n      \"negative\": \"\"\\n    }\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bhi_ak_nonnull_api[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46a3e27a-3c0a-46f7-a9b3-34e251e51c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:41:26.763762Z",
     "iopub.status.busy": "2025-06-11T04:41:26.763444Z",
     "iopub.status.idle": "2025-06-11T04:41:26.767677Z",
     "shell.execute_reply": "2025-06-11T04:41:26.767119Z",
     "shell.execute_reply.started": "2025-06-11T04:41:26.763741Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in bhi_ak_nonnull_api & convert to DataFrame\n",
    "bhi_ak_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in bhi_ak_nonnull_api\n",
    "]                                  \n",
    "bhi_ak_nonnull_api_cleaned_df = pd.DataFrame(bhi_ak_nonnull_api_cleaned)\n",
    "#bhi_ak_nonnull_api_cleaned_df = pd.DataFrame(bhi_ak_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b16fb295-ea3b-47c5-9117-779259fbcce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:41:29.003703Z",
     "iopub.status.busy": "2025-06-11T04:41:29.003357Z",
     "iopub.status.idle": "2025-06-11T04:41:29.009568Z",
     "shell.execute_reply": "2025-06-11T04:41:29.008967Z",
     "shell.execute_reply.started": "2025-06-11T04:41:29.003682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_bhi_ak_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in bhi_ak_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_bhi_ak_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb968c-ad22-4d9d-afe9-67d5c20436c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "bhi_ak_nonnull_api_cleaned_df.to_excel(\"bhi_ak_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa0374-9ff1-4256-90de-95fa10528f1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "bhi_ak_nonnull_api_cleaned_df = pd.read_excel(\"bhi_ak_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b3a46-42d9-46ad-b1b5-a3cb3f6ab88f",
   "metadata": {
    "tags": []
   },
   "source": [
    "bhi_ak_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5513cf32-701c-4302-98a2-9b712124523b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:42:11.442973Z",
     "iopub.status.busy": "2025-06-11T04:42:11.442654Z",
     "iopub.status.idle": "2025-06-11T04:42:11.483655Z",
     "shell.execute_reply": "2025-06-11T04:42:11.483194Z",
     "shell.execute_reply.started": "2025-06-11T04:42:11.442951Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "bhi_ak_nonnull_sen_df = pd.DataFrame(processed_data_bhi_ak_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "bhi_ak_nonnull_sen_df = bhi_ak_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "bhi_ak_nonnull_merged_df = pd.concat([combined_df_bhi_ak, bhi_ak_nonnull_sen_df], axis=1)\n",
    "\n",
    "bhi_ak_final_sen_df = pd.concat([bhi_ak_nonnull_merged_df,null_dataframes['bhi_ak_null']], ignore_index=True)\n",
    "\n",
    "bhi_ak_final_sen_df_copy = bhi_ak_final_sen_df.copy()\n",
    "bhi_ak_final_sen_df_copy[\"Published At Date\"] = bhi_ak_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "bhi_ak_final_sen_df_copy.to_excel(\"sentiment_raw_output/bhi_ak_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4736de0-b13b-4dbc-948a-dd5080422cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:42:18.903328Z",
     "iopub.status.busy": "2025-06-11T04:42:18.903007Z",
     "iopub.status.idle": "2025-06-11T04:42:18.916424Z",
     "shell.execute_reply": "2025-06-11T04:42:18.915885Z",
     "shell.execute_reply.started": "2025-06-11T04:42:18.903308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>Published At Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>review_text</th>\n",
       "      <th>Store Code Cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>count_buckets</th>\n",
       "      <th>Commentor Name</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>OLD Gold Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Binu Pillai</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent customer care.</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1-4</td>\n",
       "      <td>Binu Pillai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Sajani Manikandan</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent customer service.</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1-4</td>\n",
       "      <td>Sajani Manikandan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>ameen sb</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Good collections</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1-4</td>\n",
       "      <td>ameen sb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Parthibarajan s</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>NA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-4</td>\n",
       "      <td>Parthibarajan s</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Jacob Plackan</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Good Service by Nijin</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1-4</td>\n",
       "      <td>Jacob Plackan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name               Name Published At Date  Stars  \\\n",
       "0  Bhima Jewellers - Al Karama        Binu Pillai        2025-05-29    4.0   \n",
       "1  Bhima Jewellers - Al Karama  Sajani Manikandan        2025-05-23    5.0   \n",
       "2  Bhima Jewellers - Al Karama           ameen sb        2025-05-20    5.0   \n",
       "3  Bhima Jewellers - Al Karama    Parthibarajan s        2025-05-15    5.0   \n",
       "4  Bhima Jewellers - Al Karama      Jacob Plackan        2025-05-04    5.0   \n",
       "\n",
       "   Total Score  year  month                  review_text Store Code Cleaned  \\\n",
       "0          4.7  2025      5     Excellent customer care.                 NA   \n",
       "1          4.7  2025      5  Excellent customer service.                 NA   \n",
       "2          4.7  2025      5             Good collections                 NA   \n",
       "3          4.7  2025      5                         Good                 NA   \n",
       "4          4.7  2025      5        Good Service by Nijin                 NA   \n",
       "\n",
       "   word_count count_buckets     Commentor Name  Trust  Store Experience  \\\n",
       "0         3.0           1-4        Binu Pillai      0                 0   \n",
       "1         3.0           1-4  Sajani Manikandan      0                 0   \n",
       "2         2.0           1-4           ameen sb      0                 0   \n",
       "3         1.0           1-4    Parthibarajan s      0                 0   \n",
       "4         4.0           1-4      Jacob Plackan      0                 0   \n",
       "\n",
       "   Store Staff  Product Design  Product Variety  Discount  Making Charge  \\\n",
       "0            1               0                0         0              0   \n",
       "1            1               0                0         0              0   \n",
       "2            0               0                1         0              0   \n",
       "3            0               0                0         0              0   \n",
       "4            1               0                0         0              0   \n",
       "\n",
       "   Price  Product Quality  OLD Gold Jewellery Exchange  \n",
       "0      0                0                            0  \n",
       "1      0                0                            0  \n",
       "2      0                0                            0  \n",
       "3      0                0                            0  \n",
       "4      0                0                            0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bhi_ak_final_sen_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904648a-7882-4816-8952-9fff7e5227d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b6570859-4a3c-4c81-8580-c454ade27f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:42:22.519333Z",
     "iopub.status.busy": "2025-06-11T04:42:22.519006Z",
     "iopub.status.idle": "2025-06-11T04:42:50.596347Z",
     "shell.execute_reply": "2025-06-11T04:42:50.595790Z",
     "shell.execute_reply.started": "2025-06-11T04:42:22.519310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [6] Iterations\n",
      "Total Execution Time: 00:00:28\n",
      "Total Input Tokens - 5655\n",
      "Total Input Cost = 0.06\n",
      "Total Output Tokens - 1688\n",
      "Total Output Cost = 0.05\n",
      "Total Cost = 0.11\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_ab_nonnull_buckets['joy_ab_nonnull_1-4'])/25)+math.ceil(len(joy_ab_nonnull_buckets['joy_ab_nonnull_5-15'])/25)+math.ceil(len(joy_ab_nonnull_buckets['joy_ab_nonnull_16-30'])/25)+math.ceil(len(joy_ab_nonnull_buckets['joy_ab_nonnull_31-60'])/25)+math.ceil(len(joy_ab_nonnull_buckets['joy_ab_nonnull_61-100'])/25)+math.ceil(len(joy_ab_nonnull_buckets['joy_ab_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_ab_nonnull_buckets.keys())\n",
    "joy_ab_nonnull_api = []\n",
    "input_tokens_joy_ab_nonnull=0\n",
    "output_tokens_joy_ab_nonnull=0\n",
    "start_time_joy_ab = time.time()\n",
    "\n",
    "for key in joy_ab_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_ab_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_ab, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_ab_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_ab_nonnull+=input_tokens\n",
    "    output_tokens_joy_ab_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_ab = time.time() - start_time_joy_ab\n",
    "formatted_time_joy_ab = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_ab))\n",
    "input_token_cost_joy_ab = round((0.01/1000) * input_tokens_joy_ab_nonnull, 2)\n",
    "output_token_cost_joy_ab = round((0.03/1000) * output_tokens_joy_ab_nonnull, 2)\n",
    "total_cost_joy_ab = round(input_token_cost_joy_ab + output_token_cost_joy_ab, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_ab}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_ab_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_ab}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_ab_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_ab}\")\n",
    "print(f\"Total Cost = {total_cost_joy_ab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a050a7fb-3413-4f76-9987-aa63dfb5137e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:42:50.597544Z",
     "iopub.status.busy": "2025-06-11T04:42:50.597299Z",
     "iopub.status.idle": "2025-06-11T04:42:50.601235Z",
     "shell.execute_reply": "2025-06-11T04:42:50.600719Z",
     "shell.execute_reply.started": "2025-06-11T04:42:50.597526Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_ab_nonnull_api & convert to DataFrame\n",
    "joy_ab_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_ab_nonnull_api\n",
    "]                                  \n",
    "joy_ab_nonnull_api_cleaned_df = pd.DataFrame(joy_ab_nonnull_api_cleaned)\n",
    "#joy_ab_nonnull_api_cleaned_df = pd.DataFrame(joy_ab_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69752028-14c1-42df-a67e-e60d048cc2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:42:50.602007Z",
     "iopub.status.busy": "2025-06-11T04:42:50.601790Z",
     "iopub.status.idle": "2025-06-11T04:42:50.608504Z",
     "shell.execute_reply": "2025-06-11T04:42:50.608046Z",
     "shell.execute_reply.started": "2025-06-11T04:42:50.601990Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_ab_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_ab_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_ab_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee88d8-e3fe-455b-988d-83ff537dcfeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_ab_nonnull_api_cleaned_df.to_excel(\"joy_ab_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc781a-9462-4437-be0b-99f6054a7577",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_ab_nonnull_api_cleaned_df = pd.read_excel(\"joy_ab_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41acbc18-06cf-42ef-8fc1-142b3ce3c87c",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_ab_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31b034-d4db-499c-a959-156b838d1303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:42:50.609573Z",
     "iopub.status.busy": "2025-06-11T04:42:50.609332Z",
     "iopub.status.idle": "2025-06-11T04:42:51.417581Z",
     "shell.execute_reply": "2025-06-11T04:42:51.416757Z",
     "shell.execute_reply.started": "2025-06-11T04:42:50.609557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_ab_nonnull_sen_df = pd.DataFrame(processed_data_joy_ab_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_ab_nonnull_sen_df = joy_ab_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_ab_nonnull_merged_df = pd.concat([combined_df_joy_ab, joy_ab_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_ab_final_sen_df = pd.concat([joy_ab_nonnull_merged_df,null_dataframes['joy_ab_null']], ignore_index=True)\n",
    "\n",
    "joy_ab_final_sen_df_copy = joy_ab_final_sen_df.copy()\n",
    "joy_ab_final_sen_df_copy[\"Published At Date\"] = joy_ab_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_ab_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_ab_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ccaebad-21f8-4fc5-bdca-c62812283ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:44:02.843366Z",
     "iopub.status.busy": "2025-06-11T04:44:02.843052Z",
     "iopub.status.idle": "2025-06-11T04:44:02.886555Z",
     "shell.execute_reply": "2025-06-11T04:44:02.886049Z",
     "shell.execute_reply.started": "2025-06-11T04:44:02.843345Z"
    }
   },
   "outputs": [],
   "source": [
    "joy_ab_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_ab_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b755379-3876-4954-823f-73df4b665a82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_st_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "34fd84e3-484b-4a66-ac12-821515846e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:44:05.904636Z",
     "iopub.status.busy": "2025-06-11T04:44:05.904303Z",
     "iopub.status.idle": "2025-06-11T04:47:05.237387Z",
     "shell.execute_reply": "2025-06-11T04:47:05.236878Z",
     "shell.execute_reply.started": "2025-06-11T04:44:05.904613Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [21] Iterations\n",
      "Total Execution Time: 00:02:59\n",
      "Total Input Tokens - 26492\n",
      "Total Input Cost = 0.26\n",
      "Total Output Tokens - 12945\n",
      "Total Output Cost = 0.39\n",
      "Total Cost = 0.65\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_st_af_nonnull_buckets['joy_st_af_nonnull_1-4'])/25)+math.ceil(len(joy_st_af_nonnull_buckets['joy_st_af_nonnull_5-15'])/25)+math.ceil(len(joy_st_af_nonnull_buckets['joy_st_af_nonnull_16-30'])/25)+math.ceil(len(joy_st_af_nonnull_buckets['joy_st_af_nonnull_31-60'])/25)+math.ceil(len(joy_st_af_nonnull_buckets['joy_st_af_nonnull_61-100'])/25)+math.ceil(len(joy_st_af_nonnull_buckets['joy_st_af_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_st_af_nonnull_buckets.keys())\n",
    "joy_st_af_nonnull_api = []\n",
    "input_tokens_joy_st_af_nonnull=0\n",
    "output_tokens_joy_st_af_nonnull=0\n",
    "start_time_joy_st_af = time.time()\n",
    "\n",
    "for key in joy_st_af_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_st_af_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_st_af, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_st_af_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_st_af_nonnull+=input_tokens\n",
    "    output_tokens_joy_st_af_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_st_af = time.time() - start_time_joy_st_af\n",
    "formatted_time_joy_st_af = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_st_af))\n",
    "input_token_cost_joy_st_af = round((0.01/1000) * input_tokens_joy_st_af_nonnull, 2)\n",
    "output_token_cost_joy_st_af = round((0.03/1000) * output_tokens_joy_st_af_nonnull, 2)\n",
    "total_cost_joy_st_af = round(input_token_cost_joy_st_af + output_token_cost_joy_st_af, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_st_af}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_st_af_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_st_af}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_st_af_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_st_af}\")\n",
    "print(f\"Total Cost = {total_cost_joy_st_af}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5cc8116-b207-40b4-9e9e-6d97df70f843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:05.238480Z",
     "iopub.status.busy": "2025-06-11T04:47:05.238218Z",
     "iopub.status.idle": "2025-06-11T04:47:05.242355Z",
     "shell.execute_reply": "2025-06-11T04:47:05.241889Z",
     "shell.execute_reply.started": "2025-06-11T04:47:05.238461Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_st_af_nonnull_api & convert to DataFrame\n",
    "joy_st_af_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_st_af_nonnull_api\n",
    "]                                  \n",
    "joy_st_af_nonnull_api_cleaned_df = pd.DataFrame(joy_st_af_nonnull_api_cleaned)\n",
    "#joy_st_af_nonnull_api_cleaned_df = pd.DataFrame(joy_st_af_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f90f6661-daf7-4961-84af-8581375e354b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:05.243243Z",
     "iopub.status.busy": "2025-06-11T04:47:05.243022Z",
     "iopub.status.idle": "2025-06-11T04:47:05.253282Z",
     "shell.execute_reply": "2025-06-11T04:47:05.252775Z",
     "shell.execute_reply.started": "2025-06-11T04:47:05.243226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_st_af_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_st_af_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_st_af_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb1f9f4-7646-4eb2-86e4-8682cd45a235",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_st_af_nonnull_api_cleaned_df.to_excel(\"joy_st_af_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569a160-4675-4dde-9a73-93a6c421c7ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_st_af_nonnull_api_cleaned_df = pd.read_excel(\"joy_st_af_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9f8f0-a26f-4d1e-8886-e8bd6ef41c27",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_st_af_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "647d3d4f-e5af-4ceb-a823-93308f9094ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:05.254342Z",
     "iopub.status.busy": "2025-06-11T04:47:05.254106Z",
     "iopub.status.idle": "2025-06-11T04:47:05.562124Z",
     "shell.execute_reply": "2025-06-11T04:47:05.561609Z",
     "shell.execute_reply.started": "2025-06-11T04:47:05.254325Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_st_af_nonnull_sen_df = pd.DataFrame(processed_data_joy_st_af_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_st_af_nonnull_sen_df = joy_st_af_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_st_af_nonnull_merged_df = pd.concat([combined_df_joy_st_af, joy_st_af_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_st_af_final_sen_df = pd.concat([joy_st_af_nonnull_merged_df,null_dataframes['joy_st_af_null']], ignore_index=True)\n",
    "\n",
    "joy_st_af_final_sen_df_copy = joy_st_af_final_sen_df.copy()\n",
    "joy_st_af_final_sen_df_copy[\"Published At Date\"] = joy_st_af_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_st_af_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_st_af_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71d1a2-11be-4f19-af73-fcd7840f1967",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_dm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dbd631ef-b78b-4880-84cb-cf6f0f195277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:16.175859Z",
     "iopub.status.busy": "2025-06-11T04:47:16.175547Z",
     "iopub.status.idle": "2025-06-11T04:47:35.240856Z",
     "shell.execute_reply": "2025-06-11T04:47:35.240332Z",
     "shell.execute_reply.started": "2025-06-11T04:47:16.175837Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [4] Iterations\n",
      "Total Execution Time: 00:00:19\n",
      "Total Input Tokens - 3677\n",
      "Total Input Cost = 0.04\n",
      "Total Output Tokens - 1013\n",
      "Total Output Cost = 0.03\n",
      "Total Cost = 0.07\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_1-4'])/25)+math.ceil(len(joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_5-15'])/25)+math.ceil(len(joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_16-30'])/25)+math.ceil(len(joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_31-60'])/25)+math.ceil(len(joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_61-100'])/25)+math.ceil(len(joy_dm_ad_nonnull_buckets['joy_dm_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_dm_ad_nonnull_buckets.keys())\n",
    "joy_dm_ad_nonnull_api = []\n",
    "input_tokens_joy_dm_ad_nonnull=0\n",
    "output_tokens_joy_dm_ad_nonnull=0\n",
    "start_time_joy_dm_ad = time.time()\n",
    "\n",
    "for key in joy_dm_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_dm_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_dm_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_dm_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_dm_ad_nonnull+=input_tokens\n",
    "    output_tokens_joy_dm_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_dm_ad = time.time() - start_time_joy_dm_ad\n",
    "formatted_time_joy_dm_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_dm_ad))\n",
    "input_token_cost_joy_dm_ad = round((0.01/1000) * input_tokens_joy_dm_ad_nonnull, 2)\n",
    "output_token_cost_joy_dm_ad = round((0.03/1000) * output_tokens_joy_dm_ad_nonnull, 2)\n",
    "total_cost_joy_dm_ad = round(input_token_cost_joy_dm_ad + output_token_cost_joy_dm_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_dm_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_dm_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_dm_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_dm_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_dm_ad}\")\n",
    "print(f\"Total Cost = {total_cost_joy_dm_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "38eb48e2-ba73-4fdb-a307-8f1da8686576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:35.241948Z",
     "iopub.status.busy": "2025-06-11T04:47:35.241689Z",
     "iopub.status.idle": "2025-06-11T04:47:35.245713Z",
     "shell.execute_reply": "2025-06-11T04:47:35.245230Z",
     "shell.execute_reply.started": "2025-06-11T04:47:35.241928Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_dm_ad_nonnull_api & convert to DataFrame\n",
    "joy_dm_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_dm_ad_nonnull_api\n",
    "]                                  \n",
    "joy_dm_ad_nonnull_api_cleaned_df = pd.DataFrame(joy_dm_ad_nonnull_api_cleaned)\n",
    "#joy_dm_ad_nonnull_api_cleaned_df = pd.DataFrame(joy_dm_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bfa3ff5e-a28a-4837-83c2-cb8a6bc27b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:35.246670Z",
     "iopub.status.busy": "2025-06-11T04:47:35.246349Z",
     "iopub.status.idle": "2025-06-11T04:47:35.252755Z",
     "shell.execute_reply": "2025-06-11T04:47:35.252281Z",
     "shell.execute_reply.started": "2025-06-11T04:47:35.246645Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_dm_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_dm_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_dm_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d8b83-a889-474e-82d7-2588b89a398a",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_dm_ad_nonnull_api_cleaned_df.to_excel(\"joy_dm_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e810151-a9d1-4315-b3db-16d8130ff792",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_dm_ad_nonnull_api_cleaned_df = pd.read_excel(\"joy_dm_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fbfcf-ee2f-4fe2-b400-85723d5b7145",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_dm_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "816b46a7-0c74-4fa1-b444-d3fb252165fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:35.253805Z",
     "iopub.status.busy": "2025-06-11T04:47:35.253580Z",
     "iopub.status.idle": "2025-06-11T04:47:35.298001Z",
     "shell.execute_reply": "2025-06-11T04:47:35.297584Z",
     "shell.execute_reply.started": "2025-06-11T04:47:35.253788Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_dm_ad_nonnull_sen_df = pd.DataFrame(processed_data_joy_dm_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_dm_ad_nonnull_sen_df = joy_dm_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_dm_ad_nonnull_merged_df = pd.concat([combined_df_joy_dm_ad, joy_dm_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_dm_ad_final_sen_df = pd.concat([joy_dm_ad_nonnull_merged_df,null_dataframes['joy_dm_ad_null']], ignore_index=True)\n",
    "\n",
    "joy_dm_ad_final_sen_df_copy = joy_dm_ad_final_sen_df.copy()\n",
    "joy_dm_ad_final_sen_df_copy[\"Published At Date\"] = joy_dm_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_dm_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_dm_ad_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ccbe9-092f-481d-8b89-f19ec886615a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_mz_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78325932-9ca0-4c52-9b03-07992675fc53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:47:47.654486Z",
     "iopub.status.busy": "2025-06-11T04:47:47.654177Z",
     "iopub.status.idle": "2025-06-11T04:48:32.762686Z",
     "shell.execute_reply": "2025-06-11T04:48:32.762149Z",
     "shell.execute_reply.started": "2025-06-11T04:47:47.654467Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [7] Iterations\n",
      "Total Execution Time: 00:00:45\n",
      "Total Input Tokens - 8120\n",
      "Total Input Cost = 0.08\n",
      "Total Output Tokens - 3190\n",
      "Total Output Cost = 0.1\n",
      "Total Cost = 0.18\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_1-4'])/25)+math.ceil(len(joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_5-15'])/25)+math.ceil(len(joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_16-30'])/25)+math.ceil(len(joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_31-60'])/25)+math.ceil(len(joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_61-100'])/25)+math.ceil(len(joy_mz_ad_nonnull_buckets['joy_mz_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_mz_ad_nonnull_buckets.keys())\n",
    "joy_mz_ad_nonnull_api = []\n",
    "input_tokens_joy_mz_ad_nonnull=0\n",
    "output_tokens_joy_mz_ad_nonnull=0\n",
    "start_time_joy_mz_ad = time.time()\n",
    "\n",
    "for key in joy_mz_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_mz_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_mz_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_mz_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_mz_ad_nonnull+=input_tokens\n",
    "    output_tokens_joy_mz_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_mz_ad = time.time() - start_time_joy_mz_ad\n",
    "formatted_time_joy_mz_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_mz_ad))\n",
    "input_token_cost_joy_mz_ad = round((0.01/1000) * input_tokens_joy_mz_ad_nonnull, 2)\n",
    "output_token_cost_joy_mz_ad = round((0.03/1000) * output_tokens_joy_mz_ad_nonnull, 2)\n",
    "total_cost_joy_mz_ad = round(input_token_cost_joy_mz_ad + output_token_cost_joy_mz_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_mz_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_mz_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_mz_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_mz_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_mz_ad}\")\n",
    "print(f\"Total Cost = {total_cost_joy_mz_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b5b81597-dbf1-4c6c-b7a5-67ffad137ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:48:32.763818Z",
     "iopub.status.busy": "2025-06-11T04:48:32.763548Z",
     "iopub.status.idle": "2025-06-11T04:48:32.767534Z",
     "shell.execute_reply": "2025-06-11T04:48:32.766991Z",
     "shell.execute_reply.started": "2025-06-11T04:48:32.763800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_mz_ad_nonnull_api & convert to DataFrame\n",
    "joy_mz_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_mz_ad_nonnull_api\n",
    "]                                  \n",
    "joy_mz_ad_nonnull_api_cleaned_df = pd.DataFrame(joy_mz_ad_nonnull_api_cleaned)\n",
    "#joy_mz_ad_nonnull_api_cleaned_df = pd.DataFrame(joy_mz_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f518892d-4d9e-4203-991c-912fc6e58563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:48:32.768382Z",
     "iopub.status.busy": "2025-06-11T04:48:32.768120Z",
     "iopub.status.idle": "2025-06-11T04:48:32.775586Z",
     "shell.execute_reply": "2025-06-11T04:48:32.775025Z",
     "shell.execute_reply.started": "2025-06-11T04:48:32.768363Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_mz_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_mz_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_mz_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4bdf8-ac26-4794-9965-747ad5d2aaa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_mz_ad_nonnull_api_cleaned_df.to_excel(\"joy_mz_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b36712-64b8-425e-9384-a6c849774b30",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_mz_ad_nonnull_api_cleaned_df = pd.read_excel(\"joy_mz_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc166b8-028c-4fb5-bbce-5f3c6f70b69f",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_mz_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14c47767-c9d6-4e6f-84ff-786fd932e80a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:48:32.777319Z",
     "iopub.status.busy": "2025-06-11T04:48:32.776811Z",
     "iopub.status.idle": "2025-06-11T04:48:32.969262Z",
     "shell.execute_reply": "2025-06-11T04:48:32.968758Z",
     "shell.execute_reply.started": "2025-06-11T04:48:32.777299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_mz_ad_nonnull_sen_df = pd.DataFrame(processed_data_joy_mz_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_mz_ad_nonnull_sen_df = joy_mz_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_mz_ad_nonnull_merged_df = pd.concat([combined_df_joy_mz_ad, joy_mz_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_mz_ad_final_sen_df = pd.concat([joy_mz_ad_nonnull_merged_df,null_dataframes['joy_mz_ad_null']], ignore_index=True)\n",
    "\n",
    "joy_mz_ad_final_sen_df_copy = joy_mz_ad_final_sen_df.copy()\n",
    "joy_mz_ad_final_sen_df_copy[\"Published At Date\"] = joy_mz_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_mz_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_mz_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a3fec-7195-4cb2-bc40-d566d7de756f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_sh_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "739b7d35-cb87-4c8d-91ba-c46e4b372860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:48:49.294839Z",
     "iopub.status.busy": "2025-06-11T04:48:49.294328Z",
     "iopub.status.idle": "2025-06-11T04:49:11.365300Z",
     "shell.execute_reply": "2025-06-11T04:49:11.364717Z",
     "shell.execute_reply.started": "2025-06-11T04:48:49.294814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:22\n",
      "Total Input Tokens - 4715\n",
      "Total Input Cost = 0.05\n",
      "Total Output Tokens - 1346\n",
      "Total Output Cost = 0.04\n",
      "Total Cost = 0.09\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_1-4'])/25)+math.ceil(len(joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_5-15'])/25)+math.ceil(len(joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_16-30'])/25)+math.ceil(len(joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_31-60'])/25)+math.ceil(len(joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_61-100'])/25)+math.ceil(len(joy_sh_ad_nonnull_buckets['joy_sh_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_sh_ad_nonnull_buckets.keys())\n",
    "joy_sh_ad_nonnull_api = []\n",
    "input_tokens_joy_sh_ad_nonnull=0\n",
    "output_tokens_joy_sh_ad_nonnull=0\n",
    "start_time_joy_sh_ad = time.time()\n",
    "\n",
    "for key in joy_sh_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_sh_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_sh_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_sh_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_sh_ad_nonnull+=input_tokens\n",
    "    output_tokens_joy_sh_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_sh_ad = time.time() - start_time_joy_sh_ad\n",
    "formatted_time_joy_sh_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_sh_ad))\n",
    "input_token_cost_joy_sh_ad = round((0.01/1000) * input_tokens_joy_sh_ad_nonnull, 2)\n",
    "output_token_cost_joy_sh_ad = round((0.03/1000) * output_tokens_joy_sh_ad_nonnull, 2)\n",
    "total_cost_joy_sh_ad = round(input_token_cost_joy_sh_ad + output_token_cost_joy_sh_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_sh_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_sh_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_sh_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_sh_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_sh_ad}\")\n",
    "print(f\"Total Cost = {total_cost_joy_sh_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "73878fab-89de-4595-99e5-0b278f89f40f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:49:11.366755Z",
     "iopub.status.busy": "2025-06-11T04:49:11.366416Z",
     "iopub.status.idle": "2025-06-11T04:49:11.370441Z",
     "shell.execute_reply": "2025-06-11T04:49:11.369933Z",
     "shell.execute_reply.started": "2025-06-11T04:49:11.366733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_sh_ad_nonnull_api & convert to DataFrame\n",
    "joy_sh_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_sh_ad_nonnull_api\n",
    "]                                  \n",
    "joy_sh_ad_nonnull_api_cleaned_df = pd.DataFrame(joy_sh_ad_nonnull_api_cleaned)\n",
    "#joy_sh_ad_nonnull_api_cleaned_df = pd.DataFrame(joy_sh_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd79669b-79cd-4bb3-acbe-b57519d3ebad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:49:11.371308Z",
     "iopub.status.busy": "2025-06-11T04:49:11.371070Z",
     "iopub.status.idle": "2025-06-11T04:49:11.377852Z",
     "shell.execute_reply": "2025-06-11T04:49:11.377370Z",
     "shell.execute_reply.started": "2025-06-11T04:49:11.371286Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_sh_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_sh_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_sh_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f3671-fd3e-4963-b248-efd002d42bd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_sh_ad_nonnull_api_cleaned_df.to_excel(\"joy_sh_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d11810-37dc-43a1-9a3a-c129ee6e708e",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_sh_ad_nonnull_api_cleaned_df = pd.read_excel(\"joy_sh_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e31aae-1505-417c-8d8c-d23b25fd4981",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_sh_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ef4a9260-3e3c-40f5-a394-0c1bc15836ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:49:11.378951Z",
     "iopub.status.busy": "2025-06-11T04:49:11.378722Z",
     "iopub.status.idle": "2025-06-11T04:49:11.425683Z",
     "shell.execute_reply": "2025-06-11T04:49:11.425258Z",
     "shell.execute_reply.started": "2025-06-11T04:49:11.378934Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_sh_ad_nonnull_sen_df = pd.DataFrame(processed_data_joy_sh_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_sh_ad_nonnull_sen_df = joy_sh_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_sh_ad_nonnull_merged_df = pd.concat([combined_df_joy_sh_ad, joy_sh_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_sh_ad_final_sen_df = pd.concat([joy_sh_ad_nonnull_merged_df,null_dataframes['joy_sh_ad_null']], ignore_index=True)\n",
    "\n",
    "joy_sh_ad_final_sen_df_copy = joy_sh_ad_final_sen_df.copy()\n",
    "joy_sh_ad_final_sen_df_copy[\"Published At Date\"] = joy_sh_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_sh_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_sh_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591e353-8229-4b4e-b444-0b95b46f61f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "134b8c97-e722-48af-9787-c5a1f3df8314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:49:29.653622Z",
     "iopub.status.busy": "2025-06-11T04:49:29.653294Z",
     "iopub.status.idle": "2025-06-11T04:50:00.738128Z",
     "shell.execute_reply": "2025-06-11T04:50:00.737599Z",
     "shell.execute_reply.started": "2025-06-11T04:49:29.653601Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [7] Iterations\n",
      "Total Execution Time: 00:00:31\n",
      "Total Input Tokens - 7985\n",
      "Total Input Cost = 0.08\n",
      "Total Output Tokens - 2657\n",
      "Total Output Cost = 0.08\n",
      "Total Cost = 0.16\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_sc_nonnull_buckets['mal_sc_nonnull_1-4'])/25)+math.ceil(len(mal_sc_nonnull_buckets['mal_sc_nonnull_5-15'])/25)+math.ceil(len(mal_sc_nonnull_buckets['mal_sc_nonnull_16-30'])/25)+math.ceil(len(mal_sc_nonnull_buckets['mal_sc_nonnull_31-60'])/25)+math.ceil(len(mal_sc_nonnull_buckets['mal_sc_nonnull_61-100'])/25)+math.ceil(len(mal_sc_nonnull_buckets['mal_sc_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_sc_nonnull_buckets.keys())\n",
    "mal_sc_nonnull_api = []\n",
    "input_tokens_mal_sc_nonnull=0\n",
    "output_tokens_mal_sc_nonnull=0\n",
    "start_time_mal_sc = time.time()\n",
    "\n",
    "for key in mal_sc_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_sc_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_sc, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_sc_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_sc_nonnull+=input_tokens\n",
    "    output_tokens_mal_sc_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_sc = time.time() - start_time_mal_sc\n",
    "formatted_time_mal_sc = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_sc))\n",
    "input_token_cost_mal_sc = round((0.01/1000) * input_tokens_mal_sc_nonnull, 2)\n",
    "output_token_cost_mal_sc = round((0.03/1000) * output_tokens_mal_sc_nonnull, 2)\n",
    "total_cost_mal_sc = round(input_token_cost_mal_sc + output_token_cost_mal_sc, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_sc}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_sc_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_sc}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_sc_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_sc}\")\n",
    "print(f\"Total Cost = {total_cost_mal_sc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5d77062b-2295-4b98-8b51-79cf9bb5f419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:50:00.739564Z",
     "iopub.status.busy": "2025-06-11T04:50:00.739225Z",
     "iopub.status.idle": "2025-06-11T04:50:00.743660Z",
     "shell.execute_reply": "2025-06-11T04:50:00.743163Z",
     "shell.execute_reply.started": "2025-06-11T04:50:00.739542Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_sc_nonnull_api & convert to DataFrame\n",
    "mal_sc_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_sc_nonnull_api\n",
    "]                                  \n",
    "mal_sc_nonnull_api_cleaned_df = pd.DataFrame(mal_sc_nonnull_api_cleaned)\n",
    "#mal_sc_nonnull_api_cleaned_df = pd.DataFrame(mal_sc_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "81d4c11d-4c28-4f59-8aef-d3feca6479cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:50:00.744764Z",
     "iopub.status.busy": "2025-06-11T04:50:00.744428Z",
     "iopub.status.idle": "2025-06-11T04:50:00.750738Z",
     "shell.execute_reply": "2025-06-11T04:50:00.750270Z",
     "shell.execute_reply.started": "2025-06-11T04:50:00.744738Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_sc_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_sc_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_sc_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb34518-e06c-4c19-b1d4-cf0322cc666f",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_sc_nonnull_api_cleaned_df.to_excel(\"mal_sc_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad753f8-bb0d-473f-a9c8-a997eafdcf71",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_sc_nonnull_api_cleaned_df = pd.read_excel(\"mal_sc_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747f21b-cc78-4cdd-810f-d6a279313e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_sc_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "56f46ecc-1b75-4177-925a-a95e40938c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:50:00.751813Z",
     "iopub.status.busy": "2025-06-11T04:50:00.751561Z",
     "iopub.status.idle": "2025-06-11T04:50:00.809142Z",
     "shell.execute_reply": "2025-06-11T04:50:00.808612Z",
     "shell.execute_reply.started": "2025-06-11T04:50:00.751795Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_sc_nonnull_sen_df = pd.DataFrame(processed_data_mal_sc_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_sc_nonnull_sen_df = mal_sc_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_sc_nonnull_merged_df = pd.concat([combined_df_mal_sc, mal_sc_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_sc_final_sen_df = pd.concat([mal_sc_nonnull_merged_df,null_dataframes['mal_sc_null']], ignore_index=True)\n",
    "\n",
    "mal_sc_final_sen_df_copy = mal_sc_final_sen_df.copy()\n",
    "mal_sc_final_sen_df_copy[\"Published At Date\"] = mal_sc_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_sc_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_sc_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2325de4-4d2c-4f7b-b251-e5eabe224c5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "15670864-f992-4e73-9587-3f3007b34ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:50:05.856158Z",
     "iopub.status.busy": "2025-06-11T04:50:05.855809Z",
     "iopub.status.idle": "2025-06-11T04:51:58.077927Z",
     "shell.execute_reply": "2025-06-11T04:51:58.077369Z",
     "shell.execute_reply.started": "2025-06-11T04:50:05.856135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [15] Iterations\n",
      "Total Execution Time: 00:01:52\n",
      "Total Input Tokens - 20099\n",
      "Total Input Cost = 0.2\n",
      "Total Output Tokens - 8928\n",
      "Total Output Cost = 0.27\n",
      "Total Cost = 0.47\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_ab_nonnull_buckets['mal_ab_nonnull_1-4'])/25)+math.ceil(len(mal_ab_nonnull_buckets['mal_ab_nonnull_5-15'])/25)+math.ceil(len(mal_ab_nonnull_buckets['mal_ab_nonnull_16-30'])/25)+math.ceil(len(mal_ab_nonnull_buckets['mal_ab_nonnull_31-60'])/25)+math.ceil(len(mal_ab_nonnull_buckets['mal_ab_nonnull_61-100'])/25)+math.ceil(len(mal_ab_nonnull_buckets['mal_ab_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_ab_nonnull_buckets.keys())\n",
    "mal_ab_nonnull_api = []\n",
    "input_tokens_mal_ab_nonnull=0\n",
    "output_tokens_mal_ab_nonnull=0\n",
    "start_time_mal_ab = time.time()\n",
    "\n",
    "for key in mal_ab_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_ab_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_ab, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_ab_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_ab_nonnull+=input_tokens\n",
    "    output_tokens_mal_ab_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_ab = time.time() - start_time_mal_ab\n",
    "formatted_time_mal_ab = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_ab))\n",
    "input_token_cost_mal_ab = round((0.01/1000) * input_tokens_mal_ab_nonnull, 2)\n",
    "output_token_cost_mal_ab = round((0.03/1000) * output_tokens_mal_ab_nonnull, 2)\n",
    "total_cost_mal_ab = round(input_token_cost_mal_ab + output_token_cost_mal_ab, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_ab}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_ab_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_ab}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_ab_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_ab}\")\n",
    "print(f\"Total Cost = {total_cost_mal_ab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0885bc8e-4def-41f5-a52b-edcf5eb5dc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:51:58.078963Z",
     "iopub.status.busy": "2025-06-11T04:51:58.078754Z",
     "iopub.status.idle": "2025-06-11T04:51:58.083069Z",
     "shell.execute_reply": "2025-06-11T04:51:58.082577Z",
     "shell.execute_reply.started": "2025-06-11T04:51:58.078946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_ab_nonnull_api & convert to DataFrame\n",
    "mal_ab_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_ab_nonnull_api\n",
    "]                                  \n",
    "mal_ab_nonnull_api_cleaned_df = pd.DataFrame(mal_ab_nonnull_api_cleaned)\n",
    "#mal_ab_nonnull_api_cleaned_df = pd.DataFrame(mal_ab_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6871894a-13e5-4911-929d-50830d883823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:51:58.084102Z",
     "iopub.status.busy": "2025-06-11T04:51:58.083846Z",
     "iopub.status.idle": "2025-06-11T04:51:58.092218Z",
     "shell.execute_reply": "2025-06-11T04:51:58.091697Z",
     "shell.execute_reply.started": "2025-06-11T04:51:58.084083Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_ab_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_ab_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_ab_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97accfb9-4b6e-4d74-ab40-d3081dee4e9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ab_nonnull_api_cleaned_df.to_excel(\"mal_ab_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd01b91-e72e-4260-bf19-a65abe5c8dff",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ab_nonnull_api_cleaned_df = pd.read_excel(\"mal_ab_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dca2e5-07dd-4f76-b6d0-22936b64bf15",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ab_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9c18c04f-e7ba-4bd1-9475-8000dcbed36b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:51:58.093333Z",
     "iopub.status.busy": "2025-06-11T04:51:58.093085Z",
     "iopub.status.idle": "2025-06-11T04:51:58.201801Z",
     "shell.execute_reply": "2025-06-11T04:51:58.201333Z",
     "shell.execute_reply.started": "2025-06-11T04:51:58.093316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_ab_nonnull_sen_df = pd.DataFrame(processed_data_mal_ab_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_ab_nonnull_sen_df = mal_ab_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_ab_nonnull_merged_df = pd.concat([combined_df_mal_ab, mal_ab_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_ab_final_sen_df = pd.concat([mal_ab_nonnull_merged_df,null_dataframes['mal_ab_null']], ignore_index=True)\n",
    "\n",
    "mal_ab_final_sen_df_copy = mal_ab_final_sen_df.copy()\n",
    "mal_ab_final_sen_df_copy[\"Published At Date\"] = mal_ab_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_ab_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_ab_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a994d-37cb-42b1-8eb9-c148a87f4588",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b1_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "112190a1-7b8b-458b-940d-a1d233291a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:52:08.719266Z",
     "iopub.status.busy": "2025-06-11T04:52:08.718961Z",
     "iopub.status.idle": "2025-06-11T04:53:27.886936Z",
     "shell.execute_reply": "2025-06-11T04:53:27.886402Z",
     "shell.execute_reply.started": "2025-06-11T04:52:08.719245Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [13] Iterations\n",
      "Total Execution Time: 00:01:19\n",
      "Total Input Tokens - 14895\n",
      "Total Input Cost = 0.15\n",
      "Total Output Tokens - 6938\n",
      "Total Output Cost = 0.21\n",
      "Total Cost = 0.36\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_1-4'])/25)+math.ceil(len(mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_5-15'])/25)+math.ceil(len(mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_16-30'])/25)+math.ceil(len(mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_31-60'])/25)+math.ceil(len(mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_61-100'])/25)+math.ceil(len(mal_b1_af_nonnull_buckets['mal_b1_af_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_b1_af_nonnull_buckets.keys())\n",
    "mal_b1_af_nonnull_api = []\n",
    "input_tokens_mal_b1_af_nonnull=0\n",
    "output_tokens_mal_b1_af_nonnull=0\n",
    "start_time_mal_b1_af = time.time()\n",
    "\n",
    "for key in mal_b1_af_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_b1_af_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_b1_af, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_b1_af_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_b1_af_nonnull+=input_tokens\n",
    "    output_tokens_mal_b1_af_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_b1_af = time.time() - start_time_mal_b1_af\n",
    "formatted_time_mal_b1_af = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_b1_af))\n",
    "input_token_cost_mal_b1_af = round((0.01/1000) * input_tokens_mal_b1_af_nonnull, 2)\n",
    "output_token_cost_mal_b1_af = round((0.03/1000) * output_tokens_mal_b1_af_nonnull, 2)\n",
    "total_cost_mal_b1_af = round(input_token_cost_mal_b1_af + output_token_cost_mal_b1_af, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_b1_af}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_b1_af_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_b1_af}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_b1_af_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_b1_af}\")\n",
    "print(f\"Total Cost = {total_cost_mal_b1_af}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ac877957-7a05-4f55-9d48-4c9f777f168b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:53:27.888193Z",
     "iopub.status.busy": "2025-06-11T04:53:27.887913Z",
     "iopub.status.idle": "2025-06-11T04:53:27.891942Z",
     "shell.execute_reply": "2025-06-11T04:53:27.891405Z",
     "shell.execute_reply.started": "2025-06-11T04:53:27.888173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_b1_af_nonnull_api & convert to DataFrame\n",
    "mal_b1_af_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_b1_af_nonnull_api\n",
    "]                                  \n",
    "mal_b1_af_nonnull_api_cleaned_df = pd.DataFrame(mal_b1_af_nonnull_api_cleaned)\n",
    "#mal_b1_af_nonnull_api_cleaned_df = pd.DataFrame(mal_b1_af_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "83579898-e602-478c-bf1b-dd066f4e1802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:53:27.892995Z",
     "iopub.status.busy": "2025-06-11T04:53:27.892675Z",
     "iopub.status.idle": "2025-06-11T04:53:27.900721Z",
     "shell.execute_reply": "2025-06-11T04:53:27.900265Z",
     "shell.execute_reply.started": "2025-06-11T04:53:27.892968Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_b1_af_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_b1_af_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_b1_af_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1420b1-669b-420c-a5a7-42fea34a0965",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b1_af_nonnull_api_cleaned_df.to_excel(\"mal_b1_af_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc374e-529e-41b7-b038-0856929ddb1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b1_af_nonnull_api_cleaned_df = pd.read_excel(\"mal_b1_af_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c05e63-3bd5-4f8a-86e7-f002b9cad275",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b1_af_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "de770f65-e87b-457d-83bf-a7539a301e76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:53:27.901874Z",
     "iopub.status.busy": "2025-06-11T04:53:27.901646Z",
     "iopub.status.idle": "2025-06-11T04:53:27.992707Z",
     "shell.execute_reply": "2025-06-11T04:53:27.992263Z",
     "shell.execute_reply.started": "2025-06-11T04:53:27.901853Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_b1_af_nonnull_sen_df = pd.DataFrame(processed_data_mal_b1_af_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_b1_af_nonnull_sen_df = mal_b1_af_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_b1_af_nonnull_merged_df = pd.concat([combined_df_mal_b1_af, mal_b1_af_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_b1_af_final_sen_df = pd.concat([mal_b1_af_nonnull_merged_df,null_dataframes['mal_b1_af_null']], ignore_index=True)\n",
    "\n",
    "mal_b1_af_final_sen_df_copy = mal_b1_af_final_sen_df.copy()\n",
    "mal_b1_af_final_sen_df_copy[\"Published At Date\"] = mal_b1_af_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_b1_af_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_b1_af_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50562c-ba40-4e77-b9f4-05d8b1a7fb8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a3e556f0-bcbc-47a7-9a44-4a92d21addea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:53:38.879400Z",
     "iopub.status.busy": "2025-06-11T04:53:38.879055Z",
     "iopub.status.idle": "2025-06-11T04:56:35.204639Z",
     "shell.execute_reply": "2025-06-11T04:56:35.204078Z",
     "shell.execute_reply.started": "2025-06-11T04:53:38.879374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [24] Iterations\n",
      "Total Execution Time: 00:02:56\n",
      "Total Input Tokens - 31930\n",
      "Total Input Cost = 0.32\n",
      "Total Output Tokens - 14028\n",
      "Total Output Cost = 0.42\n",
      "Total Cost = 0.74\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_ak_nonnull_buckets['mal_ak_nonnull_1-4'])/25)+math.ceil(len(mal_ak_nonnull_buckets['mal_ak_nonnull_5-15'])/25)+math.ceil(len(mal_ak_nonnull_buckets['mal_ak_nonnull_16-30'])/25)+math.ceil(len(mal_ak_nonnull_buckets['mal_ak_nonnull_31-60'])/25)+math.ceil(len(mal_ak_nonnull_buckets['mal_ak_nonnull_61-100'])/25)+math.ceil(len(mal_ak_nonnull_buckets['mal_ak_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_ak_nonnull_buckets.keys())\n",
    "mal_ak_nonnull_api = []\n",
    "input_tokens_mal_ak_nonnull=0\n",
    "output_tokens_mal_ak_nonnull=0\n",
    "start_time_mal_ak = time.time()\n",
    "\n",
    "for key in mal_ak_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_ak_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_ak, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_ak_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_ak_nonnull+=input_tokens\n",
    "    output_tokens_mal_ak_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_ak = time.time() - start_time_mal_ak\n",
    "formatted_time_mal_ak = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_ak))\n",
    "input_token_cost_mal_ak = round((0.01/1000) * input_tokens_mal_ak_nonnull, 2)\n",
    "output_token_cost_mal_ak = round((0.03/1000) * output_tokens_mal_ak_nonnull, 2)\n",
    "total_cost_mal_ak = round(input_token_cost_mal_ak + output_token_cost_mal_ak, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_ak}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_ak_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_ak}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_ak_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_ak}\")\n",
    "print(f\"Total Cost = {total_cost_mal_ak}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a5b99e40-446d-4090-9663-cb6369d621b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:56:35.205830Z",
     "iopub.status.busy": "2025-06-11T04:56:35.205579Z",
     "iopub.status.idle": "2025-06-11T04:56:35.209743Z",
     "shell.execute_reply": "2025-06-11T04:56:35.209261Z",
     "shell.execute_reply.started": "2025-06-11T04:56:35.205812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_ak_nonnull_api & convert to DataFrame\n",
    "mal_ak_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_ak_nonnull_api\n",
    "]                                  \n",
    "mal_ak_nonnull_api_cleaned_df = pd.DataFrame(mal_ak_nonnull_api_cleaned)\n",
    "#mal_ak_nonnull_api_cleaned_df = pd.DataFrame(mal_ak_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c14f8edd-fa4d-48fb-b995-557b58c7db05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:56:35.210683Z",
     "iopub.status.busy": "2025-06-11T04:56:35.210406Z",
     "iopub.status.idle": "2025-06-11T04:56:35.221158Z",
     "shell.execute_reply": "2025-06-11T04:56:35.220653Z",
     "shell.execute_reply.started": "2025-06-11T04:56:35.210657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_ak_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_ak_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_ak_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc35b9-7e33-4a79-afc9-fe409e1805cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ak_nonnull_api_cleaned_df.to_excel(\"mal_ak_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e4476-3f6f-4e8d-a9c4-93e4390cdf48",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ak_nonnull_api_cleaned_df = pd.read_excel(\"mal_ak_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4f22e-5f06-471d-b130-cac46718d59a",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ak_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d5101913-b510-41bf-a2cd-da7840f5e94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:56:35.222327Z",
     "iopub.status.busy": "2025-06-11T04:56:35.222097Z",
     "iopub.status.idle": "2025-06-11T04:56:35.391045Z",
     "shell.execute_reply": "2025-06-11T04:56:35.390518Z",
     "shell.execute_reply.started": "2025-06-11T04:56:35.222310Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_ak_nonnull_sen_df = pd.DataFrame(processed_data_mal_ak_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_ak_nonnull_sen_df = mal_ak_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_ak_nonnull_merged_df = pd.concat([combined_df_mal_ak, mal_ak_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_ak_final_sen_df = pd.concat([mal_ak_nonnull_merged_df,null_dataframes['mal_ak_null']], ignore_index=True)\n",
    "\n",
    "mal_ak_final_sen_df_copy = mal_ak_final_sen_df.copy()\n",
    "mal_ak_final_sen_df_copy[\"Published At Date\"] = mal_ak_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_ak_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_ak_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e019862-deb8-4590-a14d-5bbb94553b33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_aw_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5374bdfb-02a0-4f48-91eb-f11e2e9c004d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:57:02.419482Z",
     "iopub.status.busy": "2025-06-11T04:57:02.419156Z",
     "iopub.status.idle": "2025-06-11T04:57:35.507274Z",
     "shell.execute_reply": "2025-06-11T04:57:35.506766Z",
     "shell.execute_reply.started": "2025-06-11T04:57:02.419459Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [8] Iterations\n",
      "Total Execution Time: 00:00:33\n",
      "Total Input Tokens - 8215\n",
      "Total Input Cost = 0.08\n",
      "Total Output Tokens - 3052\n",
      "Total Output Cost = 0.09\n",
      "Total Cost = 0.17\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_1-4'])/25)+math.ceil(len(mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_5-15'])/25)+math.ceil(len(mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_16-30'])/25)+math.ceil(len(mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_31-60'])/25)+math.ceil(len(mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_61-100'])/25)+math.ceil(len(mal_aw_ad_nonnull_buckets['mal_aw_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_aw_ad_nonnull_buckets.keys())\n",
    "mal_aw_ad_nonnull_api = []\n",
    "input_tokens_mal_aw_ad_nonnull=0\n",
    "output_tokens_mal_aw_ad_nonnull=0\n",
    "start_time_mal_aw_ad = time.time()\n",
    "\n",
    "for key in mal_aw_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_aw_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_aw_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_aw_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_aw_ad_nonnull+=input_tokens\n",
    "    output_tokens_mal_aw_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_aw_ad = time.time() - start_time_mal_aw_ad\n",
    "formatted_time_mal_aw_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_aw_ad))\n",
    "input_token_cost_mal_aw_ad = round((0.01/1000) * input_tokens_mal_aw_ad_nonnull, 2)\n",
    "output_token_cost_mal_aw_ad = round((0.03/1000) * output_tokens_mal_aw_ad_nonnull, 2)\n",
    "total_cost_mal_aw_ad = round(input_token_cost_mal_aw_ad + output_token_cost_mal_aw_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_aw_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_aw_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_aw_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_aw_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_aw_ad}\")\n",
    "print(f\"Total Cost = {total_cost_mal_aw_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "51d54ff5-0f96-49f2-abee-84c04855dd12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:57:35.508407Z",
     "iopub.status.busy": "2025-06-11T04:57:35.508137Z",
     "iopub.status.idle": "2025-06-11T04:57:35.511947Z",
     "shell.execute_reply": "2025-06-11T04:57:35.511451Z",
     "shell.execute_reply.started": "2025-06-11T04:57:35.508389Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_aw_ad_nonnull_api & convert to DataFrame\n",
    "mal_aw_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_aw_ad_nonnull_api\n",
    "]                                  \n",
    "mal_aw_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_aw_ad_nonnull_api_cleaned)\n",
    "#mal_aw_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_aw_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8173eb81-1ac6-4574-84c9-1ab36dafb6cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:57:35.512843Z",
     "iopub.status.busy": "2025-06-11T04:57:35.512602Z",
     "iopub.status.idle": "2025-06-11T04:57:35.519683Z",
     "shell.execute_reply": "2025-06-11T04:57:35.519241Z",
     "shell.execute_reply.started": "2025-06-11T04:57:35.512820Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_aw_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_aw_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_aw_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31446ee-8b67-45e6-be00-01a0181946d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_aw_ad_nonnull_api_cleaned_df.to_excel(\"mal_aw_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f08c6-e126-4684-862f-54a3289c5497",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_aw_ad_nonnull_api_cleaned_df = pd.read_excel(\"mal_aw_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df790a-62e9-422e-ac9e-094dd00477d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_aw_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1d0f1a1c-2a5c-48bb-8033-0a9182f67691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:57:35.520802Z",
     "iopub.status.busy": "2025-06-11T04:57:35.520564Z",
     "iopub.status.idle": "2025-06-11T04:57:35.587806Z",
     "shell.execute_reply": "2025-06-11T04:57:35.587320Z",
     "shell.execute_reply.started": "2025-06-11T04:57:35.520784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_aw_ad_nonnull_sen_df = pd.DataFrame(processed_data_mal_aw_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_aw_ad_nonnull_sen_df = mal_aw_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_aw_ad_nonnull_merged_df = pd.concat([combined_df_mal_aw_ad, mal_aw_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_aw_ad_final_sen_df = pd.concat([mal_aw_ad_nonnull_merged_df,null_dataframes['mal_aw_ad_null']], ignore_index=True)\n",
    "\n",
    "mal_aw_ad_final_sen_df_copy = mal_aw_ad_final_sen_df.copy()\n",
    "mal_aw_ad_final_sen_df_copy[\"Published At Date\"] = mal_aw_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_aw_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_aw_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10016cca-d75e-4322-835a-8508036fe312",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_dm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "689dcdc2-9c7c-4c38-ac56-7b13087938c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:57:46.099205Z",
     "iopub.status.busy": "2025-06-11T04:57:46.098847Z",
     "iopub.status.idle": "2025-06-11T04:59:57.352282Z",
     "shell.execute_reply": "2025-06-11T04:59:57.351731Z",
     "shell.execute_reply.started": "2025-06-11T04:57:46.099168Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [20] Iterations\n",
      "Total Execution Time: 00:02:11\n",
      "Total Input Tokens - 22903\n",
      "Total Input Cost = 0.23\n",
      "Total Output Tokens - 11351\n",
      "Total Output Cost = 0.34\n",
      "Total Cost = 0.57\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_1-4'])/25)+math.ceil(len(mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_5-15'])/25)+math.ceil(len(mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_16-30'])/25)+math.ceil(len(mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_31-60'])/25)+math.ceil(len(mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_61-100'])/25)+math.ceil(len(mal_dm_ad_nonnull_buckets['mal_dm_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_dm_ad_nonnull_buckets.keys())\n",
    "mal_dm_ad_nonnull_api = []\n",
    "input_tokens_mal_dm_ad_nonnull=0\n",
    "output_tokens_mal_dm_ad_nonnull=0\n",
    "start_time_mal_dm_ad = time.time()\n",
    "\n",
    "for key in mal_dm_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_dm_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_dm_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_dm_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_dm_ad_nonnull+=input_tokens\n",
    "    output_tokens_mal_dm_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_dm_ad = time.time() - start_time_mal_dm_ad\n",
    "formatted_time_mal_dm_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_dm_ad))\n",
    "input_token_cost_mal_dm_ad = round((0.01/1000) * input_tokens_mal_dm_ad_nonnull, 2)\n",
    "output_token_cost_mal_dm_ad = round((0.03/1000) * output_tokens_mal_dm_ad_nonnull, 2)\n",
    "total_cost_mal_dm_ad = round(input_token_cost_mal_dm_ad + output_token_cost_mal_dm_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_dm_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_dm_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_dm_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_dm_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_dm_ad}\")\n",
    "print(f\"Total Cost = {total_cost_mal_dm_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "68ddc16c-6b71-485f-976a-fd14291600e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:59:57.353696Z",
     "iopub.status.busy": "2025-06-11T04:59:57.353404Z",
     "iopub.status.idle": "2025-06-11T04:59:57.357359Z",
     "shell.execute_reply": "2025-06-11T04:59:57.356832Z",
     "shell.execute_reply.started": "2025-06-11T04:59:57.353677Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_dm_ad_nonnull_api & convert to DataFrame\n",
    "mal_dm_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_dm_ad_nonnull_api\n",
    "]                                  \n",
    "mal_dm_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_dm_ad_nonnull_api_cleaned)\n",
    "#mal_dm_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_dm_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c3f1a635-1ba5-4ac8-8d1a-f724673bd801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:59:57.358244Z",
     "iopub.status.busy": "2025-06-11T04:59:57.357993Z",
     "iopub.status.idle": "2025-06-11T04:59:57.368488Z",
     "shell.execute_reply": "2025-06-11T04:59:57.367942Z",
     "shell.execute_reply.started": "2025-06-11T04:59:57.358227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_dm_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_dm_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_dm_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775d9ad-f017-41f2-95ab-9636ed7e41ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_dm_ad_nonnull_api_cleaned_df.to_excel(\"mal_dm_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8d3f9-0d9f-4efc-bbe3-d969b4c1d924",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_dm_ad_nonnull_api_cleaned_df = pd.read_excel(\"mal_dm_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed07436-6b01-4fae-aa8c-57f5f3815f54",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_dm_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d6af5e8-db47-4abc-a54a-7a5b3ea8e9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:59:57.369624Z",
     "iopub.status.busy": "2025-06-11T04:59:57.369385Z",
     "iopub.status.idle": "2025-06-11T04:59:57.505726Z",
     "shell.execute_reply": "2025-06-11T04:59:57.505246Z",
     "shell.execute_reply.started": "2025-06-11T04:59:57.369607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_dm_ad_nonnull_sen_df = pd.DataFrame(processed_data_mal_dm_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_dm_ad_nonnull_sen_df = mal_dm_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_dm_ad_nonnull_merged_df = pd.concat([combined_df_mal_dm_ad, mal_dm_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_dm_ad_final_sen_df = pd.concat([mal_dm_ad_nonnull_merged_df,null_dataframes['mal_dm_ad_null']], ignore_index=True)\n",
    "\n",
    "mal_dm_ad_final_sen_df_copy = mal_dm_ad_final_sen_df.copy()\n",
    "mal_dm_ad_final_sen_df_copy[\"Published At Date\"] = mal_dm_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_dm_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_dm_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055abcbb-e6b2-4fbd-8178-f594511d24a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b1_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6eb96ad1-76ef-4de2-91a0-75d0f2a7e2b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:00:06.779398Z",
     "iopub.status.busy": "2025-06-11T05:00:06.779089Z",
     "iopub.status.idle": "2025-06-11T05:01:31.949611Z",
     "shell.execute_reply": "2025-06-11T05:01:31.949074Z",
     "shell.execute_reply.started": "2025-06-11T05:00:06.779377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [13] Iterations\n",
      "Total Execution Time: 00:01:25\n",
      "Total Input Tokens - 14273\n",
      "Total Input Cost = 0.14\n",
      "Total Output Tokens - 6555\n",
      "Total Output Cost = 0.2\n",
      "Total Cost = 0.34\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_1-4'])/25)+math.ceil(len(mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_5-15'])/25)+math.ceil(len(mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_16-30'])/25)+math.ceil(len(mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_31-60'])/25)+math.ceil(len(mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_61-100'])/25)+math.ceil(len(mal_b1_ad_nonnull_buckets['mal_b1_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_b1_ad_nonnull_buckets.keys())\n",
    "mal_b1_ad_nonnull_api = []\n",
    "input_tokens_mal_b1_ad_nonnull=0\n",
    "output_tokens_mal_b1_ad_nonnull=0\n",
    "start_time_mal_b1_ad = time.time()\n",
    "\n",
    "for key in mal_b1_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_b1_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_b1_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_b1_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_b1_ad_nonnull+=input_tokens\n",
    "    output_tokens_mal_b1_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_b1_ad = time.time() - start_time_mal_b1_ad\n",
    "formatted_time_mal_b1_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_b1_ad))\n",
    "input_token_cost_mal_b1_ad = round((0.01/1000) * input_tokens_mal_b1_ad_nonnull, 2)\n",
    "output_token_cost_mal_b1_ad = round((0.03/1000) * output_tokens_mal_b1_ad_nonnull, 2)\n",
    "total_cost_mal_b1_ad = round(input_token_cost_mal_b1_ad + output_token_cost_mal_b1_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_b1_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_b1_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_b1_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_b1_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_b1_ad}\")\n",
    "print(f\"Total Cost = {total_cost_mal_b1_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ad5bd2ee-727c-4214-a758-2f98c840dcd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:01:31.950716Z",
     "iopub.status.busy": "2025-06-11T05:01:31.950451Z",
     "iopub.status.idle": "2025-06-11T05:01:31.954444Z",
     "shell.execute_reply": "2025-06-11T05:01:31.953953Z",
     "shell.execute_reply.started": "2025-06-11T05:01:31.950697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_b1_ad_nonnull_api & convert to DataFrame\n",
    "mal_b1_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_b1_ad_nonnull_api\n",
    "]                                  \n",
    "mal_b1_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_b1_ad_nonnull_api_cleaned)\n",
    "#mal_b1_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_b1_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "88b9f3d6-85a0-4420-ab24-2c5066ac6588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:01:31.955271Z",
     "iopub.status.busy": "2025-06-11T05:01:31.955092Z",
     "iopub.status.idle": "2025-06-11T05:01:31.963524Z",
     "shell.execute_reply": "2025-06-11T05:01:31.963017Z",
     "shell.execute_reply.started": "2025-06-11T05:01:31.955256Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_b1_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_b1_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_b1_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f5e88-7132-4d5e-92b1-75ef07eebc43",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b1_ad_nonnull_api_cleaned_df.to_excel(\"mal_b1_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b335f-b067-42ea-a228-a0247f3222b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b1_ad_nonnull_api_cleaned_df = pd.read_excel(\"mal_b1_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a195e-0128-455f-b58d-098ef2d7ffdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b1_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "333b71f8-9bec-4558-9854-2e10fbb9aa63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:01:31.965152Z",
     "iopub.status.busy": "2025-06-11T05:01:31.964798Z",
     "iopub.status.idle": "2025-06-11T05:01:32.056688Z",
     "shell.execute_reply": "2025-06-11T05:01:32.056162Z",
     "shell.execute_reply.started": "2025-06-11T05:01:31.965134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_b1_ad_nonnull_sen_df = pd.DataFrame(processed_data_mal_b1_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_b1_ad_nonnull_sen_df = mal_b1_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_b1_ad_nonnull_merged_df = pd.concat([combined_df_mal_b1_ad, mal_b1_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_b1_ad_final_sen_df = pd.concat([mal_b1_ad_nonnull_merged_df,null_dataframes['mal_b1_ad_null']], ignore_index=True)\n",
    "\n",
    "mal_b1_ad_final_sen_df_copy = mal_b1_ad_final_sen_df.copy()\n",
    "mal_b1_ad_final_sen_df_copy[\"Published At Date\"] = mal_b1_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_b1_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_b1_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91590a4b-03c0-4974-a6fa-181301c858bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b2_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e75afee8-2556-448e-9c95-7d0eb4213a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:01:32.057671Z",
     "iopub.status.busy": "2025-06-11T05:01:32.057416Z",
     "iopub.status.idle": "2025-06-11T05:05:53.525897Z",
     "shell.execute_reply": "2025-06-11T05:05:53.525340Z",
     "shell.execute_reply.started": "2025-06-11T05:01:32.057653Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [33] Iterations\n",
      "Total Execution Time: 00:04:21\n",
      "Total Input Tokens - 44785\n",
      "Total Input Cost = 0.45\n",
      "Total Output Tokens - 21419\n",
      "Total Output Cost = 0.64\n",
      "Total Cost = 1.09\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_1-4'])/25)+math.ceil(len(mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_5-15'])/25)+math.ceil(len(mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_16-30'])/25)+math.ceil(len(mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_31-60'])/25)+math.ceil(len(mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_61-100'])/25)+math.ceil(len(mal_b2_ad_nonnull_buckets['mal_b2_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_b2_ad_nonnull_buckets.keys())\n",
    "mal_b2_ad_nonnull_api = []\n",
    "input_tokens_mal_b2_ad_nonnull=0\n",
    "output_tokens_mal_b2_ad_nonnull=0\n",
    "start_time_mal_b2_ad = time.time()\n",
    "\n",
    "for key in mal_b2_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_b2_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_b2_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_b2_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_b2_ad_nonnull+=input_tokens\n",
    "    output_tokens_mal_b2_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_b2_ad = time.time() - start_time_mal_b2_ad\n",
    "formatted_time_mal_b2_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_b2_ad))\n",
    "input_token_cost_mal_b2_ad = round((0.01/1000) * input_tokens_mal_b2_ad_nonnull, 2)\n",
    "output_token_cost_mal_b2_ad = round((0.03/1000) * output_tokens_mal_b2_ad_nonnull, 2)\n",
    "total_cost_mal_b2_ad = round(input_token_cost_mal_b2_ad + output_token_cost_mal_b2_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_b2_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_b2_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_b2_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_b2_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_b2_ad}\")\n",
    "print(f\"Total Cost = {total_cost_mal_b2_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7e2d1e3f-d4ad-4736-9eb3-510d652b9e9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:05:53.526778Z",
     "iopub.status.busy": "2025-06-11T05:05:53.526585Z",
     "iopub.status.idle": "2025-06-11T05:05:53.530847Z",
     "shell.execute_reply": "2025-06-11T05:05:53.530327Z",
     "shell.execute_reply.started": "2025-06-11T05:05:53.526761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_b2_ad_nonnull_api & convert to DataFrame\n",
    "mal_b2_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_b2_ad_nonnull_api\n",
    "]                                  \n",
    "mal_b2_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_b2_ad_nonnull_api_cleaned)\n",
    "#mal_b2_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_b2_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "83c54bc4-fd1d-4247-86ba-61b4ca8e2053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:05:53.531780Z",
     "iopub.status.busy": "2025-06-11T05:05:53.531526Z",
     "iopub.status.idle": "2025-06-11T05:05:53.543490Z",
     "shell.execute_reply": "2025-06-11T05:05:53.543006Z",
     "shell.execute_reply.started": "2025-06-11T05:05:53.531762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_b2_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_b2_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_b2_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3380ecc-f169-47e2-bea9-56a161ffa5a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b2_ad_nonnull_api_cleaned_df.to_excel(\"mal_b2_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65cc39-5896-4b89-bbf0-585619c32608",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b2_ad_nonnull_api_cleaned_df = pd.read_excel(\"mal_b2_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc2c31-f504-45b6-97b7-406e1355168f",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b2_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1ca6a433-c885-47b1-a9b6-149033f12852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:05:53.544337Z",
     "iopub.status.busy": "2025-06-11T05:05:53.544078Z",
     "iopub.status.idle": "2025-06-11T05:05:53.785295Z",
     "shell.execute_reply": "2025-06-11T05:05:53.784771Z",
     "shell.execute_reply.started": "2025-06-11T05:05:53.544319Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_b2_ad_nonnull_sen_df = pd.DataFrame(processed_data_mal_b2_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_b2_ad_nonnull_sen_df = mal_b2_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_b2_ad_nonnull_merged_df = pd.concat([combined_df_mal_b2_ad, mal_b2_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_b2_ad_final_sen_df = pd.concat([mal_b2_ad_nonnull_merged_df,null_dataframes['mal_b2_ad_null']], ignore_index=True)\n",
    "\n",
    "mal_b2_ad_final_sen_df_copy = mal_b2_ad_final_sen_df.copy()\n",
    "mal_b2_ad_final_sen_df_copy[\"Published At Date\"] = mal_b2_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_b2_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_b2_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abb125-84c5-4b24-ae47-76f738e0c5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d7023f7-e57e-42a3-ad03-fc963c297801",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_lu_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3789289a-589b-4f6e-810d-424145464e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:05:53.787249Z",
     "iopub.status.busy": "2025-06-11T05:05:53.787007Z",
     "iopub.status.idle": "2025-06-11T05:09:47.214640Z",
     "shell.execute_reply": "2025-06-11T05:09:47.214095Z",
     "shell.execute_reply.started": "2025-06-11T05:05:53.787231Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [30] Iterations\n",
      "Total Execution Time: 00:03:53\n",
      "Total Input Tokens - 36066\n",
      "Total Input Cost = 0.36\n",
      "Total Output Tokens - 17852\n",
      "Total Output Cost = 0.54\n",
      "Total Cost = 0.9\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_1-4'])/25)+math.ceil(len(mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_5-15'])/25)+math.ceil(len(mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_16-30'])/25)+math.ceil(len(mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_31-60'])/25)+math.ceil(len(mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_61-100'])/25)+math.ceil(len(mal_lu_ad_nonnull_buckets['mal_lu_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_lu_ad_nonnull_buckets.keys())\n",
    "mal_lu_ad_nonnull_api = []\n",
    "input_tokens_mal_lu_ad_nonnull=0\n",
    "output_tokens_mal_lu_ad_nonnull=0\n",
    "start_time_mal_lu_ad = time.time()\n",
    "\n",
    "for key in mal_lu_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_lu_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_lu_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_lu_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_lu_ad_nonnull+=input_tokens\n",
    "    output_tokens_mal_lu_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_lu_ad = time.time() - start_time_mal_lu_ad\n",
    "formatted_time_mal_lu_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_lu_ad))\n",
    "input_token_cost_mal_lu_ad = round((0.01/1000) * input_tokens_mal_lu_ad_nonnull, 2)\n",
    "output_token_cost_mal_lu_ad = round((0.03/1000) * output_tokens_mal_lu_ad_nonnull, 2)\n",
    "total_cost_mal_lu_ad = round(input_token_cost_mal_lu_ad + output_token_cost_mal_lu_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_lu_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_lu_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_lu_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_lu_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_lu_ad}\")\n",
    "print(f\"Total Cost = {total_cost_mal_lu_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8c8bd9b5-290c-4397-9a8e-5602bd2528df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:09:47.215444Z",
     "iopub.status.busy": "2025-06-11T05:09:47.215245Z",
     "iopub.status.idle": "2025-06-11T05:09:47.219796Z",
     "shell.execute_reply": "2025-06-11T05:09:47.219251Z",
     "shell.execute_reply.started": "2025-06-11T05:09:47.215426Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_lu_ad_nonnull_api & convert to DataFrame\n",
    "mal_lu_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_lu_ad_nonnull_api\n",
    "]                                  \n",
    "mal_lu_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_lu_ad_nonnull_api_cleaned)\n",
    "#mal_lu_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_lu_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "965303e0-a0cd-48e6-bdbe-836a89faa0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:09:47.220721Z",
     "iopub.status.busy": "2025-06-11T05:09:47.220471Z",
     "iopub.status.idle": "2025-06-11T05:09:47.231732Z",
     "shell.execute_reply": "2025-06-11T05:09:47.231247Z",
     "shell.execute_reply.started": "2025-06-11T05:09:47.220704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_lu_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_lu_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_lu_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d2a9d-ec11-4587-8e9f-6196a826d299",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_lu_ad_nonnull_api_cleaned_df.to_excel(\"mal_lu_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e0ab5-8b4b-4b4d-a36e-f4a6a64796c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_lu_ad_nonnull_api_cleaned_df = pd.read_excel(\"mal_lu_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b434f-f6a3-4c6c-be2b-7810c165c4e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_lu_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7646efd7-00a6-4f68-a221-fc0d66185e9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:09:47.233109Z",
     "iopub.status.busy": "2025-06-11T05:09:47.232299Z",
     "iopub.status.idle": "2025-06-11T05:09:47.597293Z",
     "shell.execute_reply": "2025-06-11T05:09:47.596748Z",
     "shell.execute_reply.started": "2025-06-11T05:09:47.233091Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_lu_ad_nonnull_sen_df = pd.DataFrame(processed_data_mal_lu_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_lu_ad_nonnull_sen_df = mal_lu_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_lu_ad_nonnull_merged_df = pd.concat([combined_df_mal_lu_ad, mal_lu_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_lu_ad_final_sen_df = pd.concat([mal_lu_ad_nonnull_merged_df,null_dataframes['mal_lu_ad_null']], ignore_index=True)\n",
    "\n",
    "mal_lu_ad_final_sen_df_copy = mal_lu_ad_final_sen_df.copy()\n",
    "mal_lu_ad_final_sen_df_copy[\"Published At Date\"] = mal_lu_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_lu_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_lu_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8279e-33bf-4cf8-9e33-c65d6cbb5689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e776f120-c8c7-44d0-9df4-7448e65c269f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "406b94bb-525a-469f-ad67-9456cd62b3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:09:47.599613Z",
     "iopub.status.busy": "2025-06-11T05:09:47.599169Z",
     "iopub.status.idle": "2025-06-11T05:12:03.364565Z",
     "shell.execute_reply": "2025-06-11T05:12:03.363997Z",
     "shell.execute_reply.started": "2025-06-11T05:09:47.599592Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [16] Iterations\n",
      "Total Execution Time: 00:02:15\n",
      "Total Input Tokens - 20601\n",
      "Total Input Cost = 0.21\n",
      "Total Output Tokens - 9156\n",
      "Total Output Cost = 0.27\n",
      "Total Cost = 0.48\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_mb_nonnull_buckets['mal_mb_nonnull_1-4'])/25)+math.ceil(len(mal_mb_nonnull_buckets['mal_mb_nonnull_5-15'])/25)+math.ceil(len(mal_mb_nonnull_buckets['mal_mb_nonnull_16-30'])/25)+math.ceil(len(mal_mb_nonnull_buckets['mal_mb_nonnull_31-60'])/25)+math.ceil(len(mal_mb_nonnull_buckets['mal_mb_nonnull_61-100'])/25)+math.ceil(len(mal_mb_nonnull_buckets['mal_mb_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_mb_nonnull_buckets.keys())\n",
    "mal_mb_nonnull_api = []\n",
    "input_tokens_mal_mb_nonnull=0\n",
    "output_tokens_mal_mb_nonnull=0\n",
    "start_time_mal_mb = time.time()\n",
    "\n",
    "for key in mal_mb_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_mb_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_mb, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_mb_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_mb_nonnull+=input_tokens\n",
    "    output_tokens_mal_mb_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_mb = time.time() - start_time_mal_mb\n",
    "formatted_time_mal_mb = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_mb))\n",
    "input_token_cost_mal_mb = round((0.01/1000) * input_tokens_mal_mb_nonnull, 2)\n",
    "output_token_cost_mal_mb = round((0.03/1000) * output_tokens_mal_mb_nonnull, 2)\n",
    "total_cost_mal_mb = round(input_token_cost_mal_mb + output_token_cost_mal_mb, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_mb}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_mb_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_mb}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_mb_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_mb}\")\n",
    "print(f\"Total Cost = {total_cost_mal_mb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c8bd9-88d8-4ae2-917c-ed698ba500da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "899709c8-de7f-44cd-bdd1-104de1122665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:12:03.365478Z",
     "iopub.status.busy": "2025-06-11T05:12:03.365236Z",
     "iopub.status.idle": "2025-06-11T05:12:03.369459Z",
     "shell.execute_reply": "2025-06-11T05:12:03.368940Z",
     "shell.execute_reply.started": "2025-06-11T05:12:03.365459Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_mb_nonnull_api & convert to DataFrame\n",
    "mal_mb_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_mb_nonnull_api\n",
    "]                                  \n",
    "mal_mb_nonnull_api_cleaned_df = pd.DataFrame(mal_mb_nonnull_api_cleaned)\n",
    "#mal_mb_nonnull_api_cleaned_df = pd.DataFrame(mal_mb_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "910a64dc-57e6-457b-848f-ea384a511dc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:12:03.370325Z",
     "iopub.status.busy": "2025-06-11T05:12:03.370051Z",
     "iopub.status.idle": "2025-06-11T05:12:03.379059Z",
     "shell.execute_reply": "2025-06-11T05:12:03.378539Z",
     "shell.execute_reply.started": "2025-06-11T05:12:03.370302Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_mb_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_mb_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_mb_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f01908-e25e-4097-b0d7-7a64e9de3711",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_mb_nonnull_api_cleaned_df.to_excel(\"mal_mb_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56da3a-cf0b-4c64-b9bc-d629cb4cb06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_mb_nonnull_api_cleaned_df = pd.read_excel(\"mal_mb_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e245b536-371a-42d4-b120-79e399164ad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_mb_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "69b27f34-dfae-4f71-92e1-83907dee4244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:12:03.379914Z",
     "iopub.status.busy": "2025-06-11T05:12:03.379657Z",
     "iopub.status.idle": "2025-06-11T05:12:03.493999Z",
     "shell.execute_reply": "2025-06-11T05:12:03.493553Z",
     "shell.execute_reply.started": "2025-06-11T05:12:03.379891Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_mb_nonnull_sen_df = pd.DataFrame(processed_data_mal_mb_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_mb_nonnull_sen_df = mal_mb_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_mb_nonnull_merged_df = pd.concat([combined_df_mal_mb, mal_mb_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_mb_final_sen_df = pd.concat([mal_mb_nonnull_merged_df,null_dataframes['mal_mb_null']], ignore_index=True)\n",
    "\n",
    "mal_mb_final_sen_df_copy = mal_mb_final_sen_df.copy()\n",
    "mal_mb_final_sen_df_copy[\"Published At Date\"] = mal_mb_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_mb_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_mb_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2637cc-47a2-4017-90b4-4510fb86a901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e1976e-6314-4910-ab0e-704eb4562291",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_sh_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e6831929-1f55-4b3e-a054-5503a1badc43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:12:03.494879Z",
     "iopub.status.busy": "2025-06-11T05:12:03.494639Z",
     "iopub.status.idle": "2025-06-11T05:13:29.170036Z",
     "shell.execute_reply": "2025-06-11T05:13:29.169535Z",
     "shell.execute_reply.started": "2025-06-11T05:12:03.494861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [12] Iterations\n",
      "Total Execution Time: 00:01:25\n",
      "Total Input Tokens - 12307\n",
      "Total Input Cost = 0.12\n",
      "Total Output Tokens - 5528\n",
      "Total Output Cost = 0.17\n",
      "Total Cost = 0.29\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_1-4'])/25)+math.ceil(len(mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_5-15'])/25)+math.ceil(len(mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_16-30'])/25)+math.ceil(len(mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_31-60'])/25)+math.ceil(len(mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_61-100'])/25)+math.ceil(len(mal_sh_ad_nonnull_buckets['mal_sh_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_sh_ad_nonnull_buckets.keys())\n",
    "mal_sh_ad_nonnull_api = []\n",
    "input_tokens_mal_sh_ad_nonnull=0\n",
    "output_tokens_mal_sh_ad_nonnull=0\n",
    "start_time_mal_sh_ad = time.time()\n",
    "\n",
    "for key in mal_sh_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_sh_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_sh_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_sh_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_sh_ad_nonnull+=input_tokens\n",
    "    output_tokens_mal_sh_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_sh_ad = time.time() - start_time_mal_sh_ad\n",
    "formatted_time_mal_sh_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_sh_ad))\n",
    "input_token_cost_mal_sh_ad = round((0.01/1000) * input_tokens_mal_sh_ad_nonnull, 2)\n",
    "output_token_cost_mal_sh_ad = round((0.03/1000) * output_tokens_mal_sh_ad_nonnull, 2)\n",
    "total_cost_mal_sh_ad = round(input_token_cost_mal_sh_ad + output_token_cost_mal_sh_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_sh_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_sh_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_sh_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_sh_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_sh_ad}\")\n",
    "print(f\"Total Cost = {total_cost_mal_sh_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c03e5ca6-7fad-4793-98cd-36c6981c70aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:13:29.170961Z",
     "iopub.status.busy": "2025-06-11T05:13:29.170703Z",
     "iopub.status.idle": "2025-06-11T05:13:29.174888Z",
     "shell.execute_reply": "2025-06-11T05:13:29.174368Z",
     "shell.execute_reply.started": "2025-06-11T05:13:29.170941Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_sh_ad_nonnull_api & convert to DataFrame\n",
    "mal_sh_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_sh_ad_nonnull_api\n",
    "]                                  \n",
    "mal_sh_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_sh_ad_nonnull_api_cleaned)\n",
    "#mal_sh_ad_nonnull_api_cleaned_df = pd.DataFrame(mal_sh_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "33ba5e8e-f0fb-4181-b897-2d59fe256f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:13:29.175831Z",
     "iopub.status.busy": "2025-06-11T05:13:29.175539Z",
     "iopub.status.idle": "2025-06-11T05:13:29.183339Z",
     "shell.execute_reply": "2025-06-11T05:13:29.182871Z",
     "shell.execute_reply.started": "2025-06-11T05:13:29.175812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_sh_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_sh_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_sh_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08437a-1801-484f-a5d2-2f835dfb7cdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_sh_ad_nonnull_api_cleaned_df.to_excel(\"mal_sh_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47525d99-13ea-4e08-8d4c-880e02f392bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_sh_ad_nonnull_api_cleaned_df = pd.read_excel(\"mal_sh_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15242076-95b1-4267-aba2-baccf6bade6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_sh_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "79352c14-0f54-433d-a695-d8047f3fe1f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:13:29.184307Z",
     "iopub.status.busy": "2025-06-11T05:13:29.183983Z",
     "iopub.status.idle": "2025-06-11T05:13:29.268047Z",
     "shell.execute_reply": "2025-06-11T05:13:29.267545Z",
     "shell.execute_reply.started": "2025-06-11T05:13:29.184282Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_sh_ad_nonnull_sen_df = pd.DataFrame(processed_data_mal_sh_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_sh_ad_nonnull_sen_df = mal_sh_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_sh_ad_nonnull_merged_df = pd.concat([combined_df_mal_sh_ad, mal_sh_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_sh_ad_final_sen_df = pd.concat([mal_sh_ad_nonnull_merged_df,null_dataframes['mal_sh_ad_null']], ignore_index=True)\n",
    "\n",
    "mal_sh_ad_final_sen_df_copy = mal_sh_ad_final_sen_df.copy()\n",
    "mal_sh_ad_final_sen_df_copy[\"Published At Date\"] = mal_sh_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_sh_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_sh_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8becc18-51bd-45e5-bbe4-9f0db378980b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32b4c33a-7494-4714-9416-60e10278cf5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b2_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7d1d7451-661f-4f96-a4f9-d7c37a5a4b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:13:29.269138Z",
     "iopub.status.busy": "2025-06-11T05:13:29.268842Z",
     "iopub.status.idle": "2025-06-11T05:14:28.899839Z",
     "shell.execute_reply": "2025-06-11T05:14:28.899330Z",
     "shell.execute_reply.started": "2025-06-11T05:13:29.269118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [10] Iterations\n",
      "Total Execution Time: 00:00:59\n",
      "Total Input Tokens - 11020\n",
      "Total Input Cost = 0.11\n",
      "Total Output Tokens - 4405\n",
      "Total Output Cost = 0.13\n",
      "Total Cost = 0.24\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_1-4'])/25)+math.ceil(len(mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_5-15'])/25)+math.ceil(len(mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_16-30'])/25)+math.ceil(len(mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_31-60'])/25)+math.ceil(len(mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_61-100'])/25)+math.ceil(len(mal_b2_af_nonnull_buckets['mal_b2_af_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_b2_af_nonnull_buckets.keys())\n",
    "mal_b2_af_nonnull_api = []\n",
    "input_tokens_mal_b2_af_nonnull=0\n",
    "output_tokens_mal_b2_af_nonnull=0\n",
    "start_time_mal_b2_af = time.time()\n",
    "\n",
    "for key in mal_b2_af_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_b2_af_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_b2_af, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_b2_af_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_b2_af_nonnull+=input_tokens\n",
    "    output_tokens_mal_b2_af_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_b2_af = time.time() - start_time_mal_b2_af\n",
    "formatted_time_mal_b2_af = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_b2_af))\n",
    "input_token_cost_mal_b2_af = round((0.01/1000) * input_tokens_mal_b2_af_nonnull, 2)\n",
    "output_token_cost_mal_b2_af = round((0.03/1000) * output_tokens_mal_b2_af_nonnull, 2)\n",
    "total_cost_mal_b2_af = round(input_token_cost_mal_b2_af + output_token_cost_mal_b2_af, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_b2_af}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_b2_af_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_b2_af}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_b2_af_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_b2_af}\")\n",
    "print(f\"Total Cost = {total_cost_mal_b2_af}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dbe149f4-a057-4dbc-88dc-da91f2de4d7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:14:28.900759Z",
     "iopub.status.busy": "2025-06-11T05:14:28.900505Z",
     "iopub.status.idle": "2025-06-11T05:14:28.904589Z",
     "shell.execute_reply": "2025-06-11T05:14:28.904086Z",
     "shell.execute_reply.started": "2025-06-11T05:14:28.900740Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_b2_af_nonnull_api & convert to DataFrame\n",
    "mal_b2_af_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_b2_af_nonnull_api\n",
    "]                                  \n",
    "mal_b2_af_nonnull_api_cleaned_df = pd.DataFrame(mal_b2_af_nonnull_api_cleaned)\n",
    "#mal_b2_af_nonnull_api_cleaned_df = pd.DataFrame(mal_b2_af_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "df93875c-bb00-4bab-a409-15a61811b2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:14:28.905408Z",
     "iopub.status.busy": "2025-06-11T05:14:28.905159Z",
     "iopub.status.idle": "2025-06-11T05:14:28.912480Z",
     "shell.execute_reply": "2025-06-11T05:14:28.911981Z",
     "shell.execute_reply.started": "2025-06-11T05:14:28.905392Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_b2_af_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_b2_af_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_b2_af_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d203164-0cf6-447d-ad10-96e3ce39f6e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b2_af_nonnull_api_cleaned_df.to_excel(\"mal_b2_af_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141d997-a6de-482d-a7a9-2688ea05a507",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b2_af_nonnull_api_cleaned_df = pd.read_excel(\"mal_b2_af_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7682566-bdc0-4db0-9270-1ded66bca266",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_b2_af_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5a71ad95-70f6-44f8-be3a-a8a9884176b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:14:28.914622Z",
     "iopub.status.busy": "2025-06-11T05:14:28.914373Z",
     "iopub.status.idle": "2025-06-11T05:14:28.982650Z",
     "shell.execute_reply": "2025-06-11T05:14:28.982111Z",
     "shell.execute_reply.started": "2025-06-11T05:14:28.914604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_b2_af_nonnull_sen_df = pd.DataFrame(processed_data_mal_b2_af_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_b2_af_nonnull_sen_df = mal_b2_af_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_b2_af_nonnull_merged_df = pd.concat([combined_df_mal_b2_af, mal_b2_af_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_b2_af_final_sen_df = pd.concat([mal_b2_af_nonnull_merged_df,null_dataframes['mal_b2_af_null']], ignore_index=True)\n",
    "\n",
    "mal_b2_af_final_sen_df_copy = mal_b2_af_final_sen_df.copy()\n",
    "mal_b2_af_final_sen_df_copy[\"Published At Date\"] = mal_b2_af_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_b2_af_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_b2_af_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce475c8-c998-4b3e-9522-2f590e7378cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3989c703-50bd-4db0-bce3-9f8a063ae83a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mna_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1c00cbcd-8f6f-4d88-8133-c4ca6ae523c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:30:20.400651Z",
     "iopub.status.busy": "2025-06-11T05:30:20.400348Z",
     "iopub.status.idle": "2025-06-11T05:30:25.938166Z",
     "shell.execute_reply": "2025-06-11T05:30:25.937659Z",
     "shell.execute_reply.started": "2025-06-11T05:30:20.400631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [3] Iterations\n",
      "Total Execution Time: 00:00:05\n",
      "Total Input Tokens - 2102\n",
      "Total Input Cost = 0.02\n",
      "Total Output Tokens - 114\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.02\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mna_mb_nonnull_buckets['mna_mb_nonnull_1-4'])/25)+math.ceil(len(mna_mb_nonnull_buckets['mna_mb_nonnull_5-15'])/25)+math.ceil(len(mna_mb_nonnull_buckets['mna_mb_nonnull_16-30'])/25)+math.ceil(len(mna_mb_nonnull_buckets['mna_mb_nonnull_31-60'])/25)+math.ceil(len(mna_mb_nonnull_buckets['mna_mb_nonnull_61-100'])/25)+math.ceil(len(mna_mb_nonnull_buckets['mna_mb_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mna_mb_nonnull_buckets.keys())\n",
    "mna_mb_nonnull_api = []\n",
    "input_tokens_mna_mb_nonnull=0\n",
    "output_tokens_mna_mb_nonnull=0\n",
    "start_time_mna_mb = time.time()\n",
    "\n",
    "for key in mna_mb_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mna_mb_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mna_mb, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mna_mb_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mna_mb_nonnull+=input_tokens\n",
    "    output_tokens_mna_mb_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mna_mb = time.time() - start_time_mna_mb\n",
    "formatted_time_mna_mb = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mna_mb))\n",
    "input_token_cost_mna_mb = round((0.01/1000) * input_tokens_mna_mb_nonnull, 2)\n",
    "output_token_cost_mna_mb = round((0.03/1000) * output_tokens_mna_mb_nonnull, 2)\n",
    "total_cost_mna_mb = round(input_token_cost_mna_mb + output_token_cost_mna_mb, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mna_mb}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mna_mb_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mna_mb}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mna_mb_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mna_mb}\")\n",
    "print(f\"Total Cost = {total_cost_mna_mb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d53e13af-586a-44e2-af7e-304b290a5be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:30:25.939575Z",
     "iopub.status.busy": "2025-06-11T05:30:25.939157Z",
     "iopub.status.idle": "2025-06-11T05:30:25.943084Z",
     "shell.execute_reply": "2025-06-11T05:30:25.942620Z",
     "shell.execute_reply.started": "2025-06-11T05:30:25.939553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mna_mb_nonnull_api & convert to DataFrame\n",
    "mna_mb_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mna_mb_nonnull_api\n",
    "]                                  \n",
    "mna_mb_nonnull_api_cleaned_df = pd.DataFrame(mna_mb_nonnull_api_cleaned)\n",
    "#mna_mb_nonnull_api_cleaned_df = pd.DataFrame(mna_mb_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "aee1babc-f119-43e6-be97-e8cd87fc35da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:30:27.859970Z",
     "iopub.status.busy": "2025-06-11T05:30:27.859658Z",
     "iopub.status.idle": "2025-06-11T05:30:27.865915Z",
     "shell.execute_reply": "2025-06-11T05:30:27.865424Z",
     "shell.execute_reply.started": "2025-06-11T05:30:27.859949Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mna_mb_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mna_mb_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mna_mb_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28964224-4c49-436f-9455-a99536c326bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "mna_mb_nonnull_api_cleaned_df.to_excel(\"mna_mb_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56dc06-b70c-4249-bc19-357b410199e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "mna_mb_nonnull_api_cleaned_df = pd.read_excel(\"mna_mb_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee33b7-a3bc-44d2-9142-4942d2fe2d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "mna_mb_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cc5a5e5e-a9ba-4c83-b5dc-d5af7df7cf23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:30:30.149988Z",
     "iopub.status.busy": "2025-06-11T05:30:30.149668Z",
     "iopub.status.idle": "2025-06-11T05:30:30.188414Z",
     "shell.execute_reply": "2025-06-11T05:30:30.187875Z",
     "shell.execute_reply.started": "2025-06-11T05:30:30.149965Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mna_mb_nonnull_sen_df = pd.DataFrame(processed_data_mna_mb_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mna_mb_nonnull_sen_df = mna_mb_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mna_mb_nonnull_merged_df = pd.concat([combined_df_mna_mb, mna_mb_nonnull_sen_df], axis=1)\n",
    "\n",
    "mna_mb_final_sen_df = pd.concat([mna_mb_nonnull_merged_df,null_dataframes['mna_mb_null']], ignore_index=True)\n",
    "\n",
    "mna_mb_final_sen_df_copy = mna_mb_final_sen_df.copy()\n",
    "mna_mb_final_sen_df_copy[\"Published At Date\"] = mna_mb_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mna_mb_final_sen_df_copy.to_excel(\"sentiment_raw_output/mna_mb_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946dbc16-12e4-455c-856a-78a9fd4a9f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f78bbf08-2f41-4be7-a655-9feb85376549",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### min_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1c160d59-0d5c-4960-908c-729aacf45274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:31:01.884674Z",
     "iopub.status.busy": "2025-06-11T05:31:01.884347Z",
     "iopub.status.idle": "2025-06-11T05:32:20.551704Z",
     "shell.execute_reply": "2025-06-11T05:32:20.551212Z",
     "shell.execute_reply.started": "2025-06-11T05:31:01.884652Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [11] Iterations\n",
      "Total Execution Time: 00:01:18\n",
      "Total Input Tokens - 13299\n",
      "Total Input Cost = 0.13\n",
      "Total Output Tokens - 5885\n",
      "Total Output Cost = 0.18\n",
      "Total Cost = 0.31\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(min_ak_nonnull_buckets['min_ak_nonnull_1-4'])/25)+math.ceil(len(min_ak_nonnull_buckets['min_ak_nonnull_5-15'])/25)+math.ceil(len(min_ak_nonnull_buckets['min_ak_nonnull_16-30'])/25)+math.ceil(len(min_ak_nonnull_buckets['min_ak_nonnull_31-60'])/25)+math.ceil(len(min_ak_nonnull_buckets['min_ak_nonnull_61-100'])/25)+math.ceil(len(min_ak_nonnull_buckets['min_ak_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(min_ak_nonnull_buckets.keys())\n",
    "min_ak_nonnull_api = []\n",
    "input_tokens_min_ak_nonnull=0\n",
    "output_tokens_min_ak_nonnull=0\n",
    "start_time_min_ak = time.time()\n",
    "\n",
    "for key in min_ak_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = min_ak_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_min_ak, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        min_ak_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_min_ak_nonnull+=input_tokens\n",
    "    output_tokens_min_ak_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_min_ak = time.time() - start_time_min_ak\n",
    "formatted_time_min_ak = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_min_ak))\n",
    "input_token_cost_min_ak = round((0.01/1000) * input_tokens_min_ak_nonnull, 2)\n",
    "output_token_cost_min_ak = round((0.03/1000) * output_tokens_min_ak_nonnull, 2)\n",
    "total_cost_min_ak = round(input_token_cost_min_ak + output_token_cost_min_ak, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_min_ak}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_min_ak_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_min_ak}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_min_ak_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_min_ak}\")\n",
    "print(f\"Total Cost = {total_cost_min_ak}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eea26790-4084-4f0f-b082-00066cce141c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:32:20.553195Z",
     "iopub.status.busy": "2025-06-11T05:32:20.552909Z",
     "iopub.status.idle": "2025-06-11T05:32:20.556891Z",
     "shell.execute_reply": "2025-06-11T05:32:20.556298Z",
     "shell.execute_reply.started": "2025-06-11T05:32:20.553174Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in min_ak_nonnull_api & convert to DataFrame\n",
    "min_ak_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in min_ak_nonnull_api\n",
    "]                                  \n",
    "min_ak_nonnull_api_cleaned_df = pd.DataFrame(min_ak_nonnull_api_cleaned)\n",
    "#min_ak_nonnull_api_cleaned_df = pd.DataFrame(min_ak_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5119e4fa-4516-4f9c-831e-50265e42e22e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:32:20.558030Z",
     "iopub.status.busy": "2025-06-11T05:32:20.557723Z",
     "iopub.status.idle": "2025-06-11T05:32:20.565393Z",
     "shell.execute_reply": "2025-06-11T05:32:20.564946Z",
     "shell.execute_reply.started": "2025-06-11T05:32:20.558004Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_min_ak_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in min_ak_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_min_ak_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c68a0-0650-4647-9431-6edf0752fc13",
   "metadata": {
    "tags": []
   },
   "source": [
    "min_ak_nonnull_api_cleaned_df.to_excel(\"min_ak_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10d0e7-deeb-4e8b-a1c0-40a97d4aeb99",
   "metadata": {
    "tags": []
   },
   "source": [
    "min_ak_nonnull_api_cleaned_df = pd.read_excel(\"min_ak_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77194dfd-3fc6-43ff-bcb7-640eab6f078e",
   "metadata": {
    "tags": []
   },
   "source": [
    "min_ak_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0e009d94-c7a2-4f1e-8501-69043560ab17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:32:20.566234Z",
     "iopub.status.busy": "2025-06-11T05:32:20.566056Z",
     "iopub.status.idle": "2025-06-11T05:32:20.662921Z",
     "shell.execute_reply": "2025-06-11T05:32:20.662451Z",
     "shell.execute_reply.started": "2025-06-11T05:32:20.566219Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "min_ak_nonnull_sen_df = pd.DataFrame(processed_data_min_ak_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "min_ak_nonnull_sen_df = min_ak_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "min_ak_nonnull_merged_df = pd.concat([combined_df_min_ak, min_ak_nonnull_sen_df], axis=1)\n",
    "\n",
    "min_ak_final_sen_df = pd.concat([min_ak_nonnull_merged_df,null_dataframes['min_ak_null']], ignore_index=True)\n",
    "\n",
    "min_ak_final_sen_df_copy = min_ak_final_sen_df.copy()\n",
    "min_ak_final_sen_df_copy[\"Published At Date\"] = min_ak_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "min_ak_final_sen_df_copy.to_excel(\"sentiment_raw_output/min_ak_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161a2f7-fe07-431e-9246-613396234e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3037b8d0-94f6-4970-8e78-00c43ff243bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e9dfca7e-d8e0-45f1-b24f-113354d4c9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:32:32.134099Z",
     "iopub.status.busy": "2025-06-11T05:32:32.133797Z",
     "iopub.status.idle": "2025-06-11T05:34:00.319000Z",
     "shell.execute_reply": "2025-06-11T05:34:00.318408Z",
     "shell.execute_reply.started": "2025-06-11T05:32:32.134079Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [13] Iterations\n",
      "Total Execution Time: 00:01:28\n",
      "Total Input Tokens - 14322\n",
      "Total Input Cost = 0.14\n",
      "Total Output Tokens - 6359\n",
      "Total Output Cost = 0.19\n",
      "Total Cost = 0.33\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_ak_nonnull_buckets['joy_ak_nonnull_1-4'])/25)+math.ceil(len(joy_ak_nonnull_buckets['joy_ak_nonnull_5-15'])/25)+math.ceil(len(joy_ak_nonnull_buckets['joy_ak_nonnull_16-30'])/25)+math.ceil(len(joy_ak_nonnull_buckets['joy_ak_nonnull_31-60'])/25)+math.ceil(len(joy_ak_nonnull_buckets['joy_ak_nonnull_61-100'])/25)+math.ceil(len(joy_ak_nonnull_buckets['joy_ak_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_ak_nonnull_buckets.keys())\n",
    "joy_ak_nonnull_api = []\n",
    "input_tokens_joy_ak_nonnull=0\n",
    "output_tokens_joy_ak_nonnull=0\n",
    "start_time_joy_ak = time.time()\n",
    "\n",
    "for key in joy_ak_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_ak_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_ak, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_ak_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_ak_nonnull+=input_tokens\n",
    "    output_tokens_joy_ak_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_ak = time.time() - start_time_joy_ak\n",
    "formatted_time_joy_ak = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_ak))\n",
    "input_token_cost_joy_ak = round((0.01/1000) * input_tokens_joy_ak_nonnull, 2)\n",
    "output_token_cost_joy_ak = round((0.03/1000) * output_tokens_joy_ak_nonnull, 2)\n",
    "total_cost_joy_ak = round(input_token_cost_joy_ak + output_token_cost_joy_ak, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_ak}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_ak_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_ak}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_ak_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_ak}\")\n",
    "print(f\"Total Cost = {total_cost_joy_ak}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a0ff0acf-2c22-4463-82b4-cc02330e7cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:00.320458Z",
     "iopub.status.busy": "2025-06-11T05:34:00.320091Z",
     "iopub.status.idle": "2025-06-11T05:34:00.324284Z",
     "shell.execute_reply": "2025-06-11T05:34:00.323702Z",
     "shell.execute_reply.started": "2025-06-11T05:34:00.320434Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_ak_nonnull_api & convert to DataFrame\n",
    "joy_ak_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_ak_nonnull_api\n",
    "]                                  \n",
    "joy_ak_nonnull_api_cleaned_df = pd.DataFrame(joy_ak_nonnull_api_cleaned)\n",
    "#joy_ak_nonnull_api_cleaned_df = pd.DataFrame(joy_ak_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d2b3aea1-9b0a-4562-ae3c-f11a0b661c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:00.325322Z",
     "iopub.status.busy": "2025-06-11T05:34:00.325101Z",
     "iopub.status.idle": "2025-06-11T05:34:00.333212Z",
     "shell.execute_reply": "2025-06-11T05:34:00.332695Z",
     "shell.execute_reply.started": "2025-06-11T05:34:00.325305Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_ak_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_ak_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_ak_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaab601-7b18-4876-80ee-22aa748a0e50",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_ak_nonnull_api_cleaned_df.to_excel(\"joy_ak_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269cd41-6083-4d9c-ae2b-c33b44124295",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_ak_nonnull_api_cleaned_df = pd.read_excel(\"joy_ak_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e7ebb-4201-4686-9442-f346e7f4cff1",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_ak_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "092eaf76-649c-433a-851d-21be1cac1491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:00.334843Z",
     "iopub.status.busy": "2025-06-11T05:34:00.334588Z",
     "iopub.status.idle": "2025-06-11T05:34:00.464884Z",
     "shell.execute_reply": "2025-06-11T05:34:00.464396Z",
     "shell.execute_reply.started": "2025-06-11T05:34:00.334826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_ak_nonnull_sen_df = pd.DataFrame(processed_data_joy_ak_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_ak_nonnull_sen_df = joy_ak_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_ak_nonnull_merged_df = pd.concat([combined_df_joy_ak, joy_ak_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_ak_final_sen_df = pd.concat([joy_ak_nonnull_merged_df,null_dataframes['joy_ak_null']], ignore_index=True)\n",
    "\n",
    "joy_ak_final_sen_df_copy = joy_ak_final_sen_df.copy()\n",
    "joy_ak_final_sen_df_copy[\"Published At Date\"] = joy_ak_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_ak_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_ak_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9711a9e-cc9a-47bc-b677-9659eac94dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1664095b-e07b-42d1-9217-54de2c2453ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### kan_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "10c1a7c2-4517-469e-bd89-7e63768df2a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:00.465973Z",
     "iopub.status.busy": "2025-06-11T05:34:00.465647Z",
     "iopub.status.idle": "2025-06-11T05:34:11.015701Z",
     "shell.execute_reply": "2025-06-11T05:34:11.015171Z",
     "shell.execute_reply.started": "2025-06-11T05:34:00.465945Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [4] Iterations\n",
      "Total Execution Time: 00:00:10\n",
      "Total Input Tokens - 3139\n",
      "Total Input Cost = 0.03\n",
      "Total Output Tokens - 501\n",
      "Total Output Cost = 0.02\n",
      "Total Cost = 0.05\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(kan_mb_nonnull_buckets['kan_mb_nonnull_1-4'])/25)+math.ceil(len(kan_mb_nonnull_buckets['kan_mb_nonnull_5-15'])/25)+math.ceil(len(kan_mb_nonnull_buckets['kan_mb_nonnull_16-30'])/25)+math.ceil(len(kan_mb_nonnull_buckets['kan_mb_nonnull_31-60'])/25)+math.ceil(len(kan_mb_nonnull_buckets['kan_mb_nonnull_61-100'])/25)+math.ceil(len(kan_mb_nonnull_buckets['kan_mb_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(kan_mb_nonnull_buckets.keys())\n",
    "kan_mb_nonnull_api = []\n",
    "input_tokens_kan_mb_nonnull=0\n",
    "output_tokens_kan_mb_nonnull=0\n",
    "start_time_kan_mb = time.time()\n",
    "\n",
    "for key in kan_mb_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = kan_mb_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_kan_mb, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        kan_mb_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_kan_mb_nonnull+=input_tokens\n",
    "    output_tokens_kan_mb_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_kan_mb = time.time() - start_time_kan_mb\n",
    "formatted_time_kan_mb = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_kan_mb))\n",
    "input_token_cost_kan_mb = round((0.01/1000) * input_tokens_kan_mb_nonnull, 2)\n",
    "output_token_cost_kan_mb = round((0.03/1000) * output_tokens_kan_mb_nonnull, 2)\n",
    "total_cost_kan_mb = round(input_token_cost_kan_mb + output_token_cost_kan_mb, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_kan_mb}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_kan_mb_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_kan_mb}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_kan_mb_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_kan_mb}\")\n",
    "print(f\"Total Cost = {total_cost_kan_mb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e1f19498-530a-4a15-a6fc-468d431ddc2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:11.016643Z",
     "iopub.status.busy": "2025-06-11T05:34:11.016424Z",
     "iopub.status.idle": "2025-06-11T05:34:11.020413Z",
     "shell.execute_reply": "2025-06-11T05:34:11.019852Z",
     "shell.execute_reply.started": "2025-06-11T05:34:11.016624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in kan_mb_nonnull_api & convert to DataFrame\n",
    "kan_mb_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in kan_mb_nonnull_api\n",
    "]                                  \n",
    "kan_mb_nonnull_api_cleaned_df = pd.DataFrame(kan_mb_nonnull_api_cleaned)\n",
    "#kan_mb_nonnull_api_cleaned_df = pd.DataFrame(kan_mb_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cf28a9bd-8d67-46a5-87ee-3c9206f80a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:11.021303Z",
     "iopub.status.busy": "2025-06-11T05:34:11.021036Z",
     "iopub.status.idle": "2025-06-11T05:34:11.027325Z",
     "shell.execute_reply": "2025-06-11T05:34:11.026814Z",
     "shell.execute_reply.started": "2025-06-11T05:34:11.021284Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_kan_mb_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in kan_mb_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_kan_mb_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4972adf-1188-4568-a086-2d450da61f71",
   "metadata": {
    "tags": []
   },
   "source": [
    "kan_mb_nonnull_api_cleaned_df.to_excel(\"kan_mb_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac2057-18f0-4494-8412-8b8e5101d5ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "kan_mb_nonnull_api_cleaned_df = pd.read_excel(\"kan_mb_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f8ec7-8474-47bc-b901-550899355b16",
   "metadata": {
    "tags": []
   },
   "source": [
    "kan_mb_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "efbcde78-66fe-4439-9d52-3981bcc6ca95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:11.028201Z",
     "iopub.status.busy": "2025-06-11T05:34:11.027949Z",
     "iopub.status.idle": "2025-06-11T05:34:11.064299Z",
     "shell.execute_reply": "2025-06-11T05:34:11.063835Z",
     "shell.execute_reply.started": "2025-06-11T05:34:11.028184Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "kan_mb_nonnull_sen_df = pd.DataFrame(processed_data_kan_mb_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "kan_mb_nonnull_sen_df = kan_mb_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "kan_mb_nonnull_merged_df = pd.concat([combined_df_kan_mb, kan_mb_nonnull_sen_df], axis=1)\n",
    "\n",
    "kan_mb_final_sen_df = pd.concat([kan_mb_nonnull_merged_df,null_dataframes['kan_mb_null']], ignore_index=True)\n",
    "\n",
    "kan_mb_final_sen_df_copy = kan_mb_final_sen_df.copy()\n",
    "kan_mb_final_sen_df_copy[\"Published At Date\"] = kan_mb_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "kan_mb_final_sen_df_copy.to_excel(\"sentiment_raw_output/kan_mb_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd23bf-2fc7-480e-aa73-bc45b389bc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4089ea0e-91da-46be-a29b-c2ba9fa4ff97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### agd_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "59d01aa4-10b5-4232-ac7f-aa9c73b72dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:11.065264Z",
     "iopub.status.busy": "2025-06-11T05:34:11.065001Z",
     "iopub.status.idle": "2025-06-11T05:34:12.592062Z",
     "shell.execute_reply": "2025-06-11T05:34:12.591549Z",
     "shell.execute_reply.started": "2025-06-11T05:34:11.065247Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:01\n",
      "Total Input Tokens - 670\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 38\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(agd_mb_nonnull_buckets['agd_mb_nonnull_1-4'])/25)+math.ceil(len(agd_mb_nonnull_buckets['agd_mb_nonnull_5-15'])/25)+math.ceil(len(agd_mb_nonnull_buckets['agd_mb_nonnull_16-30'])/25)+math.ceil(len(agd_mb_nonnull_buckets['agd_mb_nonnull_31-60'])/25)+math.ceil(len(agd_mb_nonnull_buckets['agd_mb_nonnull_61-100'])/25)+math.ceil(len(agd_mb_nonnull_buckets['agd_mb_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(agd_mb_nonnull_buckets.keys())\n",
    "agd_mb_nonnull_api = []\n",
    "input_tokens_agd_mb_nonnull=0\n",
    "output_tokens_agd_mb_nonnull=0\n",
    "start_time_agd_mb = time.time()\n",
    "\n",
    "for key in agd_mb_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = agd_mb_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_agd_mb, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        agd_mb_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_agd_mb_nonnull+=input_tokens\n",
    "    output_tokens_agd_mb_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_agd_mb = time.time() - start_time_agd_mb\n",
    "formatted_time_agd_mb = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_agd_mb))\n",
    "input_token_cost_agd_mb = round((0.01/1000) * input_tokens_agd_mb_nonnull, 2)\n",
    "output_token_cost_agd_mb = round((0.03/1000) * output_tokens_agd_mb_nonnull, 2)\n",
    "total_cost_agd_mb = round(input_token_cost_agd_mb + output_token_cost_agd_mb, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_agd_mb}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_agd_mb_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_agd_mb}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_agd_mb_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_agd_mb}\")\n",
    "print(f\"Total Cost = {total_cost_agd_mb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fcf72c83-5458-44f5-a481-0dea386d40df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:12.593707Z",
     "iopub.status.busy": "2025-06-11T05:34:12.593465Z",
     "iopub.status.idle": "2025-06-11T05:34:12.597512Z",
     "shell.execute_reply": "2025-06-11T05:34:12.597025Z",
     "shell.execute_reply.started": "2025-06-11T05:34:12.593689Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in agd_mb_nonnull_api & convert to DataFrame\n",
    "agd_mb_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in agd_mb_nonnull_api\n",
    "]                                  \n",
    "agd_mb_nonnull_api_cleaned_df = pd.DataFrame(agd_mb_nonnull_api_cleaned)\n",
    "#agd_mb_nonnull_api_cleaned_df = pd.DataFrame(agd_mb_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "71673073-84a5-43c8-84da-01658a79ee54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:12.598323Z",
     "iopub.status.busy": "2025-06-11T05:34:12.598072Z",
     "iopub.status.idle": "2025-06-11T05:34:12.604072Z",
     "shell.execute_reply": "2025-06-11T05:34:12.603547Z",
     "shell.execute_reply.started": "2025-06-11T05:34:12.598305Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_agd_mb_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in agd_mb_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_agd_mb_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f713cfa-d82f-4ade-908d-f2226914159c",
   "metadata": {
    "tags": []
   },
   "source": [
    "agd_mb_nonnull_api_cleaned_df.to_excel(\"agd_mb_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe2143-6713-4d04-92bf-b3951bb62f19",
   "metadata": {
    "tags": []
   },
   "source": [
    "agd_mb_nonnull_api_cleaned_df = pd.read_excel(\"agd_mb_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd759e7a-a905-43a8-83c2-128472ec45c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "agd_mb_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "306c7f84-cc67-4f03-8a28-2e8caa322864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:12.604905Z",
     "iopub.status.busy": "2025-06-11T05:34:12.604666Z",
     "iopub.status.idle": "2025-06-11T05:34:12.635825Z",
     "shell.execute_reply": "2025-06-11T05:34:12.635384Z",
     "shell.execute_reply.started": "2025-06-11T05:34:12.604889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "agd_mb_nonnull_sen_df = pd.DataFrame(processed_data_agd_mb_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "agd_mb_nonnull_sen_df = agd_mb_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "agd_mb_nonnull_merged_df = pd.concat([combined_df_agd_mb, agd_mb_nonnull_sen_df], axis=1)\n",
    "\n",
    "agd_mb_final_sen_df = pd.concat([agd_mb_nonnull_merged_df,null_dataframes['agd_mb_null']], ignore_index=True)\n",
    "\n",
    "agd_mb_final_sen_df_copy = agd_mb_final_sen_df.copy()\n",
    "agd_mb_final_sen_df_copy[\"Published At Date\"] = agd_mb_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "agd_mb_final_sen_df_copy.to_excel(\"sentiment_raw_output/agd_mb_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1ae46-fb49-49b3-930c-a65c4f28bad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a190b4b7-28bc-496c-81d2-037ba472ff36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### bhi_dec_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3b696d62-f6ca-4e94-bcfb-057e700088d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:12.636844Z",
     "iopub.status.busy": "2025-06-11T05:34:12.636623Z",
     "iopub.status.idle": "2025-06-11T05:34:15.664782Z",
     "shell.execute_reply": "2025-06-11T05:34:15.664285Z",
     "shell.execute_reply.started": "2025-06-11T05:34:12.636827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [2] Iterations\n",
      "Total Execution Time: 00:00:03\n",
      "Total Input Tokens - 1409\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 72\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_1-4'])/25)+math.ceil(len(bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_5-15'])/25)+math.ceil(len(bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_16-30'])/25)+math.ceil(len(bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_31-60'])/25)+math.ceil(len(bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_61-100'])/25)+math.ceil(len(bhi_dec_ga_nonnull_buckets['bhi_dec_ga_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(bhi_dec_ga_nonnull_buckets.keys())\n",
    "bhi_dec_ga_nonnull_api = []\n",
    "input_tokens_bhi_dec_ga_nonnull=0\n",
    "output_tokens_bhi_dec_ga_nonnull=0\n",
    "start_time_bhi_dec_ga = time.time()\n",
    "\n",
    "for key in bhi_dec_ga_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = bhi_dec_ga_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_bhi_dec_ga, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        bhi_dec_ga_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_bhi_dec_ga_nonnull+=input_tokens\n",
    "    output_tokens_bhi_dec_ga_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_bhi_dec_ga = time.time() - start_time_bhi_dec_ga\n",
    "formatted_time_bhi_dec_ga = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_bhi_dec_ga))\n",
    "input_token_cost_bhi_dec_ga = round((0.01/1000) * input_tokens_bhi_dec_ga_nonnull, 2)\n",
    "output_token_cost_bhi_dec_ga = round((0.03/1000) * output_tokens_bhi_dec_ga_nonnull, 2)\n",
    "total_cost_bhi_dec_ga = round(input_token_cost_bhi_dec_ga + output_token_cost_bhi_dec_ga, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_bhi_dec_ga}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_bhi_dec_ga_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_bhi_dec_ga}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_bhi_dec_ga_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_bhi_dec_ga}\")\n",
    "print(f\"Total Cost = {total_cost_bhi_dec_ga}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "48fc1bd0-0f0e-419d-987f-df4df8783ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:15.665655Z",
     "iopub.status.busy": "2025-06-11T05:34:15.665415Z",
     "iopub.status.idle": "2025-06-11T05:34:15.669242Z",
     "shell.execute_reply": "2025-06-11T05:34:15.668762Z",
     "shell.execute_reply.started": "2025-06-11T05:34:15.665636Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in bhi_dec_ga_nonnull_api & convert to DataFrame\n",
    "bhi_dec_ga_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in bhi_dec_ga_nonnull_api\n",
    "]                                  \n",
    "bhi_dec_ga_nonnull_api_cleaned_df = pd.DataFrame(bhi_dec_ga_nonnull_api_cleaned)\n",
    "#bhi_dec_ga_nonnull_api_cleaned_df = pd.DataFrame(bhi_dec_ga_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "58467d1e-d895-4520-b1bf-c1d223836a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:15.670237Z",
     "iopub.status.busy": "2025-06-11T05:34:15.669914Z",
     "iopub.status.idle": "2025-06-11T05:34:15.676505Z",
     "shell.execute_reply": "2025-06-11T05:34:15.675803Z",
     "shell.execute_reply.started": "2025-06-11T05:34:15.670210Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_bhi_dec_ga_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in bhi_dec_ga_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_bhi_dec_ga_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c2c48-6603-4e43-9c97-e2fc902f2cc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "bhi_dec_ga_nonnull_api_cleaned_df.to_excel(\"bhi_dec_ga_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136c1d0-68d7-419c-8303-2102a8c4688f",
   "metadata": {
    "tags": []
   },
   "source": [
    "bhi_dec_ga_nonnull_api_cleaned_df = pd.read_excel(\"bhi_dec_ga_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d85697-2447-481d-bcba-11509a8b7370",
   "metadata": {
    "tags": []
   },
   "source": [
    "bhi_dec_ga_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1c5db273-d46d-4977-b664-4ae694c782f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:34:15.677715Z",
     "iopub.status.busy": "2025-06-11T05:34:15.677363Z",
     "iopub.status.idle": "2025-06-11T05:34:15.714666Z",
     "shell.execute_reply": "2025-06-11T05:34:15.714183Z",
     "shell.execute_reply.started": "2025-06-11T05:34:15.677686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "bhi_dec_ga_nonnull_sen_df = pd.DataFrame(processed_data_bhi_dec_ga_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "bhi_dec_ga_nonnull_sen_df = bhi_dec_ga_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "bhi_dec_ga_nonnull_merged_df = pd.concat([combined_df_bhi_dec_ga, bhi_dec_ga_nonnull_sen_df], axis=1)\n",
    "\n",
    "bhi_dec_ga_final_sen_df = pd.concat([bhi_dec_ga_nonnull_merged_df,null_dataframes['bhi_dec_ga_null']], ignore_index=True)\n",
    "\n",
    "bhi_dec_ga_final_sen_df_copy = bhi_dec_ga_final_sen_df.copy()\n",
    "bhi_dec_ga_final_sen_df_copy[\"Published At Date\"] = bhi_dec_ga_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "bhi_dec_ga_final_sen_df_copy.to_excel(\"sentiment_raw_output/bhi_dec_ga_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cdcd5-ca45-4351-8cc3-f8e3f5f20e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b06accd0-6d8e-4950-9def-6e01fb892191",
   "metadata": {
    "tags": []
   },
   "source": [
    "### eve_joh_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "27f264e5-8330-4d53-b4d7-f86f21a93aba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:35:52.720480Z",
     "iopub.status.busy": "2025-06-11T05:35:52.720149Z",
     "iopub.status.idle": "2025-06-11T05:35:52.742811Z",
     "shell.execute_reply": "2025-06-11T05:35:52.742289Z",
     "shell.execute_reply.started": "2025-06-11T05:35:52.720459Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [0] Iterations\n",
      "Total Execution Time: 00:00:00\n",
      "Total Input Tokens - 0\n",
      "Total Input Cost = 0.0\n",
      "Total Output Tokens - 0\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.0\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_1-4'])/25)+math.ceil(len(eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_5-15'])/25)+math.ceil(len(eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_16-30'])/25)+math.ceil(len(eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_31-60'])/25)+math.ceil(len(eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_61-100'])/25)+math.ceil(len(eve_joh_ga_nonnull_buckets['eve_joh_ga_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(eve_joh_ga_nonnull_buckets.keys())\n",
    "eve_joh_ga_nonnull_api = []\n",
    "input_tokens_eve_joh_ga_nonnull=0\n",
    "output_tokens_eve_joh_ga_nonnull=0\n",
    "start_time_eve_joh_ga = time.time()\n",
    "\n",
    "for key in eve_joh_ga_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = eve_joh_ga_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_eve_joh_ga, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        eve_joh_ga_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_eve_joh_ga_nonnull+=input_tokens\n",
    "    output_tokens_eve_joh_ga_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_eve_joh_ga = time.time() - start_time_eve_joh_ga\n",
    "formatted_time_eve_joh_ga = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_eve_joh_ga))\n",
    "input_token_cost_eve_joh_ga = round((0.01/1000) * input_tokens_eve_joh_ga_nonnull, 2)\n",
    "output_token_cost_eve_joh_ga = round((0.03/1000) * output_tokens_eve_joh_ga_nonnull, 2)\n",
    "total_cost_eve_joh_ga = round(input_token_cost_eve_joh_ga + output_token_cost_eve_joh_ga, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_eve_joh_ga}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_eve_joh_ga_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_eve_joh_ga}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_eve_joh_ga_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_eve_joh_ga}\")\n",
    "print(f\"Total Cost = {total_cost_eve_joh_ga}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a3cc9e78-d8cf-4c8d-afd8-e3668ecf0137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:35:52.809646Z",
     "iopub.status.busy": "2025-06-11T05:35:52.809419Z",
     "iopub.status.idle": "2025-06-11T05:35:52.813441Z",
     "shell.execute_reply": "2025-06-11T05:35:52.812894Z",
     "shell.execute_reply.started": "2025-06-11T05:35:52.809629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in eve_joh_ga_nonnull_api & convert to DataFrame\n",
    "eve_joh_ga_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in eve_joh_ga_nonnull_api\n",
    "]                                  \n",
    "eve_joh_ga_nonnull_api_cleaned_df = pd.DataFrame(eve_joh_ga_nonnull_api_cleaned)\n",
    "#eve_joh_ga_nonnull_api_cleaned_df = pd.DataFrame(eve_joh_ga_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7c88a6c4-0505-4086-8676-9512cf09ad87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:35:57.980299Z",
     "iopub.status.busy": "2025-06-11T05:35:57.979943Z",
     "iopub.status.idle": "2025-06-11T05:35:57.986526Z",
     "shell.execute_reply": "2025-06-11T05:35:57.986022Z",
     "shell.execute_reply.started": "2025-06-11T05:35:57.980275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_eve_joh_ga_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in eve_joh_ga_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_eve_joh_ga_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed1a1d-93c8-445a-8630-e9613f941333",
   "metadata": {
    "tags": []
   },
   "source": [
    "eve_joh_ga_nonnull_api_cleaned_df.to_excel(\"eve_joh_ga_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73375d-e733-4a30-b93e-61a8472c8117",
   "metadata": {
    "tags": []
   },
   "source": [
    "eve_joh_ga_nonnull_api_cleaned_df = pd.read_excel(\"eve_joh_ga_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0062ca-7470-4cd4-8c31-f88d741373e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "eve_joh_ga_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6d1906c8-1cfa-47df-a136-0dd876b6e332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:02.174137Z",
     "iopub.status.busy": "2025-06-11T05:36:02.173833Z",
     "iopub.status.idle": "2025-06-11T05:36:02.178205Z",
     "shell.execute_reply": "2025-06-11T05:36:02.177658Z",
     "shell.execute_reply.started": "2025-06-11T05:36:02.174118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_eve_joh_ga_nonnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652bfc4-4a53-4f9c-be72-b61d8e563ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "eve_joh_ga_nonnull_sen_df = pd.DataFrame(processed_data_eve_joh_ga_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "eve_joh_ga_nonnull_sen_df = eve_joh_ga_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "eve_joh_ga_nonnull_merged_df = pd.concat([combined_df_eve_joh_ga, eve_joh_ga_nonnull_sen_df], axis=1)\n",
    "\n",
    "eve_joh_ga_final_sen_df = pd.concat([eve_joh_ga_nonnull_merged_df,null_dataframes['eve_joh_ga_null']], ignore_index=True)\n",
    "\n",
    "eve_joh_ga_final_sen_df_copy = eve_joh_ga_final_sen_df.copy()\n",
    "eve_joh_ga_final_sen_df_copy[\"Published At Date\"] = eve_joh_ga_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "eve_joh_ga_final_sen_df_copy.to_excel(\"sentiment_raw_output/eve_joh_ga_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2d2b3-6bc9-4928-b5af-f2ae9a953e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4857b9aa-4d4c-4369-a3ba-e6e846ab6203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_bol_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a4b971ed-66a3-43dc-9bc2-07810c547298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:15.384385Z",
     "iopub.status.busy": "2025-06-11T05:36:15.384046Z",
     "iopub.status.idle": "2025-06-11T05:36:23.428612Z",
     "shell.execute_reply": "2025-06-11T05:36:23.428011Z",
     "shell.execute_reply.started": "2025-06-11T05:36:15.384362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [4] Iterations\n",
      "Total Execution Time: 00:00:08\n",
      "Total Input Tokens - 3195\n",
      "Total Input Cost = 0.03\n",
      "Total Output Tokens - 285\n",
      "Total Output Cost = 0.01\n",
      "Total Cost = 0.04\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_1-4'])/25)+math.ceil(len(jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_5-15'])/25)+math.ceil(len(jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_16-30'])/25)+math.ceil(len(jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_31-60'])/25)+math.ceil(len(jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_61-100'])/25)+math.ceil(len(jar_bol_il_nonnull_buckets['jar_bol_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(jar_bol_il_nonnull_buckets.keys())\n",
    "jar_bol_il_nonnull_api = []\n",
    "input_tokens_jar_bol_il_nonnull=0\n",
    "output_tokens_jar_bol_il_nonnull=0\n",
    "start_time_jar_bol_il = time.time()\n",
    "\n",
    "for key in jar_bol_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = jar_bol_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_jar_bol_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        jar_bol_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_jar_bol_il_nonnull+=input_tokens\n",
    "    output_tokens_jar_bol_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_jar_bol_il = time.time() - start_time_jar_bol_il\n",
    "formatted_time_jar_bol_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_jar_bol_il))\n",
    "input_token_cost_jar_bol_il = round((0.01/1000) * input_tokens_jar_bol_il_nonnull, 2)\n",
    "output_token_cost_jar_bol_il = round((0.03/1000) * output_tokens_jar_bol_il_nonnull, 2)\n",
    "total_cost_jar_bol_il = round(input_token_cost_jar_bol_il + output_token_cost_jar_bol_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_jar_bol_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_jar_bol_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_jar_bol_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_jar_bol_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_jar_bol_il}\")\n",
    "print(f\"Total Cost = {total_cost_jar_bol_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a9a6b52a-167f-4081-a387-55fdceeec137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:23.429842Z",
     "iopub.status.busy": "2025-06-11T05:36:23.429596Z",
     "iopub.status.idle": "2025-06-11T05:36:23.433725Z",
     "shell.execute_reply": "2025-06-11T05:36:23.433233Z",
     "shell.execute_reply.started": "2025-06-11T05:36:23.429823Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in jar_bol_il_nonnull_api & convert to DataFrame\n",
    "jar_bol_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in jar_bol_il_nonnull_api\n",
    "]                                  \n",
    "jar_bol_il_nonnull_api_cleaned_df = pd.DataFrame(jar_bol_il_nonnull_api_cleaned)\n",
    "#jar_bol_il_nonnull_api_cleaned_df = pd.DataFrame(jar_bol_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "724330f1-f2ef-4f25-b126-7ed2edd72a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:23.434556Z",
     "iopub.status.busy": "2025-06-11T05:36:23.434318Z",
     "iopub.status.idle": "2025-06-11T05:36:23.440120Z",
     "shell.execute_reply": "2025-06-11T05:36:23.439635Z",
     "shell.execute_reply.started": "2025-06-11T05:36:23.434537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_jar_bol_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in jar_bol_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_jar_bol_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f0f1f-b7f8-432c-bbd7-d520f98ff079",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_bol_il_nonnull_api_cleaned_df.to_excel(\"jar_bol_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e414bf-5bed-4967-a785-6924c0c9264f",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_bol_il_nonnull_api_cleaned_df = pd.read_excel(\"jar_bol_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0a6db-4e66-474a-8220-eba215167c19",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_bol_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "217f9991-c0eb-40c9-8672-10c9a07a4ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:23.441529Z",
     "iopub.status.busy": "2025-06-11T05:36:23.441324Z",
     "iopub.status.idle": "2025-06-11T05:36:23.483724Z",
     "shell.execute_reply": "2025-06-11T05:36:23.483301Z",
     "shell.execute_reply.started": "2025-06-11T05:36:23.441512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "jar_bol_il_nonnull_sen_df = pd.DataFrame(processed_data_jar_bol_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "jar_bol_il_nonnull_sen_df = jar_bol_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "jar_bol_il_nonnull_merged_df = pd.concat([combined_df_jar_bol_il, jar_bol_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "jar_bol_il_final_sen_df = pd.concat([jar_bol_il_nonnull_merged_df,null_dataframes['jar_bol_il_null']], ignore_index=True)\n",
    "\n",
    "jar_bol_il_final_sen_df_copy = jar_bol_il_final_sen_df.copy()\n",
    "jar_bol_il_final_sen_df_copy[\"Published At Date\"] = jar_bol_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "jar_bol_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/jar_bol_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42458414-ccea-43cd-844d-ac49377438d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c066fee5-859d-4e45-8c62-dbc24106256b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_ver_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6108c51d-b49c-43f8-8da0-33af0a5a9bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:47.400147Z",
     "iopub.status.busy": "2025-06-11T05:36:47.399802Z",
     "iopub.status.idle": "2025-06-11T05:36:55.444721Z",
     "shell.execute_reply": "2025-06-11T05:36:55.444153Z",
     "shell.execute_reply.started": "2025-06-11T05:36:47.400127Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:08\n",
      "Total Input Tokens - 3732\n",
      "Total Input Cost = 0.04\n",
      "Total Output Tokens - 179\n",
      "Total Output Cost = 0.01\n",
      "Total Cost = 0.05\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_1-4'])/25)+math.ceil(len(jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_5-15'])/25)+math.ceil(len(jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_16-30'])/25)+math.ceil(len(jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_31-60'])/25)+math.ceil(len(jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_61-100'])/25)+math.ceil(len(jar_ver_il_nonnull_buckets['jar_ver_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(jar_ver_il_nonnull_buckets.keys())\n",
    "jar_ver_il_nonnull_api = []\n",
    "input_tokens_jar_ver_il_nonnull=0\n",
    "output_tokens_jar_ver_il_nonnull=0\n",
    "start_time_jar_ver_il = time.time()\n",
    "\n",
    "for key in jar_ver_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = jar_ver_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_jar_ver_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        jar_ver_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_jar_ver_il_nonnull+=input_tokens\n",
    "    output_tokens_jar_ver_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_jar_ver_il = time.time() - start_time_jar_ver_il\n",
    "formatted_time_jar_ver_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_jar_ver_il))\n",
    "input_token_cost_jar_ver_il = round((0.01/1000) * input_tokens_jar_ver_il_nonnull, 2)\n",
    "output_token_cost_jar_ver_il = round((0.03/1000) * output_tokens_jar_ver_il_nonnull, 2)\n",
    "total_cost_jar_ver_il = round(input_token_cost_jar_ver_il + output_token_cost_jar_ver_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_jar_ver_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_jar_ver_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_jar_ver_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_jar_ver_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_jar_ver_il}\")\n",
    "print(f\"Total Cost = {total_cost_jar_ver_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "89100a98-6242-4e97-920d-e215749bf570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:55.446196Z",
     "iopub.status.busy": "2025-06-11T05:36:55.445887Z",
     "iopub.status.idle": "2025-06-11T05:36:55.449941Z",
     "shell.execute_reply": "2025-06-11T05:36:55.449419Z",
     "shell.execute_reply.started": "2025-06-11T05:36:55.446173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in jar_ver_il_nonnull_api & convert to DataFrame\n",
    "jar_ver_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in jar_ver_il_nonnull_api\n",
    "]                                  \n",
    "jar_ver_il_nonnull_api_cleaned_df = pd.DataFrame(jar_ver_il_nonnull_api_cleaned)\n",
    "#jar_ver_il_nonnull_api_cleaned_df = pd.DataFrame(jar_ver_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ba12d3a8-1cf0-464f-974f-40f8c9b48ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:55.450968Z",
     "iopub.status.busy": "2025-06-11T05:36:55.450652Z",
     "iopub.status.idle": "2025-06-11T05:36:55.457119Z",
     "shell.execute_reply": "2025-06-11T05:36:55.456610Z",
     "shell.execute_reply.started": "2025-06-11T05:36:55.450942Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_jar_ver_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in jar_ver_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_jar_ver_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d1a2a-0677-4697-a013-ae5dd69ced9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_ver_il_nonnull_api_cleaned_df.to_excel(\"jar_ver_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a923517-2c67-4fcc-a8a6-7906c15dee57",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_ver_il_nonnull_api_cleaned_df = pd.read_excel(\"jar_ver_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25268fd8-c1ac-4310-8195-25e6731b00c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_ver_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0132ffa6-c2ff-491c-8e8a-55a48f7ee67a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:55.458408Z",
     "iopub.status.busy": "2025-06-11T05:36:55.458181Z",
     "iopub.status.idle": "2025-06-11T05:36:55.488827Z",
     "shell.execute_reply": "2025-06-11T05:36:55.488392Z",
     "shell.execute_reply.started": "2025-06-11T05:36:55.458391Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "jar_ver_il_nonnull_sen_df = pd.DataFrame(processed_data_jar_ver_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "jar_ver_il_nonnull_sen_df = jar_ver_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "jar_ver_il_nonnull_merged_df = pd.concat([combined_df_jar_ver_il, jar_ver_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "jar_ver_il_final_sen_df = pd.concat([jar_ver_il_nonnull_merged_df,null_dataframes['jar_ver_il_null']], ignore_index=True)\n",
    "\n",
    "jar_ver_il_final_sen_df_copy = jar_ver_il_final_sen_df.copy()\n",
    "jar_ver_il_final_sen_df_copy[\"Published At Date\"] = jar_ver_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "jar_ver_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/jar_ver_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bde7c-4513-4cf2-8817-66c030aeb547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9283712e-0078-4924-9cc8-f83f966f3172",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_lom_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5b95b2f1-8171-4fde-b667-0e579b07aaca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:55.489745Z",
     "iopub.status.busy": "2025-06-11T05:36:55.489500Z",
     "iopub.status.idle": "2025-06-11T05:36:59.021774Z",
     "shell.execute_reply": "2025-06-11T05:36:59.021269Z",
     "shell.execute_reply.started": "2025-06-11T05:36:55.489729Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [2] Iterations\n",
      "Total Execution Time: 00:00:03\n",
      "Total Input Tokens - 1581\n",
      "Total Input Cost = 0.02\n",
      "Total Output Tokens - 105\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.02\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_1-4'])/25)+math.ceil(len(jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_5-15'])/25)+math.ceil(len(jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_16-30'])/25)+math.ceil(len(jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_31-60'])/25)+math.ceil(len(jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_61-100'])/25)+math.ceil(len(jar_lom_il_nonnull_buckets['jar_lom_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(jar_lom_il_nonnull_buckets.keys())\n",
    "jar_lom_il_nonnull_api = []\n",
    "input_tokens_jar_lom_il_nonnull=0\n",
    "output_tokens_jar_lom_il_nonnull=0\n",
    "start_time_jar_lom_il = time.time()\n",
    "\n",
    "for key in jar_lom_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = jar_lom_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_jar_lom_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        jar_lom_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_jar_lom_il_nonnull+=input_tokens\n",
    "    output_tokens_jar_lom_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_jar_lom_il = time.time() - start_time_jar_lom_il\n",
    "formatted_time_jar_lom_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_jar_lom_il))\n",
    "input_token_cost_jar_lom_il = round((0.01/1000) * input_tokens_jar_lom_il_nonnull, 2)\n",
    "output_token_cost_jar_lom_il = round((0.03/1000) * output_tokens_jar_lom_il_nonnull, 2)\n",
    "total_cost_jar_lom_il = round(input_token_cost_jar_lom_il + output_token_cost_jar_lom_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_jar_lom_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_jar_lom_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_jar_lom_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_jar_lom_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_jar_lom_il}\")\n",
    "print(f\"Total Cost = {total_cost_jar_lom_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0f01f87d-3b03-44ea-9363-c24869468916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:59.022618Z",
     "iopub.status.busy": "2025-06-11T05:36:59.022397Z",
     "iopub.status.idle": "2025-06-11T05:36:59.026381Z",
     "shell.execute_reply": "2025-06-11T05:36:59.025876Z",
     "shell.execute_reply.started": "2025-06-11T05:36:59.022599Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in jar_lom_il_nonnull_api & convert to DataFrame\n",
    "jar_lom_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in jar_lom_il_nonnull_api\n",
    "]                                  \n",
    "jar_lom_il_nonnull_api_cleaned_df = pd.DataFrame(jar_lom_il_nonnull_api_cleaned)\n",
    "#jar_lom_il_nonnull_api_cleaned_df = pd.DataFrame(jar_lom_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "40c671c9-9241-4f51-bd1e-96df63afa2bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:59.027258Z",
     "iopub.status.busy": "2025-06-11T05:36:59.027080Z",
     "iopub.status.idle": "2025-06-11T05:36:59.033341Z",
     "shell.execute_reply": "2025-06-11T05:36:59.032888Z",
     "shell.execute_reply.started": "2025-06-11T05:36:59.027242Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_jar_lom_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in jar_lom_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_jar_lom_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb3036-85b5-46e1-8f33-ef2577bb7ea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_lom_il_nonnull_api_cleaned_df.to_excel(\"jar_lom_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4cc15b-b198-44ad-8ae5-5606936bf62f",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_lom_il_nonnull_api_cleaned_df = pd.read_excel(\"jar_lom_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78947844-e7fa-4820-b53a-cfaa668e2773",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_lom_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "14a7b104-7c45-48cd-827c-6fdac673bb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:59.034140Z",
     "iopub.status.busy": "2025-06-11T05:36:59.033895Z",
     "iopub.status.idle": "2025-06-11T05:36:59.063463Z",
     "shell.execute_reply": "2025-06-11T05:36:59.062972Z",
     "shell.execute_reply.started": "2025-06-11T05:36:59.034123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "jar_lom_il_nonnull_sen_df = pd.DataFrame(processed_data_jar_lom_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "jar_lom_il_nonnull_sen_df = jar_lom_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "jar_lom_il_nonnull_merged_df = pd.concat([combined_df_jar_lom_il, jar_lom_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "jar_lom_il_final_sen_df = pd.concat([jar_lom_il_nonnull_merged_df,null_dataframes['jar_lom_il_null']], ignore_index=True)\n",
    "\n",
    "jar_lom_il_final_sen_df_copy = jar_lom_il_final_sen_df.copy()\n",
    "jar_lom_il_final_sen_df_copy[\"Published At Date\"] = jar_lom_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "jar_lom_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/jar_lom_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfa6cc-56fe-455b-9ea8-f97c8458028f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17f22031-0e48-4955-bffa-062ff5d9ad60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_orl_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e17fb398-2348-402d-b1ee-4d9d4407a978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:36:59.064422Z",
     "iopub.status.busy": "2025-06-11T05:36:59.064171Z",
     "iopub.status.idle": "2025-06-11T05:37:01.091915Z",
     "shell.execute_reply": "2025-06-11T05:37:01.091453Z",
     "shell.execute_reply.started": "2025-06-11T05:36:59.064405Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:02\n",
      "Total Input Tokens - 759\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 92\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_1-4'])/25)+math.ceil(len(jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_5-15'])/25)+math.ceil(len(jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_16-30'])/25)+math.ceil(len(jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_31-60'])/25)+math.ceil(len(jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_61-100'])/25)+math.ceil(len(jar_orl_il_nonnull_buckets['jar_orl_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(jar_orl_il_nonnull_buckets.keys())\n",
    "jar_orl_il_nonnull_api = []\n",
    "input_tokens_jar_orl_il_nonnull=0\n",
    "output_tokens_jar_orl_il_nonnull=0\n",
    "start_time_jar_orl_il = time.time()\n",
    "\n",
    "for key in jar_orl_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = jar_orl_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_jar_orl_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        jar_orl_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_jar_orl_il_nonnull+=input_tokens\n",
    "    output_tokens_jar_orl_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_jar_orl_il = time.time() - start_time_jar_orl_il\n",
    "formatted_time_jar_orl_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_jar_orl_il))\n",
    "input_token_cost_jar_orl_il = round((0.01/1000) * input_tokens_jar_orl_il_nonnull, 2)\n",
    "output_token_cost_jar_orl_il = round((0.03/1000) * output_tokens_jar_orl_il_nonnull, 2)\n",
    "total_cost_jar_orl_il = round(input_token_cost_jar_orl_il + output_token_cost_jar_orl_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_jar_orl_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_jar_orl_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_jar_orl_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_jar_orl_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_jar_orl_il}\")\n",
    "print(f\"Total Cost = {total_cost_jar_orl_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4280158a-a30e-4bda-a1fd-298f2d5e3098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:37:01.093627Z",
     "iopub.status.busy": "2025-06-11T05:37:01.093378Z",
     "iopub.status.idle": "2025-06-11T05:37:01.097678Z",
     "shell.execute_reply": "2025-06-11T05:37:01.097158Z",
     "shell.execute_reply.started": "2025-06-11T05:37:01.093609Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in jar_orl_il_nonnull_api & convert to DataFrame\n",
    "jar_orl_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in jar_orl_il_nonnull_api\n",
    "]                                  \n",
    "jar_orl_il_nonnull_api_cleaned_df = pd.DataFrame(jar_orl_il_nonnull_api_cleaned)\n",
    "#jar_orl_il_nonnull_api_cleaned_df = pd.DataFrame(jar_orl_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "63500f1a-b667-446f-ba18-5be49ccb8f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:37:01.098439Z",
     "iopub.status.busy": "2025-06-11T05:37:01.098256Z",
     "iopub.status.idle": "2025-06-11T05:37:01.104356Z",
     "shell.execute_reply": "2025-06-11T05:37:01.103894Z",
     "shell.execute_reply.started": "2025-06-11T05:37:01.098423Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_jar_orl_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in jar_orl_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_jar_orl_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce06fd4-103b-4373-a324-8a4834900f6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_orl_il_nonnull_api_cleaned_df.to_excel(\"jar_orl_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48909ba5-7222-406b-8991-4de11dea9434",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_orl_il_nonnull_api_cleaned_df = pd.read_excel(\"jar_orl_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ea904-1e8b-41d4-bd12-0fa3ed7201fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_orl_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a94901eb-8025-418f-9b7f-e3a34e72013a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:37:01.105174Z",
     "iopub.status.busy": "2025-06-11T05:37:01.104928Z",
     "iopub.status.idle": "2025-06-11T05:37:01.136370Z",
     "shell.execute_reply": "2025-06-11T05:37:01.135828Z",
     "shell.execute_reply.started": "2025-06-11T05:37:01.105157Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "jar_orl_il_nonnull_sen_df = pd.DataFrame(processed_data_jar_orl_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "jar_orl_il_nonnull_sen_df = jar_orl_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "jar_orl_il_nonnull_merged_df = pd.concat([combined_df_jar_orl_il, jar_orl_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "jar_orl_il_final_sen_df = pd.concat([jar_orl_il_nonnull_merged_df,null_dataframes['jar_orl_il_null']], ignore_index=True)\n",
    "\n",
    "jar_orl_il_final_sen_df_copy = jar_orl_il_final_sen_df.copy()\n",
    "jar_orl_il_final_sen_df_copy[\"Published At Date\"] = jar_orl_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "jar_orl_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/jar_orl_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91baf4-0978-44e9-be98-0f59020f7e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31d550bf-4da7-4b58-8f63-2938fa974c5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_aur_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c73c8040-2850-49cb-9e31-e62863235584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:16.894016Z",
     "iopub.status.busy": "2025-06-11T05:38:16.893703Z",
     "iopub.status.idle": "2025-06-11T05:38:25.440730Z",
     "shell.execute_reply": "2025-06-11T05:38:25.440170Z",
     "shell.execute_reply.started": "2025-06-11T05:38:16.893995Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:08\n",
      "Total Input Tokens - 3687\n",
      "Total Input Cost = 0.04\n",
      "Total Output Tokens - 209\n",
      "Total Output Cost = 0.01\n",
      "Total Cost = 0.05\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_1-4'])/25)+math.ceil(len(jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_5-15'])/25)+math.ceil(len(jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_16-30'])/25)+math.ceil(len(jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_31-60'])/25)+math.ceil(len(jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_61-100'])/25)+math.ceil(len(jar_aur_il_nonnull_buckets['jar_aur_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(jar_aur_il_nonnull_buckets.keys())\n",
    "jar_aur_il_nonnull_api = []\n",
    "input_tokens_jar_aur_il_nonnull=0\n",
    "output_tokens_jar_aur_il_nonnull=0\n",
    "start_time_jar_aur_il = time.time()\n",
    "\n",
    "for key in jar_aur_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = jar_aur_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_jar_aur_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        jar_aur_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_jar_aur_il_nonnull+=input_tokens\n",
    "    output_tokens_jar_aur_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_jar_aur_il = time.time() - start_time_jar_aur_il\n",
    "formatted_time_jar_aur_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_jar_aur_il))\n",
    "input_token_cost_jar_aur_il = round((0.01/1000) * input_tokens_jar_aur_il_nonnull, 2)\n",
    "output_token_cost_jar_aur_il = round((0.03/1000) * output_tokens_jar_aur_il_nonnull, 2)\n",
    "total_cost_jar_aur_il = round(input_token_cost_jar_aur_il + output_token_cost_jar_aur_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_jar_aur_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_jar_aur_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_jar_aur_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_jar_aur_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_jar_aur_il}\")\n",
    "print(f\"Total Cost = {total_cost_jar_aur_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4e0a3c20-3a2a-4c80-9f64-3b6b81850087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:25.441805Z",
     "iopub.status.busy": "2025-06-11T05:38:25.441541Z",
     "iopub.status.idle": "2025-06-11T05:38:25.445609Z",
     "shell.execute_reply": "2025-06-11T05:38:25.445096Z",
     "shell.execute_reply.started": "2025-06-11T05:38:25.441786Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in jar_aur_il_nonnull_api & convert to DataFrame\n",
    "jar_aur_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in jar_aur_il_nonnull_api\n",
    "]                                  \n",
    "jar_aur_il_nonnull_api_cleaned_df = pd.DataFrame(jar_aur_il_nonnull_api_cleaned)\n",
    "#jar_aur_il_nonnull_api_cleaned_df = pd.DataFrame(jar_aur_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8ba0f863-bc8b-473d-b59d-84679defb00b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:25.446541Z",
     "iopub.status.busy": "2025-06-11T05:38:25.446197Z",
     "iopub.status.idle": "2025-06-11T05:38:25.452548Z",
     "shell.execute_reply": "2025-06-11T05:38:25.452047Z",
     "shell.execute_reply.started": "2025-06-11T05:38:25.446515Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_jar_aur_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in jar_aur_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_jar_aur_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3862c95-c033-4add-b4fc-ccf5da0c8b7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_aur_il_nonnull_api_cleaned_df.to_excel(\"jar_aur_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4c5f0-e30a-46af-9ba6-cd534885a8ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_aur_il_nonnull_api_cleaned_df = pd.read_excel(\"jar_aur_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf54704-10f6-4fde-bda6-322eec36c9a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_aur_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8d7b468a-9732-40d2-9cd6-f1e56aa36f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:25.454377Z",
     "iopub.status.busy": "2025-06-11T05:38:25.453916Z",
     "iopub.status.idle": "2025-06-11T05:38:25.486665Z",
     "shell.execute_reply": "2025-06-11T05:38:25.486207Z",
     "shell.execute_reply.started": "2025-06-11T05:38:25.454359Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "jar_aur_il_nonnull_sen_df = pd.DataFrame(processed_data_jar_aur_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "jar_aur_il_nonnull_sen_df = jar_aur_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "jar_aur_il_nonnull_merged_df = pd.concat([combined_df_jar_aur_il, jar_aur_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "jar_aur_il_final_sen_df = pd.concat([jar_aur_il_nonnull_merged_df,null_dataframes['jar_aur_il_null']], ignore_index=True)\n",
    "\n",
    "jar_aur_il_final_sen_df_copy = jar_aur_il_final_sen_df.copy()\n",
    "jar_aur_il_final_sen_df_copy[\"Published At Date\"] = jar_aur_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "jar_aur_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/jar_aur_il_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3b75f-e6ca-4d74-9f61-2d6fde07646a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff8f07e3-7a27-455f-9a3d-2d792515e260",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_alg_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bef49753-a84a-4876-acea-f6e95714a771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:25.487509Z",
     "iopub.status.busy": "2025-06-11T05:38:25.487277Z",
     "iopub.status.idle": "2025-06-11T05:38:39.044414Z",
     "shell.execute_reply": "2025-06-11T05:38:39.043881Z",
     "shell.execute_reply.started": "2025-06-11T05:38:25.487492Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [6] Iterations\n",
      "Total Execution Time: 00:00:13\n",
      "Total Input Tokens - 5143\n",
      "Total Input Cost = 0.05\n",
      "Total Output Tokens - 612\n",
      "Total Output Cost = 0.02\n",
      "Total Cost = 0.07\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_1-4'])/25)+math.ceil(len(jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_5-15'])/25)+math.ceil(len(jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_16-30'])/25)+math.ceil(len(jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_31-60'])/25)+math.ceil(len(jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_61-100'])/25)+math.ceil(len(jar_alg_il_nonnull_buckets['jar_alg_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(jar_alg_il_nonnull_buckets.keys())\n",
    "jar_alg_il_nonnull_api = []\n",
    "input_tokens_jar_alg_il_nonnull=0\n",
    "output_tokens_jar_alg_il_nonnull=0\n",
    "start_time_jar_alg_il = time.time()\n",
    "\n",
    "for key in jar_alg_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = jar_alg_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_jar_alg_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        jar_alg_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_jar_alg_il_nonnull+=input_tokens\n",
    "    output_tokens_jar_alg_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_jar_alg_il = time.time() - start_time_jar_alg_il\n",
    "formatted_time_jar_alg_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_jar_alg_il))\n",
    "input_token_cost_jar_alg_il = round((0.01/1000) * input_tokens_jar_alg_il_nonnull, 2)\n",
    "output_token_cost_jar_alg_il = round((0.03/1000) * output_tokens_jar_alg_il_nonnull, 2)\n",
    "total_cost_jar_alg_il = round(input_token_cost_jar_alg_il + output_token_cost_jar_alg_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_jar_alg_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_jar_alg_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_jar_alg_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_jar_alg_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_jar_alg_il}\")\n",
    "print(f\"Total Cost = {total_cost_jar_alg_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5df63bcd-cf18-4f1a-a9c5-3b004db3bbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:39.045342Z",
     "iopub.status.busy": "2025-06-11T05:38:39.045054Z",
     "iopub.status.idle": "2025-06-11T05:38:39.049137Z",
     "shell.execute_reply": "2025-06-11T05:38:39.048607Z",
     "shell.execute_reply.started": "2025-06-11T05:38:39.045323Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in jar_alg_il_nonnull_api & convert to DataFrame\n",
    "jar_alg_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in jar_alg_il_nonnull_api\n",
    "]                                  \n",
    "jar_alg_il_nonnull_api_cleaned_df = pd.DataFrame(jar_alg_il_nonnull_api_cleaned)\n",
    "#jar_alg_il_nonnull_api_cleaned_df = pd.DataFrame(jar_alg_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0dbaa32a-d42c-4f40-a2e5-d0e4fe7fa374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:39.050181Z",
     "iopub.status.busy": "2025-06-11T05:38:39.049731Z",
     "iopub.status.idle": "2025-06-11T05:38:39.056250Z",
     "shell.execute_reply": "2025-06-11T05:38:39.055746Z",
     "shell.execute_reply.started": "2025-06-11T05:38:39.050162Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_jar_alg_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in jar_alg_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_jar_alg_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a97ac-4f73-40e3-bea5-d8fe7b653418",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_alg_il_nonnull_api_cleaned_df.to_excel(\"jar_alg_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b25cb85-8ea4-45f9-8796-756176d77d40",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_alg_il_nonnull_api_cleaned_df = pd.read_excel(\"jar_alg_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0105bf-cd23-4078-9a86-3656da8b3d1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_alg_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "16b30b5e-cea9-47b1-82ec-8345e4ef843a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:39.057078Z",
     "iopub.status.busy": "2025-06-11T05:38:39.056832Z",
     "iopub.status.idle": "2025-06-11T05:38:39.093330Z",
     "shell.execute_reply": "2025-06-11T05:38:39.092835Z",
     "shell.execute_reply.started": "2025-06-11T05:38:39.057033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "jar_alg_il_nonnull_sen_df = pd.DataFrame(processed_data_jar_alg_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "jar_alg_il_nonnull_sen_df = jar_alg_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "jar_alg_il_nonnull_merged_df = pd.concat([combined_df_jar_alg_il, jar_alg_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "jar_alg_il_final_sen_df = pd.concat([jar_alg_il_nonnull_merged_df,null_dataframes['jar_alg_il_null']], ignore_index=True)\n",
    "\n",
    "jar_alg_il_final_sen_df_copy = jar_alg_il_final_sen_df.copy()\n",
    "jar_alg_il_final_sen_df_copy[\"Published At Date\"] = jar_alg_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "jar_alg_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/jar_alg_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b3d1e-1093-41f4-95e0-69ca58c42744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcf6c2ae-f58f-4c2b-8d0d-6e5265f42ccc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_sch_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a5777579-d4eb-42c1-8813-3de344e58998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:39.094217Z",
     "iopub.status.busy": "2025-06-11T05:38:39.093968Z",
     "iopub.status.idle": "2025-06-11T05:38:49.643324Z",
     "shell.execute_reply": "2025-06-11T05:38:49.642798Z",
     "shell.execute_reply.started": "2025-06-11T05:38:39.094201Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:10\n",
      "Total Input Tokens - 4180\n",
      "Total Input Cost = 0.04\n",
      "Total Output Tokens - 408\n",
      "Total Output Cost = 0.01\n",
      "Total Cost = 0.05\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_1-4'])/25)+math.ceil(len(jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_5-15'])/25)+math.ceil(len(jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_16-30'])/25)+math.ceil(len(jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_31-60'])/25)+math.ceil(len(jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_61-100'])/25)+math.ceil(len(jar_sch_il_nonnull_buckets['jar_sch_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(jar_sch_il_nonnull_buckets.keys())\n",
    "jar_sch_il_nonnull_api = []\n",
    "input_tokens_jar_sch_il_nonnull=0\n",
    "output_tokens_jar_sch_il_nonnull=0\n",
    "start_time_jar_sch_il = time.time()\n",
    "\n",
    "for key in jar_sch_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = jar_sch_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_jar_sch_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        jar_sch_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_jar_sch_il_nonnull+=input_tokens\n",
    "    output_tokens_jar_sch_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_jar_sch_il = time.time() - start_time_jar_sch_il\n",
    "formatted_time_jar_sch_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_jar_sch_il))\n",
    "input_token_cost_jar_sch_il = round((0.01/1000) * input_tokens_jar_sch_il_nonnull, 2)\n",
    "output_token_cost_jar_sch_il = round((0.03/1000) * output_tokens_jar_sch_il_nonnull, 2)\n",
    "total_cost_jar_sch_il = round(input_token_cost_jar_sch_il + output_token_cost_jar_sch_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_jar_sch_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_jar_sch_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_jar_sch_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_jar_sch_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_jar_sch_il}\")\n",
    "print(f\"Total Cost = {total_cost_jar_sch_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "57d56c86-0292-49f7-84b1-d50c44cd5c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:49.645053Z",
     "iopub.status.busy": "2025-06-11T05:38:49.644790Z",
     "iopub.status.idle": "2025-06-11T05:38:49.648885Z",
     "shell.execute_reply": "2025-06-11T05:38:49.648385Z",
     "shell.execute_reply.started": "2025-06-11T05:38:49.645033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in jar_sch_il_nonnull_api & convert to DataFrame\n",
    "jar_sch_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in jar_sch_il_nonnull_api\n",
    "]                                  \n",
    "jar_sch_il_nonnull_api_cleaned_df = pd.DataFrame(jar_sch_il_nonnull_api_cleaned)\n",
    "#jar_sch_il_nonnull_api_cleaned_df = pd.DataFrame(jar_sch_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0388bc82-30af-4f79-80f6-73a09d410a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:49.649779Z",
     "iopub.status.busy": "2025-06-11T05:38:49.649557Z",
     "iopub.status.idle": "2025-06-11T05:38:49.655565Z",
     "shell.execute_reply": "2025-06-11T05:38:49.655097Z",
     "shell.execute_reply.started": "2025-06-11T05:38:49.649763Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_jar_sch_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in jar_sch_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_jar_sch_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede53ca-136b-4e14-85d6-4fc98938b636",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_sch_il_nonnull_api_cleaned_df.to_excel(\"jar_sch_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178de0e0-b781-4126-aeba-5cd465a227f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_sch_il_nonnull_api_cleaned_df = pd.read_excel(\"jar_sch_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a13038-069f-4bd8-9dfc-89c53de9568d",
   "metadata": {
    "tags": []
   },
   "source": [
    "jar_sch_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3efd8bae-4582-4312-9368-5837b991d38f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:38:49.656451Z",
     "iopub.status.busy": "2025-06-11T05:38:49.656197Z",
     "iopub.status.idle": "2025-06-11T05:38:49.691098Z",
     "shell.execute_reply": "2025-06-11T05:38:49.690594Z",
     "shell.execute_reply.started": "2025-06-11T05:38:49.656433Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "jar_sch_il_nonnull_sen_df = pd.DataFrame(processed_data_jar_sch_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "jar_sch_il_nonnull_sen_df = jar_sch_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "jar_sch_il_nonnull_merged_df = pd.concat([combined_df_jar_sch_il, jar_sch_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "jar_sch_il_final_sen_df = pd.concat([jar_sch_il_nonnull_merged_df,null_dataframes['jar_sch_il_null']], ignore_index=True)\n",
    "\n",
    "jar_sch_il_final_sen_df_copy = jar_sch_il_final_sen_df.copy()\n",
    "jar_sch_il_final_sen_df_copy[\"Published At Date\"] = jar_sch_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "jar_sch_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/jar_sch_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc3131-d493-45b6-86ae-c40ca0884950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6babb6ff-512d-4f41-ae79-8666ac6d8574",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_suw_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b6e4701f-d4e7-49fd-acc6-57dd58dc70de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:39:14.490146Z",
     "iopub.status.busy": "2025-06-11T05:39:14.489824Z",
     "iopub.status.idle": "2025-06-11T05:40:27.149090Z",
     "shell.execute_reply": "2025-06-11T05:40:27.148548Z",
     "shell.execute_reply.started": "2025-06-11T05:39:14.490125Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [10] Iterations\n",
      "Total Execution Time: 00:01:12\n",
      "Total Input Tokens - 15228\n",
      "Total Input Cost = 0.15\n",
      "Total Output Tokens - 5391\n",
      "Total Output Cost = 0.16\n",
      "Total Cost = 0.31\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_1-4'])/25)+math.ceil(len(joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_5-15'])/25)+math.ceil(len(joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_16-30'])/25)+math.ceil(len(joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_31-60'])/25)+math.ceil(len(joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_61-100'])/25)+math.ceil(len(joy_suw_ga_nonnull_buckets['joy_suw_ga_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_suw_ga_nonnull_buckets.keys())\n",
    "joy_suw_ga_nonnull_api = []\n",
    "input_tokens_joy_suw_ga_nonnull=0\n",
    "output_tokens_joy_suw_ga_nonnull=0\n",
    "start_time_joy_suw_ga = time.time()\n",
    "\n",
    "for key in joy_suw_ga_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_suw_ga_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_suw_ga, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_suw_ga_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_suw_ga_nonnull+=input_tokens\n",
    "    output_tokens_joy_suw_ga_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_suw_ga = time.time() - start_time_joy_suw_ga\n",
    "formatted_time_joy_suw_ga = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_suw_ga))\n",
    "input_token_cost_joy_suw_ga = round((0.01/1000) * input_tokens_joy_suw_ga_nonnull, 2)\n",
    "output_token_cost_joy_suw_ga = round((0.03/1000) * output_tokens_joy_suw_ga_nonnull, 2)\n",
    "total_cost_joy_suw_ga = round(input_token_cost_joy_suw_ga + output_token_cost_joy_suw_ga, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_suw_ga}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_suw_ga_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_suw_ga}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_suw_ga_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_suw_ga}\")\n",
    "print(f\"Total Cost = {total_cost_joy_suw_ga}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cdba6989-41eb-48c1-856f-61e68c0e4a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:40:27.150125Z",
     "iopub.status.busy": "2025-06-11T05:40:27.149877Z",
     "iopub.status.idle": "2025-06-11T05:40:27.153918Z",
     "shell.execute_reply": "2025-06-11T05:40:27.153417Z",
     "shell.execute_reply.started": "2025-06-11T05:40:27.150105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_suw_ga_nonnull_api & convert to DataFrame\n",
    "joy_suw_ga_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_suw_ga_nonnull_api\n",
    "]                                  \n",
    "joy_suw_ga_nonnull_api_cleaned_df = pd.DataFrame(joy_suw_ga_nonnull_api_cleaned)\n",
    "#joy_suw_ga_nonnull_api_cleaned_df = pd.DataFrame(joy_suw_ga_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "41847bb5-b64b-44cd-b194-789ee8062f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:40:27.154787Z",
     "iopub.status.busy": "2025-06-11T05:40:27.154513Z",
     "iopub.status.idle": "2025-06-11T05:40:27.161947Z",
     "shell.execute_reply": "2025-06-11T05:40:27.161522Z",
     "shell.execute_reply.started": "2025-06-11T05:40:27.154768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_suw_ga_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_suw_ga_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_suw_ga_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdea26-dbc6-44da-b542-2dd62bc6b2d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_suw_ga_nonnull_api_cleaned_df.to_excel(\"joy_suw_ga_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b35e0-c78d-4af8-9a2a-2da27dca22cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_suw_ga_nonnull_api_cleaned_df = pd.read_excel(\"joy_suw_ga_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b6b2eb-91d7-407e-8efb-540e3b30a870",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_suw_ga_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6c6b5265-8ee7-4e65-adf4-26246ef99e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:40:27.163224Z",
     "iopub.status.busy": "2025-06-11T05:40:27.163006Z",
     "iopub.status.idle": "2025-06-11T05:40:27.247513Z",
     "shell.execute_reply": "2025-06-11T05:40:27.247083Z",
     "shell.execute_reply.started": "2025-06-11T05:40:27.163207Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_suw_ga_nonnull_sen_df = pd.DataFrame(processed_data_joy_suw_ga_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_suw_ga_nonnull_sen_df = joy_suw_ga_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_suw_ga_nonnull_merged_df = pd.concat([combined_df_joy_suw_ga, joy_suw_ga_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_suw_ga_final_sen_df = pd.concat([joy_suw_ga_nonnull_merged_df,null_dataframes['joy_suw_ga_null']], ignore_index=True)\n",
    "\n",
    "joy_suw_ga_final_sen_df_copy = joy_suw_ga_final_sen_df.copy()\n",
    "joy_suw_ga_final_sen_df_copy[\"Published At Date\"] = joy_suw_ga_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_suw_ga_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_suw_ga_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf2ab2-6ff8-4997-ba84-b470b8b3c430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2a2b6e3-1e23-49d2-a5be-89633916b83d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8619baf5-f757-48dc-9860-ee890892484a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:40:27.248444Z",
     "iopub.status.busy": "2025-06-11T05:40:27.248251Z",
     "iopub.status.idle": "2025-06-11T05:41:03.344986Z",
     "shell.execute_reply": "2025-06-11T05:41:03.344426Z",
     "shell.execute_reply.started": "2025-06-11T05:40:27.248427Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [8] Iterations\n",
      "Total Execution Time: 00:00:36\n",
      "Total Input Tokens - 8285\n",
      "Total Input Cost = 0.08\n",
      "Total Output Tokens - 2489\n",
      "Total Output Cost = 0.07\n",
      "Total Cost = 0.15\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_1-4'])/25)+math.ceil(len(joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_5-15'])/25)+math.ceil(len(joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_16-30'])/25)+math.ceil(len(joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_31-60'])/25)+math.ceil(len(joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_61-100'])/25)+math.ceil(len(joy_chi_il_nonnull_buckets['joy_chi_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_chi_il_nonnull_buckets.keys())\n",
    "joy_chi_il_nonnull_api = []\n",
    "input_tokens_joy_chi_il_nonnull=0\n",
    "output_tokens_joy_chi_il_nonnull=0\n",
    "start_time_joy_chi_il = time.time()\n",
    "\n",
    "for key in joy_chi_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_chi_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_chi_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_chi_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_chi_il_nonnull+=input_tokens\n",
    "    output_tokens_joy_chi_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_chi_il = time.time() - start_time_joy_chi_il\n",
    "formatted_time_joy_chi_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_chi_il))\n",
    "input_token_cost_joy_chi_il = round((0.01/1000) * input_tokens_joy_chi_il_nonnull, 2)\n",
    "output_token_cost_joy_chi_il = round((0.03/1000) * output_tokens_joy_chi_il_nonnull, 2)\n",
    "total_cost_joy_chi_il = round(input_token_cost_joy_chi_il + output_token_cost_joy_chi_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_chi_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_chi_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_chi_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_chi_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_chi_il}\")\n",
    "print(f\"Total Cost = {total_cost_joy_chi_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "58fb23ae-1423-4b31-8916-77dfe80dd99a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:03.346374Z",
     "iopub.status.busy": "2025-06-11T05:41:03.345747Z",
     "iopub.status.idle": "2025-06-11T05:41:03.350098Z",
     "shell.execute_reply": "2025-06-11T05:41:03.349637Z",
     "shell.execute_reply.started": "2025-06-11T05:41:03.346344Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_chi_il_nonnull_api & convert to DataFrame\n",
    "joy_chi_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_chi_il_nonnull_api\n",
    "]                                  \n",
    "joy_chi_il_nonnull_api_cleaned_df = pd.DataFrame(joy_chi_il_nonnull_api_cleaned)\n",
    "#joy_chi_il_nonnull_api_cleaned_df = pd.DataFrame(joy_chi_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "02ef1bcb-f2b3-460d-b3f6-bb19a8ccde66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:03.350892Z",
     "iopub.status.busy": "2025-06-11T05:41:03.350704Z",
     "iopub.status.idle": "2025-06-11T05:41:03.357917Z",
     "shell.execute_reply": "2025-06-11T05:41:03.357456Z",
     "shell.execute_reply.started": "2025-06-11T05:41:03.350876Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_chi_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_chi_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_chi_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55345b21-9447-4a4c-9b86-0909c397b58c",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_chi_il_nonnull_api_cleaned_df.to_excel(\"joy_chi_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5795562-2dee-4dac-bb3b-bb8cfd6f188e",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_chi_il_nonnull_api_cleaned_df = pd.read_excel(\"joy_chi_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b75d07-60d2-4119-9a74-553b37669a90",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_chi_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8ace0c14-1553-41c4-820e-ed9c0e7000fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:03.358663Z",
     "iopub.status.busy": "2025-06-11T05:41:03.358473Z",
     "iopub.status.idle": "2025-06-11T05:41:03.412539Z",
     "shell.execute_reply": "2025-06-11T05:41:03.412099Z",
     "shell.execute_reply.started": "2025-06-11T05:41:03.358648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_chi_il_nonnull_sen_df = pd.DataFrame(processed_data_joy_chi_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_chi_il_nonnull_sen_df = joy_chi_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_chi_il_nonnull_merged_df = pd.concat([combined_df_joy_chi_il, joy_chi_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_chi_il_final_sen_df = pd.concat([joy_chi_il_nonnull_merged_df,null_dataframes['joy_chi_il_null']], ignore_index=True)\n",
    "\n",
    "joy_chi_il_final_sen_df_copy = joy_chi_il_final_sen_df.copy()\n",
    "joy_chi_il_final_sen_df_copy[\"Published At Date\"] = joy_chi_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_chi_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_chi_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398fd44-3652-4912-88db-c67812ce41b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aa4be1a-8c30-4003-b392-9f867cfe97d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_hou_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bb59bb0f-3754-4054-b725-3e027e2e3c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:03.413418Z",
     "iopub.status.busy": "2025-06-11T05:41:03.413177Z",
     "iopub.status.idle": "2025-06-11T05:41:42.511214Z",
     "shell.execute_reply": "2025-06-11T05:41:42.510711Z",
     "shell.execute_reply.started": "2025-06-11T05:41:03.413401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [8] Iterations\n",
      "Total Execution Time: 00:00:39\n",
      "Total Input Tokens - 8945\n",
      "Total Input Cost = 0.09\n",
      "Total Output Tokens - 2825\n",
      "Total Output Cost = 0.08\n",
      "Total Cost = 0.17\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_1-4'])/25)+math.ceil(len(joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_5-15'])/25)+math.ceil(len(joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_16-30'])/25)+math.ceil(len(joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_31-60'])/25)+math.ceil(len(joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_61-100'])/25)+math.ceil(len(joy_hou_tx_nonnull_buckets['joy_hou_tx_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_hou_tx_nonnull_buckets.keys())\n",
    "joy_hou_tx_nonnull_api = []\n",
    "input_tokens_joy_hou_tx_nonnull=0\n",
    "output_tokens_joy_hou_tx_nonnull=0\n",
    "start_time_joy_hou_tx = time.time()\n",
    "\n",
    "for key in joy_hou_tx_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_hou_tx_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_hou_tx, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_hou_tx_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_hou_tx_nonnull+=input_tokens\n",
    "    output_tokens_joy_hou_tx_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_hou_tx = time.time() - start_time_joy_hou_tx\n",
    "formatted_time_joy_hou_tx = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_hou_tx))\n",
    "input_token_cost_joy_hou_tx = round((0.01/1000) * input_tokens_joy_hou_tx_nonnull, 2)\n",
    "output_token_cost_joy_hou_tx = round((0.03/1000) * output_tokens_joy_hou_tx_nonnull, 2)\n",
    "total_cost_joy_hou_tx = round(input_token_cost_joy_hou_tx + output_token_cost_joy_hou_tx, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_hou_tx}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_hou_tx_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_hou_tx}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_hou_tx_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_hou_tx}\")\n",
    "print(f\"Total Cost = {total_cost_joy_hou_tx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "da6bc101-0749-41a4-bc1a-7afb38fce63d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:42.512906Z",
     "iopub.status.busy": "2025-06-11T05:41:42.512636Z",
     "iopub.status.idle": "2025-06-11T05:41:42.516595Z",
     "shell.execute_reply": "2025-06-11T05:41:42.516086Z",
     "shell.execute_reply.started": "2025-06-11T05:41:42.512886Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_hou_tx_nonnull_api & convert to DataFrame\n",
    "joy_hou_tx_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_hou_tx_nonnull_api\n",
    "]                                  \n",
    "joy_hou_tx_nonnull_api_cleaned_df = pd.DataFrame(joy_hou_tx_nonnull_api_cleaned)\n",
    "#joy_hou_tx_nonnull_api_cleaned_df = pd.DataFrame(joy_hou_tx_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b510105b-8fe8-4e88-a527-734b88a224da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:42.517613Z",
     "iopub.status.busy": "2025-06-11T05:41:42.517300Z",
     "iopub.status.idle": "2025-06-11T05:41:42.524323Z",
     "shell.execute_reply": "2025-06-11T05:41:42.523796Z",
     "shell.execute_reply.started": "2025-06-11T05:41:42.517587Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_hou_tx_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_hou_tx_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_hou_tx_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e15eb-5148-4d74-9d6a-40f47837a63d",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_hou_tx_nonnull_api_cleaned_df.to_excel(\"joy_hou_tx_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f12c92-2f9b-4596-9b14-f0dfbd137ea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_hou_tx_nonnull_api_cleaned_df = pd.read_excel(\"joy_hou_tx_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2757fe1-f8c3-4b80-a588-95ba98bb3b16",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_hou_tx_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "77251142-a9cc-4c2b-8188-e084deca3573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:42.525258Z",
     "iopub.status.busy": "2025-06-11T05:41:42.524954Z",
     "iopub.status.idle": "2025-06-11T05:41:42.581224Z",
     "shell.execute_reply": "2025-06-11T05:41:42.580709Z",
     "shell.execute_reply.started": "2025-06-11T05:41:42.525240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_hou_tx_nonnull_sen_df = pd.DataFrame(processed_data_joy_hou_tx_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_hou_tx_nonnull_sen_df = joy_hou_tx_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_hou_tx_nonnull_merged_df = pd.concat([combined_df_joy_hou_tx, joy_hou_tx_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_hou_tx_final_sen_df = pd.concat([joy_hou_tx_nonnull_merged_df,null_dataframes['joy_hou_tx_null']], ignore_index=True)\n",
    "\n",
    "joy_hou_tx_final_sen_df_copy = joy_hou_tx_final_sen_df.copy()\n",
    "joy_hou_tx_final_sen_df_copy[\"Published At Date\"] = joy_hou_tx_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_hou_tx_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_hou_tx_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4f16f-deea-421e-a148-3ec6e59b086e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62bbcfca-2058-4911-b33b-34398ab6d4df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "84fbd59c-12dc-400d-9eb2-c1a5d9d7bb8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:41:42.582449Z",
     "iopub.status.busy": "2025-06-11T05:41:42.581936Z",
     "iopub.status.idle": "2025-06-11T05:43:02.252312Z",
     "shell.execute_reply": "2025-06-11T05:43:02.251735Z",
     "shell.execute_reply.started": "2025-06-11T05:41:42.582400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [12] Iterations\n",
      "Total Execution Time: 00:01:19\n",
      "Total Input Tokens - 16908\n",
      "Total Input Cost = 0.17\n",
      "Total Output Tokens - 6217\n",
      "Total Output Cost = 0.19\n",
      "Total Cost = 0.36\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_1-4'])/25)+math.ceil(len(joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_5-15'])/25)+math.ceil(len(joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_16-30'])/25)+math.ceil(len(joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_31-60'])/25)+math.ceil(len(joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_61-100'])/25)+math.ceil(len(joy_fri_tx_nonnull_buckets['joy_fri_tx_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(joy_fri_tx_nonnull_buckets.keys())\n",
    "joy_fri_tx_nonnull_api = []\n",
    "input_tokens_joy_fri_tx_nonnull=0\n",
    "output_tokens_joy_fri_tx_nonnull=0\n",
    "start_time_joy_fri_tx = time.time()\n",
    "\n",
    "for key in joy_fri_tx_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = joy_fri_tx_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_joy_fri_tx, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        joy_fri_tx_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_joy_fri_tx_nonnull+=input_tokens\n",
    "    output_tokens_joy_fri_tx_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_joy_fri_tx = time.time() - start_time_joy_fri_tx\n",
    "formatted_time_joy_fri_tx = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_joy_fri_tx))\n",
    "input_token_cost_joy_fri_tx = round((0.01/1000) * input_tokens_joy_fri_tx_nonnull, 2)\n",
    "output_token_cost_joy_fri_tx = round((0.03/1000) * output_tokens_joy_fri_tx_nonnull, 2)\n",
    "total_cost_joy_fri_tx = round(input_token_cost_joy_fri_tx + output_token_cost_joy_fri_tx, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_joy_fri_tx}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_joy_fri_tx_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_joy_fri_tx}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_joy_fri_tx_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_joy_fri_tx}\")\n",
    "print(f\"Total Cost = {total_cost_joy_fri_tx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3c362482-4493-40aa-9c53-b02b8081edd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:43:02.253214Z",
     "iopub.status.busy": "2025-06-11T05:43:02.252998Z",
     "iopub.status.idle": "2025-06-11T05:43:02.257174Z",
     "shell.execute_reply": "2025-06-11T05:43:02.256489Z",
     "shell.execute_reply.started": "2025-06-11T05:43:02.253185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in joy_fri_tx_nonnull_api & convert to DataFrame\n",
    "joy_fri_tx_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in joy_fri_tx_nonnull_api\n",
    "]                                  \n",
    "joy_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(joy_fri_tx_nonnull_api_cleaned)\n",
    "#joy_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(joy_fri_tx_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c2a64e2c-1d9c-49ae-b658-111496e6cca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:43:02.258098Z",
     "iopub.status.busy": "2025-06-11T05:43:02.257852Z",
     "iopub.status.idle": "2025-06-11T05:43:02.265432Z",
     "shell.execute_reply": "2025-06-11T05:43:02.264925Z",
     "shell.execute_reply.started": "2025-06-11T05:43:02.258082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_joy_fri_tx_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in joy_fri_tx_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_joy_fri_tx_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec05ca1-6144-4454-84d1-80b13493d333",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_fri_tx_nonnull_api_cleaned_df.to_excel(\"joy_fri_tx_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12011bb1-4852-4b6d-bb94-561063e2a0ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_fri_tx_nonnull_api_cleaned_df = pd.read_excel(\"joy_fri_tx_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1cd31f-ec0f-4bb1-8e54-5d4b7c43a4d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "joy_fri_tx_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2db95ba6-0624-4c26-a49f-e14bf6e2f138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:43:02.266270Z",
     "iopub.status.busy": "2025-06-11T05:43:02.266034Z",
     "iopub.status.idle": "2025-06-11T05:43:02.356339Z",
     "shell.execute_reply": "2025-06-11T05:43:02.355789Z",
     "shell.execute_reply.started": "2025-06-11T05:43:02.266252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "joy_fri_tx_nonnull_sen_df = pd.DataFrame(processed_data_joy_fri_tx_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "joy_fri_tx_nonnull_sen_df = joy_fri_tx_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "joy_fri_tx_nonnull_merged_df = pd.concat([combined_df_joy_fri_tx, joy_fri_tx_nonnull_sen_df], axis=1)\n",
    "\n",
    "joy_fri_tx_final_sen_df = pd.concat([joy_fri_tx_nonnull_merged_df,null_dataframes['joy_fri_tx_null']], ignore_index=True)\n",
    "\n",
    "joy_fri_tx_final_sen_df_copy = joy_fri_tx_final_sen_df.copy()\n",
    "joy_fri_tx_final_sen_df_copy[\"Published At Date\"] = joy_fri_tx_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "joy_fri_tx_final_sen_df_copy.to_excel(\"sentiment_raw_output/joy_fri_tx_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73e138-95a4-40db-81b3-175f5f090a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6354e2a0-a9ce-4bb8-a608-87198a494780",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a6d7296b-8273-49e0-bedf-e0c87788fc4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:43:22.564423Z",
     "iopub.status.busy": "2025-06-11T05:43:22.564113Z",
     "iopub.status.idle": "2025-06-11T05:44:44.740894Z",
     "shell.execute_reply": "2025-06-11T05:44:44.740375Z",
     "shell.execute_reply.started": "2025-06-11T05:43:22.564401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [13] Iterations\n",
      "Total Execution Time: 00:01:22\n",
      "Total Input Tokens - 18124\n",
      "Total Input Cost = 0.18\n",
      "Total Output Tokens - 7052\n",
      "Total Output Cost = 0.21\n",
      "Total Cost = 0.39\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_1-4'])/25)+math.ceil(len(mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_5-15'])/25)+math.ceil(len(mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_16-30'])/25)+math.ceil(len(mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_31-60'])/25)+math.ceil(len(mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_61-100'])/25)+math.ceil(len(mal_chi_il_nonnull_buckets['mal_chi_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_chi_il_nonnull_buckets.keys())\n",
    "mal_chi_il_nonnull_api = []\n",
    "input_tokens_mal_chi_il_nonnull=0\n",
    "output_tokens_mal_chi_il_nonnull=0\n",
    "start_time_mal_chi_il = time.time()\n",
    "\n",
    "for key in mal_chi_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_chi_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_chi_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_chi_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_chi_il_nonnull+=input_tokens\n",
    "    output_tokens_mal_chi_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_chi_il = time.time() - start_time_mal_chi_il\n",
    "formatted_time_mal_chi_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_chi_il))\n",
    "input_token_cost_mal_chi_il = round((0.01/1000) * input_tokens_mal_chi_il_nonnull, 2)\n",
    "output_token_cost_mal_chi_il = round((0.03/1000) * output_tokens_mal_chi_il_nonnull, 2)\n",
    "total_cost_mal_chi_il = round(input_token_cost_mal_chi_il + output_token_cost_mal_chi_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_chi_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_chi_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_chi_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_chi_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_chi_il}\")\n",
    "print(f\"Total Cost = {total_cost_mal_chi_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2d96817c-89a6-435c-962f-c998acea6465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:44:44.742033Z",
     "iopub.status.busy": "2025-06-11T05:44:44.741763Z",
     "iopub.status.idle": "2025-06-11T05:44:44.745895Z",
     "shell.execute_reply": "2025-06-11T05:44:44.745359Z",
     "shell.execute_reply.started": "2025-06-11T05:44:44.742013Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_chi_il_nonnull_api & convert to DataFrame\n",
    "mal_chi_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_chi_il_nonnull_api\n",
    "]                                  \n",
    "mal_chi_il_nonnull_api_cleaned_df = pd.DataFrame(mal_chi_il_nonnull_api_cleaned)\n",
    "#mal_chi_il_nonnull_api_cleaned_df = pd.DataFrame(mal_chi_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8f3d32a4-4e93-411b-ac19-c2349d2f740a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:44:44.746708Z",
     "iopub.status.busy": "2025-06-11T05:44:44.746497Z",
     "iopub.status.idle": "2025-06-11T05:44:44.754699Z",
     "shell.execute_reply": "2025-06-11T05:44:44.754210Z",
     "shell.execute_reply.started": "2025-06-11T05:44:44.746690Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_chi_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_chi_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_chi_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f814ba1-6dc2-450e-8f04-ae1343666b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_chi_il_nonnull_api_cleaned_df.to_excel(\"mal_chi_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dacae07-5179-4681-a77c-5897e5126204",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_chi_il_nonnull_api_cleaned_df = pd.read_excel(\"mal_chi_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b80d5-8955-4df5-b103-51c149061a45",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_chi_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "98352651-d8b2-4354-accb-58469570fa03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:44:44.756305Z",
     "iopub.status.busy": "2025-06-11T05:44:44.756077Z",
     "iopub.status.idle": "2025-06-11T05:44:44.853799Z",
     "shell.execute_reply": "2025-06-11T05:44:44.853329Z",
     "shell.execute_reply.started": "2025-06-11T05:44:44.756288Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_chi_il_nonnull_sen_df = pd.DataFrame(processed_data_mal_chi_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_chi_il_nonnull_sen_df = mal_chi_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_chi_il_nonnull_merged_df = pd.concat([combined_df_mal_chi_il, mal_chi_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_chi_il_final_sen_df = pd.concat([mal_chi_il_nonnull_merged_df,null_dataframes['mal_chi_il_null']], ignore_index=True)\n",
    "\n",
    "mal_chi_il_final_sen_df_copy = mal_chi_il_final_sen_df.copy()\n",
    "mal_chi_il_final_sen_df_copy[\"Published At Date\"] = mal_chi_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_chi_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_chi_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9857a-ce73-44c1-8f29-43e53be04992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcc71197-53f4-4bf7-8d41-528fd403088a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_nap_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "aefdd0f9-1824-4763-bf55-7bc4cf9c5ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:44:44.854815Z",
     "iopub.status.busy": "2025-06-11T05:44:44.854615Z",
     "iopub.status.idle": "2025-06-11T05:46:37.082096Z",
     "shell.execute_reply": "2025-06-11T05:46:37.081544Z",
     "shell.execute_reply.started": "2025-06-11T05:44:44.854797Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [17] Iterations\n",
      "Total Execution Time: 00:01:52\n",
      "Total Input Tokens - 23167\n",
      "Total Input Cost = 0.23\n",
      "Total Output Tokens - 9785\n",
      "Total Output Cost = 0.29\n",
      "Total Cost = 0.52\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_1-4'])/25)+math.ceil(len(mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_5-15'])/25)+math.ceil(len(mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_16-30'])/25)+math.ceil(len(mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_31-60'])/25)+math.ceil(len(mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_61-100'])/25)+math.ceil(len(mal_nap_il_nonnull_buckets['mal_nap_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_nap_il_nonnull_buckets.keys())\n",
    "mal_nap_il_nonnull_api = []\n",
    "input_tokens_mal_nap_il_nonnull=0\n",
    "output_tokens_mal_nap_il_nonnull=0\n",
    "start_time_mal_nap_il = time.time()\n",
    "\n",
    "for key in mal_nap_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_nap_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_nap_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_nap_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_nap_il_nonnull+=input_tokens\n",
    "    output_tokens_mal_nap_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_nap_il = time.time() - start_time_mal_nap_il\n",
    "formatted_time_mal_nap_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_nap_il))\n",
    "input_token_cost_mal_nap_il = round((0.01/1000) * input_tokens_mal_nap_il_nonnull, 2)\n",
    "output_token_cost_mal_nap_il = round((0.03/1000) * output_tokens_mal_nap_il_nonnull, 2)\n",
    "total_cost_mal_nap_il = round(input_token_cost_mal_nap_il + output_token_cost_mal_nap_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_nap_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_nap_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_nap_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_nap_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_nap_il}\")\n",
    "print(f\"Total Cost = {total_cost_mal_nap_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e8a5343a-5b63-4927-bf76-84ce1388bfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:46:37.083197Z",
     "iopub.status.busy": "2025-06-11T05:46:37.082854Z",
     "iopub.status.idle": "2025-06-11T05:46:37.087086Z",
     "shell.execute_reply": "2025-06-11T05:46:37.086542Z",
     "shell.execute_reply.started": "2025-06-11T05:46:37.083169Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_nap_il_nonnull_api & convert to DataFrame\n",
    "mal_nap_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_nap_il_nonnull_api\n",
    "]                                  \n",
    "mal_nap_il_nonnull_api_cleaned_df = pd.DataFrame(mal_nap_il_nonnull_api_cleaned)\n",
    "#mal_nap_il_nonnull_api_cleaned_df = pd.DataFrame(mal_nap_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "65dced40-4c81-4c4b-8a3b-bad743eafff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:46:37.087948Z",
     "iopub.status.busy": "2025-06-11T05:46:37.087689Z",
     "iopub.status.idle": "2025-06-11T05:46:37.096596Z",
     "shell.execute_reply": "2025-06-11T05:46:37.096082Z",
     "shell.execute_reply.started": "2025-06-11T05:46:37.087930Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_nap_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_nap_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_nap_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40860722-69e7-409b-96e5-2ae6a2aba17a",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_nap_il_nonnull_api_cleaned_df.to_excel(\"mal_nap_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5360e-773a-4202-b52a-b84900dab997",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_nap_il_nonnull_api_cleaned_df = pd.read_excel(\"mal_nap_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88dee7-583d-465c-a1b9-f1451ce8676b",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_nap_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a1ab54cb-60e9-439d-938b-f9fe317df252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:46:37.097533Z",
     "iopub.status.busy": "2025-06-11T05:46:37.097271Z",
     "iopub.status.idle": "2025-06-11T05:46:37.366837Z",
     "shell.execute_reply": "2025-06-11T05:46:37.366328Z",
     "shell.execute_reply.started": "2025-06-11T05:46:37.097516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_nap_il_nonnull_sen_df = pd.DataFrame(processed_data_mal_nap_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_nap_il_nonnull_sen_df = mal_nap_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_nap_il_nonnull_merged_df = pd.concat([combined_df_mal_nap_il, mal_nap_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_nap_il_final_sen_df = pd.concat([mal_nap_il_nonnull_merged_df,null_dataframes['mal_nap_il_null']], ignore_index=True)\n",
    "\n",
    "mal_nap_il_final_sen_df_copy = mal_nap_il_final_sen_df.copy()\n",
    "mal_nap_il_final_sen_df_copy[\"Published At Date\"] = mal_nap_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_nap_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_nap_il_final_sen_df_jul.xlsx\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d4c00-6cf4-4602-8784-9de706f51270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1c7a992-9830-4228-83eb-01754f247616",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ise_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e38fce78-339d-4213-9d60-84be9a7a196d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:46:37.367802Z",
     "iopub.status.busy": "2025-06-11T05:46:37.367540Z",
     "iopub.status.idle": "2025-06-11T05:48:44.615779Z",
     "shell.execute_reply": "2025-06-11T05:48:44.615205Z",
     "shell.execute_reply.started": "2025-06-11T05:46:37.367784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [18] Iterations\n",
      "Total Execution Time: 00:02:07\n",
      "Total Input Tokens - 24135\n",
      "Total Input Cost = 0.24\n",
      "Total Output Tokens - 10058\n",
      "Total Output Cost = 0.3\n",
      "Total Cost = 0.54\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_1-4'])/25)+math.ceil(len(mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_5-15'])/25)+math.ceil(len(mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_16-30'])/25)+math.ceil(len(mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_31-60'])/25)+math.ceil(len(mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_61-100'])/25)+math.ceil(len(mal_ise_nj_nonnull_buckets['mal_ise_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_ise_nj_nonnull_buckets.keys())\n",
    "mal_ise_nj_nonnull_api = []\n",
    "input_tokens_mal_ise_nj_nonnull=0\n",
    "output_tokens_mal_ise_nj_nonnull=0\n",
    "start_time_mal_ise_nj = time.time()\n",
    "\n",
    "for key in mal_ise_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_ise_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_ise_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_ise_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_ise_nj_nonnull+=input_tokens\n",
    "    output_tokens_mal_ise_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_ise_nj = time.time() - start_time_mal_ise_nj\n",
    "formatted_time_mal_ise_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_ise_nj))\n",
    "input_token_cost_mal_ise_nj = round((0.01/1000) * input_tokens_mal_ise_nj_nonnull, 2)\n",
    "output_token_cost_mal_ise_nj = round((0.03/1000) * output_tokens_mal_ise_nj_nonnull, 2)\n",
    "total_cost_mal_ise_nj = round(input_token_cost_mal_ise_nj + output_token_cost_mal_ise_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_ise_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_ise_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_ise_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_ise_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_ise_nj}\")\n",
    "print(f\"Total Cost = {total_cost_mal_ise_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b6c84c07-3a23-4d74-919b-bb6c75694809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:48:44.618069Z",
     "iopub.status.busy": "2025-06-11T05:48:44.617781Z",
     "iopub.status.idle": "2025-06-11T05:48:44.621964Z",
     "shell.execute_reply": "2025-06-11T05:48:44.621457Z",
     "shell.execute_reply.started": "2025-06-11T05:48:44.618044Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_ise_nj_nonnull_api & convert to DataFrame\n",
    "mal_ise_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_ise_nj_nonnull_api\n",
    "]                                  \n",
    "mal_ise_nj_nonnull_api_cleaned_df = pd.DataFrame(mal_ise_nj_nonnull_api_cleaned)\n",
    "#mal_ise_nj_nonnull_api_cleaned_df = pd.DataFrame(mal_ise_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2f3f0c4f-cbeb-4867-93ba-ee01ed90faf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:48:44.622973Z",
     "iopub.status.busy": "2025-06-11T05:48:44.622653Z",
     "iopub.status.idle": "2025-06-11T05:48:44.631903Z",
     "shell.execute_reply": "2025-06-11T05:48:44.631402Z",
     "shell.execute_reply.started": "2025-06-11T05:48:44.622947Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_ise_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_ise_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_ise_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b153f-2b34-43d3-8cf2-6be4edc2960f",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ise_nj_nonnull_api_cleaned_df.to_excel(\"mal_ise_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866b752-68bc-407c-8a6b-a3a6ad4cff41",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ise_nj_nonnull_api_cleaned_df = pd.read_excel(\"mal_ise_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9de7c-221b-423c-9d46-91af369a95fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ise_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "afe7e9b4-2165-42a7-af2c-bb1c4e1a92ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:48:44.632872Z",
     "iopub.status.busy": "2025-06-11T05:48:44.632690Z",
     "iopub.status.idle": "2025-06-11T05:48:44.752657Z",
     "shell.execute_reply": "2025-06-11T05:48:44.752193Z",
     "shell.execute_reply.started": "2025-06-11T05:48:44.632856Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_ise_nj_nonnull_sen_df = pd.DataFrame(processed_data_mal_ise_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_ise_nj_nonnull_sen_df = mal_ise_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_ise_nj_nonnull_merged_df = pd.concat([combined_df_mal_ise_nj, mal_ise_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_ise_nj_final_sen_df = pd.concat([mal_ise_nj_nonnull_merged_df,null_dataframes['mal_ise_nj_null']], ignore_index=True)\n",
    "\n",
    "mal_ise_nj_final_sen_df_copy = mal_ise_nj_final_sen_df.copy()\n",
    "mal_ise_nj_final_sen_df_copy[\"Published At Date\"] = mal_ise_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_ise_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_ise_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc48f83-4ea6-4db1-aa2b-e6e72a816f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b487d7-b9f8-44ac-9d20-4227ad1daf55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a8a9af1e-ed79-4b9e-941a-c435180cb291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:48:44.753807Z",
     "iopub.status.busy": "2025-06-11T05:48:44.753541Z",
     "iopub.status.idle": "2025-06-11T05:50:39.483798Z",
     "shell.execute_reply": "2025-06-11T05:50:39.483242Z",
     "shell.execute_reply.started": "2025-06-11T05:48:44.753782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [15] Iterations\n",
      "Total Execution Time: 00:01:54\n",
      "Total Input Tokens - 21931\n",
      "Total Input Cost = 0.22\n",
      "Total Output Tokens - 8889\n",
      "Total Output Cost = 0.27\n",
      "Total Cost = 0.49\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_1-4'])/25)+math.ceil(len(mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_5-15'])/25)+math.ceil(len(mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_16-30'])/25)+math.ceil(len(mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_31-60'])/25)+math.ceil(len(mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_61-100'])/25)+math.ceil(len(mal_fri_tx_nonnull_buckets['mal_fri_tx_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_fri_tx_nonnull_buckets.keys())\n",
    "mal_fri_tx_nonnull_api = []\n",
    "input_tokens_mal_fri_tx_nonnull=0\n",
    "output_tokens_mal_fri_tx_nonnull=0\n",
    "start_time_mal_fri_tx = time.time()\n",
    "\n",
    "for key in mal_fri_tx_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_fri_tx_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_fri_tx, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_fri_tx_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_fri_tx_nonnull+=input_tokens\n",
    "    output_tokens_mal_fri_tx_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_fri_tx = time.time() - start_time_mal_fri_tx\n",
    "formatted_time_mal_fri_tx = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_fri_tx))\n",
    "input_token_cost_mal_fri_tx = round((0.01/1000) * input_tokens_mal_fri_tx_nonnull, 2)\n",
    "output_token_cost_mal_fri_tx = round((0.03/1000) * output_tokens_mal_fri_tx_nonnull, 2)\n",
    "total_cost_mal_fri_tx = round(input_token_cost_mal_fri_tx + output_token_cost_mal_fri_tx, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_fri_tx}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_fri_tx_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_fri_tx}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_fri_tx_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_fri_tx}\")\n",
    "print(f\"Total Cost = {total_cost_mal_fri_tx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "dbaf27d3-5ad7-47c6-a930-0aed21d934b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:50:39.484758Z",
     "iopub.status.busy": "2025-06-11T05:50:39.484489Z",
     "iopub.status.idle": "2025-06-11T05:50:39.488659Z",
     "shell.execute_reply": "2025-06-11T05:50:39.488122Z",
     "shell.execute_reply.started": "2025-06-11T05:50:39.484739Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_fri_tx_nonnull_api & convert to DataFrame\n",
    "mal_fri_tx_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_fri_tx_nonnull_api\n",
    "]                                  \n",
    "mal_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(mal_fri_tx_nonnull_api_cleaned)\n",
    "#mal_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(mal_fri_tx_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ae93561c-fdcd-4185-b99c-4125341757f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:50:39.489502Z",
     "iopub.status.busy": "2025-06-11T05:50:39.489283Z",
     "iopub.status.idle": "2025-06-11T05:50:39.497758Z",
     "shell.execute_reply": "2025-06-11T05:50:39.497299Z",
     "shell.execute_reply.started": "2025-06-11T05:50:39.489485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_fri_tx_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_fri_tx_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_fri_tx_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f94de40-8279-4d44-851a-b8366472539a",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_fri_tx_nonnull_api_cleaned_df.to_excel(\"mal_fri_tx_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aba56c-81a1-4eca-a080-c3e6157cc84c",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_fri_tx_nonnull_api_cleaned_df = pd.read_excel(\"mal_fri_tx_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6426ba-351b-4fa8-a8ba-ad18623ee287",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_fri_tx_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8dc504af-3054-4377-a132-b1ef2ccb6c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:50:39.498691Z",
     "iopub.status.busy": "2025-06-11T05:50:39.498368Z",
     "iopub.status.idle": "2025-06-11T05:50:39.609494Z",
     "shell.execute_reply": "2025-06-11T05:50:39.608986Z",
     "shell.execute_reply.started": "2025-06-11T05:50:39.498665Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_fri_tx_nonnull_sen_df = pd.DataFrame(processed_data_mal_fri_tx_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_fri_tx_nonnull_sen_df = mal_fri_tx_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_fri_tx_nonnull_merged_df = pd.concat([combined_df_mal_fri_tx, mal_fri_tx_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_fri_tx_final_sen_df = pd.concat([mal_fri_tx_nonnull_merged_df,null_dataframes['mal_fri_tx_null']], ignore_index=True)\n",
    "\n",
    "mal_fri_tx_final_sen_df_copy = mal_fri_tx_final_sen_df.copy()\n",
    "mal_fri_tx_final_sen_df_copy[\"Published At Date\"] = mal_fri_tx_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_fri_tx_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_fri_tx_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b282d-0e60-4736-a768-f1da94887d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b62e071-f9cd-4dd5-9af8-96b110ab8486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ric_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ea288921-699c-42c8-ae4a-593dfb719888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:50:39.610591Z",
     "iopub.status.busy": "2025-06-11T05:50:39.610249Z",
     "iopub.status.idle": "2025-06-11T05:51:06.692962Z",
     "shell.execute_reply": "2025-06-11T05:51:06.692367Z",
     "shell.execute_reply.started": "2025-06-11T05:50:39.610544Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [6] Iterations\n",
      "Total Execution Time: 00:00:27\n",
      "Total Input Tokens - 6737\n",
      "Total Input Cost = 0.07\n",
      "Total Output Tokens - 1834\n",
      "Total Output Cost = 0.06\n",
      "Total Cost = 0.13\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_1-4'])/25)+math.ceil(len(mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_5-15'])/25)+math.ceil(len(mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_16-30'])/25)+math.ceil(len(mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_31-60'])/25)+math.ceil(len(mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_61-100'])/25)+math.ceil(len(mal_ric_tx_nonnull_buckets['mal_ric_tx_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mal_ric_tx_nonnull_buckets.keys())\n",
    "mal_ric_tx_nonnull_api = []\n",
    "input_tokens_mal_ric_tx_nonnull=0\n",
    "output_tokens_mal_ric_tx_nonnull=0\n",
    "start_time_mal_ric_tx = time.time()\n",
    "\n",
    "for key in mal_ric_tx_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mal_ric_tx_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mal_ric_tx, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mal_ric_tx_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mal_ric_tx_nonnull+=input_tokens\n",
    "    output_tokens_mal_ric_tx_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mal_ric_tx = time.time() - start_time_mal_ric_tx\n",
    "formatted_time_mal_ric_tx = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mal_ric_tx))\n",
    "input_token_cost_mal_ric_tx = round((0.01/1000) * input_tokens_mal_ric_tx_nonnull, 2)\n",
    "output_token_cost_mal_ric_tx = round((0.03/1000) * output_tokens_mal_ric_tx_nonnull, 2)\n",
    "total_cost_mal_ric_tx = round(input_token_cost_mal_ric_tx + output_token_cost_mal_ric_tx, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mal_ric_tx}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mal_ric_tx_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mal_ric_tx}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mal_ric_tx_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mal_ric_tx}\")\n",
    "print(f\"Total Cost = {total_cost_mal_ric_tx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9cd339fb-237f-4235-af50-7a5100df6cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:51:06.693931Z",
     "iopub.status.busy": "2025-06-11T05:51:06.693646Z",
     "iopub.status.idle": "2025-06-11T05:51:06.698017Z",
     "shell.execute_reply": "2025-06-11T05:51:06.697472Z",
     "shell.execute_reply.started": "2025-06-11T05:51:06.693911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mal_ric_tx_nonnull_api & convert to DataFrame\n",
    "mal_ric_tx_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mal_ric_tx_nonnull_api\n",
    "]                                  \n",
    "mal_ric_tx_nonnull_api_cleaned_df = pd.DataFrame(mal_ric_tx_nonnull_api_cleaned)\n",
    "#mal_ric_tx_nonnull_api_cleaned_df = pd.DataFrame(mal_ric_tx_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "357eb2ad-6f2e-4758-9ae5-a5c370025e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:51:06.698791Z",
     "iopub.status.busy": "2025-06-11T05:51:06.698589Z",
     "iopub.status.idle": "2025-06-11T05:51:06.705447Z",
     "shell.execute_reply": "2025-06-11T05:51:06.704847Z",
     "shell.execute_reply.started": "2025-06-11T05:51:06.698774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mal_ric_tx_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mal_ric_tx_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mal_ric_tx_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4e32e-4be3-49ab-965a-b4b0a71990a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ric_tx_nonnull_api_cleaned_df.to_excel(\"mal_ric_tx_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55393070-dcbd-4060-a897-aa6aa0e31c4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ric_tx_nonnull_api_cleaned_df = pd.read_excel(\"mal_ric_tx_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916984b1-8f85-4220-acae-907cdb0b72ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "mal_ric_tx_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "fa1b2dcc-5f80-4668-bdb0-686d3fbb3854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:51:06.706580Z",
     "iopub.status.busy": "2025-06-11T05:51:06.706302Z",
     "iopub.status.idle": "2025-06-11T05:51:06.749008Z",
     "shell.execute_reply": "2025-06-11T05:51:06.748524Z",
     "shell.execute_reply.started": "2025-06-11T05:51:06.706532Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mal_ric_tx_nonnull_sen_df = pd.DataFrame(processed_data_mal_ric_tx_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mal_ric_tx_nonnull_sen_df = mal_ric_tx_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mal_ric_tx_nonnull_merged_df = pd.concat([combined_df_mal_ric_tx, mal_ric_tx_nonnull_sen_df], axis=1)\n",
    "\n",
    "mal_ric_tx_final_sen_df = pd.concat([mal_ric_tx_nonnull_merged_df,null_dataframes['mal_ric_tx_null']], ignore_index=True)\n",
    "\n",
    "mal_ric_tx_final_sen_df_copy = mal_ric_tx_final_sen_df.copy()\n",
    "mal_ric_tx_final_sen_df_copy[\"Published At Date\"] = mal_ric_tx_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mal_ric_tx_final_sen_df_copy.to_excel(\"sentiment_raw_output/mal_ric_tx_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c948c-1fa1-447b-84cc-b32f0b25e306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f50d7530-8242-4db7-99d1-dd81637484b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### may_vie_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "992fa689-946f-49c1-8ff8-aa0f8a101b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:53:38.494817Z",
     "iopub.status.busy": "2025-06-11T05:53:38.494438Z",
     "iopub.status.idle": "2025-06-11T05:53:40.025456Z",
     "shell.execute_reply": "2025-06-11T05:53:40.024928Z",
     "shell.execute_reply.started": "2025-06-11T05:53:38.494786Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:01\n",
      "Total Input Tokens - 658\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 35\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(may_vie_va_nonnull_buckets['may_vie_va_nonnull_1-4'])/25)+math.ceil(len(may_vie_va_nonnull_buckets['may_vie_va_nonnull_5-15'])/25)+math.ceil(len(may_vie_va_nonnull_buckets['may_vie_va_nonnull_16-30'])/25)+math.ceil(len(may_vie_va_nonnull_buckets['may_vie_va_nonnull_31-60'])/25)+math.ceil(len(may_vie_va_nonnull_buckets['may_vie_va_nonnull_61-100'])/25)+math.ceil(len(may_vie_va_nonnull_buckets['may_vie_va_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(may_vie_va_nonnull_buckets.keys())\n",
    "may_vie_va_nonnull_api = []\n",
    "input_tokens_may_vie_va_nonnull=0\n",
    "output_tokens_may_vie_va_nonnull=0\n",
    "start_time_may_vie_va = time.time()\n",
    "\n",
    "for key in may_vie_va_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = may_vie_va_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_may_vie_va, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        may_vie_va_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_may_vie_va_nonnull+=input_tokens\n",
    "    output_tokens_may_vie_va_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_may_vie_va = time.time() - start_time_may_vie_va\n",
    "formatted_time_may_vie_va = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_may_vie_va))\n",
    "input_token_cost_may_vie_va = round((0.01/1000) * input_tokens_may_vie_va_nonnull, 2)\n",
    "output_token_cost_may_vie_va = round((0.03/1000) * output_tokens_may_vie_va_nonnull, 2)\n",
    "total_cost_may_vie_va = round(input_token_cost_may_vie_va + output_token_cost_may_vie_va, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_may_vie_va}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_may_vie_va_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_may_vie_va}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_may_vie_va_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_may_vie_va}\")\n",
    "print(f\"Total Cost = {total_cost_may_vie_va}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e45810e0-f0a0-44b8-baa1-0c160cd0fa90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:53:41.449945Z",
     "iopub.status.busy": "2025-06-11T05:53:41.449629Z",
     "iopub.status.idle": "2025-06-11T05:53:41.454276Z",
     "shell.execute_reply": "2025-06-11T05:53:41.453462Z",
     "shell.execute_reply.started": "2025-06-11T05:53:41.449922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in may_vie_va_nonnull_api & convert to DataFrame\n",
    "may_vie_va_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in may_vie_va_nonnull_api\n",
    "]                                  \n",
    "may_vie_va_nonnull_api_cleaned_df = pd.DataFrame(may_vie_va_nonnull_api_cleaned)\n",
    "#may_vie_va_nonnull_api_cleaned_df = pd.DataFrame(may_vie_va_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5d199598-d5f5-4531-93e8-6c8f8f79956e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:53:42.114094Z",
     "iopub.status.busy": "2025-06-11T05:53:42.113778Z",
     "iopub.status.idle": "2025-06-11T05:53:42.120190Z",
     "shell.execute_reply": "2025-06-11T05:53:42.119527Z",
     "shell.execute_reply.started": "2025-06-11T05:53:42.114072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_may_vie_va_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in may_vie_va_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_may_vie_va_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c400e10-7411-47fe-89d3-94a95eb163de",
   "metadata": {
    "tags": []
   },
   "source": [
    "may_vie_va_nonnull_api_cleaned_df.to_excel(\"may_vie_va_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cfb1a-972f-4858-a69a-202706cae996",
   "metadata": {
    "tags": []
   },
   "source": [
    "may_vie_va_nonnull_api_cleaned_df = pd.read_excel(\"may_vie_va_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4c499-f15c-4d97-805b-759b2435a303",
   "metadata": {
    "tags": []
   },
   "source": [
    "may_vie_va_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "24ec5165-f514-4bdd-a145-a1997020424a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:53:43.350198Z",
     "iopub.status.busy": "2025-06-11T05:53:43.349481Z",
     "iopub.status.idle": "2025-06-11T05:53:43.377030Z",
     "shell.execute_reply": "2025-06-11T05:53:43.376472Z",
     "shell.execute_reply.started": "2025-06-11T05:53:43.350142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "may_vie_va_nonnull_sen_df = pd.DataFrame(processed_data_may_vie_va_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "may_vie_va_nonnull_sen_df = may_vie_va_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "may_vie_va_nonnull_merged_df = pd.concat([combined_df_may_vie_va, may_vie_va_nonnull_sen_df], axis=1)\n",
    "\n",
    "may_vie_va_final_sen_df = pd.concat([may_vie_va_nonnull_merged_df,null_dataframes['may_vie_va_null']], ignore_index=True)\n",
    "\n",
    "may_vie_va_final_sen_df_copy = may_vie_va_final_sen_df.copy()\n",
    "may_vie_va_final_sen_df_copy[\"Published At Date\"] = may_vie_va_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "may_vie_va_final_sen_df_copy.to_excel(\"sentiment_raw_output/may_vie_va_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f881f80-0358-40e4-81f8-f059cfb3ad3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a02e18-6eed-4b6b-9be6-f40a83c358d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### son_ise_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b3190654-27d4-4d74-9678-134be5d2e02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:58:59.702508Z",
     "iopub.status.busy": "2025-06-11T05:58:59.702264Z",
     "iopub.status.idle": "2025-06-11T05:59:07.242525Z",
     "shell.execute_reply": "2025-06-11T05:59:07.241994Z",
     "shell.execute_reply.started": "2025-06-11T05:58:59.702488Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [4] Iterations\n",
      "Total Execution Time: 00:00:07\n",
      "Total Input Tokens - 2836\n",
      "Total Input Cost = 0.03\n",
      "Total Output Tokens - 190\n",
      "Total Output Cost = 0.01\n",
      "Total Cost = 0.04\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_1-4'])/25)+math.ceil(len(son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_5-15'])/25)+math.ceil(len(son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_16-30'])/25)+math.ceil(len(son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_31-60'])/25)+math.ceil(len(son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_61-100'])/25)+math.ceil(len(son_ise_nj_nonnull_buckets['son_ise_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(son_ise_nj_nonnull_buckets.keys())\n",
    "son_ise_nj_nonnull_api = []\n",
    "input_tokens_son_ise_nj_nonnull=0\n",
    "output_tokens_son_ise_nj_nonnull=0\n",
    "start_time_son_ise_nj = time.time()\n",
    "\n",
    "for key in son_ise_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = son_ise_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_son_ise_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        son_ise_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_son_ise_nj_nonnull+=input_tokens\n",
    "    output_tokens_son_ise_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_son_ise_nj = time.time() - start_time_son_ise_nj\n",
    "formatted_time_son_ise_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_son_ise_nj))\n",
    "input_token_cost_son_ise_nj = round((0.01/1000) * input_tokens_son_ise_nj_nonnull, 2)\n",
    "output_token_cost_son_ise_nj = round((0.03/1000) * output_tokens_son_ise_nj_nonnull, 2)\n",
    "total_cost_son_ise_nj = round(input_token_cost_son_ise_nj + output_token_cost_son_ise_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_son_ise_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_son_ise_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_son_ise_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_son_ise_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_son_ise_nj}\")\n",
    "print(f\"Total Cost = {total_cost_son_ise_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "87178c26-1c67-4d87-9872-e2947bab979d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:07.243811Z",
     "iopub.status.busy": "2025-06-11T05:59:07.243353Z",
     "iopub.status.idle": "2025-06-11T05:59:07.247349Z",
     "shell.execute_reply": "2025-06-11T05:59:07.246888Z",
     "shell.execute_reply.started": "2025-06-11T05:59:07.243790Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in son_ise_nj_nonnull_api & convert to DataFrame\n",
    "son_ise_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in son_ise_nj_nonnull_api\n",
    "]                                  \n",
    "son_ise_nj_nonnull_api_cleaned_df = pd.DataFrame(son_ise_nj_nonnull_api_cleaned)\n",
    "#son_ise_nj_nonnull_api_cleaned_df = pd.DataFrame(son_ise_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "34777239-ac91-4c27-aeeb-073169f078da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:07.248193Z",
     "iopub.status.busy": "2025-06-11T05:59:07.247906Z",
     "iopub.status.idle": "2025-06-11T05:59:07.254049Z",
     "shell.execute_reply": "2025-06-11T05:59:07.253605Z",
     "shell.execute_reply.started": "2025-06-11T05:59:07.248169Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_son_ise_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in son_ise_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_son_ise_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609b902-f99a-4333-a11e-4a5f39b6b76e",
   "metadata": {
    "tags": []
   },
   "source": [
    "son_ise_nj_nonnull_api_cleaned_df.to_excel(\"son_ise_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88c216-0041-4d80-8a7c-9286714a6396",
   "metadata": {
    "tags": []
   },
   "source": [
    "son_ise_nj_nonnull_api_cleaned_df = pd.read_excel(\"son_ise_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6f574-c91c-42b4-8605-18c1f0f00c24",
   "metadata": {
    "tags": []
   },
   "source": [
    "son_ise_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f0151519-4aa1-49ab-8ba4-3f6f71cdbe14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:07.255399Z",
     "iopub.status.busy": "2025-06-11T05:59:07.255129Z",
     "iopub.status.idle": "2025-06-11T05:59:07.287379Z",
     "shell.execute_reply": "2025-06-11T05:59:07.286887Z",
     "shell.execute_reply.started": "2025-06-11T05:59:07.255382Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "son_ise_nj_nonnull_sen_df = pd.DataFrame(processed_data_son_ise_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "son_ise_nj_nonnull_sen_df = son_ise_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "son_ise_nj_nonnull_merged_df = pd.concat([combined_df_son_ise_nj, son_ise_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "son_ise_nj_final_sen_df = pd.concat([son_ise_nj_nonnull_merged_df,null_dataframes['son_ise_nj_null']], ignore_index=True)\n",
    "\n",
    "son_ise_nj_final_sen_df_copy = son_ise_nj_final_sen_df.copy()\n",
    "son_ise_nj_final_sen_df_copy[\"Published At Date\"] = son_ise_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "son_ise_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/son_ise_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a685fc-b0f9-4735-9afa-e0de6b78db30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3c0afb8-6be0-4e7a-a9b6-808b86c40bfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8ae30174-d88c-42d8-906c-66431297236d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:11.848823Z",
     "iopub.status.busy": "2025-06-11T05:59:11.848311Z",
     "iopub.status.idle": "2025-06-11T05:59:20.892273Z",
     "shell.execute_reply": "2025-06-11T05:59:20.891727Z",
     "shell.execute_reply.started": "2025-06-11T05:59:11.848799Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:09\n",
      "Total Input Tokens - 3661\n",
      "Total Input Cost = 0.04\n",
      "Total Output Tokens - 207\n",
      "Total Output Cost = 0.01\n",
      "Total Cost = 0.05\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_1-4'])/25)+math.ceil(len(tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_5-15'])/25)+math.ceil(len(tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_16-30'])/25)+math.ceil(len(tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_31-60'])/25)+math.ceil(len(tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_61-100'])/25)+math.ceil(len(tif_chi_il_nonnull_buckets['tif_chi_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_chi_il_nonnull_buckets.keys())\n",
    "tif_chi_il_nonnull_api = []\n",
    "input_tokens_tif_chi_il_nonnull=0\n",
    "output_tokens_tif_chi_il_nonnull=0\n",
    "start_time_tif_chi_il = time.time()\n",
    "\n",
    "for key in tif_chi_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_chi_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_chi_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_chi_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_chi_il_nonnull+=input_tokens\n",
    "    output_tokens_tif_chi_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_chi_il = time.time() - start_time_tif_chi_il\n",
    "formatted_time_tif_chi_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_chi_il))\n",
    "input_token_cost_tif_chi_il = round((0.01/1000) * input_tokens_tif_chi_il_nonnull, 2)\n",
    "output_token_cost_tif_chi_il = round((0.03/1000) * output_tokens_tif_chi_il_nonnull, 2)\n",
    "total_cost_tif_chi_il = round(input_token_cost_tif_chi_il + output_token_cost_tif_chi_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_chi_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_chi_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_chi_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_chi_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_chi_il}\")\n",
    "print(f\"Total Cost = {total_cost_tif_chi_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7e12bf25-b885-4350-85d7-b766e6314842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:20.893660Z",
     "iopub.status.busy": "2025-06-11T05:59:20.893345Z",
     "iopub.status.idle": "2025-06-11T05:59:20.897501Z",
     "shell.execute_reply": "2025-06-11T05:59:20.896991Z",
     "shell.execute_reply.started": "2025-06-11T05:59:20.893639Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_chi_il_nonnull_api & convert to DataFrame\n",
    "tif_chi_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_chi_il_nonnull_api\n",
    "]                                  \n",
    "tif_chi_il_nonnull_api_cleaned_df = pd.DataFrame(tif_chi_il_nonnull_api_cleaned)\n",
    "#tif_chi_il_nonnull_api_cleaned_df = pd.DataFrame(tif_chi_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "43f9fe9e-ceb4-4c3d-9103-371e62e20c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:20.898722Z",
     "iopub.status.busy": "2025-06-11T05:59:20.898073Z",
     "iopub.status.idle": "2025-06-11T05:59:20.904434Z",
     "shell.execute_reply": "2025-06-11T05:59:20.903960Z",
     "shell.execute_reply.started": "2025-06-11T05:59:20.898694Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_chi_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_chi_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_chi_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45017ccf-9b56-409c-8ac5-732723ea0b27",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_chi_il_nonnull_api_cleaned_df.to_excel(\"tif_chi_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cde5f-c6a9-4ee7-96ff-ebeee3424952",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_chi_il_nonnull_api_cleaned_df = pd.read_excel(\"tif_chi_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d6f5e-662c-41d8-9fca-5e22d395526f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_chi_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "35078a41-6bc7-48bb-a6c7-7a24ade6f566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:20.905678Z",
     "iopub.status.busy": "2025-06-11T05:59:20.905438Z",
     "iopub.status.idle": "2025-06-11T05:59:20.934502Z",
     "shell.execute_reply": "2025-06-11T05:59:20.934074Z",
     "shell.execute_reply.started": "2025-06-11T05:59:20.905662Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_chi_il_nonnull_sen_df = pd.DataFrame(processed_data_tif_chi_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_chi_il_nonnull_sen_df = tif_chi_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_chi_il_nonnull_merged_df = pd.concat([combined_df_tif_chi_il, tif_chi_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_chi_il_final_sen_df = pd.concat([tif_chi_il_nonnull_merged_df,null_dataframes['tif_chi_il_null']], ignore_index=True)\n",
    "\n",
    "tif_chi_il_final_sen_df_copy = tif_chi_il_final_sen_df.copy()\n",
    "tif_chi_il_final_sen_df_copy[\"Published At Date\"] = tif_chi_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_chi_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_chi_il_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb034e-71d8-4ecf-ac75-3dfc6cb164f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63013509-0a47-4bd0-aac1-96fa1fbed0cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_nor_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "76b8a6c5-7441-48ae-b3f1-b7af84d3c9ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:20.935342Z",
     "iopub.status.busy": "2025-06-11T05:59:20.935129Z",
     "iopub.status.idle": "2025-06-11T05:59:22.962830Z",
     "shell.execute_reply": "2025-06-11T05:59:22.962311Z",
     "shell.execute_reply.started": "2025-06-11T05:59:20.935326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:02\n",
      "Total Input Tokens - 656\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 33\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_1-4'])/25)+math.ceil(len(tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_5-15'])/25)+math.ceil(len(tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_16-30'])/25)+math.ceil(len(tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_31-60'])/25)+math.ceil(len(tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_61-100'])/25)+math.ceil(len(tif_nor_il_nonnull_buckets['tif_nor_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_nor_il_nonnull_buckets.keys())\n",
    "tif_nor_il_nonnull_api = []\n",
    "input_tokens_tif_nor_il_nonnull=0\n",
    "output_tokens_tif_nor_il_nonnull=0\n",
    "start_time_tif_nor_il = time.time()\n",
    "\n",
    "for key in tif_nor_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_nor_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_nor_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_nor_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_nor_il_nonnull+=input_tokens\n",
    "    output_tokens_tif_nor_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_nor_il = time.time() - start_time_tif_nor_il\n",
    "formatted_time_tif_nor_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_nor_il))\n",
    "input_token_cost_tif_nor_il = round((0.01/1000) * input_tokens_tif_nor_il_nonnull, 2)\n",
    "output_token_cost_tif_nor_il = round((0.03/1000) * output_tokens_tif_nor_il_nonnull, 2)\n",
    "total_cost_tif_nor_il = round(input_token_cost_tif_nor_il + output_token_cost_tif_nor_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_nor_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_nor_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_nor_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_nor_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_nor_il}\")\n",
    "print(f\"Total Cost = {total_cost_tif_nor_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ec3f8c8c-a5e7-4ca8-a7a3-315aba42c2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:22.963811Z",
     "iopub.status.busy": "2025-06-11T05:59:22.963495Z",
     "iopub.status.idle": "2025-06-11T05:59:22.967778Z",
     "shell.execute_reply": "2025-06-11T05:59:22.967284Z",
     "shell.execute_reply.started": "2025-06-11T05:59:22.963780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_nor_il_nonnull_api & convert to DataFrame\n",
    "tif_nor_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_nor_il_nonnull_api\n",
    "]                                  \n",
    "tif_nor_il_nonnull_api_cleaned_df = pd.DataFrame(tif_nor_il_nonnull_api_cleaned)\n",
    "#tif_nor_il_nonnull_api_cleaned_df = pd.DataFrame(tif_nor_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e9a4c280-1f0d-40e0-a62d-6a13843fb0cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:22.968584Z",
     "iopub.status.busy": "2025-06-11T05:59:22.968372Z",
     "iopub.status.idle": "2025-06-11T05:59:22.974590Z",
     "shell.execute_reply": "2025-06-11T05:59:22.974123Z",
     "shell.execute_reply.started": "2025-06-11T05:59:22.968566Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_nor_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_nor_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_nor_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c5cf7-e73b-4f55-b05c-2c21f80d4572",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_nor_il_nonnull_api_cleaned_df.to_excel(\"tif_nor_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ae415-77a5-4e0e-b7cc-d4852258b31a",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_nor_il_nonnull_api_cleaned_df = pd.read_excel(\"tif_nor_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e78a10a-5d1d-4868-a025-be7e8b29bedf",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_nor_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "16633f9d-fbbe-4d26-ac06-9965a4ad5d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:22.975425Z",
     "iopub.status.busy": "2025-06-11T05:59:22.975202Z",
     "iopub.status.idle": "2025-06-11T05:59:23.005913Z",
     "shell.execute_reply": "2025-06-11T05:59:23.005507Z",
     "shell.execute_reply.started": "2025-06-11T05:59:22.975409Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_nor_il_nonnull_sen_df = pd.DataFrame(processed_data_tif_nor_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_nor_il_nonnull_sen_df = tif_nor_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_nor_il_nonnull_merged_df = pd.concat([combined_df_tif_nor_il, tif_nor_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_nor_il_final_sen_df = pd.concat([tif_nor_il_nonnull_merged_df,null_dataframes['tif_nor_il_null']], ignore_index=True)\n",
    "\n",
    "tif_nor_il_final_sen_df_copy = tif_nor_il_final_sen_df.copy()\n",
    "tif_nor_il_final_sen_df_copy[\"Published At Date\"] = tif_nor_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_nor_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_nor_il_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13f013-c55b-4732-ab7d-f65abc6a3b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3852f274-7711-4811-9d51-75a5740e59dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_sko_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "66a02cf2-db98-4a44-9662-8f9932bb3ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:23.006864Z",
     "iopub.status.busy": "2025-06-11T05:59:23.006612Z",
     "iopub.status.idle": "2025-06-11T05:59:24.532351Z",
     "shell.execute_reply": "2025-06-11T05:59:24.531758Z",
     "shell.execute_reply.started": "2025-06-11T05:59:23.006844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:01\n",
      "Total Input Tokens - 1348\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 71\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_1-4'])/25)+math.ceil(len(tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_5-15'])/25)+math.ceil(len(tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_16-30'])/25)+math.ceil(len(tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_31-60'])/25)+math.ceil(len(tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_61-100'])/25)+math.ceil(len(tif_sko_il_nonnull_buckets['tif_sko_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_sko_il_nonnull_buckets.keys())\n",
    "tif_sko_il_nonnull_api = []\n",
    "input_tokens_tif_sko_il_nonnull=0\n",
    "output_tokens_tif_sko_il_nonnull=0\n",
    "start_time_tif_sko_il = time.time()\n",
    "\n",
    "for key in tif_sko_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_sko_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_sko_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_sko_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_sko_il_nonnull+=input_tokens\n",
    "    output_tokens_tif_sko_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_sko_il = time.time() - start_time_tif_sko_il\n",
    "formatted_time_tif_sko_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_sko_il))\n",
    "input_token_cost_tif_sko_il = round((0.01/1000) * input_tokens_tif_sko_il_nonnull, 2)\n",
    "output_token_cost_tif_sko_il = round((0.03/1000) * output_tokens_tif_sko_il_nonnull, 2)\n",
    "total_cost_tif_sko_il = round(input_token_cost_tif_sko_il + output_token_cost_tif_sko_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_sko_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_sko_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_sko_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_sko_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_sko_il}\")\n",
    "print(f\"Total Cost = {total_cost_tif_sko_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a0aced4b-3b99-4a1b-a957-58a907b51171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:24.534538Z",
     "iopub.status.busy": "2025-06-11T05:59:24.534173Z",
     "iopub.status.idle": "2025-06-11T05:59:24.538087Z",
     "shell.execute_reply": "2025-06-11T05:59:24.537513Z",
     "shell.execute_reply.started": "2025-06-11T05:59:24.534519Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_sko_il_nonnull_api & convert to DataFrame\n",
    "tif_sko_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_sko_il_nonnull_api\n",
    "]                                  \n",
    "tif_sko_il_nonnull_api_cleaned_df = pd.DataFrame(tif_sko_il_nonnull_api_cleaned)\n",
    "#tif_sko_il_nonnull_api_cleaned_df = pd.DataFrame(tif_sko_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c8eb71e2-68d9-4685-8a6d-10b723849d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:24.539208Z",
     "iopub.status.busy": "2025-06-11T05:59:24.538778Z",
     "iopub.status.idle": "2025-06-11T05:59:24.544597Z",
     "shell.execute_reply": "2025-06-11T05:59:24.544104Z",
     "shell.execute_reply.started": "2025-06-11T05:59:24.539181Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_sko_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_sko_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_sko_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfbbdc8-0099-4125-be30-4b06f51dc7d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_sko_il_nonnull_api_cleaned_df.to_excel(\"tif_sko_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a3404-b9de-491d-a03b-48ff84684d8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_sko_il_nonnull_api_cleaned_df = pd.read_excel(\"tif_sko_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26bbc3-9d9b-4766-b6fb-a9188a3f9a49",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_sko_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "84a5aa96-f669-4064-a03d-aee12fddf57e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:24.545687Z",
     "iopub.status.busy": "2025-06-11T05:59:24.545303Z",
     "iopub.status.idle": "2025-06-11T05:59:24.575663Z",
     "shell.execute_reply": "2025-06-11T05:59:24.575185Z",
     "shell.execute_reply.started": "2025-06-11T05:59:24.545669Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_sko_il_nonnull_sen_df = pd.DataFrame(processed_data_tif_sko_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_sko_il_nonnull_sen_df = tif_sko_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_sko_il_nonnull_merged_df = pd.concat([combined_df_tif_sko_il, tif_sko_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_sko_il_final_sen_df = pd.concat([tif_sko_il_nonnull_merged_df,null_dataframes['tif_sko_il_null']], ignore_index=True)\n",
    "\n",
    "tif_sko_il_final_sen_df_copy = tif_sko_il_final_sen_df.copy()\n",
    "tif_sko_il_final_sen_df_copy[\"Published At Date\"] = tif_sko_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_sko_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_sko_il_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69993a9-1256-4a1f-b0bd-b17b2007ada2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "269f1aa9-aae8-4d0a-b436-73764932204c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_eas_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "07764049-91e0-44de-b451-f005d8e926bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:24.576634Z",
     "iopub.status.busy": "2025-06-11T05:59:24.576369Z",
     "iopub.status.idle": "2025-06-11T05:59:29.111711Z",
     "shell.execute_reply": "2025-06-11T05:59:29.111215Z",
     "shell.execute_reply.started": "2025-06-11T05:59:24.576616Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [3] Iterations\n",
      "Total Execution Time: 00:00:04\n",
      "Total Input Tokens - 2050\n",
      "Total Input Cost = 0.02\n",
      "Total Output Tokens - 106\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.02\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_1-4'])/25)+math.ceil(len(tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_5-15'])/25)+math.ceil(len(tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_16-30'])/25)+math.ceil(len(tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_31-60'])/25)+math.ceil(len(tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_61-100'])/25)+math.ceil(len(tif_eas_nj_nonnull_buckets['tif_eas_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_eas_nj_nonnull_buckets.keys())\n",
    "tif_eas_nj_nonnull_api = []\n",
    "input_tokens_tif_eas_nj_nonnull=0\n",
    "output_tokens_tif_eas_nj_nonnull=0\n",
    "start_time_tif_eas_nj = time.time()\n",
    "\n",
    "for key in tif_eas_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_eas_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_eas_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_eas_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_eas_nj_nonnull+=input_tokens\n",
    "    output_tokens_tif_eas_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_eas_nj = time.time() - start_time_tif_eas_nj\n",
    "formatted_time_tif_eas_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_eas_nj))\n",
    "input_token_cost_tif_eas_nj = round((0.01/1000) * input_tokens_tif_eas_nj_nonnull, 2)\n",
    "output_token_cost_tif_eas_nj = round((0.03/1000) * output_tokens_tif_eas_nj_nonnull, 2)\n",
    "total_cost_tif_eas_nj = round(input_token_cost_tif_eas_nj + output_token_cost_tif_eas_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_eas_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_eas_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_eas_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_eas_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_eas_nj}\")\n",
    "print(f\"Total Cost = {total_cost_tif_eas_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bf62926b-c4bd-4324-8118-1b4de83d60de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:29.112598Z",
     "iopub.status.busy": "2025-06-11T05:59:29.112278Z",
     "iopub.status.idle": "2025-06-11T05:59:29.116298Z",
     "shell.execute_reply": "2025-06-11T05:59:29.115800Z",
     "shell.execute_reply.started": "2025-06-11T05:59:29.112566Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_eas_nj_nonnull_api & convert to DataFrame\n",
    "tif_eas_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_eas_nj_nonnull_api\n",
    "]                                  \n",
    "tif_eas_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_eas_nj_nonnull_api_cleaned)\n",
    "#tif_eas_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_eas_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6a4d4ce2-8a4e-4b13-8ce9-eeee958f9761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:29.117110Z",
     "iopub.status.busy": "2025-06-11T05:59:29.116873Z",
     "iopub.status.idle": "2025-06-11T05:59:29.123163Z",
     "shell.execute_reply": "2025-06-11T05:59:29.122682Z",
     "shell.execute_reply.started": "2025-06-11T05:59:29.117095Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_eas_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_eas_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_eas_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c28ff7-aca3-4c55-9df2-655d6200b32f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_eas_nj_nonnull_api_cleaned_df.to_excel(\"tif_eas_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99c66b-e6f9-47f4-a31c-a51dfed2da73",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_eas_nj_nonnull_api_cleaned_df = pd.read_excel(\"tif_eas_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58885f-a42a-474a-9019-4683417d8651",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_eas_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "039fc257-77af-4733-a98b-1dc8cd444d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:29.123958Z",
     "iopub.status.busy": "2025-06-11T05:59:29.123729Z",
     "iopub.status.idle": "2025-06-11T05:59:29.151715Z",
     "shell.execute_reply": "2025-06-11T05:59:29.151300Z",
     "shell.execute_reply.started": "2025-06-11T05:59:29.123942Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_eas_nj_nonnull_sen_df = pd.DataFrame(processed_data_tif_eas_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_eas_nj_nonnull_sen_df = tif_eas_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_eas_nj_nonnull_merged_df = pd.concat([combined_df_tif_eas_nj, tif_eas_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_eas_nj_final_sen_df = pd.concat([tif_eas_nj_nonnull_merged_df,null_dataframes['tif_eas_nj_null']], ignore_index=True)\n",
    "\n",
    "tif_eas_nj_final_sen_df_copy = tif_eas_nj_final_sen_df.copy()\n",
    "tif_eas_nj_final_sen_df_copy[\"Published At Date\"] = tif_eas_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_eas_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_eas_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8967f6-ec8b-465b-8cf0-e5237ee47d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf478770-abb2-4e48-a1aa-8b742a67e47d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_red_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d989a9dd-be99-4e4d-84ee-89623efa76b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T05:59:59.162814Z",
     "iopub.status.busy": "2025-06-11T05:59:59.162302Z",
     "iopub.status.idle": "2025-06-11T06:00:00.689241Z",
     "shell.execute_reply": "2025-06-11T06:00:00.688676Z",
     "shell.execute_reply.started": "2025-06-11T05:59:59.162793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:01\n",
      "Total Input Tokens - 1000\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 41\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_1-4'])/25)+math.ceil(len(tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_5-15'])/25)+math.ceil(len(tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_16-30'])/25)+math.ceil(len(tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_31-60'])/25)+math.ceil(len(tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_61-100'])/25)+math.ceil(len(tif_red_nj_nonnull_buckets['tif_red_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_red_nj_nonnull_buckets.keys())\n",
    "tif_red_nj_nonnull_api = []\n",
    "input_tokens_tif_red_nj_nonnull=0\n",
    "output_tokens_tif_red_nj_nonnull=0\n",
    "start_time_tif_red_nj = time.time()\n",
    "\n",
    "for key in tif_red_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_red_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_red_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_red_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_red_nj_nonnull+=input_tokens\n",
    "    output_tokens_tif_red_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_red_nj = time.time() - start_time_tif_red_nj\n",
    "formatted_time_tif_red_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_red_nj))\n",
    "input_token_cost_tif_red_nj = round((0.01/1000) * input_tokens_tif_red_nj_nonnull, 2)\n",
    "output_token_cost_tif_red_nj = round((0.03/1000) * output_tokens_tif_red_nj_nonnull, 2)\n",
    "total_cost_tif_red_nj = round(input_token_cost_tif_red_nj + output_token_cost_tif_red_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_red_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_red_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_red_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_red_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_red_nj}\")\n",
    "print(f\"Total Cost = {total_cost_tif_red_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c8a09066-352d-4a8b-b07e-8626ac678c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:00.690268Z",
     "iopub.status.busy": "2025-06-11T06:00:00.690033Z",
     "iopub.status.idle": "2025-06-11T06:00:00.694109Z",
     "shell.execute_reply": "2025-06-11T06:00:00.693560Z",
     "shell.execute_reply.started": "2025-06-11T06:00:00.690248Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_red_nj_nonnull_api & convert to DataFrame\n",
    "tif_red_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_red_nj_nonnull_api\n",
    "]                                  \n",
    "tif_red_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_red_nj_nonnull_api_cleaned)\n",
    "#tif_red_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_red_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "61c5e34f-f1c2-4dad-8982-2cd21e338923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:00.694959Z",
     "iopub.status.busy": "2025-06-11T06:00:00.694722Z",
     "iopub.status.idle": "2025-06-11T06:00:00.700590Z",
     "shell.execute_reply": "2025-06-11T06:00:00.700060Z",
     "shell.execute_reply.started": "2025-06-11T06:00:00.694943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_red_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_red_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_red_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b909a5-46a7-48a3-8aa4-16a4daaf1952",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_red_nj_nonnull_api_cleaned_df.to_excel(\"tif_red_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ad600-ae68-4bec-af04-253d4deaebd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_red_nj_nonnull_api_cleaned_df = pd.read_excel(\"tif_red_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33cf5d-4852-4493-8a0b-b47a16fc3542",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_red_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "27f3fa75-eebd-4542-88fe-25123ae544aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:00.952921Z",
     "iopub.status.busy": "2025-06-11T06:00:00.952604Z",
     "iopub.status.idle": "2025-06-11T06:00:00.980421Z",
     "shell.execute_reply": "2025-06-11T06:00:00.979923Z",
     "shell.execute_reply.started": "2025-06-11T06:00:00.952899Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_red_nj_nonnull_sen_df = pd.DataFrame(processed_data_tif_red_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_red_nj_nonnull_sen_df = tif_red_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_red_nj_nonnull_merged_df = pd.concat([combined_df_tif_red_nj, tif_red_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_red_nj_final_sen_df = pd.concat([tif_red_nj_nonnull_merged_df,null_dataframes['tif_red_nj_null']], ignore_index=True)\n",
    "\n",
    "tif_red_nj_final_sen_df_copy = tif_red_nj_final_sen_df.copy()\n",
    "tif_red_nj_final_sen_df_copy[\"Published At Date\"] = tif_red_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_red_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_red_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879e91a-4bf8-4e07-aa4f-3d92eb6ac43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e871fcf4-cd74-4ea8-bd10-20dd7af80ec3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_hac_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6f2a5dd8-18fd-4a4a-9226-0e4601c3685f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:01.828449Z",
     "iopub.status.busy": "2025-06-11T06:00:01.828121Z",
     "iopub.status.idle": "2025-06-11T06:00:06.363925Z",
     "shell.execute_reply": "2025-06-11T06:00:06.363438Z",
     "shell.execute_reply.started": "2025-06-11T06:00:01.828427Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [2] Iterations\n",
      "Total Execution Time: 00:00:04\n",
      "Total Input Tokens - 1431\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 100\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_1-4'])/25)+math.ceil(len(tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_5-15'])/25)+math.ceil(len(tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_16-30'])/25)+math.ceil(len(tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_31-60'])/25)+math.ceil(len(tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_61-100'])/25)+math.ceil(len(tif_hac_nj_nonnull_buckets['tif_hac_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_hac_nj_nonnull_buckets.keys())\n",
    "tif_hac_nj_nonnull_api = []\n",
    "input_tokens_tif_hac_nj_nonnull=0\n",
    "output_tokens_tif_hac_nj_nonnull=0\n",
    "start_time_tif_hac_nj = time.time()\n",
    "\n",
    "for key in tif_hac_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_hac_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_hac_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_hac_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_hac_nj_nonnull+=input_tokens\n",
    "    output_tokens_tif_hac_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_hac_nj = time.time() - start_time_tif_hac_nj\n",
    "formatted_time_tif_hac_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_hac_nj))\n",
    "input_token_cost_tif_hac_nj = round((0.01/1000) * input_tokens_tif_hac_nj_nonnull, 2)\n",
    "output_token_cost_tif_hac_nj = round((0.03/1000) * output_tokens_tif_hac_nj_nonnull, 2)\n",
    "total_cost_tif_hac_nj = round(input_token_cost_tif_hac_nj + output_token_cost_tif_hac_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_hac_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_hac_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_hac_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_hac_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_hac_nj}\")\n",
    "print(f\"Total Cost = {total_cost_tif_hac_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "07918aad-3adc-44cb-a957-b688490e5fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:06.365366Z",
     "iopub.status.busy": "2025-06-11T06:00:06.365053Z",
     "iopub.status.idle": "2025-06-11T06:00:06.368995Z",
     "shell.execute_reply": "2025-06-11T06:00:06.368478Z",
     "shell.execute_reply.started": "2025-06-11T06:00:06.365345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_hac_nj_nonnull_api & convert to DataFrame\n",
    "tif_hac_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_hac_nj_nonnull_api\n",
    "]                                  \n",
    "tif_hac_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_hac_nj_nonnull_api_cleaned)\n",
    "#tif_hac_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_hac_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "32cb4f53-e711-4745-a964-315a89a99dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:06.370076Z",
     "iopub.status.busy": "2025-06-11T06:00:06.369851Z",
     "iopub.status.idle": "2025-06-11T06:00:06.375714Z",
     "shell.execute_reply": "2025-06-11T06:00:06.375171Z",
     "shell.execute_reply.started": "2025-06-11T06:00:06.370060Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_hac_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_hac_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_hac_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45719351-f169-4204-8a06-79e5f4aa3780",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_hac_nj_nonnull_api_cleaned_df.to_excel(\"tif_hac_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c9660-9d77-4c2f-82e2-f7e77e17ae7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_hac_nj_nonnull_api_cleaned_df = pd.read_excel(\"tif_hac_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fa337-64a8-4f94-9bfb-07b414a76cc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_hac_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "06502eb1-0fc0-42c9-8c5d-b84448366955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:06.377054Z",
     "iopub.status.busy": "2025-06-11T06:00:06.376807Z",
     "iopub.status.idle": "2025-06-11T06:00:06.406161Z",
     "shell.execute_reply": "2025-06-11T06:00:06.405669Z",
     "shell.execute_reply.started": "2025-06-11T06:00:06.377037Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_hac_nj_nonnull_sen_df = pd.DataFrame(processed_data_tif_hac_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_hac_nj_nonnull_sen_df = tif_hac_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_hac_nj_nonnull_merged_df = pd.concat([combined_df_tif_hac_nj, tif_hac_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_hac_nj_final_sen_df = pd.concat([tif_hac_nj_nonnull_merged_df,null_dataframes['tif_hac_nj_null']], ignore_index=True)\n",
    "\n",
    "tif_hac_nj_final_sen_df_copy = tif_hac_nj_final_sen_df.copy()\n",
    "tif_hac_nj_final_sen_df_copy[\"Published At Date\"] = tif_hac_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_hac_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_hac_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e6343-1dfe-47f5-b6d5-ac724b9c17f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32815fae-04b4-470c-bef7-5b590755d33b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_sho_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "51db2b91-7a13-444d-8d79-6e9344a42a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:06.407316Z",
     "iopub.status.busy": "2025-06-11T06:00:06.407055Z",
     "iopub.status.idle": "2025-06-11T06:00:07.933793Z",
     "shell.execute_reply": "2025-06-11T06:00:07.933273Z",
     "shell.execute_reply.started": "2025-06-11T06:00:06.407289Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:01\n",
      "Total Input Tokens - 703\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 37\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_1-4'])/25)+math.ceil(len(tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_5-15'])/25)+math.ceil(len(tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_16-30'])/25)+math.ceil(len(tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_31-60'])/25)+math.ceil(len(tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_61-100'])/25)+math.ceil(len(tif_sho_nj_nonnull_buckets['tif_sho_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_sho_nj_nonnull_buckets.keys())\n",
    "tif_sho_nj_nonnull_api = []\n",
    "input_tokens_tif_sho_nj_nonnull=0\n",
    "output_tokens_tif_sho_nj_nonnull=0\n",
    "start_time_tif_sho_nj = time.time()\n",
    "\n",
    "for key in tif_sho_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_sho_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_sho_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_sho_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_sho_nj_nonnull+=input_tokens\n",
    "    output_tokens_tif_sho_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_sho_nj = time.time() - start_time_tif_sho_nj\n",
    "formatted_time_tif_sho_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_sho_nj))\n",
    "input_token_cost_tif_sho_nj = round((0.01/1000) * input_tokens_tif_sho_nj_nonnull, 2)\n",
    "output_token_cost_tif_sho_nj = round((0.03/1000) * output_tokens_tif_sho_nj_nonnull, 2)\n",
    "total_cost_tif_sho_nj = round(input_token_cost_tif_sho_nj + output_token_cost_tif_sho_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_sho_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_sho_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_sho_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_sho_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_sho_nj}\")\n",
    "print(f\"Total Cost = {total_cost_tif_sho_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "841b7deb-42da-4b90-b2a8-37a7b925c5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:07.934747Z",
     "iopub.status.busy": "2025-06-11T06:00:07.934438Z",
     "iopub.status.idle": "2025-06-11T06:00:07.938556Z",
     "shell.execute_reply": "2025-06-11T06:00:07.938066Z",
     "shell.execute_reply.started": "2025-06-11T06:00:07.934726Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_sho_nj_nonnull_api & convert to DataFrame\n",
    "tif_sho_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_sho_nj_nonnull_api\n",
    "]                                  \n",
    "tif_sho_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_sho_nj_nonnull_api_cleaned)\n",
    "#tif_sho_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_sho_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5b88fd0c-ab32-4d77-b65e-95118cc734cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:07.939580Z",
     "iopub.status.busy": "2025-06-11T06:00:07.939270Z",
     "iopub.status.idle": "2025-06-11T06:00:07.945237Z",
     "shell.execute_reply": "2025-06-11T06:00:07.944759Z",
     "shell.execute_reply.started": "2025-06-11T06:00:07.939554Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_sho_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_sho_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_sho_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cddef4d-cc0f-4aff-8f44-417da06be3d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_sho_nj_nonnull_api_cleaned_df.to_excel(\"tif_sho_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4963be-b06c-4267-a652-7e64d892be25",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_sho_nj_nonnull_api_cleaned_df = pd.read_excel(\"tif_sho_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa48ff-1d71-4bb6-91eb-78d49ef69544",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_sho_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2989752e-a515-4135-960d-4215f0b5d5f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:07.945946Z",
     "iopub.status.busy": "2025-06-11T06:00:07.945764Z",
     "iopub.status.idle": "2025-06-11T06:00:07.978403Z",
     "shell.execute_reply": "2025-06-11T06:00:07.977920Z",
     "shell.execute_reply.started": "2025-06-11T06:00:07.945930Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_sho_nj_nonnull_sen_df = pd.DataFrame(processed_data_tif_sho_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_sho_nj_nonnull_sen_df = tif_sho_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_sho_nj_nonnull_merged_df = pd.concat([combined_df_tif_sho_nj, tif_sho_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_sho_nj_final_sen_df = pd.concat([tif_sho_nj_nonnull_merged_df,null_dataframes['tif_sho_nj_null']], ignore_index=True)\n",
    "\n",
    "tif_sho_nj_final_sen_df_copy = tif_sho_nj_final_sen_df.copy()\n",
    "tif_sho_nj_final_sen_df_copy[\"Published At Date\"] = tif_sho_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_sho_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_sho_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5103f1-91be-4d8d-9ef9-d1ef0dae4bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3515550-7c0a-4e2a-9d6e-dd028f30c12e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tif_par_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7bd8c7a9-9af9-4046-962a-73c8e597c728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:07.979396Z",
     "iopub.status.busy": "2025-06-11T06:00:07.979137Z",
     "iopub.status.idle": "2025-06-11T06:00:08.000919Z",
     "shell.execute_reply": "2025-06-11T06:00:08.000462Z",
     "shell.execute_reply.started": "2025-06-11T06:00:07.979371Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [0] Iterations\n",
      "Total Execution Time: 00:00:00\n",
      "Total Input Tokens - 0\n",
      "Total Input Cost = 0.0\n",
      "Total Output Tokens - 0\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.0\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_1-4'])/25)+math.ceil(len(tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_5-15'])/25)+math.ceil(len(tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_16-30'])/25)+math.ceil(len(tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_31-60'])/25)+math.ceil(len(tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_61-100'])/25)+math.ceil(len(tif_par_nj_nonnull_buckets['tif_par_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_par_nj_nonnull_buckets.keys())\n",
    "tif_par_nj_nonnull_api = []\n",
    "input_tokens_tif_par_nj_nonnull=0\n",
    "output_tokens_tif_par_nj_nonnull=0\n",
    "start_time_tif_par_nj = time.time()\n",
    "\n",
    "for key in tif_par_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_par_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_par_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_par_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_par_nj_nonnull+=input_tokens\n",
    "    output_tokens_tif_par_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_par_nj = time.time() - start_time_tif_par_nj\n",
    "formatted_time_tif_par_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_par_nj))\n",
    "input_token_cost_tif_par_nj = round((0.01/1000) * input_tokens_tif_par_nj_nonnull, 2)\n",
    "output_token_cost_tif_par_nj = round((0.03/1000) * output_tokens_tif_par_nj_nonnull, 2)\n",
    "total_cost_tif_par_nj = round(input_token_cost_tif_par_nj + output_token_cost_tif_par_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_par_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_par_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_par_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_par_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_par_nj}\")\n",
    "print(f\"Total Cost = {total_cost_tif_par_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "882f3a9f-ede9-4654-bfc5-a579eb5fcbda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:08.002705Z",
     "iopub.status.busy": "2025-06-11T06:00:08.002465Z",
     "iopub.status.idle": "2025-06-11T06:00:08.006469Z",
     "shell.execute_reply": "2025-06-11T06:00:08.005998Z",
     "shell.execute_reply.started": "2025-06-11T06:00:08.002687Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_par_nj_nonnull_api & convert to DataFrame\n",
    "tif_par_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_par_nj_nonnull_api\n",
    "]                                  \n",
    "tif_par_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_par_nj_nonnull_api_cleaned)\n",
    "#tif_par_nj_nonnull_api_cleaned_df = pd.DataFrame(tif_par_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c10d13bb-9b7d-4757-a41e-dcd4223f4ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:08.007408Z",
     "iopub.status.busy": "2025-06-11T06:00:08.007106Z",
     "iopub.status.idle": "2025-06-11T06:00:08.012644Z",
     "shell.execute_reply": "2025-06-11T06:00:08.012175Z",
     "shell.execute_reply.started": "2025-06-11T06:00:08.007373Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_par_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_par_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_par_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f256d-bd53-4035-9c44-e0438cb3f85a",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_par_nj_nonnull_api_cleaned_df.to_excel(\"tif_par_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04f39e-f5ac-44b6-83c1-68fda0f40803",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_par_nj_nonnull_api_cleaned_df = pd.read_excel(\"tif_par_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482a7fb-942d-4bde-bad8-387441cbf369",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_par_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "031f0518-e8af-4e0a-a89d-9fa67ba20413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:00:10.249073Z",
     "iopub.status.busy": "2025-06-11T06:00:10.248744Z",
     "iopub.status.idle": "2025-06-11T06:00:10.834017Z",
     "shell.execute_reply": "2025-06-11T06:00:10.833130Z",
     "shell.execute_reply.started": "2025-06-11T06:00:10.249053Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Commentor Name', 'Trust', 'Store Experience', 'Store Staff',\\n       'Product Design', 'Product Variety', 'Discount', 'Making Charge',\\n       'Price', 'Product Quality', 'OLD Gold Jewellery Exchange'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[288], line 16\u001b[0m\n\u001b[1;32m      4\u001b[0m ordered_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommentor Name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrust\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStore Experience\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct Quality\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOLD Gold Jewellery Exchange\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#Apply the new order to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m tif_par_nj_nonnull_sen_df \u001b[38;5;241m=\u001b[39m \u001b[43mtif_par_nj_nonnull_sen_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mordered_columns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m tif_par_nj_nonnull_merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([combined_df_tif_par_nj, tif_par_nj_nonnull_sen_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m tif_par_nj_final_sen_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([tif_par_nj_nonnull_merged_df,null_dataframes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtif_par_nj_null\u001b[39m\u001b[38;5;124m'\u001b[39m]], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Commentor Name', 'Trust', 'Store Experience', 'Store Staff',\\n       'Product Design', 'Product Variety', 'Discount', 'Making Charge',\\n       'Price', 'Product Quality', 'OLD Gold Jewellery Exchange'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_par_nj_nonnull_sen_df = pd.DataFrame(processed_data_tif_par_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_par_nj_nonnull_sen_df = tif_par_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_par_nj_nonnull_merged_df = pd.concat([combined_df_tif_par_nj, tif_par_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_par_nj_final_sen_df = pd.concat([tif_par_nj_nonnull_merged_df,null_dataframes['tif_par_nj_null']], ignore_index=True)\n",
    "\n",
    "tif_par_nj_final_sen_df_copy = tif_par_nj_final_sen_df.copy()\n",
    "tif_par_nj_final_sen_df_copy[\"Published At Date\"] = tif_par_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_par_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_par_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7d463-6e60-4dcc-9bcf-84f23ff41172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5b4644-9ed3-4b66-b0b9-df7bb7c9584a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_vie_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "88164fac-16bf-4528-acaf-94890225b724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:01.718219Z",
     "iopub.status.busy": "2025-06-11T06:01:01.717822Z",
     "iopub.status.idle": "2025-06-11T06:01:07.255703Z",
     "shell.execute_reply": "2025-06-11T06:01:07.255191Z",
     "shell.execute_reply.started": "2025-06-11T06:01:01.718200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [3] Iterations\n",
      "Total Execution Time: 00:00:05\n",
      "Total Input Tokens - 2129\n",
      "Total Input Cost = 0.02\n",
      "Total Output Tokens - 112\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.02\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_1-4'])/25)+math.ceil(len(tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_5-15'])/25)+math.ceil(len(tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_16-30'])/25)+math.ceil(len(tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_31-60'])/25)+math.ceil(len(tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_61-100'])/25)+math.ceil(len(tif_vie_va_nonnull_buckets['tif_vie_va_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_vie_va_nonnull_buckets.keys())\n",
    "tif_vie_va_nonnull_api = []\n",
    "input_tokens_tif_vie_va_nonnull=0\n",
    "output_tokens_tif_vie_va_nonnull=0\n",
    "start_time_tif_vie_va = time.time()\n",
    "\n",
    "for key in tif_vie_va_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_vie_va_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_vie_va, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_vie_va_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_vie_va_nonnull+=input_tokens\n",
    "    output_tokens_tif_vie_va_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_vie_va = time.time() - start_time_tif_vie_va\n",
    "formatted_time_tif_vie_va = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_vie_va))\n",
    "input_token_cost_tif_vie_va = round((0.01/1000) * input_tokens_tif_vie_va_nonnull, 2)\n",
    "output_token_cost_tif_vie_va = round((0.03/1000) * output_tokens_tif_vie_va_nonnull, 2)\n",
    "total_cost_tif_vie_va = round(input_token_cost_tif_vie_va + output_token_cost_tif_vie_va, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_vie_va}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_vie_va_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_vie_va}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_vie_va_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_vie_va}\")\n",
    "print(f\"Total Cost = {total_cost_tif_vie_va}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "dcf851d6-a7cd-4c95-bdf0-a619f39b60c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:07.256921Z",
     "iopub.status.busy": "2025-06-11T06:01:07.256636Z",
     "iopub.status.idle": "2025-06-11T06:01:07.260498Z",
     "shell.execute_reply": "2025-06-11T06:01:07.259960Z",
     "shell.execute_reply.started": "2025-06-11T06:01:07.256902Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_vie_va_nonnull_api & convert to DataFrame\n",
    "tif_vie_va_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_vie_va_nonnull_api\n",
    "]                                  \n",
    "tif_vie_va_nonnull_api_cleaned_df = pd.DataFrame(tif_vie_va_nonnull_api_cleaned)\n",
    "#tif_vie_va_nonnull_api_cleaned_df = pd.DataFrame(tif_vie_va_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4a12ad7a-4783-4ceb-b67a-b48fa9d47082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:07.261330Z",
     "iopub.status.busy": "2025-06-11T06:01:07.261105Z",
     "iopub.status.idle": "2025-06-11T06:01:07.267165Z",
     "shell.execute_reply": "2025-06-11T06:01:07.266688Z",
     "shell.execute_reply.started": "2025-06-11T06:01:07.261312Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_vie_va_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_vie_va_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_vie_va_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c964d83-42b0-4d5b-bf36-e38c111b440f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_vie_va_nonnull_api_cleaned_df.to_excel(\"tif_vie_va_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557f170-1565-4cca-aa7d-dd898f0055c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_vie_va_nonnull_api_cleaned_df = pd.read_excel(\"tif_vie_va_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a7675-d1e3-435f-8353-e22ee16f0705",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_vie_va_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e0820a19-5d3d-4a35-8812-0631f85b3cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:07.268460Z",
     "iopub.status.busy": "2025-06-11T06:01:07.268232Z",
     "iopub.status.idle": "2025-06-11T06:01:07.303341Z",
     "shell.execute_reply": "2025-06-11T06:01:07.302913Z",
     "shell.execute_reply.started": "2025-06-11T06:01:07.268444Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_vie_va_nonnull_sen_df = pd.DataFrame(processed_data_tif_vie_va_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_vie_va_nonnull_sen_df = tif_vie_va_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_vie_va_nonnull_merged_df = pd.concat([combined_df_tif_vie_va, tif_vie_va_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_vie_va_final_sen_df = pd.concat([tif_vie_va_nonnull_merged_df,null_dataframes['tif_vie_va_null']], ignore_index=True)\n",
    "\n",
    "tif_vie_va_final_sen_df_copy = tif_vie_va_final_sen_df.copy()\n",
    "tif_vie_va_final_sen_df_copy[\"Published At Date\"] = tif_vie_va_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_vie_va_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_vie_va_final_sen_df_jul.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6644720-7cc3-4f8a-89c1-84d3abeb8a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "476ee4a5-daaa-48f7-b9e9-fff48d2a2b87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_ric_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3d4d92e9-f503-4ff5-9472-737cec1109df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:07.304292Z",
     "iopub.status.busy": "2025-06-11T06:01:07.303996Z",
     "iopub.status.idle": "2025-06-11T06:01:08.829725Z",
     "shell.execute_reply": "2025-06-11T06:01:08.829251Z",
     "shell.execute_reply.started": "2025-06-11T06:01:07.304274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [1] Iterations\n",
      "Total Execution Time: 00:00:01\n",
      "Total Input Tokens - 680\n",
      "Total Input Cost = 0.01\n",
      "Total Output Tokens - 37\n",
      "Total Output Cost = 0.0\n",
      "Total Cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_1-4'])/25)+math.ceil(len(tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_5-15'])/25)+math.ceil(len(tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_16-30'])/25)+math.ceil(len(tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_31-60'])/25)+math.ceil(len(tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_61-100'])/25)+math.ceil(len(tif_ric_va_nonnull_buckets['tif_ric_va_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tif_ric_va_nonnull_buckets.keys())\n",
    "tif_ric_va_nonnull_api = []\n",
    "input_tokens_tif_ric_va_nonnull=0\n",
    "output_tokens_tif_ric_va_nonnull=0\n",
    "start_time_tif_ric_va = time.time()\n",
    "\n",
    "for key in tif_ric_va_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tif_ric_va_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tif_ric_va, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tif_ric_va_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tif_ric_va_nonnull+=input_tokens\n",
    "    output_tokens_tif_ric_va_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tif_ric_va = time.time() - start_time_tif_ric_va\n",
    "formatted_time_tif_ric_va = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tif_ric_va))\n",
    "input_token_cost_tif_ric_va = round((0.01/1000) * input_tokens_tif_ric_va_nonnull, 2)\n",
    "output_token_cost_tif_ric_va = round((0.03/1000) * output_tokens_tif_ric_va_nonnull, 2)\n",
    "total_cost_tif_ric_va = round(input_token_cost_tif_ric_va + output_token_cost_tif_ric_va, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tif_ric_va}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tif_ric_va_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tif_ric_va}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tif_ric_va_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tif_ric_va}\")\n",
    "print(f\"Total Cost = {total_cost_tif_ric_va}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "95d85c35-e487-45a3-9c02-281351684616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:08.830625Z",
     "iopub.status.busy": "2025-06-11T06:01:08.830281Z",
     "iopub.status.idle": "2025-06-11T06:01:08.837543Z",
     "shell.execute_reply": "2025-06-11T06:01:08.836887Z",
     "shell.execute_reply.started": "2025-06-11T06:01:08.830596Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tif_ric_va_nonnull_api & convert to DataFrame\n",
    "tif_ric_va_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tif_ric_va_nonnull_api\n",
    "]                                  \n",
    "tif_ric_va_nonnull_api_cleaned_df = pd.DataFrame(tif_ric_va_nonnull_api_cleaned)\n",
    "#tif_ric_va_nonnull_api_cleaned_df = pd.DataFrame(tif_ric_va_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e00dd8f9-2265-4deb-8dae-a245d5998978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:08.838764Z",
     "iopub.status.busy": "2025-06-11T06:01:08.838470Z",
     "iopub.status.idle": "2025-06-11T06:01:08.844257Z",
     "shell.execute_reply": "2025-06-11T06:01:08.843733Z",
     "shell.execute_reply.started": "2025-06-11T06:01:08.838737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tif_ric_va_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tif_ric_va_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tif_ric_va_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b7641-a5cf-4364-aa0b-45bc2e9f0ed2",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_ric_va_nonnull_api_cleaned_df.to_excel(\"tif_ric_va_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce8a62-9d76-49af-a7b7-d2a9a234553f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_ric_va_nonnull_api_cleaned_df = pd.read_excel(\"tif_ric_va_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491f5e5-9dde-4eba-88eb-4f52e69937c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "tif_ric_va_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8bf7b880-0ce2-4d6e-b6b0-6c80886a8d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:08.845161Z",
     "iopub.status.busy": "2025-06-11T06:01:08.844854Z",
     "iopub.status.idle": "2025-06-11T06:01:08.872181Z",
     "shell.execute_reply": "2025-06-11T06:01:08.871729Z",
     "shell.execute_reply.started": "2025-06-11T06:01:08.845132Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tif_ric_va_nonnull_sen_df = pd.DataFrame(processed_data_tif_ric_va_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tif_ric_va_nonnull_sen_df = tif_ric_va_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tif_ric_va_nonnull_merged_df = pd.concat([combined_df_tif_ric_va, tif_ric_va_nonnull_sen_df], axis=1)\n",
    "\n",
    "tif_ric_va_final_sen_df = pd.concat([tif_ric_va_nonnull_merged_df,null_dataframes['tif_ric_va_null']], ignore_index=True)\n",
    "\n",
    "tif_ric_va_final_sen_df_copy = tif_ric_va_final_sen_df.copy()\n",
    "tif_ric_va_final_sen_df_copy[\"Published At Date\"] = tif_ric_va_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tif_ric_va_final_sen_df_copy.to_excel(\"sentiment_raw_output/tif_ric_va_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c326d-54ec-4144-b06f-69df9212ca2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0954f82e-13f4-41c7-9241-f3daf0daf3bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### vbj_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "0d40235e-9757-42cb-b3de-fc22b25a8091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:08.873924Z",
     "iopub.status.busy": "2025-06-11T06:01:08.873716Z",
     "iopub.status.idle": "2025-06-11T06:01:35.448086Z",
     "shell.execute_reply": "2025-06-11T06:01:35.447540Z",
     "shell.execute_reply.started": "2025-06-11T06:01:08.873907Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:26\n",
      "Total Input Tokens - 5347\n",
      "Total Input Cost = 0.05\n",
      "Total Output Tokens - 1417\n",
      "Total Output Cost = 0.04\n",
      "Total Cost = 0.09\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_1-4'])/25)+math.ceil(len(vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_5-15'])/25)+math.ceil(len(vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_16-30'])/25)+math.ceil(len(vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_31-60'])/25)+math.ceil(len(vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_61-100'])/25)+math.ceil(len(vbj_fri_tx_nonnull_buckets['vbj_fri_tx_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(vbj_fri_tx_nonnull_buckets.keys())\n",
    "vbj_fri_tx_nonnull_api = []\n",
    "input_tokens_vbj_fri_tx_nonnull=0\n",
    "output_tokens_vbj_fri_tx_nonnull=0\n",
    "start_time_vbj_fri_tx = time.time()\n",
    "\n",
    "for key in vbj_fri_tx_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = vbj_fri_tx_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_vbj_fri_tx, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        vbj_fri_tx_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_vbj_fri_tx_nonnull+=input_tokens\n",
    "    output_tokens_vbj_fri_tx_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_vbj_fri_tx = time.time() - start_time_vbj_fri_tx\n",
    "formatted_time_vbj_fri_tx = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_vbj_fri_tx))\n",
    "input_token_cost_vbj_fri_tx = round((0.01/1000) * input_tokens_vbj_fri_tx_nonnull, 2)\n",
    "output_token_cost_vbj_fri_tx = round((0.03/1000) * output_tokens_vbj_fri_tx_nonnull, 2)\n",
    "total_cost_vbj_fri_tx = round(input_token_cost_vbj_fri_tx + output_token_cost_vbj_fri_tx, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_vbj_fri_tx}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_vbj_fri_tx_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_vbj_fri_tx}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_vbj_fri_tx_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_vbj_fri_tx}\")\n",
    "print(f\"Total Cost = {total_cost_vbj_fri_tx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "164ab2f9-a401-4b41-9e44-26ff4f27ca61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:35.449299Z",
     "iopub.status.busy": "2025-06-11T06:01:35.448998Z",
     "iopub.status.idle": "2025-06-11T06:01:35.452836Z",
     "shell.execute_reply": "2025-06-11T06:01:35.452319Z",
     "shell.execute_reply.started": "2025-06-11T06:01:35.449279Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in vbj_fri_tx_nonnull_api & convert to DataFrame\n",
    "vbj_fri_tx_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in vbj_fri_tx_nonnull_api\n",
    "]                                  \n",
    "vbj_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(vbj_fri_tx_nonnull_api_cleaned)\n",
    "#vbj_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(vbj_fri_tx_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fd3f6587-ba75-4232-929a-9a9563c360a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:35.453650Z",
     "iopub.status.busy": "2025-06-11T06:01:35.453460Z",
     "iopub.status.idle": "2025-06-11T06:01:35.460298Z",
     "shell.execute_reply": "2025-06-11T06:01:35.459779Z",
     "shell.execute_reply.started": "2025-06-11T06:01:35.453629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_vbj_fri_tx_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in vbj_fri_tx_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_vbj_fri_tx_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8ffcc-a6c9-44a1-9ecc-186d9a7cadf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "vbj_fri_tx_nonnull_api_cleaned_df.to_excel(\"vbj_fri_tx_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e01f5e-7b00-4766-9e46-853e240aae4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "vbj_fri_tx_nonnull_api_cleaned_df = pd.read_excel(\"vbj_fri_tx_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12f22f-b293-4afa-a18b-24d985b03ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "vbj_fri_tx_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fc5d1b8e-56ed-445a-80e0-f759b73695be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:01:35.461475Z",
     "iopub.status.busy": "2025-06-11T06:01:35.461144Z",
     "iopub.status.idle": "2025-06-11T06:01:35.502223Z",
     "shell.execute_reply": "2025-06-11T06:01:35.501806Z",
     "shell.execute_reply.started": "2025-06-11T06:01:35.461457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "vbj_fri_tx_nonnull_sen_df = pd.DataFrame(processed_data_vbj_fri_tx_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "vbj_fri_tx_nonnull_sen_df = vbj_fri_tx_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "vbj_fri_tx_nonnull_merged_df = pd.concat([combined_df_vbj_fri_tx, vbj_fri_tx_nonnull_sen_df], axis=1)\n",
    "\n",
    "vbj_fri_tx_final_sen_df = pd.concat([vbj_fri_tx_nonnull_merged_df,null_dataframes['vbj_fri_tx_null']], ignore_index=True)\n",
    "\n",
    "vbj_fri_tx_final_sen_df_copy = vbj_fri_tx_final_sen_df.copy()\n",
    "vbj_fri_tx_final_sen_df_copy[\"Published At Date\"] = vbj_fri_tx_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "vbj_fri_tx_final_sen_df_copy.to_excel(\"sentiment_raw_output/vbj_fri_tx_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6178b7f-2eda-4ca8-8227-7835e3bb6f35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tanishq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34debb55-de5f-437a-bd46-8e9b4d3ab6ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "50545dad-46e5-418e-bbb7-d0b1fd3a732c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:04:02.462128Z",
     "iopub.status.busy": "2025-06-11T06:04:02.461735Z",
     "iopub.status.idle": "2025-06-11T06:05:33.152171Z",
     "shell.execute_reply": "2025-06-11T06:05:33.151571Z",
     "shell.execute_reply.started": "2025-06-11T06:04:02.462106Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [11] Iterations\n",
      "Total Execution Time: 00:01:30\n",
      "Total Input Tokens - 16855\n",
      "Total Input Cost = 0.17\n",
      "Total Output Tokens - 5987\n",
      "Total Output Cost = 0.18\n",
      "Total Cost = 0.35\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_1-4'])/25)+math.ceil(len(tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_5-15'])/25)+math.ceil(len(tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_16-30'])/25)+math.ceil(len(tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_31-60'])/25)+math.ceil(len(tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_61-100'])/25)+math.ceil(len(tan_chi_il_nonnull_buckets['tan_chi_il_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_chi_il_nonnull_buckets.keys())\n",
    "tan_chi_il_nonnull_api = []\n",
    "input_tokens_tan_chi_il_nonnull=0\n",
    "output_tokens_tan_chi_il_nonnull=0\n",
    "start_time_tan_chi_il = time.time()\n",
    "\n",
    "for key in tan_chi_il_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_chi_il_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_chi_il, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_chi_il_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_chi_il_nonnull+=input_tokens\n",
    "    output_tokens_tan_chi_il_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_chi_il = time.time() - start_time_tan_chi_il\n",
    "formatted_time_tan_chi_il = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_chi_il))\n",
    "input_token_cost_tan_chi_il = round((0.01/1000) * input_tokens_tan_chi_il_nonnull, 2)\n",
    "output_token_cost_tan_chi_il = round((0.03/1000) * output_tokens_tan_chi_il_nonnull, 2)\n",
    "total_cost_tan_chi_il = round(input_token_cost_tan_chi_il + output_token_cost_tan_chi_il, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_chi_il}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_chi_il_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_chi_il}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_chi_il_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_chi_il}\")\n",
    "print(f\"Total Cost = {total_cost_tan_chi_il}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d7dc20ed-4468-40f3-b017-082a7afbdc16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:05:33.153480Z",
     "iopub.status.busy": "2025-06-11T06:05:33.153224Z",
     "iopub.status.idle": "2025-06-11T06:05:33.157186Z",
     "shell.execute_reply": "2025-06-11T06:05:33.156690Z",
     "shell.execute_reply.started": "2025-06-11T06:05:33.153463Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_chi_il_nonnull_api & convert to DataFrame\n",
    "tan_chi_il_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_chi_il_nonnull_api\n",
    "]                                  \n",
    "tan_chi_il_nonnull_api_cleaned_df = pd.DataFrame(tan_chi_il_nonnull_api_cleaned)\n",
    "#tan_chi_il_nonnull_api_cleaned_df = pd.DataFrame(tan_chi_il_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "acd1f1fc-ed9e-4baa-a4a4-979425595a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:05:33.158089Z",
     "iopub.status.busy": "2025-06-11T06:05:33.157801Z",
     "iopub.status.idle": "2025-06-11T06:05:33.165177Z",
     "shell.execute_reply": "2025-06-11T06:05:33.164726Z",
     "shell.execute_reply.started": "2025-06-11T06:05:33.158071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_chi_il_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_chi_il_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_chi_il_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634dac03-4b0d-48a0-a381-fb27d25cbb0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_chi_il_nonnull_api_cleaned_df.to_excel(\"tan_chi_il_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc636e82-edc3-4e57-9434-76e2e155fdd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_chi_il_nonnull_api_cleaned_df = pd.read_excel(\"tan_chi_il_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc07d46c-0c92-4270-ab36-8159c37ce95f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_chi_il_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "23013bee-6df9-47de-896d-bbfadbce18fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:05:33.166015Z",
     "iopub.status.busy": "2025-06-11T06:05:33.165764Z",
     "iopub.status.idle": "2025-06-11T06:05:33.255393Z",
     "shell.execute_reply": "2025-06-11T06:05:33.254922Z",
     "shell.execute_reply.started": "2025-06-11T06:05:33.165993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_chi_il_nonnull_sen_df = pd.DataFrame(processed_data_tan_chi_il_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_chi_il_nonnull_sen_df = tan_chi_il_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_chi_il_nonnull_merged_df = pd.concat([combined_df_tan_chi_il, tan_chi_il_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_chi_il_final_sen_df = pd.concat([tan_chi_il_nonnull_merged_df,null_dataframes['tan_chi_il_null']], ignore_index=True)\n",
    "\n",
    "tan_chi_il_final_sen_df_copy = tan_chi_il_final_sen_df.copy()\n",
    "tan_chi_il_final_sen_df_copy[\"Published At Date\"] = tan_chi_il_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_chi_il_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_chi_il_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ed01e-72cf-49bd-a9a1-3c6b6bd41446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02facd1d-7ffe-401f-a7d6-f2237b4c7189",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "462adeda-80de-4560-8455-b1cc93b15f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:05:33.256910Z",
     "iopub.status.busy": "2025-06-11T06:05:33.256656Z",
     "iopub.status.idle": "2025-06-11T06:10:59.866998Z",
     "shell.execute_reply": "2025-06-11T06:10:59.866313Z",
     "shell.execute_reply.started": "2025-06-11T06:05:33.256891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [34] Iterations\n",
      "Total Execution Time: 00:05:26\n",
      "Total Input Tokens - 53791\n",
      "Total Input Cost = 0.54\n",
      "Total Output Tokens - 22687\n",
      "Total Output Cost = 0.68\n",
      "Total Cost = 1.22\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_1-4'])/25)+math.ceil(len(tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_5-15'])/25)+math.ceil(len(tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_16-30'])/25)+math.ceil(len(tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_31-60'])/25)+math.ceil(len(tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_61-100'])/25)+math.ceil(len(tan_fri_tx_nonnull_buckets['tan_fri_tx_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_fri_tx_nonnull_buckets.keys())\n",
    "tan_fri_tx_nonnull_api = []\n",
    "input_tokens_tan_fri_tx_nonnull=0\n",
    "output_tokens_tan_fri_tx_nonnull=0\n",
    "start_time_tan_fri_tx = time.time()\n",
    "\n",
    "for key in tan_fri_tx_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_fri_tx_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_fri_tx, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_fri_tx_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_fri_tx_nonnull+=input_tokens\n",
    "    output_tokens_tan_fri_tx_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_fri_tx = time.time() - start_time_tan_fri_tx\n",
    "formatted_time_tan_fri_tx = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_fri_tx))\n",
    "input_token_cost_tan_fri_tx = round((0.01/1000) * input_tokens_tan_fri_tx_nonnull, 2)\n",
    "output_token_cost_tan_fri_tx = round((0.03/1000) * output_tokens_tan_fri_tx_nonnull, 2)\n",
    "total_cost_tan_fri_tx = round(input_token_cost_tan_fri_tx + output_token_cost_tan_fri_tx, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_fri_tx}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_fri_tx_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_fri_tx}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_fri_tx_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_fri_tx}\")\n",
    "print(f\"Total Cost = {total_cost_tan_fri_tx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "407df66c-fc17-4367-9d55-ce08b8f51449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:10:59.868081Z",
     "iopub.status.busy": "2025-06-11T06:10:59.867841Z",
     "iopub.status.idle": "2025-06-11T06:10:59.872529Z",
     "shell.execute_reply": "2025-06-11T06:10:59.871966Z",
     "shell.execute_reply.started": "2025-06-11T06:10:59.868062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_fri_tx_nonnull_api & convert to DataFrame\n",
    "tan_fri_tx_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_fri_tx_nonnull_api\n",
    "]                                  \n",
    "tan_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(tan_fri_tx_nonnull_api_cleaned)\n",
    "#tan_fri_tx_nonnull_api_cleaned_df = pd.DataFrame(tan_fri_tx_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "75bc9a4e-fe0b-457b-81db-f5df52cb617e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:10:59.873727Z",
     "iopub.status.busy": "2025-06-11T06:10:59.873458Z",
     "iopub.status.idle": "2025-06-11T06:10:59.888955Z",
     "shell.execute_reply": "2025-06-11T06:10:59.888451Z",
     "shell.execute_reply.started": "2025-06-11T06:10:59.873702Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_fri_tx_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_fri_tx_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_fri_tx_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5fe7ab-9d94-4be8-8544-e2f88a758621",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fri_tx_nonnull_api_cleaned_df.to_excel(\"tan_fri_tx_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcb26a-89ad-4512-9049-15b6d120b21a",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fri_tx_nonnull_api_cleaned_df = pd.read_excel(\"tan_fri_tx_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42311d11-8d30-4781-9a79-d2419d904704",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fri_tx_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "76dbd089-beb6-4347-8117-cc7ba3ccf599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:10:59.890066Z",
     "iopub.status.busy": "2025-06-11T06:10:59.889801Z",
     "iopub.status.idle": "2025-06-11T06:11:00.148828Z",
     "shell.execute_reply": "2025-06-11T06:11:00.148170Z",
     "shell.execute_reply.started": "2025-06-11T06:10:59.890039Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_fri_tx_nonnull_sen_df = pd.DataFrame(processed_data_tan_fri_tx_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_fri_tx_nonnull_sen_df = tan_fri_tx_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_fri_tx_nonnull_merged_df = pd.concat([combined_df_tan_fri_tx, tan_fri_tx_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_fri_tx_final_sen_df = pd.concat([tan_fri_tx_nonnull_merged_df,null_dataframes['tan_fri_tx_null']], ignore_index=True)\n",
    "\n",
    "tan_fri_tx_final_sen_df_copy = tan_fri_tx_final_sen_df.copy()\n",
    "tan_fri_tx_final_sen_df_copy[\"Published At Date\"] = tan_fri_tx_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_fri_tx_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_fri_tx_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4a9a2-2d27-4329-acc8-9c9b8426a596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5e6c381-d25f-4af3-9c83-aa28d78e3a26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_hou_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "0752b0ba-aa33-4a01-aa2d-e5b812ea705b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:11:00.150350Z",
     "iopub.status.busy": "2025-06-11T06:11:00.149852Z",
     "iopub.status.idle": "2025-06-11T06:13:33.461175Z",
     "shell.execute_reply": "2025-06-11T06:13:33.460621Z",
     "shell.execute_reply.started": "2025-06-11T06:11:00.150321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [13] Iterations\n",
      "Total Execution Time: 00:02:33\n",
      "Total Input Tokens - 19995\n",
      "Total Input Cost = 0.2\n",
      "Total Output Tokens - 7359\n",
      "Total Output Cost = 0.22\n",
      "Total Cost = 0.42\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_1-4'])/25)+math.ceil(len(tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_5-15'])/25)+math.ceil(len(tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_16-30'])/25)+math.ceil(len(tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_31-60'])/25)+math.ceil(len(tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_61-100'])/25)+math.ceil(len(tan_hou_tx_nonnull_buckets['tan_hou_tx_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_hou_tx_nonnull_buckets.keys())\n",
    "tan_hou_tx_nonnull_api = []\n",
    "input_tokens_tan_hou_tx_nonnull=0\n",
    "output_tokens_tan_hou_tx_nonnull=0\n",
    "start_time_tan_hou_tx = time.time()\n",
    "\n",
    "for key in tan_hou_tx_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_hou_tx_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_hou_tx, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_hou_tx_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_hou_tx_nonnull+=input_tokens\n",
    "    output_tokens_tan_hou_tx_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_hou_tx = time.time() - start_time_tan_hou_tx\n",
    "formatted_time_tan_hou_tx = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_hou_tx))\n",
    "input_token_cost_tan_hou_tx = round((0.01/1000) * input_tokens_tan_hou_tx_nonnull, 2)\n",
    "output_token_cost_tan_hou_tx = round((0.03/1000) * output_tokens_tan_hou_tx_nonnull, 2)\n",
    "total_cost_tan_hou_tx = round(input_token_cost_tan_hou_tx + output_token_cost_tan_hou_tx, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_hou_tx}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_hou_tx_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_hou_tx}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_hou_tx_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_hou_tx}\")\n",
    "print(f\"Total Cost = {total_cost_tan_hou_tx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "70c2fa36-f231-4bfe-a5e6-c7d89ec4fb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:13:33.462240Z",
     "iopub.status.busy": "2025-06-11T06:13:33.461947Z",
     "iopub.status.idle": "2025-06-11T06:13:33.465996Z",
     "shell.execute_reply": "2025-06-11T06:13:33.465526Z",
     "shell.execute_reply.started": "2025-06-11T06:13:33.462218Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_hou_tx_nonnull_api & convert to DataFrame\n",
    "tan_hou_tx_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_hou_tx_nonnull_api\n",
    "]                                  \n",
    "tan_hou_tx_nonnull_api_cleaned_df = pd.DataFrame(tan_hou_tx_nonnull_api_cleaned)\n",
    "#tan_hou_tx_nonnull_api_cleaned_df = pd.DataFrame(tan_hou_tx_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4e5ab192-2343-49dd-93d7-49e4174dd07b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:13:33.466992Z",
     "iopub.status.busy": "2025-06-11T06:13:33.466679Z",
     "iopub.status.idle": "2025-06-11T06:13:33.474943Z",
     "shell.execute_reply": "2025-06-11T06:13:33.474465Z",
     "shell.execute_reply.started": "2025-06-11T06:13:33.466965Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_hou_tx_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_hou_tx_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_hou_tx_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662119d4-514d-4706-bf71-4a067b489ff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_hou_tx_nonnull_api_cleaned_df.to_excel(\"tan_hou_tx_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b507142-8d20-45e5-a95d-9f89268abb16",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_hou_tx_nonnull_api_cleaned_df = pd.read_excel(\"tan_hou_tx_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4333a5-46e5-4012-9773-fdf158549fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_hou_tx_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f1ef07a8-3697-47ed-9e92-ea2f0108f316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:13:33.475802Z",
     "iopub.status.busy": "2025-06-11T06:13:33.475488Z",
     "iopub.status.idle": "2025-06-11T06:13:33.569671Z",
     "shell.execute_reply": "2025-06-11T06:13:33.569088Z",
     "shell.execute_reply.started": "2025-06-11T06:13:33.475781Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_hou_tx_nonnull_sen_df = pd.DataFrame(processed_data_tan_hou_tx_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_hou_tx_nonnull_sen_df = tan_hou_tx_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_hou_tx_nonnull_merged_df = pd.concat([combined_df_tan_hou_tx, tan_hou_tx_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_hou_tx_final_sen_df = pd.concat([tan_hou_tx_nonnull_merged_df,null_dataframes['tan_hou_tx_null']], ignore_index=True)\n",
    "\n",
    "tan_hou_tx_final_sen_df_copy = tan_hou_tx_final_sen_df.copy()\n",
    "tan_hou_tx_final_sen_df_copy[\"Published At Date\"] = tan_hou_tx_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_hou_tx_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_hou_tx_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537bef2-85cc-4f73-87fd-cb4c2d045ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb2cb253-7ec4-46b6-b322-139fb6d82d32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_new_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "1faef939-5f4a-4bf8-af53-66566ce7c819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:13:33.570682Z",
     "iopub.status.busy": "2025-06-11T06:13:33.570415Z",
     "iopub.status.idle": "2025-06-11T06:15:34.320767Z",
     "shell.execute_reply": "2025-06-11T06:15:34.320208Z",
     "shell.execute_reply.started": "2025-06-11T06:13:33.570664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [11] Iterations\n",
      "Total Execution Time: 00:02:00\n",
      "Total Input Tokens - 22998\n",
      "Total Input Cost = 0.23\n",
      "Total Output Tokens - 6838\n",
      "Total Output Cost = 0.21\n",
      "Total Cost = 0.44\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_1-4'])/25)+math.ceil(len(tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_5-15'])/25)+math.ceil(len(tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_16-30'])/25)+math.ceil(len(tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_31-60'])/25)+math.ceil(len(tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_61-100'])/25)+math.ceil(len(tan_new_nj_nonnull_buckets['tan_new_nj_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_new_nj_nonnull_buckets.keys())\n",
    "tan_new_nj_nonnull_api = []\n",
    "input_tokens_tan_new_nj_nonnull=0\n",
    "output_tokens_tan_new_nj_nonnull=0\n",
    "start_time_tan_new_nj = time.time()\n",
    "\n",
    "for key in tan_new_nj_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_new_nj_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_new_nj, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_new_nj_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_new_nj_nonnull+=input_tokens\n",
    "    output_tokens_tan_new_nj_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_new_nj = time.time() - start_time_tan_new_nj\n",
    "formatted_time_tan_new_nj = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_new_nj))\n",
    "input_token_cost_tan_new_nj = round((0.01/1000) * input_tokens_tan_new_nj_nonnull, 2)\n",
    "output_token_cost_tan_new_nj = round((0.03/1000) * output_tokens_tan_new_nj_nonnull, 2)\n",
    "total_cost_tan_new_nj = round(input_token_cost_tan_new_nj + output_token_cost_tan_new_nj, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_new_nj}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_new_nj_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_new_nj}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_new_nj_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_new_nj}\")\n",
    "print(f\"Total Cost = {total_cost_tan_new_nj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "42098a57-f4e1-4fe7-b3b7-dab0cd89fe36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:15:34.323490Z",
     "iopub.status.busy": "2025-06-11T06:15:34.323242Z",
     "iopub.status.idle": "2025-06-11T06:15:34.327335Z",
     "shell.execute_reply": "2025-06-11T06:15:34.326827Z",
     "shell.execute_reply.started": "2025-06-11T06:15:34.323473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_new_nj_nonnull_api & convert to DataFrame\n",
    "tan_new_nj_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_new_nj_nonnull_api\n",
    "]                                  \n",
    "tan_new_nj_nonnull_api_cleaned_df = pd.DataFrame(tan_new_nj_nonnull_api_cleaned)\n",
    "#tan_new_nj_nonnull_api_cleaned_df = pd.DataFrame(tan_new_nj_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2f6d84af-bc3b-4dad-aa09-214a84301d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:15:34.328135Z",
     "iopub.status.busy": "2025-06-11T06:15:34.327924Z",
     "iopub.status.idle": "2025-06-11T06:15:34.336671Z",
     "shell.execute_reply": "2025-06-11T06:15:34.336144Z",
     "shell.execute_reply.started": "2025-06-11T06:15:34.328119Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_new_nj_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_new_nj_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_new_nj_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62bf939-4ca0-4c9b-a33f-6cbba7e1b8e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_new_nj_nonnull_api_cleaned_df.to_excel(\"tan_new_nj_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d1bf2-5ed8-478e-a5a4-6c180e5bc093",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_new_nj_nonnull_api_cleaned_df = pd.read_excel(\"tan_new_nj_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65272824-a126-4eea-b57d-1084b1deb4ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_new_nj_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "87d5f9d1-344f-487d-9475-4380703a6d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:15:34.337800Z",
     "iopub.status.busy": "2025-06-11T06:15:34.337493Z",
     "iopub.status.idle": "2025-06-11T06:15:34.427656Z",
     "shell.execute_reply": "2025-06-11T06:15:34.427164Z",
     "shell.execute_reply.started": "2025-06-11T06:15:34.337775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_new_nj_nonnull_sen_df = pd.DataFrame(processed_data_tan_new_nj_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_new_nj_nonnull_sen_df = tan_new_nj_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_new_nj_nonnull_merged_df = pd.concat([combined_df_tan_new_nj, tan_new_nj_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_new_nj_final_sen_df = pd.concat([tan_new_nj_nonnull_merged_df,null_dataframes['tan_new_nj_null']], ignore_index=True)\n",
    "\n",
    "tan_new_nj_final_sen_df_copy = tan_new_nj_final_sen_df.copy()\n",
    "tan_new_nj_final_sen_df_copy[\"Published At Date\"] = tan_new_nj_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_new_nj_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_new_nj_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcebc7c-4cfd-43a5-8f61-8dc862d4bcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a801b32-c91c-4dfd-9c1e-1aaf50286cdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_bar_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "5b2f950d-6677-49c6-b272-30b5d6dfe64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:15:34.428622Z",
     "iopub.status.busy": "2025-06-11T06:15:34.428421Z",
     "iopub.status.idle": "2025-06-11T06:23:37.290985Z",
     "shell.execute_reply": "2025-06-11T06:23:37.290424Z",
     "shell.execute_reply.started": "2025-06-11T06:15:34.428604Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [44] Iterations\n",
      "Total Execution Time: 00:08:02\n",
      "Total Input Tokens - 68101\n",
      "Total Input Cost = 0.68\n",
      "Total Output Tokens - 30247\n",
      "Total Output Cost = 0.91\n",
      "Total Cost = 1.59\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_1-4'])/25)+math.ceil(len(tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_5-15'])/25)+math.ceil(len(tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_16-30'])/25)+math.ceil(len(tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_31-60'])/25)+math.ceil(len(tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_61-100'])/25)+math.ceil(len(tan_bar_db_nonnull_buckets['tan_bar_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_bar_db_nonnull_buckets.keys())\n",
    "tan_bar_db_nonnull_api = []\n",
    "input_tokens_tan_bar_db_nonnull=0\n",
    "output_tokens_tan_bar_db_nonnull=0\n",
    "start_time_tan_bar_db = time.time()\n",
    "\n",
    "for key in tan_bar_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_bar_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_bar_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_bar_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_bar_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_bar_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_bar_db = time.time() - start_time_tan_bar_db\n",
    "formatted_time_tan_bar_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_bar_db))\n",
    "input_token_cost_tan_bar_db = round((0.01/1000) * input_tokens_tan_bar_db_nonnull, 2)\n",
    "output_token_cost_tan_bar_db = round((0.03/1000) * output_tokens_tan_bar_db_nonnull, 2)\n",
    "total_cost_tan_bar_db = round(input_token_cost_tan_bar_db + output_token_cost_tan_bar_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_bar_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_bar_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_bar_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_bar_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_bar_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_bar_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7ea95a96-eb47-47a6-b94e-c29a0fd78994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:23:37.292076Z",
     "iopub.status.busy": "2025-06-11T06:23:37.291838Z",
     "iopub.status.idle": "2025-06-11T06:23:37.296243Z",
     "shell.execute_reply": "2025-06-11T06:23:37.295704Z",
     "shell.execute_reply.started": "2025-06-11T06:23:37.292058Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_bar_db_nonnull_api & convert to DataFrame\n",
    "tan_bar_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_bar_db_nonnull_api\n",
    "]                                  \n",
    "tan_bar_db_nonnull_api_cleaned_df = pd.DataFrame(tan_bar_db_nonnull_api_cleaned)\n",
    "#tan_bar_db_nonnull_api_cleaned_df = pd.DataFrame(tan_bar_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ab98fcbe-606c-44e3-b2de-96284d9ce780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:23:37.297088Z",
     "iopub.status.busy": "2025-06-11T06:23:37.296851Z",
     "iopub.status.idle": "2025-06-11T06:23:37.311323Z",
     "shell.execute_reply": "2025-06-11T06:23:37.310852Z",
     "shell.execute_reply.started": "2025-06-11T06:23:37.297070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_bar_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_bar_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_bar_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b8691-cacb-459a-bb9a-bfddbbc56951",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_bar_db_nonnull_api_cleaned_df.to_excel(\"tan_bar_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3b257-25a8-4959-9c99-607bf66e66b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_bar_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_bar_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ded08b-0abd-43d9-9953-81e7af765f41",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_bar_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5e0adfd5-911b-4c38-a22f-2f116fb337e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:23:37.312582Z",
     "iopub.status.busy": "2025-06-11T06:23:37.312028Z",
     "iopub.status.idle": "2025-06-11T06:23:37.621823Z",
     "shell.execute_reply": "2025-06-11T06:23:37.621318Z",
     "shell.execute_reply.started": "2025-06-11T06:23:37.312555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_bar_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_bar_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_bar_db_nonnull_sen_df = tan_bar_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_bar_db_nonnull_merged_df = pd.concat([combined_df_tan_bar_db, tan_bar_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_bar_db_final_sen_df = pd.concat([tan_bar_db_nonnull_merged_df,null_dataframes['tan_bar_db_null']], ignore_index=True)\n",
    "\n",
    "tan_bar_db_final_sen_df_copy = tan_bar_db_final_sen_df.copy()\n",
    "tan_bar_db_final_sen_df_copy[\"Published At Date\"] = tan_bar_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_bar_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_bar_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3241019-bced-4d2a-9f54-16d19eb3eab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59b4cb94-8e46-491e-8ad1-e9d7f3d2cbea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_fah_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e42e5ff5-31ad-41f4-8961-ea7368ab2a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:23:37.622929Z",
     "iopub.status.busy": "2025-06-11T06:23:37.622692Z",
     "iopub.status.idle": "2025-06-11T06:36:37.966086Z",
     "shell.execute_reply": "2025-06-11T06:36:37.965527Z",
     "shell.execute_reply.started": "2025-06-11T06:23:37.622910Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [76] Iterations\n",
      "Total Execution Time: 00:13:00\n",
      "Total Input Tokens - 106933\n",
      "Total Input Cost = 1.07\n",
      "Total Output Tokens - 51735\n",
      "Total Output Cost = 1.55\n",
      "Total Cost = 2.62\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_1-4'])/25)+math.ceil(len(tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_5-15'])/25)+math.ceil(len(tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_16-30'])/25)+math.ceil(len(tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_31-60'])/25)+math.ceil(len(tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_61-100'])/25)+math.ceil(len(tan_fah_db_nonnull_buckets['tan_fah_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_fah_db_nonnull_buckets.keys())\n",
    "tan_fah_db_nonnull_api = []\n",
    "input_tokens_tan_fah_db_nonnull=0\n",
    "output_tokens_tan_fah_db_nonnull=0\n",
    "start_time_tan_fah_db = time.time()\n",
    "\n",
    "for key in tan_fah_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_fah_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_fah_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_fah_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_fah_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_fah_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_fah_db = time.time() - start_time_tan_fah_db\n",
    "formatted_time_tan_fah_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_fah_db))\n",
    "input_token_cost_tan_fah_db = round((0.01/1000) * input_tokens_tan_fah_db_nonnull, 2)\n",
    "output_token_cost_tan_fah_db = round((0.03/1000) * output_tokens_tan_fah_db_nonnull, 2)\n",
    "total_cost_tan_fah_db = round(input_token_cost_tan_fah_db + output_token_cost_tan_fah_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_fah_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_fah_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_fah_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_fah_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_fah_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_fah_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0aed6f98-fa8e-4b23-88ba-85300d3fe9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:36:37.967043Z",
     "iopub.status.busy": "2025-06-11T06:36:37.966792Z",
     "iopub.status.idle": "2025-06-11T06:36:37.971515Z",
     "shell.execute_reply": "2025-06-11T06:36:37.971050Z",
     "shell.execute_reply.started": "2025-06-11T06:36:37.967023Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_fah_db_nonnull_api & convert to DataFrame\n",
    "tan_fah_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_fah_db_nonnull_api\n",
    "]                                  \n",
    "tan_fah_db_nonnull_api_cleaned_df = pd.DataFrame(tan_fah_db_nonnull_api_cleaned)\n",
    "#tan_fah_db_nonnull_api_cleaned_df = pd.DataFrame(tan_fah_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0dfef706-0cef-4406-9c8f-f0ba0cd7cf92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:36:37.972554Z",
     "iopub.status.busy": "2025-06-11T06:36:37.972211Z",
     "iopub.status.idle": "2025-06-11T06:36:37.992202Z",
     "shell.execute_reply": "2025-06-11T06:36:37.991717Z",
     "shell.execute_reply.started": "2025-06-11T06:36:37.972535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_fah_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_fah_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_fah_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263a502-6bc9-46c7-9fb8-e248d96b06c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fah_db_nonnull_api_cleaned_df.to_excel(\"tan_fah_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f565350-025f-4665-bebb-37c0d43d9aa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fah_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_fah_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a2a5f-129e-4dab-aca7-82440a56ec38",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fah_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "12fca5d7-782f-4990-9dec-3c71e8e935d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:36:37.993105Z",
     "iopub.status.busy": "2025-06-11T06:36:37.992862Z",
     "iopub.status.idle": "2025-06-11T06:36:38.495821Z",
     "shell.execute_reply": "2025-06-11T06:36:38.495280Z",
     "shell.execute_reply.started": "2025-06-11T06:36:37.993089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_fah_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_fah_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_fah_db_nonnull_sen_df = tan_fah_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_fah_db_nonnull_merged_df = pd.concat([combined_df_tan_fah_db, tan_fah_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_fah_db_final_sen_df = pd.concat([tan_fah_db_nonnull_merged_df,null_dataframes['tan_fah_db_null']], ignore_index=True)\n",
    "\n",
    "tan_fah_db_final_sen_df_copy = tan_fah_db_final_sen_df.copy()\n",
    "tan_fah_db_final_sen_df_copy[\"Published At Date\"] = tan_fah_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_fah_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_fah_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5a1d0-a524-4e23-b66f-56a1c4066b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f10e2242-37d8-4dd3-b8b3-b1ef9b8776a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_kar_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "54ab9951-c535-4384-904b-4f2ea2d6524f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:36:38.496944Z",
     "iopub.status.busy": "2025-06-11T06:36:38.496660Z",
     "iopub.status.idle": "2025-06-11T06:40:05.382058Z",
     "shell.execute_reply": "2025-06-11T06:40:05.381508Z",
     "shell.execute_reply.started": "2025-06-11T06:36:38.496925Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [21] Iterations\n",
      "Total Execution Time: 00:03:26\n",
      "Total Input Tokens - 34017\n",
      "Total Input Cost = 0.34\n",
      "Total Output Tokens - 14301\n",
      "Total Output Cost = 0.43\n",
      "Total Cost = 0.77\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_1-4'])/25)+math.ceil(len(tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_5-15'])/25)+math.ceil(len(tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_16-30'])/25)+math.ceil(len(tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_31-60'])/25)+math.ceil(len(tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_61-100'])/25)+math.ceil(len(tan_kar_db_nonnull_buckets['tan_kar_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_kar_db_nonnull_buckets.keys())\n",
    "tan_kar_db_nonnull_api = []\n",
    "input_tokens_tan_kar_db_nonnull=0\n",
    "output_tokens_tan_kar_db_nonnull=0\n",
    "start_time_tan_kar_db = time.time()\n",
    "\n",
    "for key in tan_kar_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_kar_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_kar_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_kar_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_kar_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_kar_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_kar_db = time.time() - start_time_tan_kar_db\n",
    "formatted_time_tan_kar_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_kar_db))\n",
    "input_token_cost_tan_kar_db = round((0.01/1000) * input_tokens_tan_kar_db_nonnull, 2)\n",
    "output_token_cost_tan_kar_db = round((0.03/1000) * output_tokens_tan_kar_db_nonnull, 2)\n",
    "total_cost_tan_kar_db = round(input_token_cost_tan_kar_db + output_token_cost_tan_kar_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_kar_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_kar_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_kar_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_kar_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_kar_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_kar_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "132558ff-2fe9-40db-ae14-7013fe04702a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:40:05.383077Z",
     "iopub.status.busy": "2025-06-11T06:40:05.382787Z",
     "iopub.status.idle": "2025-06-11T06:40:05.386984Z",
     "shell.execute_reply": "2025-06-11T06:40:05.386451Z",
     "shell.execute_reply.started": "2025-06-11T06:40:05.383055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_kar_db_nonnull_api & convert to DataFrame\n",
    "tan_kar_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_kar_db_nonnull_api\n",
    "]                                  \n",
    "tan_kar_db_nonnull_api_cleaned_df = pd.DataFrame(tan_kar_db_nonnull_api_cleaned)\n",
    "#tan_kar_db_nonnull_api_cleaned_df = pd.DataFrame(tan_kar_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d660f848-2ada-4a28-a567-629cb80db4d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:40:05.387750Z",
     "iopub.status.busy": "2025-06-11T06:40:05.387570Z",
     "iopub.status.idle": "2025-06-11T06:40:05.398161Z",
     "shell.execute_reply": "2025-06-11T06:40:05.397701Z",
     "shell.execute_reply.started": "2025-06-11T06:40:05.387734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_kar_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_kar_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_kar_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783892bc-41b1-4b21-ad34-69c2322bc7f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_kar_db_nonnull_api_cleaned_df.to_excel(\"tan_kar_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177038d-efce-4da0-9b09-83dc773dc173",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_kar_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_kar_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de89b4-67e0-4b86-b36d-4a8712287058",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_kar_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "11240d16-376d-4921-8cf5-d2300af1b592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:40:05.398958Z",
     "iopub.status.busy": "2025-06-11T06:40:05.398730Z",
     "iopub.status.idle": "2025-06-11T06:40:05.571792Z",
     "shell.execute_reply": "2025-06-11T06:40:05.571236Z",
     "shell.execute_reply.started": "2025-06-11T06:40:05.398943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_kar_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_kar_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_kar_db_nonnull_sen_df = tan_kar_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_kar_db_nonnull_merged_df = pd.concat([combined_df_tan_kar_db, tan_kar_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_kar_db_final_sen_df = pd.concat([tan_kar_db_nonnull_merged_df,null_dataframes['tan_kar_db_null']], ignore_index=True)\n",
    "\n",
    "tan_kar_db_final_sen_df_copy = tan_kar_db_final_sen_df.copy()\n",
    "tan_kar_db_final_sen_df_copy[\"Published At Date\"] = tan_kar_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_kar_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_kar_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d519c1-a385-482f-85a1-7360dcdf397b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2864f692-8278-486c-b6a6-59fa9a20694a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_ham_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "363bd974-20d8-4588-ac71-d90596cc4798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:40:05.572919Z",
     "iopub.status.busy": "2025-06-11T06:40:05.572628Z",
     "iopub.status.idle": "2025-06-11T06:43:16.423541Z",
     "shell.execute_reply": "2025-06-11T06:43:16.422996Z",
     "shell.execute_reply.started": "2025-06-11T06:40:05.572902Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [20] Iterations\n",
      "Total Execution Time: 00:03:10\n",
      "Total Input Tokens - 28070\n",
      "Total Input Cost = 0.28\n",
      "Total Output Tokens - 11357\n",
      "Total Output Cost = 0.34\n",
      "Total Cost = 0.62\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_1-4'])/25)+math.ceil(len(tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_5-15'])/25)+math.ceil(len(tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_16-30'])/25)+math.ceil(len(tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_31-60'])/25)+math.ceil(len(tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_61-100'])/25)+math.ceil(len(tan_ham_ad_nonnull_buckets['tan_ham_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_ham_ad_nonnull_buckets.keys())\n",
    "tan_ham_ad_nonnull_api = []\n",
    "input_tokens_tan_ham_ad_nonnull=0\n",
    "output_tokens_tan_ham_ad_nonnull=0\n",
    "start_time_tan_ham_ad = time.time()\n",
    "\n",
    "for key in tan_ham_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_ham_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_ham_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_ham_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_ham_ad_nonnull+=input_tokens\n",
    "    output_tokens_tan_ham_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_ham_ad = time.time() - start_time_tan_ham_ad\n",
    "formatted_time_tan_ham_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_ham_ad))\n",
    "input_token_cost_tan_ham_ad = round((0.01/1000) * input_tokens_tan_ham_ad_nonnull, 2)\n",
    "output_token_cost_tan_ham_ad = round((0.03/1000) * output_tokens_tan_ham_ad_nonnull, 2)\n",
    "total_cost_tan_ham_ad = round(input_token_cost_tan_ham_ad + output_token_cost_tan_ham_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_ham_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_ham_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_ham_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_ham_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_ham_ad}\")\n",
    "print(f\"Total Cost = {total_cost_tan_ham_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4a7a0674-670a-4b9a-9d93-355aaac97831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:43:16.424539Z",
     "iopub.status.busy": "2025-06-11T06:43:16.424263Z",
     "iopub.status.idle": "2025-06-11T06:43:16.428410Z",
     "shell.execute_reply": "2025-06-11T06:43:16.427893Z",
     "shell.execute_reply.started": "2025-06-11T06:43:16.424518Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_ham_ad_nonnull_api & convert to DataFrame\n",
    "tan_ham_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_ham_ad_nonnull_api\n",
    "]                                  \n",
    "tan_ham_ad_nonnull_api_cleaned_df = pd.DataFrame(tan_ham_ad_nonnull_api_cleaned)\n",
    "#tan_ham_ad_nonnull_api_cleaned_df = pd.DataFrame(tan_ham_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "1377e26a-2a5f-40a3-a636-55734b03d750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:43:16.429396Z",
     "iopub.status.busy": "2025-06-11T06:43:16.429087Z",
     "iopub.status.idle": "2025-06-11T06:43:16.438743Z",
     "shell.execute_reply": "2025-06-11T06:43:16.438293Z",
     "shell.execute_reply.started": "2025-06-11T06:43:16.429370Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_ham_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_ham_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_ham_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7dd99-c3e8-4022-bfd3-0959bf883aa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_ham_ad_nonnull_api_cleaned_df.to_excel(\"tan_ham_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d16ec-3de6-410a-92ab-140be435e1b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_ham_ad_nonnull_api_cleaned_df = pd.read_excel(\"tan_ham_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c95f5-1e75-4a0f-bd5c-37adf438bdc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_ham_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "64a9bc51-f204-417f-b35b-5b643cdaa5af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:43:16.439738Z",
     "iopub.status.busy": "2025-06-11T06:43:16.439353Z",
     "iopub.status.idle": "2025-06-11T06:43:16.773003Z",
     "shell.execute_reply": "2025-06-11T06:43:16.772501Z",
     "shell.execute_reply.started": "2025-06-11T06:43:16.439719Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_ham_ad_nonnull_sen_df = pd.DataFrame(processed_data_tan_ham_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_ham_ad_nonnull_sen_df = tan_ham_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_ham_ad_nonnull_merged_df = pd.concat([combined_df_tan_ham_ad, tan_ham_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_ham_ad_final_sen_df = pd.concat([tan_ham_ad_nonnull_merged_df,null_dataframes['tan_ham_ad_null']], ignore_index=True)\n",
    "\n",
    "tan_ham_ad_final_sen_df_copy = tan_ham_ad_final_sen_df.copy()\n",
    "tan_ham_ad_final_sen_df_copy[\"Published At Date\"] = tan_ham_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_ham_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_ham_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1e9b2-d219-4e84-a530-eed7aaa1ced8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e893fa1-42c9-4deb-bc49-205e4dda0def",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_mee_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7872a9a3-752b-4860-9edf-195ce71fd35f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:43:16.774155Z",
     "iopub.status.busy": "2025-06-11T06:43:16.773824Z",
     "iopub.status.idle": "2025-06-11T06:47:46.256315Z",
     "shell.execute_reply": "2025-06-11T06:47:46.255758Z",
     "shell.execute_reply.started": "2025-06-11T06:43:16.774127Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [31] Iterations\n",
      "Total Execution Time: 00:04:29\n",
      "Total Input Tokens - 45905\n",
      "Total Input Cost = 0.46\n",
      "Total Output Tokens - 20129\n",
      "Total Output Cost = 0.6\n",
      "Total Cost = 1.06\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_1-4'])/25)+math.ceil(len(tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_5-15'])/25)+math.ceil(len(tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_16-30'])/25)+math.ceil(len(tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_31-60'])/25)+math.ceil(len(tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_61-100'])/25)+math.ceil(len(tan_mee_db_nonnull_buckets['tan_mee_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_mee_db_nonnull_buckets.keys())\n",
    "tan_mee_db_nonnull_api = []\n",
    "input_tokens_tan_mee_db_nonnull=0\n",
    "output_tokens_tan_mee_db_nonnull=0\n",
    "start_time_tan_mee_db = time.time()\n",
    "\n",
    "for key in tan_mee_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_mee_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_mee_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_mee_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_mee_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_mee_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_mee_db = time.time() - start_time_tan_mee_db\n",
    "formatted_time_tan_mee_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_mee_db))\n",
    "input_token_cost_tan_mee_db = round((0.01/1000) * input_tokens_tan_mee_db_nonnull, 2)\n",
    "output_token_cost_tan_mee_db = round((0.03/1000) * output_tokens_tan_mee_db_nonnull, 2)\n",
    "total_cost_tan_mee_db = round(input_token_cost_tan_mee_db + output_token_cost_tan_mee_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_mee_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_mee_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_mee_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_mee_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_mee_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_mee_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "915f9375-19e5-4747-be5d-b1f3681a173d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:47:46.257214Z",
     "iopub.status.busy": "2025-06-11T06:47:46.256933Z",
     "iopub.status.idle": "2025-06-11T06:47:46.261639Z",
     "shell.execute_reply": "2025-06-11T06:47:46.261142Z",
     "shell.execute_reply.started": "2025-06-11T06:47:46.257181Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_mee_db_nonnull_api & convert to DataFrame\n",
    "tan_mee_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_mee_db_nonnull_api\n",
    "]                                  \n",
    "tan_mee_db_nonnull_api_cleaned_df = pd.DataFrame(tan_mee_db_nonnull_api_cleaned)\n",
    "#tan_mee_db_nonnull_api_cleaned_df = pd.DataFrame(tan_mee_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "015119df-9ad0-4470-a146-129e86b8a70c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:47:46.262376Z",
     "iopub.status.busy": "2025-06-11T06:47:46.262189Z",
     "iopub.status.idle": "2025-06-11T06:47:46.273897Z",
     "shell.execute_reply": "2025-06-11T06:47:46.273461Z",
     "shell.execute_reply.started": "2025-06-11T06:47:46.262360Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_mee_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_mee_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_mee_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680f1e2-b8c0-4c59-ae20-256b0c9804e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_mee_db_nonnull_api_cleaned_df.to_excel(\"tan_mee_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87423204-30b9-494b-bea1-1b6339bdf720",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_mee_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_mee_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b07eb-0d99-4637-98ad-af692a080eb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_mee_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "6356cb4b-3050-4c0c-8c12-0127e81166de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:47:46.274919Z",
     "iopub.status.busy": "2025-06-11T06:47:46.274555Z",
     "iopub.status.idle": "2025-06-11T06:47:46.493549Z",
     "shell.execute_reply": "2025-06-11T06:47:46.493055Z",
     "shell.execute_reply.started": "2025-06-11T06:47:46.274892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_mee_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_mee_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_mee_db_nonnull_sen_df = tan_mee_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_mee_db_nonnull_merged_df = pd.concat([combined_df_tan_mee_db, tan_mee_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_mee_db_final_sen_df = pd.concat([tan_mee_db_nonnull_merged_df,null_dataframes['tan_mee_db_null']], ignore_index=True)\n",
    "\n",
    "tan_mee_db_final_sen_df_copy = tan_mee_db_final_sen_df.copy()\n",
    "tan_mee_db_final_sen_df_copy[\"Published At Date\"] = tan_mee_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_mee_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_mee_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989318e5-50c9-4cad-9e12-84d6f6e942ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d76a2f3-b138-461a-972c-0cbb05b9bb29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_sil_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fd4fca5f-d017-41a4-81f9-385b0f71c26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:47:46.494484Z",
     "iopub.status.busy": "2025-06-11T06:47:46.494222Z",
     "iopub.status.idle": "2025-06-11T06:52:37.019130Z",
     "shell.execute_reply": "2025-06-11T06:52:37.018606Z",
     "shell.execute_reply.started": "2025-06-11T06:47:46.494464Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [30] Iterations\n",
      "Total Execution Time: 00:04:50\n",
      "Total Input Tokens - 44981\n",
      "Total Input Cost = 0.45\n",
      "Total Output Tokens - 19770\n",
      "Total Output Cost = 0.59\n",
      "Total Cost = 1.04\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_1-4'])/25)+math.ceil(len(tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_5-15'])/25)+math.ceil(len(tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_16-30'])/25)+math.ceil(len(tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_31-60'])/25)+math.ceil(len(tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_61-100'])/25)+math.ceil(len(tan_sil_db_nonnull_buckets['tan_sil_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_sil_db_nonnull_buckets.keys())\n",
    "tan_sil_db_nonnull_api = []\n",
    "input_tokens_tan_sil_db_nonnull=0\n",
    "output_tokens_tan_sil_db_nonnull=0\n",
    "start_time_tan_sil_db = time.time()\n",
    "\n",
    "for key in tan_sil_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_sil_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_sil_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_sil_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_sil_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_sil_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_sil_db = time.time() - start_time_tan_sil_db\n",
    "formatted_time_tan_sil_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_sil_db))\n",
    "input_token_cost_tan_sil_db = round((0.01/1000) * input_tokens_tan_sil_db_nonnull, 2)\n",
    "output_token_cost_tan_sil_db = round((0.03/1000) * output_tokens_tan_sil_db_nonnull, 2)\n",
    "total_cost_tan_sil_db = round(input_token_cost_tan_sil_db + output_token_cost_tan_sil_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_sil_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_sil_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_sil_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_sil_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_sil_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_sil_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "80d454a1-dedc-4ff0-8133-e406ee6735ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:37.020317Z",
     "iopub.status.busy": "2025-06-11T06:52:37.019848Z",
     "iopub.status.idle": "2025-06-11T06:52:37.024246Z",
     "shell.execute_reply": "2025-06-11T06:52:37.023701Z",
     "shell.execute_reply.started": "2025-06-11T06:52:37.020294Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_sil_db_nonnull_api & convert to DataFrame\n",
    "tan_sil_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_sil_db_nonnull_api\n",
    "]                                  \n",
    "tan_sil_db_nonnull_api_cleaned_df = pd.DataFrame(tan_sil_db_nonnull_api_cleaned)\n",
    "#tan_sil_db_nonnull_api_cleaned_df = pd.DataFrame(tan_sil_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "40442797-a244-4918-83f9-69beb7b8108f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:37.025259Z",
     "iopub.status.busy": "2025-06-11T06:52:37.024870Z",
     "iopub.status.idle": "2025-06-11T06:52:37.037259Z",
     "shell.execute_reply": "2025-06-11T06:52:37.036774Z",
     "shell.execute_reply.started": "2025-06-11T06:52:37.025239Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_sil_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_sil_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_sil_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d328e9c-1b89-4cd7-9c7b-eaf125e71515",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sil_db_nonnull_api_cleaned_df.to_excel(\"tan_sil_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570725a9-489b-40fc-b84a-52494f16bc40",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sil_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_sil_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344fd22e-a03a-42a1-8fc9-280992b66627",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sil_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "abeaf629-bf24-4dda-8820-56db96c37bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:37.038209Z",
     "iopub.status.busy": "2025-06-11T06:52:37.037922Z",
     "iopub.status.idle": "2025-06-11T06:52:37.256606Z",
     "shell.execute_reply": "2025-06-11T06:52:37.256107Z",
     "shell.execute_reply.started": "2025-06-11T06:52:37.038184Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_sil_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_sil_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_sil_db_nonnull_sen_df = tan_sil_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_sil_db_nonnull_merged_df = pd.concat([combined_df_tan_sil_db, tan_sil_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_sil_db_final_sen_df = pd.concat([tan_sil_db_nonnull_merged_df,null_dataframes['tan_sil_db_null']], ignore_index=True)\n",
    "\n",
    "tan_sil_db_final_sen_df_copy = tan_sil_db_final_sen_df.copy()\n",
    "tan_sil_db_final_sen_df_copy[\"Published At Date\"] = tan_sil_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_sil_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_sil_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b7ac17-4a48-4696-abf1-e2992c251b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a50100e3-b8eb-4157-8879-1f95ab8de961",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mia_awm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "4fa590e0-e79f-427b-b53e-6aef50e62e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:37.260967Z",
     "iopub.status.busy": "2025-06-11T06:52:37.260715Z",
     "iopub.status.idle": "2025-06-11T06:52:49.310364Z",
     "shell.execute_reply": "2025-06-11T06:52:49.309861Z",
     "shell.execute_reply.started": "2025-06-11T06:52:37.260948Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [3] Iterations\n",
      "Total Execution Time: 00:00:12\n",
      "Total Input Tokens - 2606\n",
      "Total Input Cost = 0.03\n",
      "Total Output Tokens - 721\n",
      "Total Output Cost = 0.02\n",
      "Total Cost = 0.05\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_1-4'])/25)+math.ceil(len(mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_5-15'])/25)+math.ceil(len(mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_16-30'])/25)+math.ceil(len(mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_31-60'])/25)+math.ceil(len(mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_61-100'])/25)+math.ceil(len(mia_awm_ad_nonnull_buckets['mia_awm_ad_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mia_awm_ad_nonnull_buckets.keys())\n",
    "mia_awm_ad_nonnull_api = []\n",
    "input_tokens_mia_awm_ad_nonnull=0\n",
    "output_tokens_mia_awm_ad_nonnull=0\n",
    "start_time_mia_awm_ad = time.time()\n",
    "\n",
    "for key in mia_awm_ad_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mia_awm_ad_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mia_awm_ad, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mia_awm_ad_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mia_awm_ad_nonnull+=input_tokens\n",
    "    output_tokens_mia_awm_ad_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mia_awm_ad = time.time() - start_time_mia_awm_ad\n",
    "formatted_time_mia_awm_ad = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mia_awm_ad))\n",
    "input_token_cost_mia_awm_ad = round((0.01/1000) * input_tokens_mia_awm_ad_nonnull, 2)\n",
    "output_token_cost_mia_awm_ad = round((0.03/1000) * output_tokens_mia_awm_ad_nonnull, 2)\n",
    "total_cost_mia_awm_ad = round(input_token_cost_mia_awm_ad + output_token_cost_mia_awm_ad, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mia_awm_ad}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mia_awm_ad_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mia_awm_ad}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mia_awm_ad_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mia_awm_ad}\")\n",
    "print(f\"Total Cost = {total_cost_mia_awm_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e41d50ca-29e3-4391-a206-4e7a48a26916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:49.311271Z",
     "iopub.status.busy": "2025-06-11T06:52:49.311017Z",
     "iopub.status.idle": "2025-06-11T06:52:49.314847Z",
     "shell.execute_reply": "2025-06-11T06:52:49.314287Z",
     "shell.execute_reply.started": "2025-06-11T06:52:49.311253Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mia_awm_ad_nonnull_api & convert to DataFrame\n",
    "mia_awm_ad_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mia_awm_ad_nonnull_api\n",
    "]                                  \n",
    "mia_awm_ad_nonnull_api_cleaned_df = pd.DataFrame(mia_awm_ad_nonnull_api_cleaned)\n",
    "#mia_awm_ad_nonnull_api_cleaned_df = pd.DataFrame(mia_awm_ad_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "18c200cd-73be-4dea-9750-47c7cb15a181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:49.315690Z",
     "iopub.status.busy": "2025-06-11T06:52:49.315404Z",
     "iopub.status.idle": "2025-06-11T06:52:49.321620Z",
     "shell.execute_reply": "2025-06-11T06:52:49.321174Z",
     "shell.execute_reply.started": "2025-06-11T06:52:49.315671Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mia_awm_ad_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mia_awm_ad_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mia_awm_ad_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de39b1-ce11-456b-a52a-ed82cfbc58d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "mia_awm_ad_nonnull_api_cleaned_df.to_excel(\"mia_awm_ad_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95890b3f-eff5-489b-972d-31812075cfd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "mia_awm_ad_nonnull_api_cleaned_df = pd.read_excel(\"mia_awm_ad_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42f057-13ce-4907-b745-524076658a96",
   "metadata": {
    "tags": []
   },
   "source": [
    "mia_awm_ad_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a29b652d-0240-4e54-af9d-485711cec89c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:49.322648Z",
     "iopub.status.busy": "2025-06-11T06:52:49.322301Z",
     "iopub.status.idle": "2025-06-11T06:52:49.357670Z",
     "shell.execute_reply": "2025-06-11T06:52:49.357222Z",
     "shell.execute_reply.started": "2025-06-11T06:52:49.322628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mia_awm_ad_nonnull_sen_df = pd.DataFrame(processed_data_mia_awm_ad_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mia_awm_ad_nonnull_sen_df = mia_awm_ad_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mia_awm_ad_nonnull_merged_df = pd.concat([combined_df_mia_awm_ad, mia_awm_ad_nonnull_sen_df], axis=1)\n",
    "\n",
    "mia_awm_ad_final_sen_df = pd.concat([mia_awm_ad_nonnull_merged_df,null_dataframes['mia_awm_ad_null']], ignore_index=True)\n",
    "\n",
    "mia_awm_ad_final_sen_df_copy = mia_awm_ad_final_sen_df.copy()\n",
    "mia_awm_ad_final_sen_df_copy[\"Published At Date\"] = mia_awm_ad_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mia_awm_ad_final_sen_df_copy.to_excel(\"sentiment_raw_output/mia_awm_ad_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83790c94-a6da-4390-8b0d-84c93cfeba71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668e219d-ded7-4f2b-be0a-624e6c96e49c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mia_bur_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b7d91294-7d6a-4433-8d40-d11de6808267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:52:49.358502Z",
     "iopub.status.busy": "2025-06-11T06:52:49.358326Z",
     "iopub.status.idle": "2025-06-11T06:55:09.128828Z",
     "shell.execute_reply": "2025-06-11T06:55:09.128273Z",
     "shell.execute_reply.started": "2025-06-11T06:52:49.358486Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [20] Iterations\n",
      "Total Execution Time: 00:02:19\n",
      "Total Input Tokens - 27191\n",
      "Total Input Cost = 0.27\n",
      "Total Output Tokens - 11633\n",
      "Total Output Cost = 0.35\n",
      "Total Cost = 0.62\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_1-4'])/25)+math.ceil(len(mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_5-15'])/25)+math.ceil(len(mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_16-30'])/25)+math.ceil(len(mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_31-60'])/25)+math.ceil(len(mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_61-100'])/25)+math.ceil(len(mia_bur_db_nonnull_buckets['mia_bur_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(mia_bur_db_nonnull_buckets.keys())\n",
    "mia_bur_db_nonnull_api = []\n",
    "input_tokens_mia_bur_db_nonnull=0\n",
    "output_tokens_mia_bur_db_nonnull=0\n",
    "start_time_mia_bur_db = time.time()\n",
    "\n",
    "for key in mia_bur_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = mia_bur_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_mia_bur_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        mia_bur_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_mia_bur_db_nonnull+=input_tokens\n",
    "    output_tokens_mia_bur_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_mia_bur_db = time.time() - start_time_mia_bur_db\n",
    "formatted_time_mia_bur_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_mia_bur_db))\n",
    "input_token_cost_mia_bur_db = round((0.01/1000) * input_tokens_mia_bur_db_nonnull, 2)\n",
    "output_token_cost_mia_bur_db = round((0.03/1000) * output_tokens_mia_bur_db_nonnull, 2)\n",
    "total_cost_mia_bur_db = round(input_token_cost_mia_bur_db + output_token_cost_mia_bur_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_mia_bur_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_mia_bur_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_mia_bur_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_mia_bur_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_mia_bur_db}\")\n",
    "print(f\"Total Cost = {total_cost_mia_bur_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "7ff86daf-1f9a-4d52-954f-18bc894d4fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:09.129763Z",
     "iopub.status.busy": "2025-06-11T06:55:09.129502Z",
     "iopub.status.idle": "2025-06-11T06:55:09.133785Z",
     "shell.execute_reply": "2025-06-11T06:55:09.133257Z",
     "shell.execute_reply.started": "2025-06-11T06:55:09.129745Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in mia_bur_db_nonnull_api & convert to DataFrame\n",
    "mia_bur_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in mia_bur_db_nonnull_api\n",
    "]                                  \n",
    "mia_bur_db_nonnull_api_cleaned_df = pd.DataFrame(mia_bur_db_nonnull_api_cleaned)\n",
    "#mia_bur_db_nonnull_api_cleaned_df = pd.DataFrame(mia_bur_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "73bd06a5-ae05-4c1c-ac58-3f1f69b9ad77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:09.134826Z",
     "iopub.status.busy": "2025-06-11T06:55:09.134495Z",
     "iopub.status.idle": "2025-06-11T06:55:09.144139Z",
     "shell.execute_reply": "2025-06-11T06:55:09.143658Z",
     "shell.execute_reply.started": "2025-06-11T06:55:09.134800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_mia_bur_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in mia_bur_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_mia_bur_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1011585-9ddf-4f57-899d-47a2c41fce95",
   "metadata": {
    "tags": []
   },
   "source": [
    "mia_bur_db_nonnull_api_cleaned_df.to_excel(\"mia_bur_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bd5b3e-131d-4ebb-8c15-555e437f05fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "mia_bur_db_nonnull_api_cleaned_df = pd.read_excel(\"mia_bur_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019da88-3507-43b8-b0b9-3ec3667a5097",
   "metadata": {
    "tags": []
   },
   "source": [
    "mia_bur_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "3b4fff23-36c9-468c-8b9d-1948cdeb0f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:09.144924Z",
     "iopub.status.busy": "2025-06-11T06:55:09.144685Z",
     "iopub.status.idle": "2025-06-11T06:55:09.278552Z",
     "shell.execute_reply": "2025-06-11T06:55:09.278060Z",
     "shell.execute_reply.started": "2025-06-11T06:55:09.144908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "mia_bur_db_nonnull_sen_df = pd.DataFrame(processed_data_mia_bur_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "mia_bur_db_nonnull_sen_df = mia_bur_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "mia_bur_db_nonnull_merged_df = pd.concat([combined_df_mia_bur_db, mia_bur_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "mia_bur_db_final_sen_df = pd.concat([mia_bur_db_nonnull_merged_df,null_dataframes['mia_bur_db_null']], ignore_index=True)\n",
    "\n",
    "mia_bur_db_final_sen_df_copy = mia_bur_db_final_sen_df.copy()\n",
    "mia_bur_db_final_sen_df_copy[\"Published At Date\"] = mia_bur_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "mia_bur_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/mia_bur_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47450191-c5c9-40f1-bec9-995935815feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65a8141a-20c7-4d99-9888-9155d3ada073",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_am_om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f29f8ef9-f6da-4f44-9265-4d13d042eb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:09.279925Z",
     "iopub.status.busy": "2025-06-11T06:55:09.279359Z",
     "iopub.status.idle": "2025-06-11T06:55:40.367601Z",
     "shell.execute_reply": "2025-06-11T06:55:40.367125Z",
     "shell.execute_reply.started": "2025-06-11T06:55:09.279899Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [6] Iterations\n",
      "Total Execution Time: 00:00:31\n",
      "Total Input Tokens - 6374\n",
      "Total Input Cost = 0.06\n",
      "Total Output Tokens - 2299\n",
      "Total Output Cost = 0.07\n",
      "Total Cost = 0.13\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_am_om_nonnull_buckets['tan_am_om_nonnull_1-4'])/25)+math.ceil(len(tan_am_om_nonnull_buckets['tan_am_om_nonnull_5-15'])/25)+math.ceil(len(tan_am_om_nonnull_buckets['tan_am_om_nonnull_16-30'])/25)+math.ceil(len(tan_am_om_nonnull_buckets['tan_am_om_nonnull_31-60'])/25)+math.ceil(len(tan_am_om_nonnull_buckets['tan_am_om_nonnull_61-100'])/25)+math.ceil(len(tan_am_om_nonnull_buckets['tan_am_om_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_am_om_nonnull_buckets.keys())\n",
    "tan_am_om_nonnull_api = []\n",
    "input_tokens_tan_am_om_nonnull=0\n",
    "output_tokens_tan_am_om_nonnull=0\n",
    "start_time_tan_am_om = time.time()\n",
    "\n",
    "for key in tan_am_om_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_am_om_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_am_om, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_am_om_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_am_om_nonnull+=input_tokens\n",
    "    output_tokens_tan_am_om_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_am_om = time.time() - start_time_tan_am_om\n",
    "formatted_time_tan_am_om = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_am_om))\n",
    "input_token_cost_tan_am_om = round((0.01/1000) * input_tokens_tan_am_om_nonnull, 2)\n",
    "output_token_cost_tan_am_om = round((0.03/1000) * output_tokens_tan_am_om_nonnull, 2)\n",
    "total_cost_tan_am_om = round(input_token_cost_tan_am_om + output_token_cost_tan_am_om, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_am_om}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_am_om_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_am_om}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_am_om_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_am_om}\")\n",
    "print(f\"Total Cost = {total_cost_tan_am_om}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7a979c4b-e79c-4b02-aa2c-136f8a2669a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:40.368473Z",
     "iopub.status.busy": "2025-06-11T06:55:40.368218Z",
     "iopub.status.idle": "2025-06-11T06:55:40.372274Z",
     "shell.execute_reply": "2025-06-11T06:55:40.371803Z",
     "shell.execute_reply.started": "2025-06-11T06:55:40.368455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_am_om_nonnull_api & convert to DataFrame\n",
    "tan_am_om_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_am_om_nonnull_api\n",
    "]                                  \n",
    "tan_am_om_nonnull_api_cleaned_df = pd.DataFrame(tan_am_om_nonnull_api_cleaned)\n",
    "#tan_am_om_nonnull_api_cleaned_df = pd.DataFrame(tan_am_om_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "96e8dfce-dcc7-4aaa-89d1-22406e79b31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:40.373473Z",
     "iopub.status.busy": "2025-06-11T06:55:40.372959Z",
     "iopub.status.idle": "2025-06-11T06:55:40.380055Z",
     "shell.execute_reply": "2025-06-11T06:55:40.379560Z",
     "shell.execute_reply.started": "2025-06-11T06:55:40.373446Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_am_om_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_am_om_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_am_om_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6414af-fcd2-40b1-a47a-7f732fa70dd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_am_om_nonnull_api_cleaned_df.to_excel(\"tan_am_om_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428fd932-59c1-4e14-9c48-610131635fe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_am_om_nonnull_api_cleaned_df = pd.read_excel(\"tan_am_om_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c5b82-f1d4-43c8-97e3-63bd79f34c94",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_am_om_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "0c71dad8-baf1-4ab6-93d3-4a0418d5dd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:40.381009Z",
     "iopub.status.busy": "2025-06-11T06:55:40.380701Z",
     "iopub.status.idle": "2025-06-11T06:55:40.435894Z",
     "shell.execute_reply": "2025-06-11T06:55:40.435465Z",
     "shell.execute_reply.started": "2025-06-11T06:55:40.380982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_am_om_nonnull_sen_df = pd.DataFrame(processed_data_tan_am_om_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_am_om_nonnull_sen_df = tan_am_om_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_am_om_nonnull_merged_df = pd.concat([combined_df_tan_am_om, tan_am_om_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_am_om_final_sen_df = pd.concat([tan_am_om_nonnull_merged_df,null_dataframes['tan_am_om_null']], ignore_index=True)\n",
    "\n",
    "tan_am_om_final_sen_df_copy = tan_am_om_final_sen_df.copy()\n",
    "tan_am_om_final_sen_df_copy[\"Published At Date\"] = tan_am_om_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_am_om_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_am_om_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bab33-1c61-4380-9d7b-ad0457201139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e38195-59bd-4c22-830e-d506ca17e133",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_atl_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f0798a9a-d112-45e3-a2b4-7f8a1fa2439a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:55:40.437034Z",
     "iopub.status.busy": "2025-06-11T06:55:40.436773Z",
     "iopub.status.idle": "2025-06-11T06:57:49.690362Z",
     "shell.execute_reply": "2025-06-11T06:57:49.689856Z",
     "shell.execute_reply.started": "2025-06-11T06:55:40.437009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [18] Iterations\n",
      "Total Execution Time: 00:02:09\n",
      "Total Input Tokens - 25389\n",
      "Total Input Cost = 0.25\n",
      "Total Output Tokens - 10930\n",
      "Total Output Cost = 0.33\n",
      "Total Cost = 0.58\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_1-4'])/25)+math.ceil(len(tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_5-15'])/25)+math.ceil(len(tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_16-30'])/25)+math.ceil(len(tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_31-60'])/25)+math.ceil(len(tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_61-100'])/25)+math.ceil(len(tan_atl_ga_nonnull_buckets['tan_atl_ga_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_atl_ga_nonnull_buckets.keys())\n",
    "tan_atl_ga_nonnull_api = []\n",
    "input_tokens_tan_atl_ga_nonnull=0\n",
    "output_tokens_tan_atl_ga_nonnull=0\n",
    "start_time_tan_atl_ga = time.time()\n",
    "\n",
    "for key in tan_atl_ga_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_atl_ga_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_atl_ga, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_atl_ga_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_atl_ga_nonnull+=input_tokens\n",
    "    output_tokens_tan_atl_ga_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_atl_ga = time.time() - start_time_tan_atl_ga\n",
    "formatted_time_tan_atl_ga = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_atl_ga))\n",
    "input_token_cost_tan_atl_ga = round((0.01/1000) * input_tokens_tan_atl_ga_nonnull, 2)\n",
    "output_token_cost_tan_atl_ga = round((0.03/1000) * output_tokens_tan_atl_ga_nonnull, 2)\n",
    "total_cost_tan_atl_ga = round(input_token_cost_tan_atl_ga + output_token_cost_tan_atl_ga, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_atl_ga}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_atl_ga_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_atl_ga}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_atl_ga_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_atl_ga}\")\n",
    "print(f\"Total Cost = {total_cost_tan_atl_ga}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "ec129117-fe6b-439a-bffb-072446bddfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:57:49.691259Z",
     "iopub.status.busy": "2025-06-11T06:57:49.691003Z",
     "iopub.status.idle": "2025-06-11T06:57:49.695287Z",
     "shell.execute_reply": "2025-06-11T06:57:49.694762Z",
     "shell.execute_reply.started": "2025-06-11T06:57:49.691234Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_atl_ga_nonnull_api & convert to DataFrame\n",
    "tan_atl_ga_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_atl_ga_nonnull_api\n",
    "]                                  \n",
    "tan_atl_ga_nonnull_api_cleaned_df = pd.DataFrame(tan_atl_ga_nonnull_api_cleaned)\n",
    "#tan_atl_ga_nonnull_api_cleaned_df = pd.DataFrame(tan_atl_ga_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "aa014f9d-bf82-4408-b1a6-2776f3bf63b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:57:49.696619Z",
     "iopub.status.busy": "2025-06-11T06:57:49.695972Z",
     "iopub.status.idle": "2025-06-11T06:57:49.705325Z",
     "shell.execute_reply": "2025-06-11T06:57:49.704848Z",
     "shell.execute_reply.started": "2025-06-11T06:57:49.696589Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_atl_ga_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_atl_ga_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_atl_ga_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc2efe-dc12-447a-a595-1530547ce223",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_atl_ga_nonnull_api_cleaned_df.to_excel(\"tan_atl_ga_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd1267f-21b5-42ac-86a8-749e20a3399f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_atl_ga_nonnull_api_cleaned_df = pd.read_excel(\"tan_atl_ga_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a4e9f0-3e43-433a-aa5b-285d14f8e70f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_atl_ga_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1b98adc6-bee6-4e84-af07-ebb1fe42cfab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:57:49.706246Z",
     "iopub.status.busy": "2025-06-11T06:57:49.705866Z",
     "iopub.status.idle": "2025-06-11T06:57:49.830511Z",
     "shell.execute_reply": "2025-06-11T06:57:49.830067Z",
     "shell.execute_reply.started": "2025-06-11T06:57:49.706220Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_atl_ga_nonnull_sen_df = pd.DataFrame(processed_data_tan_atl_ga_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_atl_ga_nonnull_sen_df = tan_atl_ga_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_atl_ga_nonnull_merged_df = pd.concat([combined_df_tan_atl_ga, tan_atl_ga_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_atl_ga_final_sen_df = pd.concat([tan_atl_ga_nonnull_merged_df,null_dataframes['tan_atl_ga_null']], ignore_index=True)\n",
    "\n",
    "tan_atl_ga_final_sen_df_copy = tan_atl_ga_final_sen_df.copy()\n",
    "tan_atl_ga_final_sen_df_copy[\"Published At Date\"] = tan_atl_ga_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_atl_ga_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_atl_ga_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff30f6-a442-46c8-9007-3b522a7a3497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d7df63-709d-4934-81a3-4a40717c2a5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_fc_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "aec33926-fa7f-4010-a275-31fd78b9c956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:57:49.831532Z",
     "iopub.status.busy": "2025-06-11T06:57:49.831301Z",
     "iopub.status.idle": "2025-06-11T06:58:05.890928Z",
     "shell.execute_reply": "2025-06-11T06:58:05.890397Z",
     "shell.execute_reply.started": "2025-06-11T06:57:49.831512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:16\n",
      "Total Input Tokens - 4137\n",
      "Total Input Cost = 0.04\n",
      "Total Output Tokens - 854\n",
      "Total Output Cost = 0.03\n",
      "Total Cost = 0.07\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_1-4'])/25)+math.ceil(len(tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_5-15'])/25)+math.ceil(len(tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_16-30'])/25)+math.ceil(len(tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_31-60'])/25)+math.ceil(len(tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_61-100'])/25)+math.ceil(len(tan_fc_qa_nonnull_buckets['tan_fc_qa_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_fc_qa_nonnull_buckets.keys())\n",
    "tan_fc_qa_nonnull_api = []\n",
    "input_tokens_tan_fc_qa_nonnull=0\n",
    "output_tokens_tan_fc_qa_nonnull=0\n",
    "start_time_tan_fc_qa = time.time()\n",
    "\n",
    "for key in tan_fc_qa_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_fc_qa_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_fc_qa, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_fc_qa_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_fc_qa_nonnull+=input_tokens\n",
    "    output_tokens_tan_fc_qa_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_fc_qa = time.time() - start_time_tan_fc_qa\n",
    "formatted_time_tan_fc_qa = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_fc_qa))\n",
    "input_token_cost_tan_fc_qa = round((0.01/1000) * input_tokens_tan_fc_qa_nonnull, 2)\n",
    "output_token_cost_tan_fc_qa = round((0.03/1000) * output_tokens_tan_fc_qa_nonnull, 2)\n",
    "total_cost_tan_fc_qa = round(input_token_cost_tan_fc_qa + output_token_cost_tan_fc_qa, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_fc_qa}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_fc_qa_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_fc_qa}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_fc_qa_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_fc_qa}\")\n",
    "print(f\"Total Cost = {total_cost_tan_fc_qa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "85247080-a70a-4f8e-8587-8a10532ab796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:58:05.891744Z",
     "iopub.status.busy": "2025-06-11T06:58:05.891557Z",
     "iopub.status.idle": "2025-06-11T06:58:05.895412Z",
     "shell.execute_reply": "2025-06-11T06:58:05.894929Z",
     "shell.execute_reply.started": "2025-06-11T06:58:05.891727Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_fc_qa_nonnull_api & convert to DataFrame\n",
    "tan_fc_qa_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_fc_qa_nonnull_api\n",
    "]                                  \n",
    "tan_fc_qa_nonnull_api_cleaned_df = pd.DataFrame(tan_fc_qa_nonnull_api_cleaned)\n",
    "#tan_fc_qa_nonnull_api_cleaned_df = pd.DataFrame(tan_fc_qa_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "ff019148-8d24-4bb1-bd07-8d08c2535ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:58:05.896263Z",
     "iopub.status.busy": "2025-06-11T06:58:05.896009Z",
     "iopub.status.idle": "2025-06-11T06:58:05.902619Z",
     "shell.execute_reply": "2025-06-11T06:58:05.902164Z",
     "shell.execute_reply.started": "2025-06-11T06:58:05.896246Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_fc_qa_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_fc_qa_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_fc_qa_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4436f145-8bf4-4472-aa6c-0d64d69445ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fc_qa_nonnull_api_cleaned_df.to_excel(\"tan_fc_qa_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb96344-f197-497d-bdaa-935e12706769",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fc_qa_nonnull_api_cleaned_df = pd.read_excel(\"tan_fc_qa_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe62747-54d6-4d9c-8bd6-758b7141cb6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_fc_qa_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "d8488453-8521-47b7-b6c4-b8f6f52c1510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:58:05.903420Z",
     "iopub.status.busy": "2025-06-11T06:58:05.903207Z",
     "iopub.status.idle": "2025-06-11T06:58:05.945472Z",
     "shell.execute_reply": "2025-06-11T06:58:05.945003Z",
     "shell.execute_reply.started": "2025-06-11T06:58:05.903403Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_fc_qa_nonnull_sen_df = pd.DataFrame(processed_data_tan_fc_qa_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_fc_qa_nonnull_sen_df = tan_fc_qa_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_fc_qa_nonnull_merged_df = pd.concat([combined_df_tan_fc_qa, tan_fc_qa_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_fc_qa_final_sen_df = pd.concat([tan_fc_qa_nonnull_merged_df,null_dataframes['tan_fc_qa_null']], ignore_index=True)\n",
    "\n",
    "tan_fc_qa_final_sen_df_copy = tan_fc_qa_final_sen_df.copy()\n",
    "tan_fc_qa_final_sen_df_copy[\"Published At Date\"] = tan_fc_qa_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_fc_qa_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_fc_qa_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e83a7a-f162-42ae-ab1f-b30139b80a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd5b2b3-22ac-4bf2-af15-568edeb0304d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_gs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "f0968f2b-4e68-4c20-b5b2-bc97855c3029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T06:58:05.946291Z",
     "iopub.status.busy": "2025-06-11T06:58:05.946108Z",
     "iopub.status.idle": "2025-06-11T07:05:25.214589Z",
     "shell.execute_reply": "2025-06-11T07:05:25.214058Z",
     "shell.execute_reply.started": "2025-06-11T06:58:05.946275Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [43] Iterations\n",
      "Total Execution Time: 00:07:19\n",
      "Total Input Tokens - 73367\n",
      "Total Input Cost = 0.73\n",
      "Total Output Tokens - 30483\n",
      "Total Output Cost = 0.91\n",
      "Total Cost = 1.64\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_1-4'])/25)+math.ceil(len(tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_5-15'])/25)+math.ceil(len(tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_16-30'])/25)+math.ceil(len(tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_31-60'])/25)+math.ceil(len(tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_61-100'])/25)+math.ceil(len(tan_gs_db_nonnull_buckets['tan_gs_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_gs_db_nonnull_buckets.keys())\n",
    "tan_gs_db_nonnull_api = []\n",
    "input_tokens_tan_gs_db_nonnull=0\n",
    "output_tokens_tan_gs_db_nonnull=0\n",
    "start_time_tan_gs_db = time.time()\n",
    "\n",
    "for key in tan_gs_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_gs_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_gs_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_gs_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_gs_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_gs_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_gs_db = time.time() - start_time_tan_gs_db\n",
    "formatted_time_tan_gs_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_gs_db))\n",
    "input_token_cost_tan_gs_db = round((0.01/1000) * input_tokens_tan_gs_db_nonnull, 2)\n",
    "output_token_cost_tan_gs_db = round((0.03/1000) * output_tokens_tan_gs_db_nonnull, 2)\n",
    "total_cost_tan_gs_db = round(input_token_cost_tan_gs_db + output_token_cost_tan_gs_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_gs_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_gs_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_gs_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_gs_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_gs_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_gs_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "d6d14686-ddea-47f4-8040-3d24a7459f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:05:25.215871Z",
     "iopub.status.busy": "2025-06-11T07:05:25.215309Z",
     "iopub.status.idle": "2025-06-11T07:05:25.219935Z",
     "shell.execute_reply": "2025-06-11T07:05:25.219448Z",
     "shell.execute_reply.started": "2025-06-11T07:05:25.215839Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_gs_db_nonnull_api & convert to DataFrame\n",
    "tan_gs_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_gs_db_nonnull_api\n",
    "]                                  \n",
    "tan_gs_db_nonnull_api_cleaned_df = pd.DataFrame(tan_gs_db_nonnull_api_cleaned)\n",
    "#tan_gs_db_nonnull_api_cleaned_df = pd.DataFrame(tan_gs_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "fef158f9-ff4e-455b-b92d-77dc1a4fb8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:05:25.220866Z",
     "iopub.status.busy": "2025-06-11T07:05:25.220551Z",
     "iopub.status.idle": "2025-06-11T07:05:25.235570Z",
     "shell.execute_reply": "2025-06-11T07:05:25.235077Z",
     "shell.execute_reply.started": "2025-06-11T07:05:25.220838Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_gs_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_gs_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_gs_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782f44c-1f06-47a3-9b4a-0fd09ef6595a",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_gs_db_nonnull_api_cleaned_df.to_excel(\"tan_gs_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ec6fa-5a52-4b24-a8d6-691a4ae7941b",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_gs_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_gs_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497515fe-1c32-4b75-bd48-6eb90c2160e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_gs_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "925c961a-c86d-48bb-a5b0-638741477591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:05:25.236405Z",
     "iopub.status.busy": "2025-06-11T07:05:25.236177Z",
     "iopub.status.idle": "2025-06-11T07:05:25.551171Z",
     "shell.execute_reply": "2025-06-11T07:05:25.550668Z",
     "shell.execute_reply.started": "2025-06-11T07:05:25.236382Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_gs_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_gs_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_gs_db_nonnull_sen_df = tan_gs_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_gs_db_nonnull_merged_df = pd.concat([combined_df_tan_gs_db, tan_gs_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_gs_db_final_sen_df = pd.concat([tan_gs_db_nonnull_merged_df,null_dataframes['tan_gs_db_null']], ignore_index=True)\n",
    "\n",
    "tan_gs_db_final_sen_df_copy = tan_gs_db_final_sen_df.copy()\n",
    "tan_gs_db_final_sen_df_copy[\"Published At Date\"] = tan_gs_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_gs_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_gs_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a5c9a-9b6c-433d-bbff-81a09230b676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19be231a-c5d7-40b4-849d-62c501215774",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_lul_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "baaaebd1-9caf-486d-a0a3-3279be61e714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:05:25.552378Z",
     "iopub.status.busy": "2025-06-11T07:05:25.552040Z",
     "iopub.status.idle": "2025-06-11T07:06:21.679302Z",
     "shell.execute_reply": "2025-06-11T07:06:21.678739Z",
     "shell.execute_reply.started": "2025-06-11T07:05:25.552346Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [11] Iterations\n",
      "Total Execution Time: 00:00:56\n",
      "Total Input Tokens - 12367\n",
      "Total Input Cost = 0.12\n",
      "Total Output Tokens - 4177\n",
      "Total Output Cost = 0.13\n",
      "Total Cost = 0.25\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_1-4'])/25)+math.ceil(len(tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_5-15'])/25)+math.ceil(len(tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_16-30'])/25)+math.ceil(len(tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_31-60'])/25)+math.ceil(len(tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_61-100'])/25)+math.ceil(len(tan_lul_qa_nonnull_buckets['tan_lul_qa_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_lul_qa_nonnull_buckets.keys())\n",
    "tan_lul_qa_nonnull_api = []\n",
    "input_tokens_tan_lul_qa_nonnull=0\n",
    "output_tokens_tan_lul_qa_nonnull=0\n",
    "start_time_tan_lul_qa = time.time()\n",
    "\n",
    "for key in tan_lul_qa_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_lul_qa_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_lul_qa, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_lul_qa_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_lul_qa_nonnull+=input_tokens\n",
    "    output_tokens_tan_lul_qa_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_lul_qa = time.time() - start_time_tan_lul_qa\n",
    "formatted_time_tan_lul_qa = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_lul_qa))\n",
    "input_token_cost_tan_lul_qa = round((0.01/1000) * input_tokens_tan_lul_qa_nonnull, 2)\n",
    "output_token_cost_tan_lul_qa = round((0.03/1000) * output_tokens_tan_lul_qa_nonnull, 2)\n",
    "total_cost_tan_lul_qa = round(input_token_cost_tan_lul_qa + output_token_cost_tan_lul_qa, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_lul_qa}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_lul_qa_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_lul_qa}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_lul_qa_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_lul_qa}\")\n",
    "print(f\"Total Cost = {total_cost_tan_lul_qa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "79b6d108-581f-4652-b879-89b5ac8c318d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:21.680411Z",
     "iopub.status.busy": "2025-06-11T07:06:21.680041Z",
     "iopub.status.idle": "2025-06-11T07:06:21.684082Z",
     "shell.execute_reply": "2025-06-11T07:06:21.683562Z",
     "shell.execute_reply.started": "2025-06-11T07:06:21.680381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_lul_qa_nonnull_api & convert to DataFrame\n",
    "tan_lul_qa_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_lul_qa_nonnull_api\n",
    "]                                  \n",
    "tan_lul_qa_nonnull_api_cleaned_df = pd.DataFrame(tan_lul_qa_nonnull_api_cleaned)\n",
    "#tan_lul_qa_nonnull_api_cleaned_df = pd.DataFrame(tan_lul_qa_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "024990da-fca8-4f58-9ce1-0a3ba1f27278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:21.684936Z",
     "iopub.status.busy": "2025-06-11T07:06:21.684686Z",
     "iopub.status.idle": "2025-06-11T07:06:21.692315Z",
     "shell.execute_reply": "2025-06-11T07:06:21.691803Z",
     "shell.execute_reply.started": "2025-06-11T07:06:21.684910Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_lul_qa_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_lul_qa_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_lul_qa_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc0446-2fe4-4348-a423-3f451168b88f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_lul_qa_nonnull_api_cleaned_df.to_excel(\"tan_lul_qa_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea434f7-f107-43bc-94f7-e974e9f7cb2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_lul_qa_nonnull_api_cleaned_df = pd.read_excel(\"tan_lul_qa_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b3247-90ff-43c0-ba8c-704bdfe6b3bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_lul_qa_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "b9d108f3-6b90-43b7-9e48-7980b0ddfe91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:21.693163Z",
     "iopub.status.busy": "2025-06-11T07:06:21.692888Z",
     "iopub.status.idle": "2025-06-11T07:06:21.764617Z",
     "shell.execute_reply": "2025-06-11T07:06:21.764158Z",
     "shell.execute_reply.started": "2025-06-11T07:06:21.693144Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_lul_qa_nonnull_sen_df = pd.DataFrame(processed_data_tan_lul_qa_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_lul_qa_nonnull_sen_df = tan_lul_qa_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_lul_qa_nonnull_merged_df = pd.concat([combined_df_tan_lul_qa, tan_lul_qa_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_lul_qa_final_sen_df = pd.concat([tan_lul_qa_nonnull_merged_df,null_dataframes['tan_lul_qa_null']], ignore_index=True)\n",
    "\n",
    "tan_lul_qa_final_sen_df_copy = tan_lul_qa_final_sen_df.copy()\n",
    "tan_lul_qa_final_sen_df_copy[\"Published At Date\"] = tan_lul_qa_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_lul_qa_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_lul_qa_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16895284-1640-4318-8efd-1d42554b842e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba407965-b7a2-4ee9-9b83-bc5ca099bf17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_mank_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "2901a89e-f672-4855-9fe9-9911ea179b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:21.765804Z",
     "iopub.status.busy": "2025-06-11T07:06:21.765410Z",
     "iopub.status.idle": "2025-06-11T07:06:36.824196Z",
     "shell.execute_reply": "2025-06-11T07:06:36.823650Z",
     "shell.execute_reply.started": "2025-06-11T07:06:21.765768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [5] Iterations\n",
      "Total Execution Time: 00:00:15\n",
      "Total Input Tokens - 4649\n",
      "Total Input Cost = 0.05\n",
      "Total Output Tokens - 897\n",
      "Total Output Cost = 0.03\n",
      "Total Cost = 0.08\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_1-4'])/25)+math.ceil(len(tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_5-15'])/25)+math.ceil(len(tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_16-30'])/25)+math.ceil(len(tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_31-60'])/25)+math.ceil(len(tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_61-100'])/25)+math.ceil(len(tan_mank_db_nonnull_buckets['tan_mank_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_mank_db_nonnull_buckets.keys())\n",
    "tan_mank_db_nonnull_api = []\n",
    "input_tokens_tan_mank_db_nonnull=0\n",
    "output_tokens_tan_mank_db_nonnull=0\n",
    "start_time_tan_mank_db = time.time()\n",
    "\n",
    "for key in tan_mank_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_mank_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_mank_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_mank_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_mank_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_mank_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_mank_db = time.time() - start_time_tan_mank_db\n",
    "formatted_time_tan_mank_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_mank_db))\n",
    "input_token_cost_tan_mank_db = round((0.01/1000) * input_tokens_tan_mank_db_nonnull, 2)\n",
    "output_token_cost_tan_mank_db = round((0.03/1000) * output_tokens_tan_mank_db_nonnull, 2)\n",
    "total_cost_tan_mank_db = round(input_token_cost_tan_mank_db + output_token_cost_tan_mank_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_mank_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_mank_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_mank_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_mank_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_mank_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_mank_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5a306681-d249-4627-94a2-ec7fb8888eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:36.825518Z",
     "iopub.status.busy": "2025-06-11T07:06:36.824941Z",
     "iopub.status.idle": "2025-06-11T07:06:36.828923Z",
     "shell.execute_reply": "2025-06-11T07:06:36.828433Z",
     "shell.execute_reply.started": "2025-06-11T07:06:36.825496Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_mank_db_nonnull_api & convert to DataFrame\n",
    "tan_mank_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_mank_db_nonnull_api\n",
    "]                                  \n",
    "tan_mank_db_nonnull_api_cleaned_df = pd.DataFrame(tan_mank_db_nonnull_api_cleaned)\n",
    "#tan_mank_db_nonnull_api_cleaned_df = pd.DataFrame(tan_mank_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "739a5108-6685-4967-b988-f263e39d945e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:36.829788Z",
     "iopub.status.busy": "2025-06-11T07:06:36.829531Z",
     "iopub.status.idle": "2025-06-11T07:06:36.836088Z",
     "shell.execute_reply": "2025-06-11T07:06:36.835598Z",
     "shell.execute_reply.started": "2025-06-11T07:06:36.829764Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_mank_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_mank_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_mank_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0bbcf-180f-4281-889b-601245b0b042",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_mank_db_nonnull_api_cleaned_df.to_excel(\"tan_mank_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add12eca-79be-49c1-82d2-d08608a2f2c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_mank_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_mank_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca6837-4029-496a-bc76-c74287c76fd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_mank_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "cb664984-0002-487f-8ecc-dd2de2482825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:36.836886Z",
     "iopub.status.busy": "2025-06-11T07:06:36.836643Z",
     "iopub.status.idle": "2025-06-11T07:06:36.877323Z",
     "shell.execute_reply": "2025-06-11T07:06:36.876840Z",
     "shell.execute_reply.started": "2025-06-11T07:06:36.836869Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_mank_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_mank_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_mank_db_nonnull_sen_df = tan_mank_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_mank_db_nonnull_merged_df = pd.concat([combined_df_tan_mank_db, tan_mank_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_mank_db_final_sen_df = pd.concat([tan_mank_db_nonnull_merged_df,null_dataframes['tan_mank_db_null']], ignore_index=True)\n",
    "\n",
    "tan_mank_db_final_sen_df_copy = tan_mank_db_final_sen_df.copy()\n",
    "tan_mank_db_final_sen_df_copy[\"Published At Date\"] = tan_mank_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_mank_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_mank_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7a1d1-511b-4685-b29e-3c2bc47138b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7680707-17ac-4052-8c46-b97ff03643e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_rol_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ae64f2dc-0e78-4174-bf5b-801a58f2516f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:06:36.878320Z",
     "iopub.status.busy": "2025-06-11T07:06:36.878026Z",
     "iopub.status.idle": "2025-06-11T07:07:56.549432Z",
     "shell.execute_reply": "2025-06-11T07:07:56.548870Z",
     "shell.execute_reply.started": "2025-06-11T07:06:36.878302Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [11] Iterations\n",
      "Total Execution Time: 00:01:19\n",
      "Total Input Tokens - 17087\n",
      "Total Input Cost = 0.17\n",
      "Total Output Tokens - 6736\n",
      "Total Output Cost = 0.2\n",
      "Total Cost = 0.37\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_1-4'])/25)+math.ceil(len(tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_5-15'])/25)+math.ceil(len(tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_16-30'])/25)+math.ceil(len(tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_31-60'])/25)+math.ceil(len(tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_61-100'])/25)+math.ceil(len(tan_rol_sh_nonnull_buckets['tan_rol_sh_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_rol_sh_nonnull_buckets.keys())\n",
    "tan_rol_sh_nonnull_api = []\n",
    "input_tokens_tan_rol_sh_nonnull=0\n",
    "output_tokens_tan_rol_sh_nonnull=0\n",
    "start_time_tan_rol_sh = time.time()\n",
    "\n",
    "for key in tan_rol_sh_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_rol_sh_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_rol_sh, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_rol_sh_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_rol_sh_nonnull+=input_tokens\n",
    "    output_tokens_tan_rol_sh_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_rol_sh = time.time() - start_time_tan_rol_sh\n",
    "formatted_time_tan_rol_sh = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_rol_sh))\n",
    "input_token_cost_tan_rol_sh = round((0.01/1000) * input_tokens_tan_rol_sh_nonnull, 2)\n",
    "output_token_cost_tan_rol_sh = round((0.03/1000) * output_tokens_tan_rol_sh_nonnull, 2)\n",
    "total_cost_tan_rol_sh = round(input_token_cost_tan_rol_sh + output_token_cost_tan_rol_sh, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_rol_sh}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_rol_sh_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_rol_sh}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_rol_sh_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_rol_sh}\")\n",
    "print(f\"Total Cost = {total_cost_tan_rol_sh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "d782c092-b007-4cba-bf1e-07a9ca3aefbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:07:56.550431Z",
     "iopub.status.busy": "2025-06-11T07:07:56.550152Z",
     "iopub.status.idle": "2025-06-11T07:07:56.554356Z",
     "shell.execute_reply": "2025-06-11T07:07:56.553869Z",
     "shell.execute_reply.started": "2025-06-11T07:07:56.550405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_rol_sh_nonnull_api & convert to DataFrame\n",
    "tan_rol_sh_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_rol_sh_nonnull_api\n",
    "]                                  \n",
    "tan_rol_sh_nonnull_api_cleaned_df = pd.DataFrame(tan_rol_sh_nonnull_api_cleaned)\n",
    "#tan_rol_sh_nonnull_api_cleaned_df = pd.DataFrame(tan_rol_sh_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "040a56e9-436d-4145-a0ef-423e5d182588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:07:56.555282Z",
     "iopub.status.busy": "2025-06-11T07:07:56.555099Z",
     "iopub.status.idle": "2025-06-11T07:07:56.562950Z",
     "shell.execute_reply": "2025-06-11T07:07:56.562425Z",
     "shell.execute_reply.started": "2025-06-11T07:07:56.555266Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_rol_sh_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_rol_sh_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_rol_sh_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb0107-8236-49e6-be13-b46b1a8a1fdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_rol_sh_nonnull_api_cleaned_df.to_excel(\"tan_rol_sh_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417a2c3-59f2-4e70-bf21-3c62611acac4",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_rol_sh_nonnull_api_cleaned_df = pd.read_excel(\"tan_rol_sh_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b046aefd-c200-4f6b-ba9b-cf050b62cf2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_rol_sh_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "dba88388-5d91-4bb7-a587-c342f92a3ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:07:56.563991Z",
     "iopub.status.busy": "2025-06-11T07:07:56.563687Z",
     "iopub.status.idle": "2025-06-11T07:07:56.652963Z",
     "shell.execute_reply": "2025-06-11T07:07:56.652423Z",
     "shell.execute_reply.started": "2025-06-11T07:07:56.563957Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_rol_sh_nonnull_sen_df = pd.DataFrame(processed_data_tan_rol_sh_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_rol_sh_nonnull_sen_df = tan_rol_sh_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_rol_sh_nonnull_merged_df = pd.concat([combined_df_tan_rol_sh, tan_rol_sh_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_rol_sh_final_sen_df = pd.concat([tan_rol_sh_nonnull_merged_df,null_dataframes['tan_rol_sh_null']], ignore_index=True)\n",
    "\n",
    "tan_rol_sh_final_sen_df_copy = tan_rol_sh_final_sen_df.copy()\n",
    "tan_rol_sh_final_sen_df_copy[\"Published At Date\"] = tan_rol_sh_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_rol_sh_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_rol_sh_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ddca9-9759-472c-82c2-ed775696d2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad6f976a-c0e5-47c2-b646-b6c41f209c30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_rse_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "53cf3eb2-b2e6-4fc1-acf8-240deec1b24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:07:56.654238Z",
     "iopub.status.busy": "2025-06-11T07:07:56.653727Z",
     "iopub.status.idle": "2025-06-11T07:08:53.283632Z",
     "shell.execute_reply": "2025-06-11T07:08:53.283063Z",
     "shell.execute_reply.started": "2025-06-11T07:07:56.654210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [9] Iterations\n",
      "Total Execution Time: 00:00:56\n",
      "Total Input Tokens - 12207\n",
      "Total Input Cost = 0.12\n",
      "Total Output Tokens - 4070\n",
      "Total Output Cost = 0.12\n",
      "Total Cost = 0.24\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_1-4'])/25)+math.ceil(len(tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_5-15'])/25)+math.ceil(len(tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_16-30'])/25)+math.ceil(len(tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_31-60'])/25)+math.ceil(len(tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_61-100'])/25)+math.ceil(len(tan_rse_wa_nonnull_buckets['tan_rse_wa_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_rse_wa_nonnull_buckets.keys())\n",
    "tan_rse_wa_nonnull_api = []\n",
    "input_tokens_tan_rse_wa_nonnull=0\n",
    "output_tokens_tan_rse_wa_nonnull=0\n",
    "start_time_tan_rse_wa = time.time()\n",
    "\n",
    "for key in tan_rse_wa_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_rse_wa_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_rse_wa, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_rse_wa_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_rse_wa_nonnull+=input_tokens\n",
    "    output_tokens_tan_rse_wa_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_rse_wa = time.time() - start_time_tan_rse_wa\n",
    "formatted_time_tan_rse_wa = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_rse_wa))\n",
    "input_token_cost_tan_rse_wa = round((0.01/1000) * input_tokens_tan_rse_wa_nonnull, 2)\n",
    "output_token_cost_tan_rse_wa = round((0.03/1000) * output_tokens_tan_rse_wa_nonnull, 2)\n",
    "total_cost_tan_rse_wa = round(input_token_cost_tan_rse_wa + output_token_cost_tan_rse_wa, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_rse_wa}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_rse_wa_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_rse_wa}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_rse_wa_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_rse_wa}\")\n",
    "print(f\"Total Cost = {total_cost_tan_rse_wa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a6e2e17a-7c52-4992-a938-0eb123da97a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:08:53.284934Z",
     "iopub.status.busy": "2025-06-11T07:08:53.284391Z",
     "iopub.status.idle": "2025-06-11T07:08:53.288655Z",
     "shell.execute_reply": "2025-06-11T07:08:53.288135Z",
     "shell.execute_reply.started": "2025-06-11T07:08:53.284910Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_rse_wa_nonnull_api & convert to DataFrame\n",
    "tan_rse_wa_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_rse_wa_nonnull_api\n",
    "]                                  \n",
    "tan_rse_wa_nonnull_api_cleaned_df = pd.DataFrame(tan_rse_wa_nonnull_api_cleaned)\n",
    "#tan_rse_wa_nonnull_api_cleaned_df = pd.DataFrame(tan_rse_wa_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7f783e27-44a7-42f2-b515-f5b5a995e7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:08:53.289551Z",
     "iopub.status.busy": "2025-06-11T07:08:53.289315Z",
     "iopub.status.idle": "2025-06-11T07:08:53.296775Z",
     "shell.execute_reply": "2025-06-11T07:08:53.296342Z",
     "shell.execute_reply.started": "2025-06-11T07:08:53.289533Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_rse_wa_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_rse_wa_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_rse_wa_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc9a98-3d8c-4e00-8735-64b55d2f5855",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_rse_wa_nonnull_api_cleaned_df.to_excel(\"tan_rse_wa_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42185a8-7b89-4a5e-91a5-92c8c7f22831",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_rse_wa_nonnull_api_cleaned_df = pd.read_excel(\"tan_rse_wa_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9b441-5b71-41a9-9093-8d57fafa903c",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_rse_wa_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d5518db8-a2e2-4c84-90ad-b37cdf67675c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:08:53.297734Z",
     "iopub.status.busy": "2025-06-11T07:08:53.297383Z",
     "iopub.status.idle": "2025-06-11T07:08:53.359898Z",
     "shell.execute_reply": "2025-06-11T07:08:53.359351Z",
     "shell.execute_reply.started": "2025-06-11T07:08:53.297716Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_rse_wa_nonnull_sen_df = pd.DataFrame(processed_data_tan_rse_wa_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_rse_wa_nonnull_sen_df = tan_rse_wa_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_rse_wa_nonnull_merged_df = pd.concat([combined_df_tan_rse_wa, tan_rse_wa_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_rse_wa_final_sen_df = pd.concat([tan_rse_wa_nonnull_merged_df,null_dataframes['tan_rse_wa_null']], ignore_index=True)\n",
    "\n",
    "tan_rse_wa_final_sen_df_copy = tan_rse_wa_final_sen_df.copy()\n",
    "tan_rse_wa_final_sen_df_copy[\"Published At Date\"] = tan_rse_wa_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_rse_wa_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_rse_wa_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f8206-41bd-49ef-b3c3-a81c15078797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66d4e3a7-5cdc-40e7-b6e3-7cce0a97e4c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_sc_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f2cb4777-5b65-4974-bb7e-c0a75c7e54d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:08:53.360912Z",
     "iopub.status.busy": "2025-06-11T07:08:53.360639Z",
     "iopub.status.idle": "2025-06-11T07:09:21.443831Z",
     "shell.execute_reply": "2025-06-11T07:09:21.443321Z",
     "shell.execute_reply.started": "2025-06-11T07:08:53.360889Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [6] Iterations\n",
      "Total Execution Time: 00:00:28\n",
      "Total Input Tokens - 8090\n",
      "Total Input Cost = 0.08\n",
      "Total Output Tokens - 1981\n",
      "Total Output Cost = 0.06\n",
      "Total Cost = 0.14\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_1-4'])/25)+math.ceil(len(tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_5-15'])/25)+math.ceil(len(tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_16-30'])/25)+math.ceil(len(tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_31-60'])/25)+math.ceil(len(tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_61-100'])/25)+math.ceil(len(tan_sc_ca_nonnull_buckets['tan_sc_ca_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_sc_ca_nonnull_buckets.keys())\n",
    "tan_sc_ca_nonnull_api = []\n",
    "input_tokens_tan_sc_ca_nonnull=0\n",
    "output_tokens_tan_sc_ca_nonnull=0\n",
    "start_time_tan_sc_ca = time.time()\n",
    "\n",
    "for key in tan_sc_ca_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_sc_ca_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_sc_ca, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_sc_ca_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_sc_ca_nonnull+=input_tokens\n",
    "    output_tokens_tan_sc_ca_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_sc_ca = time.time() - start_time_tan_sc_ca\n",
    "formatted_time_tan_sc_ca = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_sc_ca))\n",
    "input_token_cost_tan_sc_ca = round((0.01/1000) * input_tokens_tan_sc_ca_nonnull, 2)\n",
    "output_token_cost_tan_sc_ca = round((0.03/1000) * output_tokens_tan_sc_ca_nonnull, 2)\n",
    "total_cost_tan_sc_ca = round(input_token_cost_tan_sc_ca + output_token_cost_tan_sc_ca, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_sc_ca}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_sc_ca_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_sc_ca}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_sc_ca_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_sc_ca}\")\n",
    "print(f\"Total Cost = {total_cost_tan_sc_ca}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ba1ec91a-1aa2-49dc-b5f2-3df7c6b4e2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:09:21.444937Z",
     "iopub.status.busy": "2025-06-11T07:09:21.444576Z",
     "iopub.status.idle": "2025-06-11T07:09:21.448851Z",
     "shell.execute_reply": "2025-06-11T07:09:21.448313Z",
     "shell.execute_reply.started": "2025-06-11T07:09:21.444906Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_sc_ca_nonnull_api & convert to DataFrame\n",
    "tan_sc_ca_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_sc_ca_nonnull_api\n",
    "]                                  \n",
    "tan_sc_ca_nonnull_api_cleaned_df = pd.DataFrame(tan_sc_ca_nonnull_api_cleaned)\n",
    "#tan_sc_ca_nonnull_api_cleaned_df = pd.DataFrame(tan_sc_ca_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "1c684969-919d-451f-af3d-46e1ef0b2b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:09:21.449924Z",
     "iopub.status.busy": "2025-06-11T07:09:21.449575Z",
     "iopub.status.idle": "2025-06-11T07:09:21.456473Z",
     "shell.execute_reply": "2025-06-11T07:09:21.455992Z",
     "shell.execute_reply.started": "2025-06-11T07:09:21.449898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_sc_ca_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_sc_ca_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_sc_ca_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cccf23-f817-41d6-abd4-6fb62b4d9bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sc_ca_nonnull_api_cleaned_df.to_excel(\"tan_sc_ca_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239f432-d38e-4906-a485-543bc91500a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sc_ca_nonnull_api_cleaned_df = pd.read_excel(\"tan_sc_ca_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feaed23-8dca-4191-9e54-5aa5423f92c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sc_ca_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "e6d6029e-eb71-46c3-88cc-b4f87e797ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:09:21.457402Z",
     "iopub.status.busy": "2025-06-11T07:09:21.457187Z",
     "iopub.status.idle": "2025-06-11T07:09:21.507240Z",
     "shell.execute_reply": "2025-06-11T07:09:21.506747Z",
     "shell.execute_reply.started": "2025-06-11T07:09:21.457386Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_sc_ca_nonnull_sen_df = pd.DataFrame(processed_data_tan_sc_ca_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_sc_ca_nonnull_sen_df = tan_sc_ca_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_sc_ca_nonnull_merged_df = pd.concat([combined_df_tan_sc_ca, tan_sc_ca_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_sc_ca_final_sen_df = pd.concat([tan_sc_ca_nonnull_merged_df,null_dataframes['tan_sc_ca_null']], ignore_index=True)\n",
    "\n",
    "tan_sc_ca_final_sen_df_copy = tan_sc_ca_final_sen_df.copy()\n",
    "tan_sc_ca_final_sen_df_copy[\"Published At Date\"] = tan_sc_ca_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_sc_ca_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_sc_ca_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52d906-20f2-4f18-af39-3ff5b3d6fa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc31cb2d-70c6-46da-a8e1-fdde675672f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_sc_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "a2ba8a5a-de87-4473-a546-cbfdbfc9b851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:09:21.508237Z",
     "iopub.status.busy": "2025-06-11T07:09:21.507907Z",
     "iopub.status.idle": "2025-06-11T07:11:29.258231Z",
     "shell.execute_reply": "2025-06-11T07:11:29.257677Z",
     "shell.execute_reply.started": "2025-06-11T07:09:21.508208Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [17] Iterations\n",
      "Total Execution Time: 00:02:07\n",
      "Total Input Tokens - 23068\n",
      "Total Input Cost = 0.23\n",
      "Total Output Tokens - 9282\n",
      "Total Output Cost = 0.28\n",
      "Total Cost = 0.51\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_1-4'])/25)+math.ceil(len(tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_5-15'])/25)+math.ceil(len(tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_16-30'])/25)+math.ceil(len(tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_31-60'])/25)+math.ceil(len(tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_61-100'])/25)+math.ceil(len(tan_sc_sh_nonnull_buckets['tan_sc_sh_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_sc_sh_nonnull_buckets.keys())\n",
    "tan_sc_sh_nonnull_api = []\n",
    "input_tokens_tan_sc_sh_nonnull=0\n",
    "output_tokens_tan_sc_sh_nonnull=0\n",
    "start_time_tan_sc_sh = time.time()\n",
    "\n",
    "for key in tan_sc_sh_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_sc_sh_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_sc_sh, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_sc_sh_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_sc_sh_nonnull+=input_tokens\n",
    "    output_tokens_tan_sc_sh_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_sc_sh = time.time() - start_time_tan_sc_sh\n",
    "formatted_time_tan_sc_sh = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_sc_sh))\n",
    "input_token_cost_tan_sc_sh = round((0.01/1000) * input_tokens_tan_sc_sh_nonnull, 2)\n",
    "output_token_cost_tan_sc_sh = round((0.03/1000) * output_tokens_tan_sc_sh_nonnull, 2)\n",
    "total_cost_tan_sc_sh = round(input_token_cost_tan_sc_sh + output_token_cost_tan_sc_sh, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_sc_sh}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_sc_sh_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_sc_sh}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_sc_sh_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_sc_sh}\")\n",
    "print(f\"Total Cost = {total_cost_tan_sc_sh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6b305f30-e098-4e87-8748-e692bfd13b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:11:29.259279Z",
     "iopub.status.busy": "2025-06-11T07:11:29.259013Z",
     "iopub.status.idle": "2025-06-11T07:11:29.263312Z",
     "shell.execute_reply": "2025-06-11T07:11:29.262816Z",
     "shell.execute_reply.started": "2025-06-11T07:11:29.259258Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_sc_sh_nonnull_api & convert to DataFrame\n",
    "tan_sc_sh_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_sc_sh_nonnull_api\n",
    "]                                  \n",
    "tan_sc_sh_nonnull_api_cleaned_df = pd.DataFrame(tan_sc_sh_nonnull_api_cleaned)\n",
    "#tan_sc_sh_nonnull_api_cleaned_df = pd.DataFrame(tan_sc_sh_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "c697894b-f0a9-41e4-a359-679cf46b6a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:11:29.264192Z",
     "iopub.status.busy": "2025-06-11T07:11:29.263906Z",
     "iopub.status.idle": "2025-06-11T07:11:29.272770Z",
     "shell.execute_reply": "2025-06-11T07:11:29.272289Z",
     "shell.execute_reply.started": "2025-06-11T07:11:29.264158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_sc_sh_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_sc_sh_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_sc_sh_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a55b3-5d96-4036-8d11-c1ad3b4a23a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sc_sh_nonnull_api_cleaned_df.to_excel(\"tan_sc_sh_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dabbfb-7e25-40f2-925a-e00095d15105",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sc_sh_nonnull_api_cleaned_df = pd.read_excel(\"tan_sc_sh_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bdeee-0cef-4dac-9fea-fb5095b396a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_sc_sh_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "93f5b582-3639-49e0-bbef-0be692575bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:11:29.273742Z",
     "iopub.status.busy": "2025-06-11T07:11:29.273439Z",
     "iopub.status.idle": "2025-06-11T07:11:29.384661Z",
     "shell.execute_reply": "2025-06-11T07:11:29.384203Z",
     "shell.execute_reply.started": "2025-06-11T07:11:29.273718Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_sc_sh_nonnull_sen_df = pd.DataFrame(processed_data_tan_sc_sh_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_sc_sh_nonnull_sen_df = tan_sc_sh_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_sc_sh_nonnull_merged_df = pd.concat([combined_df_tan_sc_sh, tan_sc_sh_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_sc_sh_final_sen_df = pd.concat([tan_sc_sh_nonnull_merged_df,null_dataframes['tan_sc_sh_null']], ignore_index=True)\n",
    "\n",
    "tan_sc_sh_final_sen_df_copy = tan_sc_sh_final_sen_df.copy()\n",
    "tan_sc_sh_final_sen_df_copy[\"Published At Date\"] = tan_sc_sh_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_sc_sh_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_sc_sh_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3df598-ff41-4c56-9f97-3539fe2aa30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40d58b10-ccfd-47e9-b8a1-e2977fc46264",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_taj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "964ca3e6-a83b-451c-a265-76c9da62e3a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:11:29.385559Z",
     "iopub.status.busy": "2025-06-11T07:11:29.385315Z",
     "iopub.status.idle": "2025-06-11T07:12:23.507485Z",
     "shell.execute_reply": "2025-06-11T07:12:23.506935Z",
     "shell.execute_reply.started": "2025-06-11T07:11:29.385541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed [10] Iterations\n",
      "Total Execution Time: 00:00:54\n",
      "Total Input Tokens - 10253\n",
      "Total Input Cost = 0.1\n",
      "Total Output Tokens - 4116\n",
      "Total Output Cost = 0.12\n",
      "Total Cost = 0.22\n"
     ]
    }
   ],
   "source": [
    "batch_counter = [0]\n",
    "total_batches = math.ceil(len(tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_1-4'])/25)+math.ceil(len(tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_5-15'])/25)+math.ceil(len(tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_16-30'])/25)+math.ceil(len(tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_31-60'])/25)+math.ceil(len(tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_61-100'])/25)+math.ceil(len(tan_taj_db_nonnull_buckets['tan_taj_db_nonnull_greater_100'])/25)\n",
    "key_counter = 0\n",
    "total_keys=len(tan_taj_db_nonnull_buckets.keys())\n",
    "tan_taj_db_nonnull_api = []\n",
    "input_tokens_tan_taj_db_nonnull=0\n",
    "output_tokens_tan_taj_db_nonnull=0\n",
    "start_time_tan_taj_db = time.time()\n",
    "\n",
    "for key in tan_taj_db_nonnull_buckets.keys():\n",
    "    key_counter+=1\n",
    "    current_df = tan_taj_db_nonnull_buckets[key][['Name', 'review_text']]\n",
    "    counter = [0]\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "        \n",
    "    # Threading setup\n",
    "    total_iterations = math.ceil(len(current_df) / 25)\n",
    "    stop_event = threading.Event()\n",
    "    message_thread = threading.Thread(target=print_dynamic_message, args=(batch_counter,key_counter,counter,total_batches,total_keys, total_iterations,start_time_tan_taj_db, stop_event))\n",
    "    message_thread.start()\n",
    "\n",
    "    for start in range(0, len(current_df), 25):\n",
    "        clear_output(wait=True)\n",
    "        counter[0] += 1\n",
    "        batch_counter[0] += 1\n",
    "        end = start + 25\n",
    "        result, it, ot = score_sentiments_jul(current_df[start:end])\n",
    "        tan_taj_db_nonnull_api.append(result)\n",
    "        input_tokens += it\n",
    "        output_tokens += ot\n",
    "\n",
    "    # Stopping the dynamic message thread\n",
    "    stop_event.set()\n",
    "    message_thread.join()    \n",
    "    input_tokens_tan_taj_db_nonnull+=input_tokens\n",
    "    output_tokens_tan_taj_db_nonnull+=output_tokens\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "overall_execution_time_tan_taj_db = time.time() - start_time_tan_taj_db\n",
    "formatted_time_tan_taj_db = time.strftime('%H:%M:%S', time.gmtime(overall_execution_time_tan_taj_db))\n",
    "input_token_cost_tan_taj_db = round((0.01/1000) * input_tokens_tan_taj_db_nonnull, 2)\n",
    "output_token_cost_tan_taj_db = round((0.03/1000) * output_tokens_tan_taj_db_nonnull, 2)\n",
    "total_cost_tan_taj_db = round(input_token_cost_tan_taj_db + output_token_cost_tan_taj_db, 2)    \n",
    "    \n",
    "print(f\"Executed {batch_counter} Iterations\")\n",
    "print(f\"Total Execution Time: {formatted_time_tan_taj_db}\")\n",
    "print(f\"Total Input Tokens - {input_tokens_tan_taj_db_nonnull}\")\n",
    "print(f\"Total Input Cost = {input_token_cost_tan_taj_db}\")\n",
    "print(f\"Total Output Tokens - {output_tokens_tan_taj_db_nonnull}\")\n",
    "print(f\"Total Output Cost = {output_token_cost_tan_taj_db}\")\n",
    "print(f\"Total Cost = {total_cost_tan_taj_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "22a4dc30-f004-4e1f-a460-90225e2549f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:12:23.508892Z",
     "iopub.status.busy": "2025-06-11T07:12:23.508340Z",
     "iopub.status.idle": "2025-06-11T07:12:23.512586Z",
     "shell.execute_reply": "2025-06-11T07:12:23.512113Z",
     "shell.execute_reply.started": "2025-06-11T07:12:23.508868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove \"```json\" and \"```\" from each string in tan_taj_db_nonnull_api & convert to DataFrame\n",
    "tan_taj_db_nonnull_api_cleaned = [\n",
    "    s.replace(\"```json\", \"\")\n",
    "     .replace(\"```\", \"\")\n",
    "     .replace(\"[]\", \"[{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\"}]\")\n",
    "    for s in tan_taj_db_nonnull_api\n",
    "]                                  \n",
    "tan_taj_db_nonnull_api_cleaned_df = pd.DataFrame(tan_taj_db_nonnull_api_cleaned)\n",
    "#tan_taj_db_nonnull_api_cleaned_df = pd.DataFrame(tan_taj_db_nonnull_api)\n",
    "column_names2 = ['Trust',\n",
    "                    'Store Experience',\n",
    "                    'Store Staff',\n",
    "                    'Product Design',\n",
    "                    'Product Variety',\n",
    "                    'Discount',\n",
    "                    'Making Charge',\n",
    "                    'Price',\n",
    "                    'Product Quality',\n",
    "                    'OLD Gold Jewellery Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e4cb827f-1fee-4b9e-ad70-91bf77d150cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:12:23.513490Z",
     "iopub.status.busy": "2025-06-11T07:12:23.513164Z",
     "iopub.status.idle": "2025-06-11T07:12:23.520809Z",
     "shell.execute_reply": "2025-06-11T07:12:23.520369Z",
     "shell.execute_reply.started": "2025-06-11T07:12:23.513460Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the processed data\n",
    "processed_data_tan_taj_db_nonnull = []\n",
    "\n",
    "#Iterate over each row in the DataFrame\n",
    "for index, row in tan_taj_db_nonnull_api_cleaned_df.iterrows():\n",
    "    try:\n",
    "        #Assuming the JSON string is in the first column\n",
    "        json_string = row.iloc[0] if len(row) > 0 else ''\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "        #Iterate over each key-value pair in the dictionary\n",
    "        for commentor_name, feedback_list in data.items():\n",
    "            #Create a dictionary for each commentor with default values as 0\n",
    "            commentor_data = {col: 0 for col in column_names2}\n",
    "            commentor_data[\"Commentor Name\"] = commentor_name\n",
    "\n",
    "            #Check if there is any feedback for the commentor\n",
    "            if feedback_list:\n",
    "                #Since there could be multiple feedback entries for a single commentor, we aggregate them\n",
    "                for feedback in feedback_list:\n",
    "                    positive = feedback.get(\"positive\", \"\").split(',')\n",
    "                    negative = feedback.get(\"negative\", \"\").split(',')\n",
    "\n",
    "                    for topic in column_names2:\n",
    "                        #Aggregate the value: 1 for positive, -1 for negative, 0 for not mentioned\n",
    "                        commentor_data[topic] += assign_value(topic, positive, negative)\n",
    "\n",
    "                #Finalize the values to be within -1, 0, or 1\n",
    "                for topic in column_names2:\n",
    "                    if commentor_data[topic] > 1:\n",
    "                        commentor_data[topic] = 1\n",
    "                    elif commentor_data[topic] < -1:\n",
    "                        commentor_data[topic] = -1\n",
    "\n",
    "            #Append the commentor data to the processed data list\n",
    "            processed_data_tan_taj_db_nonnull.append(commentor_data)\n",
    "    except:\n",
    "        #Skip rows with invalid JSON data\n",
    "        print(f\"Invalid JSON in row {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d4fa8-9406-4070-94ac-594407f87fec",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_taj_db_nonnull_api_cleaned_df.to_excel(\"tan_taj_db_nonnull_api_cleaned_df.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a566d6f3-c2ee-4b45-a663-71397dc536b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_taj_db_nonnull_api_cleaned_df = pd.read_excel(\"tan_taj_db_nonnull_api_cleaned_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3501898-7dca-40a1-81fb-f383d35741ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "tan_taj_db_nonnull_api_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4daf6fe4-9ad2-4337-814e-5aae979fb810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:12:23.521708Z",
     "iopub.status.busy": "2025-06-11T07:12:23.521441Z",
     "iopub.status.idle": "2025-06-11T07:12:23.591296Z",
     "shell.execute_reply": "2025-06-11T07:12:23.590805Z",
     "shell.execute_reply.started": "2025-06-11T07:12:23.521659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame from the processed data\n",
    "tan_taj_db_nonnull_sen_df = pd.DataFrame(processed_data_tan_taj_db_nonnull)\n",
    "#Reorder the columns\n",
    "ordered_columns = [\"Commentor Name\",\n",
    "                   \"Trust\",\n",
    "                    \"Store Experience\",\n",
    "                    \"Store Staff\",\n",
    "                    \"Product Design\",\n",
    "                    \"Product Variety\",\n",
    "                    \"Discount\",\n",
    "                    \"Making Charge\",\n",
    "                    \"Price\",\n",
    "                    \"Product Quality\",\n",
    "                    \"OLD Gold Jewellery Exchange\"]\n",
    "#Apply the new order to the DataFrame\n",
    "tan_taj_db_nonnull_sen_df = tan_taj_db_nonnull_sen_df[ordered_columns]\n",
    "\n",
    "tan_taj_db_nonnull_merged_df = pd.concat([combined_df_tan_taj_db, tan_taj_db_nonnull_sen_df], axis=1)\n",
    "\n",
    "tan_taj_db_final_sen_df = pd.concat([tan_taj_db_nonnull_merged_df,null_dataframes['tan_taj_db_null']], ignore_index=True)\n",
    "\n",
    "tan_taj_db_final_sen_df_copy = tan_taj_db_final_sen_df.copy()\n",
    "tan_taj_db_final_sen_df_copy[\"Published At Date\"] = tan_taj_db_final_sen_df_copy[\"Published At Date\"].astype(str).str[:10]\n",
    "\n",
    "tan_taj_db_final_sen_df_copy.to_excel(\"sentiment_raw_output/tan_taj_db_final_sen_df_jul.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c943a-ee6b-4d17-8c38-8d33ee078968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c1e1a-2db3-468b-8c69-cbfa705c06c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed39bebe-898b-4d93-93e7-cd3c637e46a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combining DataFrames & creating final data with all reviews from DAY 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6469049-1128-4473-b75e-34efc3f7f05a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Current Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "d7f4cfe1-944e-4398-beb0-17627182a959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:49:36.484535Z",
     "iopub.status.busy": "2025-06-11T07:49:36.483705Z",
     "iopub.status.idle": "2025-06-11T07:49:36.488125Z",
     "shell.execute_reply": "2025-06-11T07:49:36.487513Z",
     "shell.execute_reply.started": "2025-06-11T07:49:36.484499Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty DataFrame for the combined data\n",
    "combined_df_with_s_current = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "75bcf065-885a-40b0-90bf-c5adc9d90120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:49:52.046515Z",
     "iopub.status.busy": "2025-06-11T07:49:52.046182Z",
     "iopub.status.idle": "2025-06-11T07:49:52.052263Z",
     "shell.execute_reply": "2025-06-11T07:49:52.051588Z",
     "shell.execute_reply.started": "2025-06-11T07:49:52.046495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_name_list_s = [\n",
    "                    \"agd_mb_final_sen_df_jul\",\n",
    "                    \"bhi_ak_final_sen_df_jul\",\n",
    "                    \"bhi_dec_ga_final_sen_df_jul\",\n",
    "                    #\"eve_joh_ga_final_sen_df_jul\",\n",
    "                    \"jar_alg_il_final_sen_df_jul\",\n",
    "                    \"jar_aur_il_final_sen_df_jul\",\n",
    "                    \"jar_bol_il_final_sen_df_jul\",\n",
    "                    \"jar_lom_il_final_sen_df_jul\",\n",
    "                    \"jar_orl_il_final_sen_df_jul\",\n",
    "                    \"jar_sch_il_final_sen_df_jul\",\n",
    "                    \"jar_ver_il_final_sen_df_jul\",\n",
    "                    \"joy_ab_final_sen_df_jul\",\n",
    "                    \"joy_ak_final_sen_df_jul\",\n",
    "                    \"joy_chi_il_final_sen_df_jul\",\n",
    "                    \"joy_dm_ad_final_sen_df_jul\",\n",
    "                    \"joy_fri_tx_final_sen_df_jul\",\n",
    "                    \"joy_hou_tx_final_sen_df_jul\",\n",
    "                    \"joy_mz_ad_final_sen_df_jul\",\n",
    "                    \"joy_sh_ad_final_sen_df_jul\",\n",
    "                    \"joy_st_af_final_sen_df_jul\",\n",
    "                    \"joy_suw_ga_final_sen_df_jul\",\n",
    "                    \"kan_mb_final_sen_df_jul\",\n",
    "                    \"mal_ab_final_sen_df_jul\",\n",
    "                    \"mal_ak_final_sen_df_jul\",\n",
    "                    \"mal_aw_ad_final_sen_df_jul\",\n",
    "                    \"mal_b1_ad_final_sen_df_jul\",\n",
    "                    \"mal_b1_af_final_sen_df_jul\",\n",
    "                    \"mal_b2_ad_final_sen_df_jul\",\n",
    "                    \"mal_b2_af_final_sen_df_jul\",\n",
    "                    \"mal_chi_il_final_sen_df_jul\",\n",
    "                    \"mal_dm_ad_final_sen_df_jul\",\n",
    "                    \"mal_fri_tx_final_sen_df_jul\",\n",
    "                    \"mal_ise_nj_final_sen_df_jul\",\n",
    "                    \"mal_lu_ad_final_sen_df_jul\",\n",
    "                    \"mal_mb_final_sen_df_jul\",\n",
    "                    \"mal_nap_il_final_sen_df_jul\",\n",
    "                    \"mal_ric_tx_final_sen_df_jul\",\n",
    "                    \"mal_sc_final_sen_df_jul\",\n",
    "                    \"mal_sh_ad_final_sen_df_jul\",\n",
    "                    \"may_vie_va_final_sen_df_jul\",\n",
    "                    \"mia_awm_ad_final_sen_df_jul\",\n",
    "                    \"mia_bur_db_final_sen_df_jul\",\n",
    "                    \"min_ak_final_sen_df_jul\",\n",
    "                    \"mna_mb_final_sen_df_jul\",\n",
    "                    \"son_ise_nj_final_sen_df_jul\",\n",
    "                    \"tan_am_om_final_sen_df_jul\",\n",
    "                    \"tan_atl_ga_final_sen_df_jul\",\n",
    "                    \"tan_bar_db_final_sen_df_jul\",\n",
    "                    \"tan_chi_il_final_sen_df_jul\",\n",
    "                    \"tan_fah_db_final_sen_df_jul\",\n",
    "                    \"tan_fc_qa_final_sen_df_jul\",\n",
    "                    \"tan_fri_tx_final_sen_df_jul\",\n",
    "                    \"tan_gs_db_final_sen_df_jul\",\n",
    "                    \"tan_ham_ad_final_sen_df_jul\",\n",
    "                    \"tan_hou_tx_final_sen_df_jul\",\n",
    "                    \"tan_kar_db_final_sen_df_jul\",\n",
    "                    \"tan_lul_qa_final_sen_df_jul\",\n",
    "                    \"tan_mank_db_final_sen_df_jul\",\n",
    "                    \"tan_mee_db_final_sen_df_jul\",\n",
    "                    \"tan_new_nj_final_sen_df_jul\",\n",
    "                    \"tan_rol_sh_final_sen_df_jul\",\n",
    "                    \"tan_rse_wa_final_sen_df_jul\",\n",
    "                    \"tan_sc_ca_final_sen_df_jul\",\n",
    "                    \"tan_sc_sh_final_sen_df_jul\",\n",
    "                    \"tan_sil_db_final_sen_df_jul\",\n",
    "                    \"tan_taj_db_final_sen_df_jul\",\n",
    "                    \"tif_chi_il_final_sen_df_jul\",\n",
    "                    \"tif_eas_nj_final_sen_df_jul\",\n",
    "                    \"tif_hac_nj_final_sen_df_jul\",\n",
    "                    \"tif_nor_il_final_sen_df_jul\",\n",
    "                    #\"tif_par_nj_final_sen_df_jul\",\n",
    "                    \"tif_red_nj_final_sen_df_jul\",\n",
    "                    \"tif_ric_va_final_sen_df_jul\",\n",
    "                    \"tif_sho_nj_final_sen_df_jul\",\n",
    "                    \"tif_sko_il_final_sen_df_jul\",\n",
    "                    \"tif_vie_va_final_sen_df_jul\",\n",
    "                    \"vbj_fri_tx_final_sen_df_jul\"\n",
    "                    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "398bff6f-4fd0-4738-9b56-447f451cb425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:50:30.441534Z",
     "iopub.status.busy": "2025-06-11T07:50:30.441191Z",
     "iopub.status.idle": "2025-06-11T07:50:35.572544Z",
     "shell.execute_reply": "2025-06-11T07:50:35.571820Z",
     "shell.execute_reply.started": "2025-06-11T07:50:30.441513Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read Data\n",
    "for i in df_name_list_s:\n",
    "    #Read the file into a DataFrame\n",
    "    df = pd.read_excel(f\"sentiment_raw_output/checked/{i}.xlsx\")\n",
    "    #Append the DataFrame to the combined DataFrame\n",
    "    combined_df_with_s_current = pd.concat([combined_df_with_s_current, df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "8e781a03-282c-4c7c-9b16-794a62db9284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T07:50:35.574259Z",
     "iopub.status.busy": "2025-06-11T07:50:35.573406Z",
     "iopub.status.idle": "2025-06-11T07:50:35.578943Z",
     "shell.execute_reply": "2025-06-11T07:50:35.578396Z",
     "shell.execute_reply.started": "2025-06-11T07:50:35.574238Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store Name', 'Name', 'Published At Date', 'Stars', 'Total Score',\n",
       "       'year', 'month', 'review_text', 'Store Code Cleaned', 'word_count',\n",
       "       'count_buckets', 'Commentor Name', 'Trust', 'Store Experience',\n",
       "       'Store Staff', 'Product Design', 'Product Variety', 'Discount',\n",
       "       'Making Charge', 'Price', 'Product Quality',\n",
       "       'OLD Gold Jewellery Exchange'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7dbdd-b521-4ef7-b4b6-c1293872e87b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create the columns Country, Catchment & Grouped Store Name for the purpose of Front end requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "f564fc14-fce1-48e8-a255-1fe17f9a4e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:19:25.554127Z",
     "iopub.status.busy": "2025-06-11T08:19:25.553811Z",
     "iopub.status.idle": "2025-06-11T08:19:25.569220Z",
     "shell.execute_reply": "2025-06-11T08:19:25.568661Z",
     "shell.execute_reply.started": "2025-06-11T08:19:25.554105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mapping Dictionaries\n",
    "country_mapping_dict = {\n",
    "                            \"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)\" : \"GCC\",\n",
    "                            \"Bhima Jewellers - Al Karama\" : \"GCC\",\n",
    "                            \"Bhindi Jewellers-Decatur, GA\" : \"USA\",\n",
    "                            \"Evermark Jewelry-Johns Creek, GA\" : \"USA\",\n",
    "                            \"Jared-Algonquin, IL\" : \"USA\",\n",
    "                            \"Jared-Aurora, IL\" : \"USA\",\n",
    "                            \"Jared-Bolingbrook, IL\" : \"USA\",\n",
    "                            \"Jared-Lombard, IL\" : \"USA\",\n",
    "                            \"Jared-Orland Park, IL\" : \"USA\",\n",
    "                            \"Jared-Schaumburg, IL\" : \"USA\",\n",
    "                            \"Jared-Vernon Hills, IL\" : \"USA\",\n",
    "                            \"Joyalukkas Jewellery - Al Barsha\" : \"GCC\",\n",
    "                            \"Joyalukkas Jewellery - Al Fahidi st - Al Fahidi\" : \"GCC\",\n",
    "                            \"Joyalukkas Jewellery - Al Karama\" : \"GCC\",\n",
    "                            \"Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi\" : \"GCC\",\n",
    "                            \"Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi\" : \"GCC\",\n",
    "                            \"Joyalukkas Jewellery - Shabia - Abu Dhabi\" : \"GCC\",\n",
    "                            \"Joyalukkas Jewellery-Chicago, IL\" : \"USA\",\n",
    "                            \"Joyalukkas Jewellery-Frisco, TX\" : \"USA\",\n",
    "                            \"Joyalukkas Jewellery-Houston, TX\" : \"USA\",\n",
    "                            \"Joyalukkas Jewellery-Suwanee, GA\" : \"USA\",\n",
    "                            \"Kanz Jewellers\" : \"GCC\",\n",
    "                            \"Malabar Gold & Diamonds - Silicon Oasis Central\" : \"GCC\",\n",
    "                            \"Malabar Gold & Diamonds-Chicago, IL\" : \"USA\",\n",
    "                            \"Malabar Gold & Diamonds-Frisco, TX\" : \"USA\",\n",
    "                            \"Malabar Gold & Diamonds-Iselin, NJ\" : \"USA\",\n",
    "                            \"Malabar Gold & Diamonds-Naperville, IL\" : \"USA\",\n",
    "                            \"Malabar Gold and Diamonds - Al Barsha - Dubai\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Al Karama - Dubai\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Hamdan Street (Branch 2)\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Meena Bazar - Dubai\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Shabia Musaffah\" : \"GCC\",\n",
    "                            \"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)\" : \"GCC\",\n",
    "                            \"Malani Jewellers-Richardson, TX\" : \"USA\",\n",
    "                            \"May Jewelers-Vienna, VA\" : \"USA\",\n",
    "                            \"Meena Jewellers - Meena Bazar\" : \"GCC\",\n",
    "                            \"Mia-Al Wahda Mall, AD\" : \"GCC\",\n",
    "                            \"Mia-Burjuman, DB\" : \"GCC\",\n",
    "                            \"Mint Jewels - Al Karama\" : \"GCC\",\n",
    "                            \"Sona Jewelers-Iselin, NJ\" : \"USA\",\n",
    "                            \"Tanishq Jewellers-Al Barsha, DB\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Al Fahidi, DB\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Al Karama, DB\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Avenues Mall, OM\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Festival City, QA\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Gold Souk, DB\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Hamdan Bin Mohammed Street, AD\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Lulu Hypermarket, QA\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Meena Bazar, DB\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Rolla, SH\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Sharjah Central, SH\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Silicon Central, DB\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-Taj, DB\" : \"GCC\",\n",
    "                            \"Tanishq Jewellers-UW Mall Al Mankhool, DB\" : \"GCC\",\n",
    "                            \"Tanishq-Atlanta, GA\" : \"USA\",\n",
    "                            \"Tanishq-Chicago, IL\" : \"USA\",\n",
    "                            \"Tanishq-Frisco, TX\" : \"USA\",\n",
    "                            \"Tanishq-Houston, TX\" : \"USA\",\n",
    "                            \"Tanishq-New Jersey, NJ\" : \"USA\",\n",
    "                            \"Tanishq-Redmond Seattle, WA\" : \"USA\",\n",
    "                            \"Tanishq-Santa Clara, CA\" : \"USA\",\n",
    "                            \"Tiffany & Co-Chicago, IL\" : \"USA\",\n",
    "                            \"Tiffany & Co-East Rutherford, NJ\" : \"USA\",\n",
    "                            \"Tiffany & Co-Hackensack, NJ\" : \"USA\",\n",
    "                            \"Tiffany & Co-Northbrook, IL\" : \"USA\",\n",
    "                            \"Tiffany & Co-Paramus, NJ\" : \"USA\",\n",
    "                            \"Tiffany & Co-Red Bank, NJ\" : \"USA\",\n",
    "                            \"Tiffany & Co-Richmond, VA\" : \"USA\",\n",
    "                            \"Tiffany & Co-Short Hills, NJ\" : \"USA\",\n",
    "                            \"Tiffany & Co-Skokie, IL\" : \"USA\",\n",
    "                            \"Tiffany & Co-Vienna, VA\" : \"USA\",\n",
    "                            \"VBJ Jewellers-Frisco, TX\" : \"USA\"\n",
    "                        }\n",
    "\n",
    "##############################\n",
    "catchment_mapping_dict = {\n",
    "                            \"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)\" : \"Meena Bazar\",\n",
    "                            \"Bhima Jewellers - Al Karama\" : \"Al Karama\",\n",
    "                            \"Bhindi Jewellers-Decatur, GA\" : \"GA\",\n",
    "                            \"Evermark Jewelry-Johns Creek, GA\" : \"GA\",\n",
    "                            \"Jared-Algonquin, IL\" : \"Chicago\",\n",
    "                            \"Jared-Aurora, IL\" : \"Chicago\",\n",
    "                            \"Jared-Bolingbrook, IL\" : \"Chicago\",\n",
    "                            \"Jared-Lombard, IL\" : \"Chicago\",\n",
    "                            \"Jared-Orland Park, IL\" : \"Chicago\",\n",
    "                            \"Jared-Schaumburg, IL\" : \"Chicago\",\n",
    "                            \"Jared-Vernon Hills, IL\" : \"Chicago\",\n",
    "                            \"Joyalukkas Jewellery - Al Barsha\" : \"Al Barsha\",\n",
    "                            \"Joyalukkas Jewellery - Al Fahidi st - Al Fahidi\" : \"Al Fahidi\",\n",
    "                            \"Joyalukkas Jewellery - Al Karama\" : \"Al Karama\",\n",
    "                            \"Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi\" : \"Abu Dhabi\",\n",
    "                            \"Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi\" : \"Abu Dhabi\",\n",
    "                            \"Joyalukkas Jewellery - Shabia - Abu Dhabi\" : \"Abu Dhabi\",\n",
    "                            \"Joyalukkas Jewellery-Chicago, IL\" : \"Chicago\",\n",
    "                            \"Joyalukkas Jewellery-Frisco, TX\" : \"Dallas\",\n",
    "                            \"Joyalukkas Jewellery-Houston, TX\" : \"Houston\",\n",
    "                            \"Joyalukkas Jewellery-Suwanee, GA\" : \"GA\",\n",
    "                            \"Kanz Jewellers\" : \"Meena Bazar\",\n",
    "                            \"Malabar Gold & Diamonds - Silicon Oasis Central\" : \"Silicon Central\",\n",
    "                            \"Malabar Gold & Diamonds-Chicago, IL\" : \"Chicago\",\n",
    "                            \"Malabar Gold & Diamonds-Frisco, TX\" : \"Dallas\",\n",
    "                            \"Malabar Gold & Diamonds-Iselin, NJ\" : \"New Jersey\",\n",
    "                            \"Malabar Gold & Diamonds-Naperville, IL\" : \"Chicago\",\n",
    "                            \"Malabar Gold and Diamonds - Al Barsha - Dubai\" : \"Al Barsha\",\n",
    "                            \"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)\" : \"Al Fahidi\",\n",
    "                            \"Malabar Gold and Diamonds - Al Karama - Dubai\" : \"Al Karama\",\n",
    "                            \"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi\" : \"Abu Dhabi\",\n",
    "                            \"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi\" : \"Abu Dhabi\",\n",
    "                            \"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)\" : \"Abu Dhabi\",\n",
    "                            \"Malabar Gold and Diamonds - Hamdan Street (Branch 2)\" : \"Abu Dhabi\",\n",
    "                            \"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed\" : \"Abu Dhabi\",\n",
    "                            \"Malabar Gold and Diamonds - Meena Bazar - Dubai\" : \"Meena Bazar\",\n",
    "                            \"Malabar Gold and Diamonds - Shabia Musaffah\" : \"Abu Dhabi\",\n",
    "                            \"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)\" : \"Al Fahidi\",\n",
    "                            \"Malani Jewellers-Richardson, TX\" : \"Dallas\",\n",
    "                            \"May Jewelers-Vienna, VA\" : \"New Jersey\",\n",
    "                            \"Meena Jewellers - Meena Bazar\" : \"Meena Bazar\",\n",
    "                            \"Mint Jewels - Al Karama\" : \"Al Karama\",\n",
    "                            \"Sona Jewelers-Iselin, NJ\" : \"New Jersey\",\n",
    "                            \"Tiffany & Co-Chicago, IL\" : \"Chicago\",\n",
    "                            \"Tiffany & Co-East Rutherford, NJ\" : \"New Jersey\",\n",
    "                            \"Tiffany & Co-Hackensack, NJ\" : \"New Jersey\",\n",
    "                            \"Tiffany & Co-Northbrook, IL\" : \"Chicago\",\n",
    "                            \"Tiffany & Co-Paramus, NJ\" : \"New Jersey\",\n",
    "                            \"Tiffany & Co-Red Bank, NJ\" : \"New Jersey\",\n",
    "                            \"Tiffany & Co-Richmond, VA\" : \"New Jersey\",\n",
    "                            \"Tiffany & Co-Short Hills, NJ\" : \"New Jersey\",\n",
    "                            \"Tiffany & Co-Skokie, IL\" : \"Chicago\",\n",
    "                            \"Tiffany & Co-Vienna, VA\" : \"New Jersey\",\n",
    "                            \"VBJ Jewellers-Frisco, TX\" : \"Dallas\",\n",
    "                            \"Mia-Al Wahda Mall, AD\" : \"Abu Dhabi\",\n",
    "                            \"Mia-Burjuman, DB\" : \"Burjuman\",\n",
    "                            \"Tanishq Jewellers-Al Barsha, DB\" : \"Al Barsha\",\n",
    "                            \"Tanishq Jewellers-Al Fahidi, DB\" : \"Al Fahidi\",\n",
    "                            \"Tanishq Jewellers-Al Karama, DB\" : \"Al Karama\",\n",
    "                            \"Tanishq Jewellers-Avenues Mall, OM\" : \"Oman\",\n",
    "                            \"Tanishq Jewellers-Festival City, QA\" : \"Qatar\",\n",
    "                            \"Tanishq Jewellers-Gold Souk, DB\" : \"Gold Souk\",\n",
    "                            \"Tanishq Jewellers-Hamdan Bin Mohammed Street, AD\" : \"Abu Dhabi\",\n",
    "                            \"Tanishq Jewellers-Lulu Hypermarket, QA\" : \"Qatar\",\n",
    "                            \"Tanishq Jewellers-Meena Bazar, DB\" : \"Meena Bazar\",\n",
    "                            \"Tanishq Jewellers-Rolla, SH\" : \"Sharjah\",\n",
    "                            \"Tanishq Jewellers-Sharjah Central, SH\" : \"Sharjah\",\n",
    "                            \"Tanishq Jewellers-Silicon Central, DB\" : \"Silicon Central\",\n",
    "                            \"Tanishq Jewellers-Taj, DB\" : \"Taj\",\n",
    "                            \"Tanishq Jewellers-UW Mall Al Mankhool, DB\" : \"Mankhool\",\n",
    "                            \"Tanishq-Atlanta, GA\" : \"GA\",\n",
    "                            \"Tanishq-Chicago, IL\" : \"Chicago\",\n",
    "                            \"Tanishq-Frisco, TX\" : \"Dallas\",\n",
    "                            \"Tanishq-Houston, TX\" : \"Houston\",\n",
    "                            \"Tanishq-New Jersey, NJ\" : \"New Jersey\",\n",
    "                            \"Tanishq-Redmond Seattle, WA\" : \"Seattle\",\n",
    "                            \"Tanishq-Santa Clara, CA\" : \"Santa Clara\"\n",
    "                        }\n",
    "\n",
    "\n",
    "#########################\n",
    "grp_store_mapping_dict = {\n",
    "                            \"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)\" :  \"Arakkal\",\n",
    "                            \"Bhima Jewellers - Al Karama\" :  \"Bhima\",\n",
    "                            \"Bhindi Jewellers-Decatur, GA\" :  \"Bhindi\",\n",
    "                            \"Evermark Jewelry-Johns Creek, GA\" :  \"Evermark Jewelry\",\n",
    "                            \"Jared-Algonquin, IL\" :  \"Jared\",\n",
    "                            \"Jared-Aurora, IL\" :  \"Jared\",\n",
    "                            \"Jared-Bolingbrook, IL\" :  \"Jared\",\n",
    "                            \"Jared-Lombard, IL\" :  \"Jared\",\n",
    "                            \"Jared-Orland Park, IL\" :  \"Jared\",\n",
    "                            \"Jared-Schaumburg, IL\" :  \"Jared\",\n",
    "                            \"Jared-Vernon Hills, IL\" :  \"Jared\",\n",
    "                            \"Joyalukkas Jewellery - Al Barsha\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery - Al Fahidi st - Al Fahidi\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery - Al Karama\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery - Shabia - Abu Dhabi\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery-Chicago, IL\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery-Frisco, TX\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery-Houston, TX\" :  \"Joyalukkas\",\n",
    "                            \"Joyalukkas Jewellery-Suwanee, GA\" :  \"Joyalukkas\",\n",
    "                            \"Kanz Jewellers\" :  \"Kanz\",\n",
    "                            \"Malabar Gold & Diamonds - Silicon Oasis Central\" :  \"Malabar\",\n",
    "                            \"Malabar Gold & Diamonds-Chicago, IL\" :  \"Malabar\",\n",
    "                            \"Malabar Gold & Diamonds-Frisco, TX\" :  \"Malabar\",\n",
    "                            \"Malabar Gold & Diamonds-Iselin, NJ\" :  \"Malabar\",\n",
    "                            \"Malabar Gold & Diamonds-Naperville, IL\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Al Barsha - Dubai\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Al Karama - Dubai\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Hamdan Street (Branch 2)\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Meena Bazar - Dubai\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Shabia Musaffah\" :  \"Malabar\",\n",
    "                            \"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)\" :  \"Malabar\",\n",
    "                            \"Malani Jewellers-Richardson, TX\" :  \"Malani Jewellers\",\n",
    "                            \"May Jewelers-Vienna, VA\" :  \"May Jewelers\",\n",
    "                            \"Meena Jewellers - Meena Bazar\" :  \"Meena\",\n",
    "                            \"Mint Jewels - Al Karama\" :  \"Mint\",\n",
    "                            \"Sona Jewelers-Iselin, NJ\" :  \"Sona\",\n",
    "                            \"Tiffany & Co-Chicago, IL\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-East Rutherford, NJ\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Hackensack, NJ\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Northbrook, IL\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Paramus, NJ\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Red Bank, NJ\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Richmond, VA\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Short Hills, NJ\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Skokie, IL\" :  \"Tiffany\",\n",
    "                            \"Tiffany & Co-Vienna, VA\" :  \"Tiffany\",\n",
    "                            \"VBJ Jewellers-Frisco, TX\" :  \"VBJ\",\n",
    "                            \"Mia-Al Wahda Mall, AD\" : \"Mia\",\n",
    "                            \"Mia-Burjuman, DB\" : \"Mia\",\n",
    "                            \"Tanishq Jewellers-Al Barsha, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Al Fahidi, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Al Karama, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Avenues Mall, OM\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Festival City, QA\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Gold Souk, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Hamdan Bin Mohammed Street, AD\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Lulu Hypermarket, QA\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Meena Bazar, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Rolla, SH\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Sharjah Central, SH\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Silicon Central, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-Taj, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq Jewellers-UW Mall Al Mankhool, DB\" :  \"Tanishq\",\n",
    "                            \"Tanishq-Atlanta, GA\" :  \"Tanishq\",\n",
    "                            \"Tanishq-Chicago, IL\" :  \"Tanishq\",\n",
    "                            \"Tanishq-Frisco, TX\" :  \"Tanishq\",\n",
    "                            \"Tanishq-Houston, TX\" :  \"Tanishq\",\n",
    "                            \"Tanishq-New Jersey, NJ\" :  \"Tanishq\",\n",
    "                            \"Tanishq-Redmond Seattle, WA\" :  \"Tanishq\",\n",
    "                            \"Tanishq-Santa Clara, CA\" :  \"Tanishq\"\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "418d9f27-16ba-4b54-b87a-e9475dc4a1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:19:37.895988Z",
     "iopub.status.busy": "2025-06-11T08:19:37.895672Z",
     "iopub.status.idle": "2025-06-11T08:19:37.906370Z",
     "shell.execute_reply": "2025-06-11T08:19:37.905176Z",
     "shell.execute_reply.started": "2025-06-11T08:19:37.895955Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Column Creations - Country, Catchment & Grouped Store Name\n",
    "combined_df_with_s_current['Country'] = combined_df_with_s_current['Store Name'].map(country_mapping_dict)\n",
    "combined_df_with_s_current['Catchment'] = combined_df_with_s_current['Store Name'].map(catchment_mapping_dict)\n",
    "combined_df_with_s_current['Grouped Store Name'] = combined_df_with_s_current['Store Name'].map(grp_store_mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b87fb416-bfc5-4117-b728-6c5f3bb9e09b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:20:33.355541Z",
     "iopub.status.busy": "2025-06-11T08:20:33.355222Z",
     "iopub.status.idle": "2025-06-11T08:20:33.359982Z",
     "shell.execute_reply": "2025-06-11T08:20:33.359408Z",
     "shell.execute_reply.started": "2025-06-11T08:20:33.355520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store Name', 'Name', 'Published At Date', 'Stars', 'Total Score',\n",
       "       'year', 'month', 'review_text', 'Store Code Cleaned', 'word_count',\n",
       "       'count_buckets', 'Commentor Name', 'Trust', 'Store Experience',\n",
       "       'Store Staff', 'Product Design', 'Product Variety', 'Discount',\n",
       "       'Making Charge', 'Price', 'Product Quality',\n",
       "       'OLD Gold Jewellery Exchange', 'Country', 'Catchment',\n",
       "       'Grouped Store Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "68c12826-9cba-478a-9622-ad4a76884e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:22:35.913917Z",
     "iopub.status.busy": "2025-06-11T08:22:35.913573Z",
     "iopub.status.idle": "2025-06-11T08:22:35.930500Z",
     "shell.execute_reply": "2025-06-11T08:22:35.930025Z",
     "shell.execute_reply.started": "2025-06-11T08:22:35.913895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store Name                        0\n",
       "Name                              0\n",
       "Published At Date                 0\n",
       "Stars                             0\n",
       "Total Score                       0\n",
       "year                              0\n",
       "month                             0\n",
       "review_text                    1374\n",
       "Store Code Cleaned             8472\n",
       "word_count                     1374\n",
       "count_buckets                  1374\n",
       "Commentor Name                    0\n",
       "Trust                             0\n",
       "Store Experience                  0\n",
       "Store Staff                       0\n",
       "Product Design                    0\n",
       "Product Variety                   0\n",
       "Discount                          0\n",
       "Making Charge                     0\n",
       "Price                             0\n",
       "Product Quality                   0\n",
       "OLD Gold Jewellery Exchange       0\n",
       "Country                           0\n",
       "Catchment                         0\n",
       "Grouped Store Name                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "a18e5b71-bdce-43b6-81e6-de399c2c7e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:23:19.369111Z",
     "iopub.status.busy": "2025-06-11T08:23:19.368803Z",
     "iopub.status.idle": "2025-06-11T08:23:19.375667Z",
     "shell.execute_reply": "2025-06-11T08:23:19.375142Z",
     "shell.execute_reply.started": "2025-06-11T08:23:19.369089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store Code Cleaned\n",
       "XDF    1781\n",
       "XDB    1028\n",
       "XDG    1015\n",
       "XTD     776\n",
       "XDM     682\n",
       "XDS     681\n",
       "XDK     488\n",
       "XDJ     407\n",
       "XAH     390\n",
       "XAC     372\n",
       "XSL     318\n",
       "XTH     248\n",
       "XNJ     231\n",
       "XSR     222\n",
       "XCG     203\n",
       "XDT     152\n",
       "XQD     144\n",
       "XWS     133\n",
       "XOM      81\n",
       "XBA      63\n",
       "XDX      30\n",
       "XQF      29\n",
       "XAW      26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current[\"Store Code Cleaned\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "49a3114d-bf15-4bc5-b6b6-a7f40872881e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:23:37.680935Z",
     "iopub.status.busy": "2025-06-11T08:23:37.680597Z",
     "iopub.status.idle": "2025-06-11T08:23:37.684552Z",
     "shell.execute_reply": "2025-06-11T08:23:37.683987Z",
     "shell.execute_reply.started": "2025-06-11T08:23:37.680908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rename Columns\n",
    "rename_dict = {\n",
    "                   'Name' : 'Name of the Reviewer',\n",
    "                   'Published At Date' : 'review_datetime_utc',\n",
    "                   'Stars' : 'review_rating',\n",
    "                   'Total Score' : 'Avg Rating',\n",
    "                   # 'Check' : 'Reviewer Name Check', \n",
    "                   'Trust':'Customer Confidence', \n",
    "                   'OLD Gold Jewellery Exchange':'Jewellery Exchange'\n",
    "                }\n",
    "\n",
    "combined_df_with_s_current.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1b264449-99a9-4b2b-9d32-0794fc9298d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:23:39.935741Z",
     "iopub.status.busy": "2025-06-11T08:23:39.935415Z",
     "iopub.status.idle": "2025-06-11T08:23:39.943239Z",
     "shell.execute_reply": "2025-06-11T08:23:39.942707Z",
     "shell.execute_reply.started": "2025-06-11T08:23:39.935705Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drop unwanted columns\n",
    "combined_df_with_s_current = combined_df_with_s_current.drop(['word_count','count_buckets'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "51b8c843-a649-4f84-951a-ccc08ea38b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:23:43.420744Z",
     "iopub.status.busy": "2025-06-11T08:23:43.420391Z",
     "iopub.status.idle": "2025-06-11T08:23:43.425384Z",
     "shell.execute_reply": "2025-06-11T08:23:43.424675Z",
     "shell.execute_reply.started": "2025-06-11T08:23:43.420723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store Name', 'Name of the Reviewer', 'review_datetime_utc',\n",
       "       'review_rating', 'Avg Rating', 'year', 'month', 'review_text',\n",
       "       'Store Code Cleaned', 'Commentor Name', 'Customer Confidence',\n",
       "       'Store Experience', 'Store Staff', 'Product Design', 'Product Variety',\n",
       "       'Discount', 'Making Charge', 'Price', 'Product Quality',\n",
       "       'Jewellery Exchange', 'Country', 'Catchment', 'Grouped Store Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753321c0-798a-42f1-acc3-15378cdb7562",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Drop unwanted columns\n",
    "#combined_df_with_s_current = combined_df_with_s_current.drop(['Unnamed: 22'], axis=1)\n",
    "combined_df_with_s_current = combined_df_with_s_current.drop(['check'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "a7534f83-d49e-4e88-9f06-4a1d37e3c61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T08:24:45.750773Z",
     "iopub.status.busy": "2025-06-11T08:24:45.750446Z",
     "iopub.status.idle": "2025-06-11T08:24:51.784390Z",
     "shell.execute_reply": "2025-06-11T08:24:51.783763Z",
     "shell.execute_reply.started": "2025-06-11T08:24:45.750751Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_df_with_s_current.to_excel(\"temp/sentiment_mapped_current.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "5a5a63fe-8820-45e9-8241-1076f990220d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:21:50.402324Z",
     "iopub.status.busy": "2025-06-11T12:21:50.401946Z",
     "iopub.status.idle": "2025-06-11T12:21:50.419075Z",
     "shell.execute_reply": "2025-06-11T12:21:50.418520Z",
     "shell.execute_reply.started": "2025-06-11T12:21:50.402304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Name of the Reviewer</th>\n",
       "      <th>review_datetime_utc</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Avg Rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>review_text</th>\n",
       "      <th>Store Code Cleaned</th>\n",
       "      <th>Commentor Name</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "      <th>Country</th>\n",
       "      <th>Catchment</th>\n",
       "      <th>Grouped Store Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arakkal Gold and Diamonds LLC - Meena Bazar - ...</td>\n",
       "      <td>AlJawharaflowers&amp;Gifts</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>We are their customer for gold and they are ou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlJawharaflowers&amp;Gifts</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Meena Bazar</td>\n",
       "      <td>Arakkal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Binu Pillai</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent customer care.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Binu Pillai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Sajani Manikandan</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent customer service.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sajani Manikandan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>ameen sb</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Good collections</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ameen sb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Parthibarajan s</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parthibarajan s</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name    Name of the Reviewer  \\\n",
       "0  Arakkal Gold and Diamonds LLC - Meena Bazar - ...  AlJawharaflowers&Gifts   \n",
       "1                        Bhima Jewellers - Al Karama             Binu Pillai   \n",
       "2                        Bhima Jewellers - Al Karama       Sajani Manikandan   \n",
       "3                        Bhima Jewellers - Al Karama                ameen sb   \n",
       "4                        Bhima Jewellers - Al Karama         Parthibarajan s   \n",
       "\n",
       "  review_datetime_utc  review_rating  Avg Rating  year  month  \\\n",
       "0          2025-05-04              5         5.0  2025      5   \n",
       "1          2025-05-29              4         4.7  2025      5   \n",
       "2          2025-05-23              5         4.7  2025      5   \n",
       "3          2025-05-20              5         4.7  2025      5   \n",
       "4          2025-05-15              5         4.7  2025      5   \n",
       "\n",
       "                                         review_text Store Code Cleaned  \\\n",
       "0  We are their customer for gold and they are ou...                NaN   \n",
       "1                           Excellent customer care.                NaN   \n",
       "2                        Excellent customer service.                NaN   \n",
       "3                                   Good collections                NaN   \n",
       "4                                               Good                NaN   \n",
       "\n",
       "           Commentor Name  Customer Confidence  Store Experience  Store Staff  \\\n",
       "0  AlJawharaflowers&Gifts                    1                 0            0   \n",
       "1             Binu Pillai                    0                 0            1   \n",
       "2       Sajani Manikandan                    0                 0            1   \n",
       "3                ameen sb                    0                 0            0   \n",
       "4         Parthibarajan s                    0                 0            0   \n",
       "\n",
       "   Product Design  Product Variety  Discount  Making Charge  Price  \\\n",
       "0               0                0         0              0      0   \n",
       "1               0                0         0              0      0   \n",
       "2               0                0         0              0      0   \n",
       "3               0                1         0              0      0   \n",
       "4               0                0         0              0      0   \n",
       "\n",
       "   Product Quality  Jewellery Exchange Country    Catchment Grouped Store Name  \n",
       "0                0                   0     GCC  Meena Bazar            Arakkal  \n",
       "1                0                   0     GCC    Al Karama              Bhima  \n",
       "2                0                   0     GCC    Al Karama              Bhima  \n",
       "3                0                   0     GCC    Al Karama              Bhima  \n",
       "4                0                   0     GCC    Al Karama              Bhima  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60de1e-10c7-4262-a5be-cb8647e8a797",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Past Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "99d1eebe-9f3e-4487-b4aa-a9c79352dc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:31:25.293906Z",
     "iopub.status.busy": "2025-06-11T12:31:25.293581Z",
     "iopub.status.idle": "2025-06-11T12:32:04.632895Z",
     "shell.execute_reply": "2025-06-11T12:32:04.632341Z",
     "shell.execute_reply.started": "2025-06-11T12:31:25.293886Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize an empty DataFrame for the combined data\n",
    "combined_df_with_s_past = pd.read_excel(\"sentiment_raw_output/old_full/combined_df_final_S_full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "66b0488b-e71e-46c7-8386-d75a40cb24b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:32:04.634144Z",
     "iopub.status.busy": "2025-06-11T12:32:04.633850Z",
     "iopub.status.idle": "2025-06-11T12:32:04.639998Z",
     "shell.execute_reply": "2025-06-11T12:32:04.639395Z",
     "shell.execute_reply.started": "2025-06-11T12:32:04.634123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0,\n",
       " 4.7,\n",
       " 4.6,\n",
       " 4.3,\n",
       " 4.4,\n",
       " 4.5,\n",
       " 4.9,\n",
       " 4.8,\n",
       " 4.2,\n",
       " 4.1,\n",
       " 4.562133891213389,\n",
       " 4.900000000000001]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_past['Avg Rating'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4796d616-60fb-43bf-b8d8-38b96b3e9611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:32:22.680870Z",
     "iopub.status.busy": "2025-06-11T12:32:22.680521Z",
     "iopub.status.idle": "2025-06-11T12:32:22.686652Z",
     "shell.execute_reply": "2025-06-11T12:32:22.685714Z",
     "shell.execute_reply.started": "2025-06-11T12:32:22.680847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store Name', 'Name of the Reviewer', 'review_datetime_utc',\n",
       "       'review_rating', 'Avg Rating', 'year', 'month', 'review_text',\n",
       "       'Store Code Cleaned', 'Commentor Name', 'Customer Confidence',\n",
       "       'Store Experience', 'Store Staff', 'Product Design', 'Product Variety',\n",
       "       'Discount', 'Making Charge', 'Price', 'Product Quality',\n",
       "       'Jewellery Exchange', 'Country', 'Catchment', 'Grouped Store Name',\n",
       "       'Total Reviews'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_past.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ee4d6570-c9c4-418b-b61e-a6bf1d84bee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:35:42.394518Z",
     "iopub.status.busy": "2025-06-11T12:35:42.394193Z",
     "iopub.status.idle": "2025-06-11T12:35:42.424202Z",
     "shell.execute_reply": "2025-06-11T12:35:42.423605Z",
     "shell.execute_reply.started": "2025-06-11T12:35:42.394498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drop unwanted columns (Total Reviews to be altered as per the latest)\n",
    "combined_df_with_s_past = combined_df_with_s_past.drop(['Avg Rating','Total Reviews'], axis=1) #,'Reviewer Name Check'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "939d4695-843e-46ba-b1cc-e1b9c718c7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:35:44.936131Z",
     "iopub.status.busy": "2025-06-11T12:35:44.935769Z",
     "iopub.status.idle": "2025-06-11T12:35:44.940445Z",
     "shell.execute_reply": "2025-06-11T12:35:44.939904Z",
     "shell.execute_reply.started": "2025-06-11T12:35:44.936108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 4.7, 4.5, 4.6, 4.9, 4.8, 4.2, 4.3, 4.4, 4.1]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current['Avg Rating'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "961e21a2-88ea-4fbb-8a45-14ddd821ebe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:35:47.483305Z",
     "iopub.status.busy": "2025-06-11T12:35:47.482995Z",
     "iopub.status.idle": "2025-06-11T12:35:47.488149Z",
     "shell.execute_reply": "2025-06-11T12:35:47.487399Z",
     "shell.execute_reply.started": "2025-06-11T12:35:47.483283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan_avg_rating_stores = combined_df_with_s_current[combined_df_with_s_current['Avg Rating'].isna()]['Store Name'].unique().tolist()\n",
    "print(nan_avg_rating_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "31115d7d-1b29-4678-88f2-85aa6c48c55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:36:18.559844Z",
     "iopub.status.busy": "2025-06-11T12:36:18.559533Z",
     "iopub.status.idle": "2025-06-11T12:36:18.576741Z",
     "shell.execute_reply": "2025-06-11T12:36:18.576276Z",
     "shell.execute_reply.started": "2025-06-11T12:36:18.559824Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Aggregate the 'Avg Rating' by 'Store Name'\n",
    "rating_map_df = combined_df_with_s_current.groupby('Store Name')['Avg Rating'].mean()\n",
    "\n",
    "rating_map_df = rating_map_df.reset_index()  # Make index a column\n",
    "rating_map_df.columns = rating_map_df.columns.str.strip()\n",
    "rating_map_df = rating_map_df.loc[:, ~rating_map_df.columns.duplicated()]\n",
    "\n",
    "# Now build the map\n",
    "rating_map = dict(zip(rating_map_df['Store Name'], rating_map_df['Avg Rating']))\n",
    "\n",
    "# Apply the map to your target DataFrame\n",
    "combined_df_with_s_past['Avg Rating'] = combined_df_with_s_past['Store Name'].map(rating_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "d143c943-61cf-456b-b4ec-77fef8dedf26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:36:20.300827Z",
     "iopub.status.busy": "2025-06-11T12:36:20.300500Z",
     "iopub.status.idle": "2025-06-11T12:36:20.305682Z",
     "shell.execute_reply": "2025-06-11T12:36:20.305124Z",
     "shell.execute_reply.started": "2025-06-11T12:36:20.300808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)': 5.0,\n",
       " 'Bhima Jewellers - Al Karama': 4.7,\n",
       " 'Bhindi Jewellers-Decatur, GA': 4.7,\n",
       " 'Jared-Algonquin, IL': 4.7,\n",
       " 'Jared-Aurora, IL': 4.5,\n",
       " 'Jared-Bolingbrook, IL': 4.6,\n",
       " 'Jared-Lombard, IL': 4.5,\n",
       " 'Jared-Orland Park, IL': 4.5,\n",
       " 'Jared-Schaumburg, IL': 4.5,\n",
       " 'Jared-Vernon Hills, IL': 4.6,\n",
       " 'Joyalukkas Jewellery - Al Barsha': 4.9,\n",
       " 'Joyalukkas Jewellery - Al Fahidi st - Al Fahidi': 4.9,\n",
       " 'Joyalukkas Jewellery - Al Karama': 4.8,\n",
       " 'Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi': 4.8,\n",
       " 'Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi': 4.9,\n",
       " 'Joyalukkas Jewellery - Shabia - Abu Dhabi': 4.6,\n",
       " 'Joyalukkas Jewellery-Chicago, IL': 4.8,\n",
       " 'Joyalukkas Jewellery-Frisco, TX': 4.9,\n",
       " 'Joyalukkas Jewellery-Houston, TX': 4.7,\n",
       " 'Joyalukkas Jewellery-Suwanee, GA': 4.9,\n",
       " 'Kanz Jewellers': 4.8,\n",
       " 'Malabar Gold & Diamonds - Silicon Oasis Central': 4.9,\n",
       " 'Malabar Gold & Diamonds-Chicago, IL': 4.9,\n",
       " 'Malabar Gold & Diamonds-Frisco, TX': 4.9,\n",
       " 'Malabar Gold & Diamonds-Iselin, NJ': 4.9,\n",
       " 'Malabar Gold & Diamonds-Naperville, IL': 4.9,\n",
       " 'Malabar Gold and Diamonds - Al Barsha - Dubai': 4.9,\n",
       " 'Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)': 5.0,\n",
       " 'Malabar Gold and Diamonds - Al Karama - Dubai': 4.9,\n",
       " 'Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi': 5.0,\n",
       " 'Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi': 5.0,\n",
       " 'Malabar Gold and Diamonds - Hamdan Street ( Branch 1)': 4.9,\n",
       " 'Malabar Gold and Diamonds - Hamdan Street (Branch 2)': 5.0,\n",
       " 'Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed': 5.0,\n",
       " 'Malabar Gold and Diamonds - Meena Bazar - Dubai': 4.9,\n",
       " 'Malabar Gold and Diamonds - Shabia Musaffah': 4.8,\n",
       " 'Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)': 5.0,\n",
       " 'Malani Jewellers-Richardson, TX': 4.9,\n",
       " 'May Jewelers-Vienna, VA': 4.2,\n",
       " 'Meena Jewellers - Meena Bazar': 4.8,\n",
       " 'Mia-Al Wahda Mall, AD': 5.0,\n",
       " 'Mia-Burjuman, DB': 4.9,\n",
       " 'Mint Jewels - Al Karama': 5.0,\n",
       " 'Sona Jewelers-Iselin, NJ': 4.7,\n",
       " 'Tanishq Jewellers-Al Barsha, DB': 4.9,\n",
       " 'Tanishq Jewellers-Al Fahidi, DB': 5.0,\n",
       " 'Tanishq Jewellers-Al Karama, DB': 4.9,\n",
       " 'Tanishq Jewellers-Avenues Mall, OM': 4.7,\n",
       " 'Tanishq Jewellers-Festival City, QA': 4.9,\n",
       " 'Tanishq Jewellers-Gold Souk, DB': 5.0,\n",
       " 'Tanishq Jewellers-Hamdan Bin Mohammed Street, AD': 5.0,\n",
       " 'Tanishq Jewellers-Lulu Hypermarket, QA': 4.9,\n",
       " 'Tanishq Jewellers-Meena Bazar, DB': 4.9,\n",
       " 'Tanishq Jewellers-Rolla, SH': 5.0,\n",
       " 'Tanishq Jewellers-Sharjah Central, SH': 4.9,\n",
       " 'Tanishq Jewellers-Silicon Central, DB': 4.9,\n",
       " 'Tanishq Jewellers-Taj, DB': 4.9,\n",
       " 'Tanishq Jewellers-UW Mall Al Mankhool, DB': 4.9,\n",
       " 'Tanishq-Atlanta, GA': 4.9,\n",
       " 'Tanishq-Chicago, IL': 4.8,\n",
       " 'Tanishq-Frisco, TX': 4.9,\n",
       " 'Tanishq-Houston, TX': 4.8,\n",
       " 'Tanishq-New Jersey, NJ': 4.7,\n",
       " 'Tanishq-Redmond Seattle, WA': 4.8,\n",
       " 'Tanishq-Santa Clara, CA': 4.5,\n",
       " 'Tiffany & Co-Chicago, IL': 4.5,\n",
       " 'Tiffany & Co-East Rutherford, NJ': 4.3,\n",
       " 'Tiffany & Co-Hackensack, NJ': 4.3,\n",
       " 'Tiffany & Co-Northbrook, IL': 4.6,\n",
       " 'Tiffany & Co-Red Bank, NJ': 4.4,\n",
       " 'Tiffany & Co-Richmond, VA': 4.2,\n",
       " 'Tiffany & Co-Short Hills, NJ': 4.1,\n",
       " 'Tiffany & Co-Skokie, IL': 4.4,\n",
       " 'Tiffany & Co-Vienna, VA': 4.3,\n",
       " 'VBJ Jewellers-Frisco, TX': 4.9}"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "cf407057-4148-480c-8491-d63bf3ea5657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:37:05.119562Z",
     "iopub.status.busy": "2025-06-11T12:37:05.119239Z",
     "iopub.status.idle": "2025-06-11T12:37:05.158548Z",
     "shell.execute_reply": "2025-06-11T12:37:05.158032Z",
     "shell.execute_reply.started": "2025-06-11T12:37:05.119539Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Aligning Column Orders\n",
    "desired_column_order = [\n",
    "                            'Store Name',\n",
    "                             'Name of the Reviewer',\n",
    "                             'review_datetime_utc',\n",
    "                             'review_rating',\n",
    "                             'Avg Rating',\n",
    "                             'year',\n",
    "                             'month',\n",
    "                             'review_text',\n",
    "                             'Store Code Cleaned',\n",
    "                             'Commentor Name',\n",
    "                             'Customer Confidence',\n",
    "                             'Store Experience',\n",
    "                             'Store Staff',\n",
    "                             'Product Design',\n",
    "                             'Product Variety',\n",
    "                             'Discount',\n",
    "                             'Making Charge',\n",
    "                             'Price',\n",
    "                             'Product Quality',\n",
    "                             'Jewellery Exchange',\n",
    "                             'Country',\n",
    "                             'Catchment',\n",
    "                             'Grouped Store Name'\n",
    "                        ]\n",
    "\n",
    "combined_df_with_s_past = combined_df_with_s_past[desired_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ac0ee016-3278-4815-bb82-f23012b6e171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:38:08.080480Z",
     "iopub.status.busy": "2025-06-11T12:38:08.080167Z",
     "iopub.status.idle": "2025-06-11T12:38:08.086525Z",
     "shell.execute_reply": "2025-06-11T12:38:08.086048Z",
     "shell.execute_reply.started": "2025-06-11T12:38:08.080460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 4.7, nan, 4.5, 4.6, 4.9, 4.8, 4.2, 4.3, 4.4, 4.1]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_past['Avg Rating'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "f7a88983-f56f-492a-9244-d302eccf5581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:39:31.601054Z",
     "iopub.status.busy": "2025-06-11T12:39:31.600649Z",
     "iopub.status.idle": "2025-06-11T12:39:31.606611Z",
     "shell.execute_reply": "2025-06-11T12:39:31.605937Z",
     "shell.execute_reply.started": "2025-06-11T12:39:31.601032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Evermark Jewelry-Johns Creek, GA', 'Tiffany & Co-Paramus, NJ']\n"
     ]
    }
   ],
   "source": [
    "nan_avg_rating_stores = combined_df_with_s_past[combined_df_with_s_past['Avg Rating'].isna()]['Store Name'].unique().tolist()\n",
    "print(nan_avg_rating_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "34ce0d9f-9f05-4734-b53e-1bb59a8b32c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:40:33.788067Z",
     "iopub.status.busy": "2025-06-11T12:40:33.787696Z",
     "iopub.status.idle": "2025-06-11T12:40:33.792410Z",
     "shell.execute_reply": "2025-06-11T12:40:33.791797Z",
     "shell.execute_reply.started": "2025-06-11T12:40:33.788045Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store Name', 'Name of the Reviewer', 'review_datetime_utc',\n",
       "       'review_rating', 'Avg Rating', 'year', 'month', 'review_text',\n",
       "       'Store Code Cleaned', 'Commentor Name', 'Customer Confidence',\n",
       "       'Store Experience', 'Store Staff', 'Product Design', 'Product Variety',\n",
       "       'Discount', 'Making Charge', 'Price', 'Product Quality',\n",
       "       'Jewellery Exchange', 'Country', 'Catchment', 'Grouped Store Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_past.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "486a8720-48cc-4b2f-bc33-003807b251cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:40:35.026737Z",
     "iopub.status.busy": "2025-06-11T12:40:35.026003Z",
     "iopub.status.idle": "2025-06-11T12:40:35.031553Z",
     "shell.execute_reply": "2025-06-11T12:40:35.030916Z",
     "shell.execute_reply.started": "2025-06-11T12:40:35.026702Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store Name', 'Name of the Reviewer', 'review_datetime_utc',\n",
       "       'review_rating', 'Avg Rating', 'year', 'month', 'review_text',\n",
       "       'Store Code Cleaned', 'Commentor Name', 'Customer Confidence',\n",
       "       'Store Experience', 'Store Staff', 'Product Design', 'Product Variety',\n",
       "       'Discount', 'Making Charge', 'Price', 'Product Quality',\n",
       "       'Jewellery Exchange', 'Country', 'Catchment', 'Grouped Store Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db943e-2672-4dc6-a811-c0c2de32e6ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combining past & current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "dc30b57f-223e-4451-9e91-3d39eb19c594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:41:22.540881Z",
     "iopub.status.busy": "2025-06-11T12:41:22.540544Z",
     "iopub.status.idle": "2025-06-11T12:41:22.564626Z",
     "shell.execute_reply": "2025-06-11T12:41:22.564080Z",
     "shell.execute_reply.started": "2025-06-11T12:41:22.540859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_with_s = pd.DataFrame()\n",
    "combined_df_with_s = pd.concat([combined_df_with_s_past, combined_df_with_s_current], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "4eaca4a2-8ee1-4fe9-b9d6-bd91cae01a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:41:27.800139Z",
     "iopub.status.busy": "2025-06-11T12:41:27.799786Z",
     "iopub.status.idle": "2025-06-11T12:41:27.804115Z",
     "shell.execute_reply": "2025-06-11T12:41:27.803624Z",
     "shell.execute_reply.started": "2025-06-11T12:41:27.800117Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store Name', 'Name of the Reviewer', 'review_datetime_utc',\n",
       "       'review_rating', 'Avg Rating', 'year', 'month', 'review_text',\n",
       "       'Store Code Cleaned', 'Commentor Name', 'Customer Confidence',\n",
       "       'Store Experience', 'Store Staff', 'Product Design', 'Product Variety',\n",
       "       'Discount', 'Making Charge', 'Price', 'Product Quality',\n",
       "       'Jewellery Exchange', 'Country', 'Catchment', 'Grouped Store Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "797fa2a6-5292-4b1f-8b4b-7371db8fcfbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:43:09.683791Z",
     "iopub.status.busy": "2025-06-11T12:43:09.683499Z",
     "iopub.status.idle": "2025-06-11T12:43:09.785715Z",
     "shell.execute_reply": "2025-06-11T12:43:09.785215Z",
     "shell.execute_reply.started": "2025-06-11T12:43:09.683772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store Name                   0\n",
       "Name of the Reviewer         0\n",
       "review_datetime_utc      17162\n",
       "review_rating                0\n",
       "Avg Rating                  70\n",
       "year                         0\n",
       "month                        0\n",
       "review_text              23978\n",
       "Store Code Cleaned      179308\n",
       "Commentor Name               0\n",
       "Customer Confidence          0\n",
       "Store Experience             0\n",
       "Store Staff                  0\n",
       "Product Design               0\n",
       "Product Variety              0\n",
       "Discount                     0\n",
       "Making Charge                0\n",
       "Price                        0\n",
       "Product Quality              0\n",
       "Jewellery Exchange           0\n",
       "Country                      0\n",
       "Catchment                    0\n",
       "Grouped Store Name           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ca1bb-a1c4-4d1e-8f9b-9b2d91caa25a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adding 'Total Reviews' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "876ae46f-5a77-47e2-9563-2a99123c3bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T12:45:22.706918Z",
     "iopub.status.busy": "2025-06-11T12:45:22.706597Z",
     "iopub.status.idle": "2025-06-11T12:45:22.726498Z",
     "shell.execute_reply": "2025-06-11T12:45:22.726027Z",
     "shell.execute_reply.started": "2025-06-11T12:45:22.706896Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)',\n",
       " 'Bhima Jewellers - Al Karama',\n",
       " 'Bhindi Jewellers-Decatur, GA',\n",
       " 'Evermark Jewelry-Johns Creek, GA',\n",
       " 'Jared-Algonquin, IL',\n",
       " 'Jared-Aurora, IL',\n",
       " 'Jared-Bolingbrook, IL',\n",
       " 'Jared-Lombard, IL',\n",
       " 'Jared-Orland Park, IL',\n",
       " 'Jared-Schaumburg, IL',\n",
       " 'Jared-Vernon Hills, IL',\n",
       " 'Joyalukkas Jewellery - Al Barsha',\n",
       " 'Joyalukkas Jewellery - Al Fahidi st - Al Fahidi',\n",
       " 'Joyalukkas Jewellery - Al Karama',\n",
       " 'Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi',\n",
       " 'Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi',\n",
       " 'Joyalukkas Jewellery - Shabia - Abu Dhabi',\n",
       " 'Joyalukkas Jewellery-Chicago, IL',\n",
       " 'Joyalukkas Jewellery-Frisco, TX',\n",
       " 'Joyalukkas Jewellery-Houston, TX',\n",
       " 'Joyalukkas Jewellery-Suwanee, GA',\n",
       " 'Kanz Jewellers',\n",
       " 'Malabar Gold & Diamonds - Silicon Oasis Central',\n",
       " 'Malabar Gold & Diamonds-Chicago, IL',\n",
       " 'Malabar Gold & Diamonds-Frisco, TX',\n",
       " 'Malabar Gold & Diamonds-Iselin, NJ',\n",
       " 'Malabar Gold & Diamonds-Naperville, IL',\n",
       " 'Malabar Gold and Diamonds - Al Barsha - Dubai',\n",
       " 'Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)',\n",
       " 'Malabar Gold and Diamonds - Al Karama - Dubai',\n",
       " 'Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi',\n",
       " 'Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi',\n",
       " 'Malabar Gold and Diamonds - Hamdan Street ( Branch 1)',\n",
       " 'Malabar Gold and Diamonds - Hamdan Street (Branch 2)',\n",
       " 'Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed',\n",
       " 'Malabar Gold and Diamonds - Meena Bazar - Dubai',\n",
       " 'Malabar Gold and Diamonds - Shabia Musaffah',\n",
       " 'Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)',\n",
       " 'Malani Jewellers-Richardson, TX',\n",
       " 'May Jewelers-Vienna, VA',\n",
       " 'Meena Jewellers - Meena Bazar',\n",
       " 'Mint Jewels - Al Karama',\n",
       " 'Sona Jewelers-Iselin, NJ',\n",
       " 'Tanishq Jewellers-Al Barsha, DB',\n",
       " 'Tanishq Jewellers-Al Fahidi, DB',\n",
       " 'Tanishq Jewellers-Al Karama, DB',\n",
       " 'Tanishq Jewellers-Hamdan Bin Mohammed Street, AD',\n",
       " 'Tanishq Jewellers-Meena Bazar, DB',\n",
       " 'Tanishq Jewellers-Silicon Central, DB',\n",
       " 'Tanishq-Chicago, IL',\n",
       " 'Tanishq-Frisco, TX',\n",
       " 'Tanishq-Houston, TX',\n",
       " 'Tanishq-New Jersey, NJ',\n",
       " 'Tiffany & Co-Chicago, IL',\n",
       " 'Tiffany & Co-East Rutherford, NJ',\n",
       " 'Tiffany & Co-Hackensack, NJ',\n",
       " 'Tiffany & Co-Northbrook, IL',\n",
       " 'Tiffany & Co-Paramus, NJ',\n",
       " 'Tiffany & Co-Red Bank, NJ',\n",
       " 'Tiffany & Co-Richmond, VA',\n",
       " 'Tiffany & Co-Short Hills, NJ',\n",
       " 'Tiffany & Co-Skokie, IL',\n",
       " 'Tiffany & Co-Vienna, VA',\n",
       " 'VBJ Jewellers-Frisco, TX',\n",
       " 'Mia-Al Wahda Mall, AD',\n",
       " 'Mia-Burjuman, DB',\n",
       " 'Tanishq Jewellers-Avenues Mall, OM',\n",
       " 'Tanishq-Atlanta, GA',\n",
       " 'Tanishq Jewellers-Festival City, QA',\n",
       " 'Tanishq Jewellers-Gold Souk, DB',\n",
       " 'Tanishq Jewellers-Lulu Hypermarket, QA',\n",
       " 'Tanishq Jewellers-UW Mall Al Mankhool, DB',\n",
       " 'Tanishq Jewellers-Rolla, SH',\n",
       " 'Tanishq-Redmond Seattle, WA',\n",
       " 'Tanishq-Santa Clara, CA',\n",
       " 'Tanishq Jewellers-Sharjah Central, SH',\n",
       " 'Tanishq Jewellers-Taj, DB']"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s['Store Name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "14baba43-ae7a-449f-86d8-50b144722bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:10:41.269613Z",
     "iopub.status.busy": "2025-06-11T14:10:41.269282Z",
     "iopub.status.idle": "2025-06-11T14:10:41.276734Z",
     "shell.execute_reply": "2025-06-11T14:10:41.276045Z",
     "shell.execute_reply.started": "2025-06-11T14:10:41.269589Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "store_to_total_rating_dict = {\n",
    "                                \"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)\" : 1337,\n",
    "                                \"Bhima Jewellers - Al Karama\" : 1303,\n",
    "                                \"Bhindi Jewellers-Decatur, GA\" : 409,\n",
    "                                \"Evermark Jewelry-Johns Creek, GA\" : 27,\n",
    "                                \"Jared-Algonquin, IL\" : 378,\n",
    "                                \"Jared-Aurora, IL\" : 254,\n",
    "                                \"Jared-Bolingbrook, IL\" : 397,\n",
    "                                \"Jared-Lombard, IL\" : 193,\n",
    "                                \"Jared-Orland Park, IL\" : 349,\n",
    "                                \"Jared-Schaumburg, IL\" : 531,\n",
    "                                \"Jared-Vernon Hills, IL\" : 343,\n",
    "                                \"Joyalukkas Jewellery - Al Barsha\" : 3090,\n",
    "                                \"Joyalukkas Jewellery - Al Fahidi st - Al Fahidi\" : 12261,\n",
    "                                \"Joyalukkas Jewellery - Al Karama\" : 7174,\n",
    "                                \"Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi\" : 3463,\n",
    "                                \"Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi\" : 1730,\n",
    "                                \"Joyalukkas Jewellery - Shabia - Abu Dhabi\" : 1985,\n",
    "                                \"Joyalukkas Jewellery-Chicago, IL\" : 2780,\n",
    "                                \"Joyalukkas Jewellery-Frisco, TX\" : 2296,\n",
    "                                \"Joyalukkas Jewellery-Houston, TX\" : 2200,\n",
    "                                \"Joyalukkas Jewellery-Suwanee, GA\" : 1970,\n",
    "                                \"Kanz Jewellers\" : 1238,\n",
    "                                \"Malabar Gold & Diamonds - Silicon Oasis Central\" : 1713,\n",
    "                                \"Malabar Gold & Diamonds-Chicago, IL\" : 3574,\n",
    "                                \"Malabar Gold & Diamonds-Frisco, TX\" : 3969,\n",
    "                                \"Malabar Gold & Diamonds-Iselin, NJ\" : 7416,\n",
    "                                \"Malabar Gold & Diamonds-Naperville, IL\" : 2027,\n",
    "                                \"Malabar Gold and Diamonds - Al Barsha - Dubai\" : 11456,\n",
    "                                \"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)\" : 11326,\n",
    "                                \"Malabar Gold and Diamonds - Al Karama - Dubai\" : 9035,\n",
    "                                \"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi\" : 7872,\n",
    "                                \"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi\" : 5331,\n",
    "                                \"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)\" : 6132,\n",
    "                                \"Malabar Gold and Diamonds - Hamdan Street (Branch 2)\" : 11562,\n",
    "                                \"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed\" : 14859,\n",
    "                                \"Malabar Gold and Diamonds - Meena Bazar - Dubai\" : 12438,\n",
    "                                \"Malabar Gold and Diamonds - Shabia Musaffah\" : 10887,\n",
    "                                \"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)\" : 4620,\n",
    "                                \"Malani Jewellers-Richardson, TX\" : 6913,\n",
    "                                \"May Jewelers-Vienna, VA\" : 164,\n",
    "                                \"Meena Jewellers - Meena Bazar\" : 2723,\n",
    "                                \"Mia-Al Wahda Mall, AD\" : 23,\n",
    "                                \"Mia-Burjuman, DB\" : 619,\n",
    "                                \"Mint Jewels - Al Karama\" : 5413,\n",
    "                                \"Sona Jewelers-Iselin, NJ\" : 1288,\n",
    "                                \"Tanishq Jewellers-Al Barsha, DB\" : 3267,\n",
    "                                \"Tanishq Jewellers-Al Fahidi, DB\" : 3880,\n",
    "                                \"Tanishq Jewellers-Al Karama, DB\" : 2049,\n",
    "                                \"Tanishq Jewellers-Avenues Mall, OM\" : 78,\n",
    "                                \"Tanishq Jewellers-Festival City, QA\" : 111,\n",
    "                                \"Tanishq Jewellers-Gold Souk, DB\" : 979,\n",
    "                                \"Tanishq Jewellers-Hamdan Bin Mohammed Street, AD\" : 2270,\n",
    "                                \"Tanishq Jewellers-Lulu Hypermarket, QA\" : 425,\n",
    "                                \"Tanishq Jewellers-Meena Bazar, DB\" : 3973,\n",
    "                                \"Tanishq Jewellers-Rolla, SH\" : 270,\n",
    "                                \"Tanishq Jewellers-Sharjah Central, SH\" : 864,\n",
    "                                \"Tanishq Jewellers-Silicon Central, DB\" : 1538,\n",
    "                                \"Tanishq Jewellers-Taj, DB\" : 166,\n",
    "                                \"Tanishq Jewellers-UW Mall Al Mankhool, DB\" : 36,\n",
    "                                \"Tanishq-Atlanta, GA\" : 377,\n",
    "                                \"Tanishq-Chicago, IL\" : 297,\n",
    "                                \"Tanishq-Frisco, TX\" : 1203,\n",
    "                                \"Tanishq-Houston, TX\" : 382,\n",
    "                                \"Tanishq-New Jersey, NJ\" : 749,\n",
    "                                \"Tanishq-Redmond Seattle, WA\" : 173,\n",
    "                                \"Tanishq-Santa Clara, CA\" : 89,\n",
    "                                \"Tiffany & Co-Chicago, IL\" : 548,\n",
    "                                \"Tiffany & Co-East Rutherford, NJ\" : 30,\n",
    "                                \"Tiffany & Co-Hackensack, NJ\" : 73,\n",
    "                                \"Tiffany & Co-Northbrook, IL\" : 90,\n",
    "                                \"Tiffany & Co-Paramus, NJ\" : 103,\n",
    "                                \"Tiffany & Co-Red Bank, NJ\" : 97,\n",
    "                                \"Tiffany & Co-Richmond, VA\" : 88,\n",
    "                                \"Tiffany & Co-Short Hills, NJ\" : 199,\n",
    "                                \"Tiffany & Co-Skokie, IL\" : 87,\n",
    "                                \"Tiffany & Co-Vienna, VA\" : 296,\n",
    "                                \"VBJ Jewellers-Frisco, TX\" : 1268\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "4a827e26-ee5f-46ee-8bfe-62cf8f900a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:10:48.170888Z",
     "iopub.status.busy": "2025-06-11T14:10:48.170525Z",
     "iopub.status.idle": "2025-06-11T14:10:48.185224Z",
     "shell.execute_reply": "2025-06-11T14:10:48.184658Z",
     "shell.execute_reply.started": "2025-06-11T14:10:48.170868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Column Creation - 'Total Reviews'\n",
    "combined_df_with_s['Total Reviews'] = combined_df_with_s['Store Name'].map(store_to_total_rating_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "4c2c3e5b-87a6-4ea0-ab15-b2738343eaf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:12:04.251289Z",
     "iopub.status.busy": "2025-06-11T14:12:04.250966Z",
     "iopub.status.idle": "2025-06-11T14:12:04.256114Z",
     "shell.execute_reply": "2025-06-11T14:12:04.255574Z",
     "shell.execute_reply.started": "2025-06-11T14:12:04.251267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s['Total Reviews'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "db3e5126-967c-46ab-b442-4285a4cbd666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:23:49.315447Z",
     "iopub.status.busy": "2025-06-11T14:23:49.315147Z",
     "iopub.status.idle": "2025-06-11T14:23:49.601094Z",
     "shell.execute_reply": "2025-06-11T14:23:49.600454Z",
     "shell.execute_reply.started": "2025-06-11T14:23:49.315426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3186"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "234b2970-eb57-46e5-98d3-3b59c2b7f664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:24:38.039125Z",
     "iopub.status.busy": "2025-06-11T14:24:38.038503Z",
     "iopub.status.idle": "2025-06-11T14:24:38.365339Z",
     "shell.execute_reply": "2025-06-11T14:24:38.364636Z",
     "shell.execute_reply.started": "2025-06-11T14:24:38.039099Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_df_with_s.drop_duplicates(inplace=True)\n",
    "combined_df_with_s.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "e9c5f444-e2c8-4281-8502-faec611597de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:24:42.042890Z",
     "iopub.status.busy": "2025-06-11T14:24:42.042549Z",
     "iopub.status.idle": "2025-06-11T14:25:51.363388Z",
     "shell.execute_reply": "2025-06-11T14:25:51.362805Z",
     "shell.execute_reply.started": "2025-06-11T14:24:42.042867Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_df_with_s.to_excel(\"final_sentiment_mapped/combined_df_final_S_full.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "311d5431-959e-4246-965c-9712c4560887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:26:47.889486Z",
     "iopub.status.busy": "2025-06-11T14:26:47.889151Z",
     "iopub.status.idle": "2025-06-11T14:26:48.436234Z",
     "shell.execute_reply": "2025-06-11T14:26:48.435618Z",
     "shell.execute_reply.started": "2025-06-11T14:26:47.889464Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_df_with_s['review_datetime_utc'] = pd.to_datetime(combined_df_with_s['review_datetime_utc'], errors='coerce')\n",
    "\n",
    "combined_df_with_s.to_parquet(\"final_sentiment_mapped/combined_df_final_S_full.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e7258d22-453a-44fa-b0a1-36cd55b14b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:27:39.011962Z",
     "iopub.status.busy": "2025-06-11T14:27:39.011632Z",
     "iopub.status.idle": "2025-06-11T14:27:39.435328Z",
     "shell.execute_reply": "2025-06-11T14:27:39.434664Z",
     "shell.execute_reply.started": "2025-06-11T14:27:39.011940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204047\n"
     ]
    }
   ],
   "source": [
    "check_parquet_df = pd.read_parquet(\"final_sentiment_mapped/combined_df_final_S_full.parquet\")\n",
    "print(len(check_parquet_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "c6be8810-c52d-49ea-a2fb-47c1bea22b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:28:02.894768Z",
     "iopub.status.busy": "2025-06-11T14:28:02.894027Z",
     "iopub.status.idle": "2025-06-11T14:28:02.898126Z",
     "shell.execute_reply": "2025-06-11T14:28:02.897588Z",
     "shell.execute_reply.started": "2025-06-11T14:28:02.894731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204047\n"
     ]
    }
   ],
   "source": [
    "print(len(combined_df_with_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "c3783a5f-e1e6-411e-85b1-9cd3f75bfac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:28:35.872942Z",
     "iopub.status.busy": "2025-06-11T14:28:35.872504Z",
     "iopub.status.idle": "2025-06-11T14:28:35.877654Z",
     "shell.execute_reply": "2025-06-11T14:28:35.877090Z",
     "shell.execute_reply.started": "2025-06-11T14:28:35.872910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204047, 24)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65de2d3-f5ac-497d-9643-61327c780e73",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Keywords & Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "e9ed72d0-d4a2-4337-814a-0d21b1bea8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:34:39.229201Z",
     "iopub.status.busy": "2025-06-11T14:34:39.228856Z",
     "iopub.status.idle": "2025-06-11T14:34:39.480115Z",
     "shell.execute_reply": "2025-06-11T14:34:39.479415Z",
     "shell.execute_reply.started": "2025-06-11T14:34:39.229168Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_with_s_current = pd.read_parquet(\"final_sentiment_mapped/combined_df_final_S_full.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "2aa81716-7ec4-460c-909d-b7537a1c7660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:34:44.283062Z",
     "iopub.status.busy": "2025-06-11T14:34:44.282709Z",
     "iopub.status.idle": "2025-06-11T14:34:44.381972Z",
     "shell.execute_reply": "2025-06-11T14:34:44.381305Z",
     "shell.execute_reply.started": "2025-06-11T14:34:44.283029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204047 entries, 0 to 204046\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   Store Name            204047 non-null  object        \n",
      " 1   Name of the Reviewer  204047 non-null  object        \n",
      " 2   review_datetime_utc   186890 non-null  datetime64[ns]\n",
      " 3   review_rating         204047 non-null  int64         \n",
      " 4   Avg Rating            203977 non-null  float64       \n",
      " 5   year                  204047 non-null  int64         \n",
      " 6   month                 204047 non-null  int64         \n",
      " 7   review_text           180317 non-null  object        \n",
      " 8   Store Code Cleaned    27828 non-null   object        \n",
      " 9   Commentor Name        204047 non-null  object        \n",
      " 10  Customer Confidence   204047 non-null  int64         \n",
      " 11  Store Experience      204047 non-null  int64         \n",
      " 12  Store Staff           204047 non-null  int64         \n",
      " 13  Product Design        204047 non-null  int64         \n",
      " 14  Product Variety       204047 non-null  int64         \n",
      " 15  Discount              204047 non-null  int64         \n",
      " 16  Making Charge         204047 non-null  int64         \n",
      " 17  Price                 204047 non-null  int64         \n",
      " 18  Product Quality       204047 non-null  int64         \n",
      " 19  Jewellery Exchange    204047 non-null  int64         \n",
      " 20  Country               204047 non-null  object        \n",
      " 21  Catchment             204047 non-null  object        \n",
      " 22  Grouped Store Name    204047 non-null  object        \n",
      " 23  Total Reviews         204047 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(14), object(8)\n",
      "memory usage: 37.4+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df_with_s_current.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "4098db14-c4e0-4f00-aec1-1ee7dadc66be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:34:49.639473Z",
     "iopub.status.busy": "2025-06-11T14:34:49.639132Z",
     "iopub.status.idle": "2025-06-11T14:34:49.646318Z",
     "shell.execute_reply": "2025-06-11T14:34:49.645727Z",
     "shell.execute_reply.started": "2025-06-11T14:34:49.639443Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2024, 2023, 2022, 2021, 2025]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current['year'].unique().tolist()                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "80047902-18e7-4751-b438-b16e0d4a823b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:35:33.738203Z",
     "iopub.status.busy": "2025-06-11T14:35:33.737869Z",
     "iopub.status.idle": "2025-06-11T14:35:33.773091Z",
     "shell.execute_reply": "2025-06-11T14:35:33.772392Z",
     "shell.execute_reply.started": "2025-06-11T14:35:33.738184Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_with_s_current = combined_df_with_s_current[combined_df_with_s_current['year'].isin([2024,2025])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "bf9ce41c-e9e0-42ab-8a3e-0e6680804ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:35:34.522900Z",
     "iopub.status.busy": "2025-06-11T14:35:34.522525Z",
     "iopub.status.idle": "2025-06-11T14:35:34.527143Z",
     "shell.execute_reply": "2025-06-11T14:35:34.526488Z",
     "shell.execute_reply.started": "2025-06-11T14:35:34.522878Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115594"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df_with_s_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "f6847620-6d4d-48d7-b72f-dd22ed1913f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:35:39.231788Z",
     "iopub.status.busy": "2025-06-11T14:35:39.231463Z",
     "iopub.status.idle": "2025-06-11T14:35:39.239102Z",
     "shell.execute_reply": "2025-06-11T14:35:39.238456Z",
     "shell.execute_reply.started": "2025-06-11T14:35:39.231770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2024    77913\n",
       "2025    37681\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_with_s_current['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "0fca0ce2-dba5-470d-8230-649b73e8d3a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:37:30.737144Z",
     "iopub.status.busy": "2025-06-11T14:37:30.736821Z",
     "iopub.status.idle": "2025-06-11T14:38:20.192217Z",
     "shell.execute_reply": "2025-06-11T14:38:20.191621Z",
     "shell.execute_reply.started": "2025-06-11T14:37:30.737123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_with_s_current.to_excel(\"temp/data_for_phrases.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e35e048c-4571-408c-9c86-a38698f9ce40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T14:39:57.820899Z",
     "iopub.status.busy": "2025-06-11T14:39:57.820560Z",
     "iopub.status.idle": "2025-06-11T14:40:41.982437Z",
     "shell.execute_reply": "2025-06-11T14:40:41.981842Z",
     "shell.execute_reply.started": "2025-06-11T14:39:57.820875Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_with_s_current.to_excel(\"final_sentiment_mapped/combined_df_final_S.xlsx\", index=False)\n",
    "combined_df_with_s_current.to_parquet(\"final_sentiment_mapped/combined_df_final_S.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "2c3fd496-25c6-40e6-bfcd-f2c5b143a803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:19:09.082479Z",
     "iopub.status.busy": "2025-06-11T15:19:09.082137Z",
     "iopub.status.idle": "2025-06-11T15:19:09.700653Z",
     "shell.execute_reply": "2025-06-11T15:19:09.699949Z",
     "shell.execute_reply.started": "2025-06-11T15:19:09.082455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword_mappings = {\n",
    "                        \"agd_mb_final_sen_df_jul\" : \"Arakkal Gold and Diamonds LLC - Meena Bazar - Bur Dubai (Branch 3)\",\n",
    "                        \"bhi_ak_final_sen_df_jul\" : \"Bhima Jewellers - Al Karama\",\n",
    "                        \"bhi_dec_ga_final_sen_df_jul\" : \"Bhindi Jewellers-Decatur, GA\",\n",
    "                        \"eve_joh_ga_final_sen_df_jul\" : \"Evermark Jewelry-Johns Creek, GA\",\n",
    "                        \"jar_alg_il_final_sen_df_jul\" : \"Jared-Algonquin, IL\",\n",
    "                        \"jar_aur_il_final_sen_df_jul\" : \"Jared-Aurora, IL\",\n",
    "                        \"jar_bol_il_final_sen_df_jul\" : \"Jared-Bolingbrook, IL\",\n",
    "                        \"jar_lom_il_final_sen_df_jul\" : \"Jared-Lombard, IL\",\n",
    "                        \"jar_orl_il_final_sen_df_jul\" : \"Jared-Orland Park, IL\",\n",
    "                        \"jar_sch_il_final_sen_df_jul\" : \"Jared-Schaumburg, IL\",\n",
    "                        \"jar_ver_il_final_sen_df_jul\" : \"Jared-Vernon Hills, IL\",\n",
    "                        \"joy_ab_final_sen_df_jul\" : \"Joyalukkas Jewellery - Al Barsha\",\n",
    "                        \"joy_ak_final_sen_df_jul\" : \"Joyalukkas Jewellery - Al Karama\",\n",
    "                        \"joy_chi_il_final_sen_df_jul\" : \"Joyalukkas Jewellery-Chicago, IL\",\n",
    "                        \"joy_dm_ad_final_sen_df_jul\" : \"Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi\",\n",
    "                        \"joy_fri_tx_final_sen_df_jul\" : \"Joyalukkas Jewellery-Frisco, TX\",\n",
    "                        \"joy_hou_tx_final_sen_df_jul\" : \"Joyalukkas Jewellery-Houston, TX\",\n",
    "                        \"joy_mz_ad_final_sen_df_jul\" : \"Joyalukkas Jewellery - Madinat Zayed Shopping Centre - Abu Dhabi\",\n",
    "                        \"joy_sh_ad_final_sen_df_jul\" : \"Joyalukkas Jewellery - Shabia - Abu Dhabi\",\n",
    "                        \"joy_st_af_final_sen_df_jul\" : \"Joyalukkas Jewellery - Al Fahidi st - Al Fahidi\",\n",
    "                        \"joy_suw_ga_final_sen_df_jul\" : \"Joyalukkas Jewellery-Suwanee, GA\",\n",
    "                        \"kan_mb_final_sen_df_jul\" : \"Kanz Jewellers\",\n",
    "                        \"mal_ab_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Al Barsha - Dubai\",\n",
    "                        \"mal_ak_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Al Karama - Dubai\",\n",
    "                        \"mal_aw_ad_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Al Wahda Mall - Abu Dhabi\",\n",
    "                        \"mal_b1_ad_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Hamdan Street ( Branch 1)\",\n",
    "                        \"mal_b1_af_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)\",\n",
    "                        \"mal_b2_ad_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Hamdan Street (Branch 2)\",\n",
    "                        \"mal_b2_af_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Souq Al Kabeer Building - Bur Dubai (Branch 2)\",\n",
    "                        \"mal_chi_il_final_sen_df_jul\" : \"Malabar Gold & Diamonds-Chicago, IL\",\n",
    "                        \"mal_dm_ad_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Dalma Mall - Abu Dhabi\",\n",
    "                        \"mal_fri_tx_final_sen_df_jul\" : \"Malabar Gold & Diamonds-Frisco, TX\",\n",
    "                        \"mal_ise_nj_final_sen_df_jul\" : \"Malabar Gold & Diamonds-Iselin, NJ\",\n",
    "                        \"mal_lu_ad_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Lulu Hypermarket - Madinat Zayed\",\n",
    "                        \"mal_mb_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Meena Bazar - Dubai\",\n",
    "                        \"mal_nap_il_final_sen_df_jul\" : \"Malabar Gold & Diamonds-Naperville, IL\",\n",
    "                        \"mal_ric_tx_final_sen_df_jul\" : \"Malani Jewellers-Richardson, TX\",\n",
    "                        \"mal_sc_final_sen_df_jul\" : \"Malabar Gold & Diamonds - Silicon Oasis Central\",\n",
    "                        \"mal_sh_ad_final_sen_df_jul\" : \"Malabar Gold and Diamonds - Shabia Musaffah\",\n",
    "                        \"may_vie_va_final_sen_df_jul\" : \"May Jewelers-Vienna, VA\",\n",
    "                        \"mia_awm_ad_final_sen_df_jul\" : \"Mia-Al Wahda Mall, AD\",\n",
    "                        \"mia_bur_db_final_sen_df_jul\" : \"Mia-Burjuman, DB\",\n",
    "                        \"min_ak_final_sen_df_jul\" : \"Mint Jewels - Al Karama\",\n",
    "                        \"mna_mb_final_sen_df_jul\" : \"Meena Jewellers - Meena Bazar\",\n",
    "                        \"son_ise_nj_final_sen_df_jul\" : \"Sona Jewelers-Iselin, NJ\",\n",
    "                        \"tan_am_om_final_sen_df_jul\" : \"Tanishq Jewellers-Avenues Mall, OM\",\n",
    "                        \"tan_atl_ga_final_sen_df_jul\" : \"Tanishq-Atlanta, GA\",\n",
    "                        \"tan_bar_db_final_sen_df_jul\" : \"Tanishq Jewellers-Al Barsha, DB\",\n",
    "                        \"tan_chi_il_final_sen_df_jul\" : \"Tanishq-Chicago, IL\",\n",
    "                        \"tan_fah_db_final_sen_df_jul\" : \"Tanishq Jewellers-Al Fahidi, DB\",\n",
    "                        \"tan_fc_qa_final_sen_df_jul\" : \"Tanishq Jewellers-Festival City, QA\",\n",
    "                        \"tan_fri_tx_final_sen_df_jul\" : \"Tanishq-Frisco, TX\",\n",
    "                        \"tan_gs_db_final_sen_df_jul\" : \"Tanishq Jewellers-Gold Souk, DB\",\n",
    "                        \"tan_ham_ad_final_sen_df_jul\" : \"Tanishq Jewellers-Hamdan Bin Mohammed Street, AD\",\n",
    "                        \"tan_hou_tx_final_sen_df_jul\" : \"Tanishq-Houston, TX\",\n",
    "                        \"tan_kar_db_final_sen_df_jul\" : \"Tanishq Jewellers-Al Karama, DB\",\n",
    "                        \"tan_lul_qa_final_sen_df_jul\" : \"Tanishq Jewellers-Lulu Hypermarket, QA\",\n",
    "                        \"tan_mank_db_final_sen_df_jul\" : \"Tanishq Jewellers-UW Mall Al Mankhool, DB\",\n",
    "                        \"tan_mee_db_final_sen_df_jul\" : \"Tanishq Jewellers-Meena Bazar, DB\",\n",
    "                        \"tan_new_nj_final_sen_df_jul\" : \"Tanishq-New Jersey, NJ\",\n",
    "                        \"tan_rol_sh_final_sen_df_jul\" : \"Tanishq Jewellers-Rolla, SH\",\n",
    "                        \"tan_rse_wa_final_sen_df_jul\" : \"Tanishq-Redmond Seattle, WA\",\n",
    "                        \"tan_sc_ca_final_sen_df_jul\" : \"Tanishq-Santa Clara, CA\",\n",
    "                        \"tan_sc_sh_final_sen_df_jul\" : \"Tanishq Jewellers-Sharjah Central, SH\",\n",
    "                        \"tan_sil_db_final_sen_df_jul\" : \"Tanishq Jewellers-Silicon Central, DB\",\n",
    "                        \"tan_taj_db_final_sen_df_jul\" : \"Tanishq Jewellers-Taj, DB\",\n",
    "                        \"tif_chi_il_final_sen_df_jul\" : \"Tiffany & Co-Chicago, IL\",\n",
    "                        \"tif_eas_nj_final_sen_df_jul\" : \"Tiffany & Co-East Rutherford, NJ\",\n",
    "                        \"tif_hac_nj_final_sen_df_jul\" : \"Tiffany & Co-Hackensack, NJ\",\n",
    "                        \"tif_nor_il_final_sen_df_jul\" : \"Tiffany & Co-Northbrook, IL\",\n",
    "                        \"tif_par_nj_final_sen_df_jul\" : \"Tiffany & Co-Paramus, NJ\",\n",
    "                        \"tif_red_nj_final_sen_df_jul\" : \"Tiffany & Co-Red Bank, NJ\",\n",
    "                        \"tif_ric_va_final_sen_df_jul\" : \"Tiffany & Co-Richmond, VA\",\n",
    "                        \"tif_sho_nj_final_sen_df_jul\" : \"Tiffany & Co-Short Hills, NJ\",\n",
    "                        \"tif_sko_il_final_sen_df_jul\" : \"Tiffany & Co-Skokie, IL\",\n",
    "                        \"tif_vie_va_final_sen_df_jul\" : \"Tiffany & Co-Vienna, VA\",\n",
    "                        \"vbj_fri_tx_final_sen_df_jul\" : \"VBJ Jewellers-Frisco, TX\"\n",
    "                    }\n",
    "\n",
    "#Initialize an empty dictionary to store your dataframes\n",
    "keyword_dataframes = {}\n",
    "\n",
    "#Loop through the mappings and filter combined_df_21to23 for each title\n",
    "for df_name, title in keyword_mappings.items():\n",
    "    filtered_df = combined_df_with_s_current[combined_df_with_s_current['Store Name'] == title].reset_index(drop=True)\n",
    "    keyword_dataframes[df_name] = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "aad40d3a-c59b-4889-b67e-8a72590c0097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:19:10.761138Z",
     "iopub.status.busy": "2025-06-11T15:19:10.760729Z",
     "iopub.status.idle": "2025-06-11T15:19:10.776766Z",
     "shell.execute_reply": "2025-06-11T15:19:10.776187Z",
     "shell.execute_reply.started": "2025-06-11T15:19:10.761110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Name of the Reviewer</th>\n",
       "      <th>review_datetime_utc</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Avg Rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>review_text</th>\n",
       "      <th>Store Code Cleaned</th>\n",
       "      <th>Commentor Name</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "      <th>Country</th>\n",
       "      <th>Catchment</th>\n",
       "      <th>Grouped Store Name</th>\n",
       "      <th>Total Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Renuka Acharya</td>\n",
       "      <td>2024-06-10 14:03:38.830</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>Very good collection and service was excellent</td>\n",
       "      <td>None</td>\n",
       "      <td>Renuka Acharya</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Junaid Pervaiz</td>\n",
       "      <td>2024-06-09 22:23:49.653</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>We visited the shop 09/06/2024 evening. We wer...</td>\n",
       "      <td>None</td>\n",
       "      <td>Junaid Pervaiz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Vineetha Vijayan</td>\n",
       "      <td>2024-06-08 16:45:40.125</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Vineetha Vijayan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Bency</td>\n",
       "      <td>2024-06-08 15:38:22.884</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bency</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>jubin jose</td>\n",
       "      <td>2024-06-08 14:45:58.498</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>jubin jose</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC</td>\n",
       "      <td>Al Karama</td>\n",
       "      <td>Bhima</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Name of the Reviewer     review_datetime_utc  \\\n",
       "0  Bhima Jewellers - Al Karama       Renuka Acharya 2024-06-10 14:03:38.830   \n",
       "1  Bhima Jewellers - Al Karama       Junaid Pervaiz 2024-06-09 22:23:49.653   \n",
       "2  Bhima Jewellers - Al Karama     Vineetha Vijayan 2024-06-08 16:45:40.125   \n",
       "3  Bhima Jewellers - Al Karama                Bency 2024-06-08 15:38:22.884   \n",
       "4  Bhima Jewellers - Al Karama           jubin jose 2024-06-08 14:45:58.498   \n",
       "\n",
       "   review_rating  Avg Rating  year  month  \\\n",
       "0              5         4.7  2024      6   \n",
       "1              5         4.7  2024      6   \n",
       "2              5         4.7  2024      6   \n",
       "3              5         4.7  2024      6   \n",
       "4              5         4.7  2024      6   \n",
       "\n",
       "                                         review_text Store Code Cleaned  \\\n",
       "0     Very good collection and service was excellent               None   \n",
       "1  We visited the shop 09/06/2024 evening. We wer...               None   \n",
       "2                                               None               None   \n",
       "3                                               None               None   \n",
       "4                                               Good               None   \n",
       "\n",
       "     Commentor Name  Customer Confidence  Store Experience  Store Staff  \\\n",
       "0    Renuka Acharya                    0                 0            1   \n",
       "1    Junaid Pervaiz                    0                 1            1   \n",
       "2  Vineetha Vijayan                    0                 0            0   \n",
       "3             Bency                    0                 0            0   \n",
       "4        jubin jose                    0                 0            0   \n",
       "\n",
       "   Product Design  Product Variety  Discount  Making Charge  Price  \\\n",
       "0               0                1         0              0      0   \n",
       "1               0                0         0              0      0   \n",
       "2               0                0         0              0      0   \n",
       "3               0                0         0              0      0   \n",
       "4               0                0         0              0      0   \n",
       "\n",
       "   Product Quality  Jewellery Exchange Country  Catchment Grouped Store Name  \\\n",
       "0                0                   0     GCC  Al Karama              Bhima   \n",
       "1                0                   0     GCC  Al Karama              Bhima   \n",
       "2                0                   0     GCC  Al Karama              Bhima   \n",
       "3                0                   0     GCC  Al Karama              Bhima   \n",
       "4                0                   0     GCC  Al Karama              Bhima   \n",
       "\n",
       "   Total Reviews  \n",
       "0           1303  \n",
       "1           1303  \n",
       "2           1303  \n",
       "3           1303  \n",
       "4           1303  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_dataframes[\"bhi_ak_final_sen_df_jul\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af5dc43-dee1-4973-ae72-147173a60ea8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fed3b4-6204-4b2d-a5be-e61fdf723570",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### bhi_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "16f300ae-de2d-48bf-bf03-5f68f8f320b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:28:41.507193Z",
     "iopub.status.busy": "2025-06-11T15:28:41.506708Z",
     "iopub.status.idle": "2025-06-11T15:29:06.061047Z",
     "shell.execute_reply": "2025-06-11T15:29:06.060369Z",
     "shell.execute_reply.started": "2025-06-11T15:28:41.507168Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  24.5\n",
      "Total Input Tokens -  16005\n",
      "Total Input Cost = USD  0.16\n",
      "Total Output Tokens -  617\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.18\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_bhi_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_bhi_ak=[0]\n",
    "keyword_input_token_bhi_ak = 0\n",
    "keyword_output_token_bhi_ak = 0\n",
    "keyword_start_time_loop_bhi_ak = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_bhi_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_bhi_ak[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_bhi_ak = keyword_dataframes['bhi_ak_final_sen_df_jul'][keyword_dataframes['bhi_ak_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_bhi_ak:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_bhi_ak,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_bhi_ak.append(keywords)\n",
    "        keyword_input_token_bhi_ak += input_tokens_loop\n",
    "        keyword_output_token_bhi_ak += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_bhi_ak = time.time()\n",
    "keyword_cost_input_token_bhi_ak = round((0.01/1000)*keyword_input_token_bhi_ak,2)\n",
    "keyword_cost_output_token_bhi_ak = round((0.03/1000)*keyword_output_token_bhi_ak,2)\n",
    "keyword_total_cost_bhi_ak = keyword_cost_input_token_bhi_ak + keyword_cost_output_token_bhi_ak\n",
    "keyword_total_time_loop_bhi_ak = keyword_end_time_loop_bhi_ak - keyword_start_time_loop_bhi_ak\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_bhi_ak[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_bhi_ak,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_bhi_ak)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_bhi_ak)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_bhi_ak)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_bhi_ak)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_bhi_ak,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "d63fccca-bdd1-41b7-9a3f-d0156b8857cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:29:06.062792Z",
     "iopub.status.busy": "2025-06-11T15:29:06.062239Z",
     "iopub.status.idle": "2025-06-11T15:29:06.118469Z",
     "shell.execute_reply": "2025-06-11T15:29:06.117926Z",
     "shell.execute_reply.started": "2025-06-11T15:29:06.062763Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustable :1, Trusted :1, Reliable :1, Trustwo...</td>\n",
       "      <td>great experience :8, good experience :7, excel...</td>\n",
       "      <td>helpful :12, friendly :10, patient :8, courteo...</td>\n",
       "      <td>designs :5, Design :3, designs :2, design :1</td>\n",
       "      <td>selection :4, collections :4, range :1</td>\n",
       "      <td>discounts :1, offers :1</td>\n",
       "      <td>reasonable :1, less :1</td>\n",
       "      <td>good pricing :1, fair :1, affordable :1, good ...</td>\n",
       "      <td>Good Quality:4, Durability:1, Quality:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Customer-centric and trustable major player :1...</td>\n",
       "      <td>great shopping experience :3, smooth shopping ...</td>\n",
       "      <td>very helpful :5, friendly and helpful :3, very...</td>\n",
       "      <td>great designs :2, excellent designs :1, stunni...</td>\n",
       "      <td>good selection :2, great selection :2, best co...</td>\n",
       "      <td>great discounts :1, good offers :1</td>\n",
       "      <td>transparency regarding making charges :1</td>\n",
       "      <td>right price :1, transparency and honesty in th...</td>\n",
       "      <td>Quality is the best:1, Quality and durability ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type  \\\n",
       "0  Bhima Jewellers - Al Karama  Positive  keywords   \n",
       "1  Bhima Jewellers - Al Karama  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trustable :1, Trusted :1, Reliable :1, Trustwo...   \n",
       "1  Customer-centric and trustable major player :1...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience :8, good experience :7, excel...   \n",
       "1  great shopping experience :3, smooth shopping ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :12, friendly :10, patient :8, courteo...   \n",
       "1  very helpful :5, friendly and helpful :3, very...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0       designs :5, Design :3, designs :2, design :1   \n",
       "1  great designs :2, excellent designs :1, stunni...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0             selection :4, collections :4, range :1   \n",
       "1  good selection :2, great selection :2, best co...   \n",
       "\n",
       "                             Discount  \\\n",
       "0             discounts :1, offers :1   \n",
       "1  great discounts :1, good offers :1   \n",
       "\n",
       "                              Making Charge  \\\n",
       "0                    reasonable :1, less :1   \n",
       "1  transparency regarding making charges :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good pricing :1, fair :1, affordable :1, good ...   \n",
       "1  right price :1, transparency and honesty in th...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0            Good Quality:4, Durability:1, Quality:1                     \n",
       "1  Quality is the best:1, Quality and durability ...                     "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_bhi_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_bhi_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_bhi_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'bhi_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_bhi_ak = pd.concat([positive_keywords_bhi_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_bhi_ak = pd.concat([positive_keywords_bhi_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_bhi_ak = positive_keywords_bhi_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_bhi_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9bbfaf-32fb-4460-a57a-292bf167436f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "b938c221-e7bc-4842-9ec8-246989ebdd4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:29:24.117017Z",
     "iopub.status.busy": "2025-06-11T15:29:24.116700Z",
     "iopub.status.idle": "2025-06-11T15:29:55.180428Z",
     "shell.execute_reply": "2025-06-11T15:29:55.179879Z",
     "shell.execute_reply.started": "2025-06-11T15:29:24.116995Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  31.1\n",
      "Total Input Tokens -  28660\n",
      "Total Input Cost = USD  0.29\n",
      "Total Output Tokens -  714\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.31\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_ab = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_ab=[0]\n",
    "keyword_input_token_joy_ab = 0\n",
    "keyword_output_token_joy_ab = 0\n",
    "keyword_start_time_loop_joy_ab = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_ab, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_ab[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_ab = keyword_dataframes['joy_ab_final_sen_df_jul'][keyword_dataframes['joy_ab_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_ab:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_ab,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_ab.append(keywords)\n",
    "        keyword_input_token_joy_ab += input_tokens_loop\n",
    "        keyword_output_token_joy_ab += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_ab = time.time()\n",
    "keyword_cost_input_token_joy_ab = round((0.01/1000)*keyword_input_token_joy_ab,2)\n",
    "keyword_cost_output_token_joy_ab = round((0.03/1000)*keyword_output_token_joy_ab,2)\n",
    "keyword_total_cost_joy_ab = keyword_cost_input_token_joy_ab + keyword_cost_output_token_joy_ab\n",
    "keyword_total_time_loop_joy_ab = keyword_end_time_loop_joy_ab - keyword_start_time_loop_joy_ab\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_ab[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_ab,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_ab)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_ab)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_ab)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_ab)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_ab,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "8c6da583-ee0b-467d-a60f-f9a2c8cdda8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:29:55.181699Z",
     "iopub.status.busy": "2025-06-11T15:29:55.181413Z",
     "iopub.status.idle": "2025-06-11T15:29:55.229997Z",
     "shell.execute_reply": "2025-06-11T15:29:55.229535Z",
     "shell.execute_reply.started": "2025-06-11T15:29:55.181679Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Al Barsha</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Reliable :2, Trust :1</td>\n",
       "      <td>good location :1, good ambience :1, pleasant a...</td>\n",
       "      <td>helpful : 45, friendly : 40, patient : 20, kno...</td>\n",
       "      <td>Good designs: 12, Nice designs: 5, Beautiful d...</td>\n",
       "      <td>Variety :3, Options :2, Choices :2, Selections...</td>\n",
       "      <td>discount :6, offer :5, offers :3, deal :2, dea...</td>\n",
       "      <td>making charges :3, making charge :1</td>\n",
       "      <td>good price :5, great prices :3, reasonable pri...</td>\n",
       "      <td>Good quality:3, Quality:2, Excellent:1</td>\n",
       "      <td>exchanging :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Al Barsha</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>You can fully trust the quality of their produ...</td>\n",
       "      <td>pleasant shopping atmosphere :1, enjoyable and...</td>\n",
       "      <td>very helpful : 10, extremely friendly : 8, ver...</td>\n",
       "      <td>Plenty of designs to choose from: 1, Beautiful...</td>\n",
       "      <td>Wide range of collections :2, Large collection...</td>\n",
       "      <td>good discount :3, great discount :2, attractiv...</td>\n",
       "      <td>reasonable making charges :1, good making char...</td>\n",
       "      <td>value for money :1, prices are the best :1, ch...</td>\n",
       "      <td>Good quality of jewelry:1, Quality exceeded my...</td>\n",
       "      <td>helping us buying new jewelry :1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Al Barsha  Positive  keywords   \n",
       "1  Joyalukkas Jewellery - Al Barsha  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                              Reliable :2, Trust :1   \n",
       "1  You can fully trust the quality of their produ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good location :1, good ambience :1, pleasant a...   \n",
       "1  pleasant shopping atmosphere :1, enjoyable and...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 45, friendly : 40, patient : 20, kno...   \n",
       "1  very helpful : 10, extremely friendly : 8, ver...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs: 12, Nice designs: 5, Beautiful d...   \n",
       "1  Plenty of designs to choose from: 1, Beautiful...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  Variety :3, Options :2, Choices :2, Selections...   \n",
       "1  Wide range of collections :2, Large collection...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :6, offer :5, offers :3, deal :2, dea...   \n",
       "1  good discount :3, great discount :2, attractiv...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                making charges :3, making charge :1   \n",
       "1  reasonable making charges :1, good making char...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good price :5, great prices :3, reasonable pri...   \n",
       "1  value for money :1, prices are the best :1, ch...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0             Good quality:3, Quality:2, Excellent:1   \n",
       "1  Good quality of jewelry:1, Quality exceeded my...   \n",
       "\n",
       "                 Jewellery Exchange  \n",
       "0                     exchanging :1  \n",
       "1  helping us buying new jewelry :1  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_ab = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_ab[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_ab:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_ab'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_ab = pd.concat([positive_keywords_joy_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_ab = pd.concat([positive_keywords_joy_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_ab = positive_keywords_joy_ab.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fd3b0-ce27-4d6b-a0d9-7ff8ea8cffc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_st_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "a99dce13-d006-4abf-9857-91b0986be1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:29:55.231148Z",
     "iopub.status.busy": "2025-06-11T15:29:55.230881Z",
     "iopub.status.idle": "2025-06-11T15:30:39.815958Z",
     "shell.execute_reply": "2025-06-11T15:30:39.815450Z",
     "shell.execute_reply.started": "2025-06-11T15:29:55.231123Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  44.6\n",
      "Total Input Tokens -  143319\n",
      "Total Input Cost = USD  1.43\n",
      "Total Output Tokens -  845\n",
      "Total Output Cost = USD  0.03\n",
      "Total Cost = USD  1.46\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_st_af = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_st_af=[0]\n",
    "keyword_input_token_joy_st_af = 0\n",
    "keyword_output_token_joy_st_af = 0\n",
    "keyword_start_time_loop_joy_st_af = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_st_af, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_st_af[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_st_af = keyword_dataframes['joy_st_af_final_sen_df_jul'][keyword_dataframes['joy_st_af_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_st_af:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_st_af,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_st_af.append(keywords)\n",
    "        keyword_input_token_joy_st_af += input_tokens_loop\n",
    "        keyword_output_token_joy_st_af += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_st_af = time.time()\n",
    "keyword_cost_input_token_joy_st_af = round((0.01/1000)*keyword_input_token_joy_st_af,2)\n",
    "keyword_cost_output_token_joy_st_af = round((0.03/1000)*keyword_output_token_joy_st_af,2)\n",
    "keyword_total_cost_joy_st_af = keyword_cost_input_token_joy_st_af + keyword_cost_output_token_joy_st_af\n",
    "keyword_total_time_loop_joy_st_af = keyword_end_time_loop_joy_st_af - keyword_start_time_loop_joy_st_af\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_st_af[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_st_af,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_st_af)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_st_af)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_st_af)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_st_af)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_st_af,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "6ea19481-e7bd-4e9c-a625-fc60be97c70d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:30:39.817774Z",
     "iopub.status.busy": "2025-06-11T15:30:39.817573Z",
     "iopub.status.idle": "2025-06-11T15:30:39.865650Z",
     "shell.execute_reply": "2025-06-11T15:30:39.865121Z",
     "shell.execute_reply.started": "2025-06-11T15:30:39.817757Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Al Fahidi st - Al Fahidi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Reliable :3, Trustable :2, Honest :2...</td>\n",
       "      <td>Good : 100, Excellent : 80, Nice : 60, Great :...</td>\n",
       "      <td>friendly : 50, helpful : 45, polite : 30, prof...</td>\n",
       "      <td>Good designs: 45, Excellent designs: 10, Nice ...</td>\n",
       "      <td>collection : 100, variety : 10, options : 5, c...</td>\n",
       "      <td>discount : 45, offer : 30, scheme : 15, deal :...</td>\n",
       "      <td>reasonable :5, low :3, discount :3, affordable...</td>\n",
       "      <td>good price :10, best price :9, reasonable pric...</td>\n",
       "      <td>Good quality :12, Excellent quality :8, Best q...</td>\n",
       "      <td>exchange :5, exchange policy :1, exchange pric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Al Fahidi st - Al Fahidi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy Jeweler :1, Reliable choice for je...</td>\n",
       "      <td>Good experience : 40, Excellent service : 30, ...</td>\n",
       "      <td>very friendly staff : 10, extremely helpful : ...</td>\n",
       "      <td>Good design of jewellery: 2, Nice design of je...</td>\n",
       "      <td>good collection : 50, nice collection : 30, ex...</td>\n",
       "      <td>good discount : 20, great discount : 10, best ...</td>\n",
       "      <td>50% off making charges :3, reasonable making c...</td>\n",
       "      <td>value for money :5, great prices :5, reasonabl...</td>\n",
       "      <td>Quality of the gold is also amazing :1, Qualit...</td>\n",
       "      <td>easy exchange :2, flexible diamond exchange po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Al Fahidi st - Al Fahidi  Positive  keywords   \n",
       "1  Joyalukkas Jewellery - Al Fahidi st - Al Fahidi  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Reliable :3, Trustable :2, Honest :2...   \n",
       "1  Trustworthy Jeweler :1, Reliable choice for je...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good : 100, Excellent : 80, Nice : 60, Great :...   \n",
       "1  Good experience : 40, Excellent service : 30, ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  friendly : 50, helpful : 45, polite : 30, prof...   \n",
       "1  very friendly staff : 10, extremely helpful : ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs: 45, Excellent designs: 10, Nice ...   \n",
       "1  Good design of jewellery: 2, Nice design of je...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 100, variety : 10, options : 5, c...   \n",
       "1  good collection : 50, nice collection : 30, ex...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount : 45, offer : 30, scheme : 15, deal :...   \n",
       "1  good discount : 20, great discount : 10, best ...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  reasonable :5, low :3, discount :3, affordable...   \n",
       "1  50% off making charges :3, reasonable making c...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good price :10, best price :9, reasonable pric...   \n",
       "1  value for money :5, great prices :5, reasonabl...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  Good quality :12, Excellent quality :8, Best q...   \n",
       "1  Quality of the gold is also amazing :1, Qualit...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :5, exchange policy :1, exchange pric...  \n",
       "1  easy exchange :2, flexible diamond exchange po...  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_st_af = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_st_af[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_st_af:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_st_af'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_st_af = pd.concat([positive_keywords_joy_st_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_st_af = pd.concat([positive_keywords_joy_st_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_st_af = positive_keywords_joy_st_af.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_st_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc9ddb-8651-4104-a410-b9474dfaf5ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_dm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "d601d2a0-6b9e-4534-b838-edda8dd6010d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:30:39.866546Z",
     "iopub.status.busy": "2025-06-11T15:30:39.866353Z",
     "iopub.status.idle": "2025-06-11T15:31:07.923133Z",
     "shell.execute_reply": "2025-06-11T15:31:07.922551Z",
     "shell.execute_reply.started": "2025-06-11T15:30:39.866529Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  28.0\n",
      "Total Input Tokens -  39987\n",
      "Total Input Cost = USD  0.4\n",
      "Total Output Tokens -  801\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.42\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_dm_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_dm_ad=[0]\n",
    "keyword_input_token_joy_dm_ad = 0\n",
    "keyword_output_token_joy_dm_ad = 0\n",
    "keyword_start_time_loop_joy_dm_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_dm_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_dm_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_dm_ad = keyword_dataframes['joy_dm_ad_final_sen_df_jul'][keyword_dataframes['joy_dm_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_dm_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_dm_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_dm_ad.append(keywords)\n",
    "        keyword_input_token_joy_dm_ad += input_tokens_loop\n",
    "        keyword_output_token_joy_dm_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_dm_ad = time.time()\n",
    "keyword_cost_input_token_joy_dm_ad = round((0.01/1000)*keyword_input_token_joy_dm_ad,2)\n",
    "keyword_cost_output_token_joy_dm_ad = round((0.03/1000)*keyword_output_token_joy_dm_ad,2)\n",
    "keyword_total_cost_joy_dm_ad = keyword_cost_input_token_joy_dm_ad + keyword_cost_output_token_joy_dm_ad\n",
    "keyword_total_time_loop_joy_dm_ad = keyword_end_time_loop_joy_dm_ad - keyword_start_time_loop_joy_dm_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_dm_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_dm_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_dm_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_dm_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_dm_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_dm_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_dm_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "99e5921b-7b53-40a6-b08e-87184fbfff2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:31:07.924008Z",
     "iopub.status.busy": "2025-06-11T15:31:07.923797Z",
     "iopub.status.idle": "2025-06-11T15:31:07.984608Z",
     "shell.execute_reply": "2025-06-11T15:31:07.983962Z",
     "shell.execute_reply.started": "2025-06-11T15:31:07.923990Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trusted :2, Trust :2, Trustworthy :2, Reliable...</td>\n",
       "      <td>Good experience :15, Great experience :10, Exc...</td>\n",
       "      <td>helpful : 50, friendly : 45, patient : 40, pro...</td>\n",
       "      <td>Good design :5, Beautiful designs :4, Nice des...</td>\n",
       "      <td>Good collection : 50, Nice collection : 20, Ex...</td>\n",
       "      <td>discount :10, deal :5, offer :3, voucher :2, p...</td>\n",
       "      <td>affordable :1, cheap :1, worth :1, excellence ...</td>\n",
       "      <td>good price :5, best price :4, great price :3, ...</td>\n",
       "      <td>Good quality :4, Excellent quality :3, High qu...</td>\n",
       "      <td>exchange :5, value :1, choice :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted shop :1, My trusted gold shop :1, Trus...</td>\n",
       "      <td>Very good experience :10, Wonderful experience...</td>\n",
       "      <td>very helpful : 20, very friendly : 18, very pa...</td>\n",
       "      <td>Beautiful designs :3, Nice designs :3, Best de...</td>\n",
       "      <td>variety of jewellery : 3, variety of designs :...</td>\n",
       "      <td>good discount :5, best discount :4, maximum di...</td>\n",
       "      <td>less making charges :2, discount on the making...</td>\n",
       "      <td>value for money :2, prices are fair :1, pricin...</td>\n",
       "      <td>Good quality jewerelly :1, Excellent quality j...</td>\n",
       "      <td>exchange process was really smooth :1, exchang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi  Positive  keywords   \n",
       "1  Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trusted :2, Trust :2, Trustworthy :2, Reliable...   \n",
       "1  Trusted shop :1, My trusted gold shop :1, Trus...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good experience :15, Great experience :10, Exc...   \n",
       "1  Very good experience :10, Wonderful experience...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, friendly : 45, patient : 40, pro...   \n",
       "1  very helpful : 20, very friendly : 18, very pa...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good design :5, Beautiful designs :4, Nice des...   \n",
       "1  Beautiful designs :3, Nice designs :3, Best de...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  Good collection : 50, Nice collection : 20, Ex...   \n",
       "1  variety of jewellery : 3, variety of designs :...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :10, deal :5, offer :3, voucher :2, p...   \n",
       "1  good discount :5, best discount :4, maximum di...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  affordable :1, cheap :1, worth :1, excellence ...   \n",
       "1  less making charges :2, discount on the making...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good price :5, best price :4, great price :3, ...   \n",
       "1  value for money :2, prices are fair :1, pricin...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  Good quality :4, Excellent quality :3, High qu...   \n",
       "1  Good quality jewerelly :1, Excellent quality j...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                   exchange :5, value :1, choice :1  \n",
       "1  exchange process was really smooth :1, exchang...  "
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_dm_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_dm_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_dm_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_dm_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_dm_ad = pd.concat([positive_keywords_joy_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_dm_ad = pd.concat([positive_keywords_joy_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_dm_ad = positive_keywords_joy_dm_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_dm_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0d396-51d0-423a-8bdd-91d0ef9329df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_mz_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "fff237da-07de-486a-ba3b-5028e0fa8ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:31:07.985970Z",
     "iopub.status.busy": "2025-06-11T15:31:07.985566Z",
     "iopub.status.idle": "2025-06-11T15:31:39.047411Z",
     "shell.execute_reply": "2025-06-11T15:31:39.046905Z",
     "shell.execute_reply.started": "2025-06-11T15:31:07.985943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  31.1\n",
      "Total Input Tokens -  41020\n",
      "Total Input Cost = USD  0.41\n",
      "Total Output Tokens -  760\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.43\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_mz_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_mz_ad=[0]\n",
    "keyword_input_token_joy_mz_ad = 0\n",
    "keyword_output_token_joy_mz_ad = 0\n",
    "keyword_start_time_loop_joy_mz_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_mz_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_mz_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_mz_ad = keyword_dataframes['joy_mz_ad_final_sen_df_jul'][keyword_dataframes['joy_mz_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_mz_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_mz_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_mz_ad.append(keywords)\n",
    "        keyword_input_token_joy_mz_ad += input_tokens_loop\n",
    "        keyword_output_token_joy_mz_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_mz_ad = time.time()\n",
    "keyword_cost_input_token_joy_mz_ad = round((0.01/1000)*keyword_input_token_joy_mz_ad,2)\n",
    "keyword_cost_output_token_joy_mz_ad = round((0.03/1000)*keyword_output_token_joy_mz_ad,2)\n",
    "keyword_total_cost_joy_mz_ad = keyword_cost_input_token_joy_mz_ad + keyword_cost_output_token_joy_mz_ad\n",
    "keyword_total_time_loop_joy_mz_ad = keyword_end_time_loop_joy_mz_ad - keyword_start_time_loop_joy_mz_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_mz_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_mz_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_mz_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_mz_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_mz_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_mz_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_mz_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "3eb315c3-d3b1-49fe-98bb-dac4f7893c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:31:39.048393Z",
     "iopub.status.busy": "2025-06-11T15:31:39.048120Z",
     "iopub.status.idle": "2025-06-11T15:31:39.097509Z",
     "shell.execute_reply": "2025-06-11T15:31:39.097023Z",
     "shell.execute_reply.started": "2025-06-11T15:31:39.048373Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Madinat Zayed Shopping ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trusted :4, Trust :2, Trusted brand :2, Trustw...</td>\n",
       "      <td>great experience : 20, good experience : 18, n...</td>\n",
       "      <td>patient : 10, helpful : 9, friendly : 8, accom...</td>\n",
       "      <td>designs :15, variety :3, collection :3, option...</td>\n",
       "      <td>collection : 45, variety : 3, selection : 3, o...</td>\n",
       "      <td>discount :10, deal :6, offers :2, discounts :2...</td>\n",
       "      <td>reasonable :1, affordable :1, low :1, less :1</td>\n",
       "      <td>good price :5, best price :4, reasonable price...</td>\n",
       "      <td>good quality :3, high-quality :3, quality :3, ...</td>\n",
       "      <td>exchange :2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Madinat Zayed Shopping ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted shop :1, Trustworthy and premium gold ...</td>\n",
       "      <td>great shopping experience : 5, pleasant experi...</td>\n",
       "      <td>very patient and helpful : 3, very friendly an...</td>\n",
       "      <td>beautiful earings :1, beautiful nose ring :1, ...</td>\n",
       "      <td>good collection : 20, nice collection : 10, gr...</td>\n",
       "      <td>good discount :5, very good discount :3, great...</td>\n",
       "      <td>50 percent deduction in the making charge :1</td>\n",
       "      <td>best rates :1, price value very remarkable :1,...</td>\n",
       "      <td>quality exceeded my expectations :1, product q...</td>\n",
       "      <td>make the exchange smoothly :1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Madinat Zayed Shopping ...  Positive  keywords   \n",
       "1  Joyalukkas Jewellery - Madinat Zayed Shopping ...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trusted :4, Trust :2, Trusted brand :2, Trustw...   \n",
       "1  Trusted shop :1, Trustworthy and premium gold ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience : 20, good experience : 18, n...   \n",
       "1  great shopping experience : 5, pleasant experi...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 10, helpful : 9, friendly : 8, accom...   \n",
       "1  very patient and helpful : 3, very friendly an...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :15, variety :3, collection :3, option...   \n",
       "1  beautiful earings :1, beautiful nose ring :1, ...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, variety : 3, selection : 3, o...   \n",
       "1  good collection : 20, nice collection : 10, gr...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :10, deal :6, offers :2, discounts :2...   \n",
       "1  good discount :5, very good discount :3, great...   \n",
       "\n",
       "                                   Making Charge  \\\n",
       "0  reasonable :1, affordable :1, low :1, less :1   \n",
       "1   50 percent deduction in the making charge :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good price :5, best price :4, reasonable price...   \n",
       "1  best rates :1, price value very remarkable :1,...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  good quality :3, high-quality :3, quality :3, ...   \n",
       "1  quality exceeded my expectations :1, product q...   \n",
       "\n",
       "              Jewellery Exchange  \n",
       "0                    exchange :2  \n",
       "1  make the exchange smoothly :1  "
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_mz_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_mz_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_mz_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_mz_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_mz_ad = pd.concat([positive_keywords_joy_mz_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_mz_ad = pd.concat([positive_keywords_joy_mz_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_mz_ad = positive_keywords_joy_mz_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_mz_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce37632-b2aa-49f0-a809-dd798561ba06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_sh_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "103dfd53-f19c-4a55-9a88-caa02a12e899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:31:39.098417Z",
     "iopub.status.busy": "2025-06-11T15:31:39.098098Z",
     "iopub.status.idle": "2025-06-11T15:32:06.152186Z",
     "shell.execute_reply": "2025-06-11T15:32:06.151600Z",
     "shell.execute_reply.started": "2025-06-11T15:31:39.098393Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  27.0\n",
      "Total Input Tokens -  21157\n",
      "Total Input Cost = USD  0.21\n",
      "Total Output Tokens -  738\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.23\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_sh_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_sh_ad=[0]\n",
    "keyword_input_token_joy_sh_ad = 0\n",
    "keyword_output_token_joy_sh_ad = 0\n",
    "keyword_start_time_loop_joy_sh_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_sh_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_sh_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_sh_ad = keyword_dataframes['joy_sh_ad_final_sen_df_jul'][keyword_dataframes['joy_sh_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_sh_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_sh_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_sh_ad.append(keywords)\n",
    "        keyword_input_token_joy_sh_ad += input_tokens_loop\n",
    "        keyword_output_token_joy_sh_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_sh_ad = time.time()\n",
    "keyword_cost_input_token_joy_sh_ad = round((0.01/1000)*keyword_input_token_joy_sh_ad,2)\n",
    "keyword_cost_output_token_joy_sh_ad = round((0.03/1000)*keyword_output_token_joy_sh_ad,2)\n",
    "keyword_total_cost_joy_sh_ad = keyword_cost_input_token_joy_sh_ad + keyword_cost_output_token_joy_sh_ad\n",
    "keyword_total_time_loop_joy_sh_ad = keyword_end_time_loop_joy_sh_ad - keyword_start_time_loop_joy_sh_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_sh_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_sh_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_sh_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_sh_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_sh_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_sh_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_sh_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "d80ccdcc-fa10-4fa9-8a18-badcb951d501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:32:06.154252Z",
     "iopub.status.busy": "2025-06-11T15:32:06.153991Z",
     "iopub.status.idle": "2025-06-11T15:32:06.202100Z",
     "shell.execute_reply": "2025-06-11T15:32:06.201535Z",
     "shell.execute_reply.started": "2025-06-11T15:32:06.154233Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Shabia - Abu Dhabi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trusted :2, Regular :2, Consistent :1, Securel...</td>\n",
       "      <td>pleasant :3, smooth :3, welcoming :2, seamless...</td>\n",
       "      <td>polite :3, helpful :3, friendly :3, kind :3, s...</td>\n",
       "      <td>designs :5, design :4, beautiful :2, impressiv...</td>\n",
       "      <td>collection : 30, collections : 20, variety : 3...</td>\n",
       "      <td>discount :10, offer :6, offers :3, discounted ...</td>\n",
       "      <td>reasonable :2, low :1, genuine :1</td>\n",
       "      <td>Good price :5, Reasonable price :2, Affordable...</td>\n",
       "      <td>quality :5, good quality :2, best quality :2, ...</td>\n",
       "      <td>same value :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Shabia - Abu Dhabi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted name in jewelry :1, Regular customer f...</td>\n",
       "      <td>pleasant experience :2, smooth transaction :1,...</td>\n",
       "      <td>very friendly staff :3, very helpful and suppo...</td>\n",
       "      <td>good designs :1, impressive designs :1, beauti...</td>\n",
       "      <td>variety of collections : 3, good collection : ...</td>\n",
       "      <td>good discount :5, good offer :2, big discount ...</td>\n",
       "      <td>reasonable making charge :2, genuine making ch...</td>\n",
       "      <td>Great prices :1, Amazing prices :1, Nice price...</td>\n",
       "      <td>quality of the bracelet is simply outstanding ...</td>\n",
       "      <td>exchanged our old ring with same value :1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Shabia - Abu Dhabi  Positive  keywords   \n",
       "1  Joyalukkas Jewellery - Shabia - Abu Dhabi  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trusted :2, Regular :2, Consistent :1, Securel...   \n",
       "1  Trusted name in jewelry :1, Regular customer f...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant :3, smooth :3, welcoming :2, seamless...   \n",
       "1  pleasant experience :2, smooth transaction :1,...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  polite :3, helpful :3, friendly :3, kind :3, s...   \n",
       "1  very friendly staff :3, very helpful and suppo...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :5, design :4, beautiful :2, impressiv...   \n",
       "1  good designs :1, impressive designs :1, beauti...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 30, collections : 20, variety : 3...   \n",
       "1  variety of collections : 3, good collection : ...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :10, offer :6, offers :3, discounted ...   \n",
       "1  good discount :5, good offer :2, big discount ...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                  reasonable :2, low :1, genuine :1   \n",
       "1  reasonable making charge :2, genuine making ch...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  Good price :5, Reasonable price :2, Affordable...   \n",
       "1  Great prices :1, Amazing prices :1, Nice price...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :5, good quality :2, best quality :2, ...   \n",
       "1  quality of the bracelet is simply outstanding ...   \n",
       "\n",
       "                          Jewellery Exchange  \n",
       "0                              same value :1  \n",
       "1  exchanged our old ring with same value :1  "
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_sh_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_sh_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_sh_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_sh_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_sh_ad = pd.concat([positive_keywords_joy_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_sh_ad = pd.concat([positive_keywords_joy_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_sh_ad = positive_keywords_joy_sh_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_sh_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a67bdb-612e-4085-ad49-8f6977fc6f97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "db7c61fa-c166-4ccd-b48a-d345b1615788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:32:06.203275Z",
     "iopub.status.busy": "2025-06-11T15:32:06.203000Z",
     "iopub.status.idle": "2025-06-11T15:32:42.273490Z",
     "shell.execute_reply": "2025-06-11T15:32:42.272940Z",
     "shell.execute_reply.started": "2025-06-11T15:32:06.203247Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  36.1\n",
      "Total Input Tokens -  42793\n",
      "Total Input Cost = USD  0.43\n",
      "Total Output Tokens -  765\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.45\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_sc = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_sc=[0]\n",
    "keyword_input_token_mal_sc = 0\n",
    "keyword_output_token_mal_sc = 0\n",
    "keyword_start_time_loop_mal_sc = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_sc, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_sc[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_sc = keyword_dataframes['mal_sc_final_sen_df_jul'][keyword_dataframes['mal_sc_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_sc:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_sc,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_sc.append(keywords)\n",
    "        keyword_input_token_mal_sc += input_tokens_loop\n",
    "        keyword_output_token_mal_sc += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_sc = time.time()\n",
    "keyword_cost_input_token_mal_sc = round((0.01/1000)*keyword_input_token_mal_sc,2)\n",
    "keyword_cost_output_token_mal_sc = round((0.03/1000)*keyword_output_token_mal_sc,2)\n",
    "keyword_total_cost_mal_sc = keyword_cost_input_token_mal_sc + keyword_cost_output_token_mal_sc\n",
    "keyword_total_time_loop_mal_sc = keyword_end_time_loop_mal_sc - keyword_start_time_loop_mal_sc\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_sc[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_sc,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_sc)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_sc)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_sc)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_sc)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_sc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "a4bc9a6f-b293-479e-b081-c9d758ebc36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:32:42.274504Z",
     "iopub.status.busy": "2025-06-11T15:32:42.274228Z",
     "iopub.status.idle": "2025-06-11T15:32:42.322217Z",
     "shell.execute_reply": "2025-06-11T15:32:42.321749Z",
     "shell.execute_reply.started": "2025-06-11T15:32:42.274484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :2, Transparent :2, Knowledgeable :2, Pr...</td>\n",
       "      <td>pleasant :3, smooth :2, seamless :1, enjoyable...</td>\n",
       "      <td>helpful : 78, patient : 36, professional : 34,...</td>\n",
       "      <td>designs :15, good design :10, beautiful design...</td>\n",
       "      <td>collection : 45, selections : 5, variety : 4, ...</td>\n",
       "      <td>good discount :6, best deal :3, best offer :1,...</td>\n",
       "      <td>making charges :2</td>\n",
       "      <td>best price :3, good price :2, reasonable rates...</td>\n",
       "      <td>good quality:3, excellent quality:2, top notch...</td>\n",
       "      <td>exchange rates :1, exchange :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust and rapport with customers :1, Completel...</td>\n",
       "      <td>wonderful experience :10, amazing experience :...</td>\n",
       "      <td>very helpful : 20, very patient : 10, very pro...</td>\n",
       "      <td>great designs :3, amazing designs :3, best des...</td>\n",
       "      <td>amazing collection : 4, good collection : 4, g...</td>\n",
       "      <td>gave me good discount :1, giving good discount...</td>\n",
       "      <td>proper making charges :1</td>\n",
       "      <td>within our budget :2, fitted within our budget...</td>\n",
       "      <td>quality of their pieces is top notch:1, qualit...</td>\n",
       "      <td>best deal :1, good exchange rates :1, explaine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds - Silicon Oasis Central  Positive  keywords   \n",
       "1  Malabar Gold & Diamonds - Silicon Oasis Central  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :2, Transparent :2, Knowledgeable :2, Pr...   \n",
       "1  Trust and rapport with customers :1, Completel...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant :3, smooth :2, seamless :1, enjoyable...   \n",
       "1  wonderful experience :10, amazing experience :...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 78, patient : 36, professional : 34,...   \n",
       "1  very helpful : 20, very patient : 10, very pro...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :15, good design :10, beautiful design...   \n",
       "1  great designs :3, amazing designs :3, best des...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, selections : 5, variety : 4, ...   \n",
       "1  amazing collection : 4, good collection : 4, g...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount :6, best deal :3, best offer :1,...   \n",
       "1  gave me good discount :1, giving good discount...   \n",
       "\n",
       "              Making Charge  \\\n",
       "0         making charges :2   \n",
       "1  proper making charges :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :3, good price :2, reasonable rates...   \n",
       "1  within our budget :2, fitted within our budget...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  good quality:3, excellent quality:2, top notch...   \n",
       "1  quality of their pieces is top notch:1, qualit...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                     exchange rates :1, exchange :1  \n",
       "1  best deal :1, good exchange rates :1, explaine...  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_sc = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_sc[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_sc:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_sc'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_sc = pd.concat([positive_keywords_mal_sc, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_sc = pd.concat([positive_keywords_mal_sc, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_sc = positive_keywords_mal_sc.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbacbc2-9110-43a9-b830-43f15801ff7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "bde47ff6-aa5d-4cfc-a584-ea84a71d8ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:32:42.323203Z",
     "iopub.status.busy": "2025-06-11T15:32:42.323010Z",
     "iopub.status.idle": "2025-06-11T15:44:18.991525Z",
     "shell.execute_reply": "2025-06-11T15:44:18.990944Z",
     "shell.execute_reply.started": "2025-06-11T15:32:42.323186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed 10 Iterations\n",
      "Total Execution time (in secs) - 696.7\n",
      "Total Input Tokens - 348324\n",
      "Total Input Cost = USD 3.48\n",
      "Total Output Tokens - 21210\n",
      "Total Output Cost = USD 0.64\n",
      "Total Cost = USD 4.12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_ab = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = [\n",
    "    'Customer Confidence', 'Store Experience', 'Store Staff', 'Product Design',\n",
    "    'Product Variety', 'Discount', 'Making Charge', 'Price', \n",
    "    'Product Quality', 'Jewellery Exchange'\n",
    "]\n",
    "\n",
    "keyword_counter_mal_ab = [0]\n",
    "keyword_input_token_mal_ab = 0\n",
    "keyword_output_token_mal_ab = 0\n",
    "keyword_start_time_loop_mal_ab = time.time()\n",
    "\n",
    "# Threading setup\n",
    "keyword_total_iterations = len(keyword_topics)\n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ab, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ab[0] += 1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ab = keyword_dataframes['mal_ab_final_sen_df_jul'][keyword_dataframes['mal_ab_final_sen_df_jul'][topic] == 1]['review_text'].tolist()\n",
    "    \n",
    "    # If there are positive comments, process them in chunks of 25\n",
    "    if filtered_comments_mal_ab:\n",
    "        # Loop through the filtered comments in batches of 25\n",
    "        for i in range(0, len(filtered_comments_mal_ab), 25):\n",
    "            # Get the current batch of 25 comments (or less if it's the last batch)\n",
    "            comment_batch = filtered_comments_mal_ab[i:i + 25]\n",
    "            # Call the positive_keywords function and store the result for each batch\n",
    "            keywords, input_tokens_loop, output_token_loop = positive_keywords(comment_batch, topic)\n",
    "            # Add the result to the output dictionary\n",
    "            keyword_positive_output_mal_ab.append(keywords)\n",
    "            keyword_input_token_mal_ab += input_tokens_loop\n",
    "            keyword_output_token_mal_ab += output_token_loop\n",
    "\n",
    "# Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ab = time.time()\n",
    "keyword_cost_input_token_mal_ab = round((0.01 / 1000) * keyword_input_token_mal_ab, 2)\n",
    "keyword_cost_output_token_mal_ab = round((0.03 / 1000) * keyword_output_token_mal_ab, 2)\n",
    "keyword_total_cost_mal_ab = keyword_cost_input_token_mal_ab + keyword_cost_output_token_mal_ab\n",
    "keyword_total_time_loop_mal_ab = keyword_end_time_loop_mal_ab - keyword_start_time_loop_mal_ab\n",
    "\n",
    "# Display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed\", keyword_counter_mal_ab[0], \"Iterations\")\n",
    "print(\"Total Execution time (in secs) -\", round(keyword_total_time_loop_mal_ab, 1))\n",
    "print(\"Total Input Tokens -\", keyword_input_token_mal_ab)\n",
    "print(\"Total Input Cost = USD\", keyword_cost_input_token_mal_ab)\n",
    "print(\"Total Output Tokens -\", keyword_output_token_mal_ab)\n",
    "print(\"Total Output Cost = USD\", keyword_cost_output_token_mal_ab)\n",
    "print(\"Total Cost = USD\", round(keyword_total_cost_mal_ab, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "bce45bf0-d06f-47f1-ae76-f78bc194adab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:44:18.992539Z",
     "iopub.status.busy": "2025-06-11T15:44:18.992323Z",
     "iopub.status.idle": "2025-06-11T15:44:20.457589Z",
     "shell.execute_reply": "2025-06-11T15:44:20.457094Z",
     "shell.execute_reply.started": "2025-06-11T15:44:18.992521Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Barsha - Dubai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Reliable :1, Authentic :1, Trusted :...</td>\n",
       "      <td>good experience :5, excellent experience :4, g...</td>\n",
       "      <td>helpful :4, polite :3, courteous :1, knowledge...</td>\n",
       "      <td>designs :15, good designs :4, beautiful design...</td>\n",
       "      <td>collections :12, variety :2, options :2, array...</td>\n",
       "      <td>good discount :6, best discount :2, good deal ...</td>\n",
       "      <td>good making charge :2, reasonable making charg...</td>\n",
       "      <td>best price :4, good price :4, great price :3, ...</td>\n",
       "      <td>good quality:5, best quality:2, excellent qual...</td>\n",
       "      <td>exchange :8, exchanging :3, exchanged :2, retu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Barsha - Dubai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust worthy :1, Trusted shop of buying gold :...</td>\n",
       "      <td>very good experience :3, excellent customer se...</td>\n",
       "      <td>excellent service :5, amazing support :1, very...</td>\n",
       "      <td>lot of designs :2, wonderful designs :2, pleth...</td>\n",
       "      <td>wide variety of collections :2, vast variety o...</td>\n",
       "      <td>providing good discount :1, offered discount :...</td>\n",
       "      <td>very low making charges than market :2, seriou...</td>\n",
       "      <td>best price and discounts :1, suited our tastes...</td>\n",
       "      <td>quality of the product:1, quality of gold jewe...</td>\n",
       "      <td>100% refund on exchange :1, easy exchange hass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Barsha - Dubai  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Barsha - Dubai  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Reliable :1, Authentic :1, Trusted :...   \n",
       "1  Trust worthy :1, Trusted shop of buying gold :...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience :5, excellent experience :4, g...   \n",
       "1  very good experience :3, excellent customer se...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :4, polite :3, courteous :1, knowledge...   \n",
       "1  excellent service :5, amazing support :1, very...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :15, good designs :4, beautiful design...   \n",
       "1  lot of designs :2, wonderful designs :2, pleth...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collections :12, variety :2, options :2, array...   \n",
       "1  wide variety of collections :2, vast variety o...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount :6, best discount :2, good deal ...   \n",
       "1  providing good discount :1, offered discount :...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  good making charge :2, reasonable making charg...   \n",
       "1  very low making charges than market :2, seriou...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :4, good price :4, great price :3, ...   \n",
       "1  best price and discounts :1, suited our tastes...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  good quality:5, best quality:2, excellent qual...   \n",
       "1  quality of the product:1, quality of gold jewe...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :8, exchanging :3, exchanged :2, retu...  \n",
       "1  100% refund on exchange :1, easy exchange hass...  "
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_ab = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_ab[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_ab:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ab'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_ab = pd.concat([positive_keywords_mal_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_ab = pd.concat([positive_keywords_mal_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_ab = positive_keywords_mal_ab.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd10a3b-151d-46ca-ae5c-4087e9440573",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b1_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "6c01557c-93a7-4d57-996e-800f7ee1b05f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:44:20.458540Z",
     "iopub.status.busy": "2025-06-11T15:44:20.458319Z",
     "iopub.status.idle": "2025-06-11T15:54:58.526478Z",
     "shell.execute_reply": "2025-06-11T15:54:58.525961Z",
     "shell.execute_reply.started": "2025-06-11T15:44:20.458522Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed 10 Iterations\n",
      "Total Execution time (in secs) - 638.1\n",
      "Total Input Tokens - 319980\n",
      "Total Input Cost = USD 3.2\n",
      "Total Output Tokens - 21670\n",
      "Total Output Cost = USD 0.65\n",
      "Total Cost = USD 3.85\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_b1_af = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = [\n",
    "    'Customer Confidence', 'Store Experience', 'Store Staff', 'Product Design',\n",
    "    'Product Variety', 'Discount', 'Making Charge', 'Price', \n",
    "    'Product Quality', 'Jewellery Exchange'\n",
    "]\n",
    "\n",
    "keyword_counter_mal_b1_af = [0]\n",
    "keyword_input_token_mal_b1_af = 0\n",
    "keyword_output_token_mal_b1_af = 0\n",
    "keyword_start_time_loop_mal_b1_af = time.time()\n",
    "\n",
    "# Threading setup\n",
    "keyword_total_iterations = len(keyword_topics)\n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b1_af, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b1_af[0] += 1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b1_af = keyword_dataframes['mal_b1_af_final_sen_df_jul'][keyword_dataframes['mal_b1_af_final_sen_df_jul'][topic] == 1]['review_text'].tolist()\n",
    "    \n",
    "    # If there are positive comments, process them in chunks of 25\n",
    "    if filtered_comments_mal_b1_af:\n",
    "        # Loop through the filtered comments in batches of 25\n",
    "        for i in range(0, len(filtered_comments_mal_b1_af), 25):\n",
    "            # Get the current batch of 25 comments (or less if it's the last batch)\n",
    "            comment_batch = filtered_comments_mal_b1_af[i:i + 25]\n",
    "            # Call the positive_keywords function and store the result for each batch\n",
    "            keywords, input_tokens_loop, output_token_loop = positive_keywords(comment_batch, topic)\n",
    "            # Add the result to the output dictionary\n",
    "            keyword_positive_output_mal_b1_af.append(keywords)\n",
    "            keyword_input_token_mal_b1_af += input_tokens_loop\n",
    "            keyword_output_token_mal_b1_af += output_token_loop\n",
    "\n",
    "# Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b1_af = time.time()\n",
    "keyword_cost_input_token_mal_b1_af = round((0.01 / 1000) * keyword_input_token_mal_b1_af, 2)\n",
    "keyword_cost_output_token_mal_b1_af = round((0.03 / 1000) * keyword_output_token_mal_b1_af, 2)\n",
    "keyword_total_cost_mal_b1_af = keyword_cost_input_token_mal_b1_af + keyword_cost_output_token_mal_b1_af\n",
    "keyword_total_time_loop_mal_b1_af = keyword_end_time_loop_mal_b1_af - keyword_start_time_loop_mal_b1_af\n",
    "\n",
    "# Display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed\", keyword_counter_mal_b1_af[0], \"Iterations\")\n",
    "print(\"Total Execution time (in secs) -\", round(keyword_total_time_loop_mal_b1_af, 1))\n",
    "print(\"Total Input Tokens -\", keyword_input_token_mal_b1_af)\n",
    "print(\"Total Input Cost = USD\", keyword_cost_input_token_mal_b1_af)\n",
    "print(\"Total Output Tokens -\", keyword_output_token_mal_b1_af)\n",
    "print(\"Total Output Cost = USD\", keyword_cost_output_token_mal_b1_af)\n",
    "print(\"Total Cost = USD\", round(keyword_total_cost_mal_b1_af, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "d9f3e9e9-c9d9-4660-8b55-5f020d7eeeb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:54:58.527527Z",
     "iopub.status.busy": "2025-06-11T15:54:58.527232Z",
     "iopub.status.idle": "2025-06-11T15:55:00.043130Z",
     "shell.execute_reply": "2025-06-11T15:55:00.042595Z",
     "shell.execute_reply.started": "2025-06-11T15:54:58.527507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street -...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :2, Confidence :1, Assurance :1, Reliabl...</td>\n",
       "      <td>great experience :3, good experience :3, pleas...</td>\n",
       "      <td>service :15, professional :2, helpful :2, assi...</td>\n",
       "      <td>design :12, designs :8, variety :2, options :1...</td>\n",
       "      <td>variety :2, options :1 collection :24 Variety ...</td>\n",
       "      <td>best deal :7, good discount :5, best discount ...</td>\n",
       "      <td>reasonable :3, less :2, discount :1</td>\n",
       "      <td>best price :5, good price :4, competitive :1, ...</td>\n",
       "      <td>good quality:4, best quality:2, great quality:...</td>\n",
       "      <td>exchange policy:1, exchange gold:1, exchange o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street -...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted purchase :3, Highly recommended :3, Fe...</td>\n",
       "      <td>shopping experience was great :1, great &amp; plea...</td>\n",
       "      <td>very good service :3, good service by :3, best...</td>\n",
       "      <td>nice design :3, best design :3, excellent desi...</td>\n",
       "      <td>wide range :1, lot of variety :1, lot of varie...</td>\n",
       "      <td>good discount on making :1, reasonable discoun...</td>\n",
       "      <td>reasonable making charges :2, best price on ma...</td>\n",
       "      <td>special price :1, better price :1, excellent p...</td>\n",
       "      <td>quality and service:5, quality of the gold is ...</td>\n",
       "      <td>comfortable to exchange:1, assisted us with th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Fahidi Street -...  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Fahidi Street -...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :2, Confidence :1, Assurance :1, Reliabl...   \n",
       "1  Trusted purchase :3, Highly recommended :3, Fe...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience :3, good experience :3, pleas...   \n",
       "1  shopping experience was great :1, great & plea...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  service :15, professional :2, helpful :2, assi...   \n",
       "1  very good service :3, good service by :3, best...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  design :12, designs :8, variety :2, options :1...   \n",
       "1  nice design :3, best design :3, excellent desi...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :2, options :1 collection :24 Variety ...   \n",
       "1  wide range :1, lot of variety :1, lot of varie...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  best deal :7, good discount :5, best discount ...   \n",
       "1  good discount on making :1, reasonable discoun...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                reasonable :3, less :2, discount :1   \n",
       "1  reasonable making charges :2, best price on ma...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :5, good price :4, competitive :1, ...   \n",
       "1  special price :1, better price :1, excellent p...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  good quality:4, best quality:2, great quality:...   \n",
       "1  quality and service:5, quality of the gold is ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange policy:1, exchange gold:1, exchange o...  \n",
       "1  comfortable to exchange:1, assisted us with th...  "
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "positive_keywords_mal_b1_af = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_b1_af[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_b1_af:\n",
    "    if not json_str.strip():  # Check if the string is empty\n",
    "        print(f\"Warning: Empty JSON string encountered.\")\n",
    "        continue  # Skip this iteration\n",
    "    \n",
    "    try:\n",
    "        # Load the JSON string into a dictionary\n",
    "        data = json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}. Skipping this entry: {json_str}\")\n",
    "        continue  # Skip this iteration\n",
    "\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b1_af'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content.get('keywords', '').split(',')])\n",
    "            positive_keywords_mal_b1_af = pd.concat([positive_keywords_mal_b1_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content.get('phrases', '').split(',')])\n",
    "            positive_keywords_mal_b1_af = pd.concat([positive_keywords_mal_b1_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_b1_af = positive_keywords_mal_b1_af.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "# Display the result\n",
    "positive_keywords_mal_b1_af\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8744270-d74d-4f31-a936-69c681ad27e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "567efa93-59cb-46a7-9a36-11d3a52b850b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T15:55:00.044335Z",
     "iopub.status.busy": "2025-06-11T15:55:00.044047Z",
     "iopub.status.idle": "2025-06-11T16:02:35.311110Z",
     "shell.execute_reply": "2025-06-11T16:02:35.310596Z",
     "shell.execute_reply.started": "2025-06-11T15:55:00.044309Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed 10 Iterations\n",
      "Total Execution time (in secs) - 455.3\n",
      "Total Input Tokens - 247921\n",
      "Total Input Cost = USD 2.48\n",
      "Total Output Tokens - 14973\n",
      "Total Output Cost = USD 0.45\n",
      "Total Cost = USD 2.93\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = [\n",
    "    'Customer Confidence', 'Store Experience', 'Store Staff', 'Product Design',\n",
    "    'Product Variety', 'Discount', 'Making Charge', 'Price', \n",
    "    'Product Quality', 'Jewellery Exchange'\n",
    "]\n",
    "\n",
    "keyword_counter_mal_ak = [0]\n",
    "keyword_input_token_mal_ak = 0\n",
    "keyword_output_token_mal_ak = 0\n",
    "keyword_start_time_loop_mal_ak = time.time()\n",
    "\n",
    "# Threading setup\n",
    "keyword_total_iterations = len(keyword_topics)\n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ak[0] += 1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ak = keyword_dataframes['mal_ak_final_sen_df_jul'][keyword_dataframes['mal_ak_final_sen_df_jul'][topic] == 1]['review_text'].tolist()\n",
    "    \n",
    "    # If there are positive comments, process them in chunks of 25\n",
    "    if filtered_comments_mal_ak:\n",
    "        # Loop through the filtered comments in batches of 25\n",
    "        for i in range(0, len(filtered_comments_mal_ak), 25):\n",
    "            # Get the current batch of 25 comments (or less if it's the last batch)\n",
    "            comment_batch = filtered_comments_mal_ak[i:i + 25]\n",
    "            # Call the positive_keywords function and store the result for each batch\n",
    "            keywords, input_tokens_loop, output_token_loop = positive_keywords(comment_batch, topic)\n",
    "            # Add the result to the output dictionary\n",
    "            keyword_positive_output_mal_ak.append(keywords)\n",
    "            keyword_input_token_mal_ak += input_tokens_loop\n",
    "            keyword_output_token_mal_ak += output_token_loop\n",
    "\n",
    "# Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ak = time.time()\n",
    "keyword_cost_input_token_mal_ak = round((0.01 / 1000) * keyword_input_token_mal_ak, 2)\n",
    "keyword_cost_output_token_mal_ak = round((0.03 / 1000) * keyword_output_token_mal_ak, 2)\n",
    "keyword_total_cost_mal_ak = keyword_cost_input_token_mal_ak + keyword_cost_output_token_mal_ak\n",
    "keyword_total_time_loop_mal_ak = keyword_end_time_loop_mal_ak - keyword_start_time_loop_mal_ak\n",
    "\n",
    "# Display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed\", keyword_counter_mal_ak[0], \"Iterations\")\n",
    "print(\"Total Execution time (in secs) -\", round(keyword_total_time_loop_mal_ak, 1))\n",
    "print(\"Total Input Tokens -\", keyword_input_token_mal_ak)\n",
    "print(\"Total Input Cost = USD\", keyword_cost_input_token_mal_ak)\n",
    "print(\"Total Output Tokens -\", keyword_output_token_mal_ak)\n",
    "print(\"Total Output Cost = USD\", keyword_cost_output_token_mal_ak)\n",
    "print(\"Total Cost = USD\", round(keyword_total_cost_mal_ak, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "f4808760-f90c-4d7d-a22a-7bfadb40d7d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:02:35.312453Z",
     "iopub.status.busy": "2025-06-11T16:02:35.311896Z",
     "iopub.status.idle": "2025-06-11T16:02:36.191837Z",
     "shell.execute_reply": "2025-06-11T16:02:36.191334Z",
     "shell.execute_reply.started": "2025-06-11T16:02:35.312430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Karama - Dubai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trusted brand :1, Reliable salesperson :1 Reli...</td>\n",
       "      <td>pleasant :3, comfortable :1, amazing :1, wonde...</td>\n",
       "      <td>helpful :3, cooperative :2, patient :2, polite...</td>\n",
       "      <td>good design :5, unique design :2, attractive d...</td>\n",
       "      <td>collection :12, options :3, variety :2, choice...</td>\n",
       "      <td>discount :10, deals :3, offers :2, price :1, r...</td>\n",
       "      <td>reasonable :1, less :1, cheap :1</td>\n",
       "      <td>best price :3, good price :3, affordable price...</td>\n",
       "      <td>quality :8, good quality :3, high-quality :2, ...</td>\n",
       "      <td>exchange :11, value :3, price :2, option :1, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Karama - Dubai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted brand :1, Reliable salesperson for any...</td>\n",
       "      <td>pleasant experience :3, amazing experience :2,...</td>\n",
       "      <td>excellent service :2, very good service :2, aw...</td>\n",
       "      <td>rare designs are available :1, unique collecti...</td>\n",
       "      <td>nice collection :3, good collection :3, excell...</td>\n",
       "      <td>good discount :5, best discount :2, bargain di...</td>\n",
       "      <td>reasonable making charge :1, reduce making cha...</td>\n",
       "      <td>best price that we can afford :1, best price b...</td>\n",
       "      <td>quality of the jewelry surpassed our expectati...</td>\n",
       "      <td>exchange of gold :3, exchange process :2, exch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Karama - Dubai  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Karama - Dubai  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trusted brand :1, Reliable salesperson :1 Reli...   \n",
       "1  Trusted brand :1, Reliable salesperson for any...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant :3, comfortable :1, amazing :1, wonde...   \n",
       "1  pleasant experience :3, amazing experience :2,...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :3, cooperative :2, patient :2, polite...   \n",
       "1  excellent service :2, very good service :2, aw...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  good design :5, unique design :2, attractive d...   \n",
       "1  rare designs are available :1, unique collecti...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection :12, options :3, variety :2, choice...   \n",
       "1  nice collection :3, good collection :3, excell...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :10, deals :3, offers :2, price :1, r...   \n",
       "1  good discount :5, best discount :2, bargain di...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                   reasonable :1, less :1, cheap :1   \n",
       "1  reasonable making charge :1, reduce making cha...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :3, good price :3, affordable price...   \n",
       "1  best price that we can afford :1, best price b...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, good quality :3, high-quality :2, ...   \n",
       "1  quality of the jewelry surpassed our expectati...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :11, value :3, price :2, option :1, p...  \n",
       "1  exchange of gold :3, exchange process :2, exch...  "
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_ak = pd.concat([positive_keywords_mal_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_ak = pd.concat([positive_keywords_mal_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_ak = positive_keywords_mal_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d8a9bd-24dc-4281-b10d-5cfb8830df26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_aw_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "d640aba7-cc72-499d-b2de-0b753470fc7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:02:36.193066Z",
     "iopub.status.busy": "2025-06-11T16:02:36.192779Z",
     "iopub.status.idle": "2025-06-11T16:03:12.763878Z",
     "shell.execute_reply": "2025-06-11T16:03:12.763322Z",
     "shell.execute_reply.started": "2025-06-11T16:02:36.193040Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  36.6\n",
      "Total Input Tokens -  103086\n",
      "Total Input Cost = USD  1.03\n",
      "Total Output Tokens -  774\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_aw_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_aw_ad=[0]\n",
    "keyword_input_token_mal_aw_ad = 0\n",
    "keyword_output_token_mal_aw_ad = 0\n",
    "keyword_start_time_loop_mal_aw_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_aw_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_aw_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_aw_ad = keyword_dataframes['mal_aw_ad_final_sen_df_jul'][keyword_dataframes['mal_aw_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_aw_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_aw_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_aw_ad.append(keywords)\n",
    "        keyword_input_token_mal_aw_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_aw_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_aw_ad = time.time()\n",
    "keyword_cost_input_token_mal_aw_ad = round((0.01/1000)*keyword_input_token_mal_aw_ad,2)\n",
    "keyword_cost_output_token_mal_aw_ad = round((0.03/1000)*keyword_output_token_mal_aw_ad,2)\n",
    "keyword_total_cost_mal_aw_ad = keyword_cost_input_token_mal_aw_ad + keyword_cost_output_token_mal_aw_ad\n",
    "keyword_total_time_loop_mal_aw_ad = keyword_end_time_loop_mal_aw_ad - keyword_start_time_loop_mal_aw_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_aw_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_aw_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_aw_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_aw_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_aw_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_aw_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_aw_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "546740c5-3c76-466b-9ff5-cb39d76975a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:03:12.764877Z",
     "iopub.status.busy": "2025-06-11T16:03:12.764602Z",
     "iopub.status.idle": "2025-06-11T16:03:12.813607Z",
     "shell.execute_reply": "2025-06-11T16:03:12.813062Z",
     "shell.execute_reply.started": "2025-06-11T16:03:12.764859Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Wahda Mall - Ab...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trust :3, trusted :2, trustable :1, honest :1,...</td>\n",
       "      <td>good experience : 45, great experience : 40, n...</td>\n",
       "      <td>helpful : 98, friendly : 85, accommodating : 8...</td>\n",
       "      <td>designs :30, beautiful :5, unique :3, stunning...</td>\n",
       "      <td>collection : 45, variety : 8, selections : 6, ...</td>\n",
       "      <td>discount :15, offers :8, deal :6, good discoun...</td>\n",
       "      <td>good making :2, affordable :1</td>\n",
       "      <td>best price :10, good price :9, reasonable pric...</td>\n",
       "      <td>Good quality :5, High quality :5, Quality :4, ...</td>\n",
       "      <td>good price :2, best price :1, affordable rate :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Wahda Mall - Ab...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>fully trust Malabar :1, most trusted Malabar :...</td>\n",
       "      <td>very good experience : 10, amazing experience ...</td>\n",
       "      <td>very helpful : 25, very accommodating : 20, ex...</td>\n",
       "      <td>beautiful designs :3, amazing designs :3, nice...</td>\n",
       "      <td>wide variety : 4, good collection : 3, variety...</td>\n",
       "      <td>good discount :5, special discount :5, great d...</td>\n",
       "      <td>good making cost :1, good making rate :1, affo...</td>\n",
       "      <td>within my budget :3, fits your budget :2, with...</td>\n",
       "      <td>Quality are always 100% :1, The product qualit...</td>\n",
       "      <td>completely satisfied :1, extremely satisfied :...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Wahda Mall - Ab...  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Wahda Mall - Ab...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  trust :3, trusted :2, trustable :1, honest :1,...   \n",
       "1  fully trust Malabar :1, most trusted Malabar :...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience : 45, great experience : 40, n...   \n",
       "1  very good experience : 10, amazing experience ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 98, friendly : 85, accommodating : 8...   \n",
       "1  very helpful : 25, very accommodating : 20, ex...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :30, beautiful :5, unique :3, stunning...   \n",
       "1  beautiful designs :3, amazing designs :3, nice...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, variety : 8, selections : 6, ...   \n",
       "1  wide variety : 4, good collection : 3, variety...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :15, offers :8, deal :6, good discoun...   \n",
       "1  good discount :5, special discount :5, great d...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                      good making :2, affordable :1   \n",
       "1  good making cost :1, good making rate :1, affo...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :10, good price :9, reasonable pric...   \n",
       "1  within my budget :3, fits your budget :2, with...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  Good quality :5, High quality :5, Quality :4, ...   \n",
       "1  Quality are always 100% :1, The product qualit...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0   good price :2, best price :1, affordable rate :1  \n",
       "1  completely satisfied :1, extremely satisfied :...  "
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_aw_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_aw_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_aw_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_aw_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_aw_ad = pd.concat([positive_keywords_mal_aw_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_aw_ad = pd.concat([positive_keywords_mal_aw_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_aw_ad = positive_keywords_mal_aw_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_aw_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a77181-c8ca-482c-93d1-4baecb7897a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_dm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "0dee0d0f-246a-4335-b040-794d8addd192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:03:12.814493Z",
     "iopub.status.busy": "2025-06-11T16:03:12.814243Z",
     "iopub.status.idle": "2025-06-11T16:03:38.868615Z",
     "shell.execute_reply": "2025-06-11T16:03:38.868103Z",
     "shell.execute_reply.started": "2025-06-11T16:03:12.814476Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  26.0\n",
      "Total Input Tokens -  57634\n",
      "Total Input Cost = USD  0.58\n",
      "Total Output Tokens -  632\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.6\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_dm_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_dm_ad=[0]\n",
    "keyword_input_token_mal_dm_ad = 0\n",
    "keyword_output_token_mal_dm_ad = 0\n",
    "keyword_start_time_loop_mal_dm_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_dm_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_dm_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_dm_ad = keyword_dataframes['mal_dm_ad_final_sen_df_jul'][keyword_dataframes['mal_dm_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_dm_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_dm_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_dm_ad.append(keywords)\n",
    "        keyword_input_token_mal_dm_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_dm_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_dm_ad = time.time()\n",
    "keyword_cost_input_token_mal_dm_ad = round((0.01/1000)*keyword_input_token_mal_dm_ad,2)\n",
    "keyword_cost_output_token_mal_dm_ad = round((0.03/1000)*keyword_output_token_mal_dm_ad,2)\n",
    "keyword_total_cost_mal_dm_ad = keyword_cost_input_token_mal_dm_ad + keyword_cost_output_token_mal_dm_ad\n",
    "keyword_total_time_loop_mal_dm_ad = keyword_end_time_loop_mal_dm_ad - keyword_start_time_loop_mal_dm_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_dm_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_dm_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_dm_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_dm_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_dm_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_dm_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_dm_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "0d52a44d-d3e1-472e-a300-9f28d9ac9f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:03:38.869586Z",
     "iopub.status.busy": "2025-06-11T16:03:38.869327Z",
     "iopub.status.idle": "2025-06-11T16:03:38.915817Z",
     "shell.execute_reply": "2025-06-11T16:03:38.915340Z",
     "shell.execute_reply.started": "2025-06-11T16:03:38.869567Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Dalma Mall - Abu D...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :2, Honest :2, Trustworthy :1, Reliable ...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>helpful : 50, friendly : 45, professional : 40...</td>\n",
       "      <td>Good designs :4, Awesome designs :1, Nice desi...</td>\n",
       "      <td>variety :3, options :3, selection :2, range :2...</td>\n",
       "      <td>discount :5, deal :5, offer :2, offers :1, sch...</td>\n",
       "      <td>low making :1</td>\n",
       "      <td>reasonable :2, affordable :2, good price :2, b...</td>\n",
       "      <td>Good Quality :2, Quality :2, High-Quality :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Dalma Mall - Abu D...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>trusted advices :1, trustworthy, friendly :1, ...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>very helpful and kind : 10, excellent customer...</td>\n",
       "      <td>best design :4, perfect design :2, unique desi...</td>\n",
       "      <td>variety of collections :1, wide collection :1,...</td>\n",
       "      <td>best possible discount :1, maximum discount :2...</td>\n",
       "      <td>making charge details very clearly :1</td>\n",
       "      <td>reasonable price :2, affordable prices :2, goo...</td>\n",
       "      <td>Good quality golds :1, Quality of their jewelr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Dalma Mall - Abu D...  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Dalma Mall - Abu D...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :2, Honest :2, Trustworthy :1, Reliable ...   \n",
       "1  trusted advices :1, trustworthy, friendly :1, ...   \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, friendly : 45, professional : 40...   \n",
       "1  very helpful and kind : 10, excellent customer...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs :4, Awesome designs :1, Nice desi...   \n",
       "1  best design :4, perfect design :2, unique desi...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :3, options :3, selection :2, range :2...   \n",
       "1  variety of collections :1, wide collection :1,...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :5, deal :5, offer :2, offers :1, sch...   \n",
       "1  best possible discount :1, maximum discount :2...   \n",
       "\n",
       "                           Making Charge  \\\n",
       "0                          low making :1   \n",
       "1  making charge details very clearly :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :2, affordable :2, good price :2, b...   \n",
       "1  reasonable price :2, affordable prices :2, goo...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0       Good Quality :2, Quality :2, High-Quality :1                     \n",
       "1  Good quality golds :1, Quality of their jewelr...                     "
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_dm_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_dm_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_dm_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_dm_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_dm_ad = pd.concat([positive_keywords_mal_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_dm_ad = pd.concat([positive_keywords_mal_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_dm_ad = positive_keywords_mal_dm_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_dm_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ae34a-49d1-47d3-aff8-7c04c2dfec9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b1_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "cb507d75-efa6-4a58-b388-18efac9caa77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:03:38.917069Z",
     "iopub.status.busy": "2025-06-11T16:03:38.916642Z",
     "iopub.status.idle": "2025-06-11T16:04:14.486723Z",
     "shell.execute_reply": "2025-06-11T16:04:14.486188Z",
     "shell.execute_reply.started": "2025-06-11T16:03:38.917041Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  35.6\n",
      "Total Input Tokens -  47091\n",
      "Total Input Cost = USD  0.47\n",
      "Total Output Tokens -  760\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.49\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_b1_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_b1_ad=[0]\n",
    "keyword_input_token_mal_b1_ad = 0\n",
    "keyword_output_token_mal_b1_ad = 0\n",
    "keyword_start_time_loop_mal_b1_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b1_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b1_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b1_ad = keyword_dataframes['mal_b1_ad_final_sen_df_jul'][keyword_dataframes['mal_b1_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_b1_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_b1_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_b1_ad.append(keywords)\n",
    "        keyword_input_token_mal_b1_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_b1_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b1_ad = time.time()\n",
    "keyword_cost_input_token_mal_b1_ad = round((0.01/1000)*keyword_input_token_mal_b1_ad,2)\n",
    "keyword_cost_output_token_mal_b1_ad = round((0.03/1000)*keyword_output_token_mal_b1_ad,2)\n",
    "keyword_total_cost_mal_b1_ad = keyword_cost_input_token_mal_b1_ad + keyword_cost_output_token_mal_b1_ad\n",
    "keyword_total_time_loop_mal_b1_ad = keyword_end_time_loop_mal_b1_ad - keyword_start_time_loop_mal_b1_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_b1_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_b1_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_b1_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_b1_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_b1_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_b1_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_b1_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "29f642f0-054c-4292-9522-8925de88cf10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:04:14.487875Z",
     "iopub.status.busy": "2025-06-11T16:04:14.487519Z",
     "iopub.status.idle": "2025-06-11T16:04:14.535805Z",
     "shell.execute_reply": "2025-06-11T16:04:14.535282Z",
     "shell.execute_reply.started": "2025-06-11T16:04:14.487845Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street ( Br...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Reliable :1, Trust :1, Confidence :1, Assuranc...</td>\n",
       "      <td>good experience : 25, great experience : 15, w...</td>\n",
       "      <td>Good service : 300, Excellent service : 50, Ve...</td>\n",
       "      <td>designs :15, collection :5, models :1, pieces ...</td>\n",
       "      <td>collections : 15, variety : 3, models : 2, opt...</td>\n",
       "      <td>discount :7, offers :3, deal :3, deals :2, off...</td>\n",
       "      <td>reasonable :1, low :1, less :1</td>\n",
       "      <td>Good price :4, Best price :3, Reasonable price...</td>\n",
       "      <td>quality :8, good :2, outstanding :2, high :1, ...</td>\n",
       "      <td>exchanging :1, traded :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street ( Br...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>very good experience : 5, had a great experien...</td>\n",
       "      <td>Good customer service : 10, Very accommodating...</td>\n",
       "      <td>beautiful designs :3, nice designs :3, wonderf...</td>\n",
       "      <td>Good collection : 50, Very good collection : 1...</td>\n",
       "      <td>good discount :3, good deals :2, excellent dis...</td>\n",
       "      <td>very reasonable and very low :1, reasonably go...</td>\n",
       "      <td>Good prices :1, Beat price :1, Very good price...</td>\n",
       "      <td>high quality of the product :1, quality gold :...</td>\n",
       "      <td>buying and exchanging the jewelry :1, sell our...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Hamdan Street ( Br...  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Hamdan Street ( Br...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Reliable :1, Trust :1, Confidence :1, Assuranc...   \n",
       "1                       No relevant positive phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience : 25, great experience : 15, w...   \n",
       "1  very good experience : 5, had a great experien...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  Good service : 300, Excellent service : 50, Ve...   \n",
       "1  Good customer service : 10, Very accommodating...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :15, collection :5, models :1, pieces ...   \n",
       "1  beautiful designs :3, nice designs :3, wonderf...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collections : 15, variety : 3, models : 2, opt...   \n",
       "1  Good collection : 50, Very good collection : 1...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :7, offers :3, deal :3, deals :2, off...   \n",
       "1  good discount :3, good deals :2, excellent dis...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                     reasonable :1, low :1, less :1   \n",
       "1  very reasonable and very low :1, reasonably go...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  Good price :4, Best price :3, Reasonable price...   \n",
       "1  Good prices :1, Beat price :1, Very good price...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, good :2, outstanding :2, high :1, ...   \n",
       "1  high quality of the product :1, quality gold :...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                           exchanging :1, traded :1  \n",
       "1  buying and exchanging the jewelry :1, sell our...  "
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_b1_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_b1_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_b1_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b1_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_b1_ad = pd.concat([positive_keywords_mal_b1_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_b1_ad = pd.concat([positive_keywords_mal_b1_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_b1_ad = positive_keywords_mal_b1_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_b1_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005cd17-ebe6-4a51-9ccf-e8c50a2b6eb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b2_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "cd17cb13-281f-4653-8680-c235752cc64e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:04:14.536780Z",
     "iopub.status.busy": "2025-06-11T16:04:14.536548Z",
     "iopub.status.idle": "2025-06-11T16:04:58.618595Z",
     "shell.execute_reply": "2025-06-11T16:04:58.618089Z",
     "shell.execute_reply.started": "2025-06-11T16:04:14.536761Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  44.1\n",
      "Total Input Tokens -  122486\n",
      "Total Input Cost = USD  1.22\n",
      "Total Output Tokens -  815\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.24\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_b2_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_b2_ad=[0]\n",
    "keyword_input_token_mal_b2_ad = 0\n",
    "keyword_output_token_mal_b2_ad = 0\n",
    "keyword_start_time_loop_mal_b2_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b2_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b2_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b2_ad = keyword_dataframes['mal_b2_ad_final_sen_df_jul'][keyword_dataframes['mal_b2_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_b2_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_b2_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_b2_ad.append(keywords)\n",
    "        keyword_input_token_mal_b2_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_b2_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b2_ad = time.time()\n",
    "keyword_cost_input_token_mal_b2_ad = round((0.01/1000)*keyword_input_token_mal_b2_ad,2)\n",
    "keyword_cost_output_token_mal_b2_ad = round((0.03/1000)*keyword_output_token_mal_b2_ad,2)\n",
    "keyword_total_cost_mal_b2_ad = keyword_cost_input_token_mal_b2_ad + keyword_cost_output_token_mal_b2_ad\n",
    "keyword_total_time_loop_mal_b2_ad = keyword_end_time_loop_mal_b2_ad - keyword_start_time_loop_mal_b2_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_b2_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_b2_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_b2_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_b2_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_b2_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_b2_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_b2_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "c44645e7-de9e-46e3-82e0-3923d9eec657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:04:58.619581Z",
     "iopub.status.busy": "2025-06-11T16:04:58.619283Z",
     "iopub.status.idle": "2025-06-11T16:04:58.667503Z",
     "shell.execute_reply": "2025-06-11T16:04:58.667068Z",
     "shell.execute_reply.started": "2025-06-11T16:04:58.619543Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street (Bra...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trusted :3, Trust :2, Confidence :1, Secure :1...</td>\n",
       "      <td>good experience : 50, great experience : 40, n...</td>\n",
       "      <td>good service : 100, excellent service : 50, he...</td>\n",
       "      <td>design : 15, designs : 12, unique : 3, beautif...</td>\n",
       "      <td>collection : 98, variety : 15, options : 14, m...</td>\n",
       "      <td>good discount :15, best discount :8, maximum d...</td>\n",
       "      <td>reasonable making charges:3, minimum making ch...</td>\n",
       "      <td>best price :5, good price :5, reasonable price...</td>\n",
       "      <td>quality :10, good :6, pure :2, superior :1, ge...</td>\n",
       "      <td>exchange :4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street (Bra...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted shop :1, Trusted jewellery shop :1, Tr...</td>\n",
       "      <td>pleasant experience : 10, smooth experience : ...</td>\n",
       "      <td>very good service : 15, great service : 10, go...</td>\n",
       "      <td>amazing designs : 3, unique designs : 2, beaut...</td>\n",
       "      <td>wide variety : 3, variety of options : 3, vari...</td>\n",
       "      <td>good deal :5, great discount :4, best offer :3...</td>\n",
       "      <td>good rate on making:1, amazing deals on making...</td>\n",
       "      <td>best rates for make customers satisfied :2, go...</td>\n",
       "      <td>good quality :3, high-quality :3, quality prod...</td>\n",
       "      <td>very accommodating :1, very professional and h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Hamdan Street (Bra...  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Hamdan Street (Bra...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trusted :3, Trust :2, Confidence :1, Secure :1...   \n",
       "1  Trusted shop :1, Trusted jewellery shop :1, Tr...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience : 50, great experience : 40, n...   \n",
       "1  pleasant experience : 10, smooth experience : ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  good service : 100, excellent service : 50, he...   \n",
       "1  very good service : 15, great service : 10, go...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  design : 15, designs : 12, unique : 3, beautif...   \n",
       "1  amazing designs : 3, unique designs : 2, beaut...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 98, variety : 15, options : 14, m...   \n",
       "1  wide variety : 3, variety of options : 3, vari...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount :15, best discount :8, maximum d...   \n",
       "1  good deal :5, great discount :4, best offer :3...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  reasonable making charges:3, minimum making ch...   \n",
       "1  good rate on making:1, amazing deals on making...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :5, good price :5, reasonable price...   \n",
       "1  best rates for make customers satisfied :2, go...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :10, good :6, pure :2, superior :1, ge...   \n",
       "1  good quality :3, high-quality :3, quality prod...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                                        exchange :4  \n",
       "1  very accommodating :1, very professional and h...  "
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_b2_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_b2_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_b2_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b2_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_b2_ad = pd.concat([positive_keywords_mal_b2_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_b2_ad = pd.concat([positive_keywords_mal_b2_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_b2_ad = positive_keywords_mal_b2_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_b2_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887f419-d84e-4089-a07a-41cf561274b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_lu_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "7489cae4-842d-4bfd-ab5f-05af8631726d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:04:58.668641Z",
     "iopub.status.busy": "2025-06-11T16:04:58.668231Z",
     "iopub.status.idle": "2025-06-11T16:05:49.765517Z",
     "shell.execute_reply": "2025-06-11T16:05:49.765019Z",
     "shell.execute_reply.started": "2025-06-11T16:04:58.668614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  51.1\n",
      "Total Input Tokens -  104545\n",
      "Total Input Cost = USD  1.05\n",
      "Total Output Tokens -  863\n",
      "Total Output Cost = USD  0.03\n",
      "Total Cost = USD  1.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_lu_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_lu_ad=[0]\n",
    "keyword_input_token_mal_lu_ad = 0\n",
    "keyword_output_token_mal_lu_ad = 0\n",
    "keyword_start_time_loop_mal_lu_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_lu_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_lu_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_lu_ad = keyword_dataframes['mal_lu_ad_final_sen_df_jul'][keyword_dataframes['mal_lu_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_lu_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_lu_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_lu_ad.append(keywords)\n",
    "        keyword_input_token_mal_lu_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_lu_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_lu_ad = time.time()\n",
    "keyword_cost_input_token_mal_lu_ad = round((0.01/1000)*keyword_input_token_mal_lu_ad,2)\n",
    "keyword_cost_output_token_mal_lu_ad = round((0.03/1000)*keyword_output_token_mal_lu_ad,2)\n",
    "keyword_total_cost_mal_lu_ad = keyword_cost_input_token_mal_lu_ad + keyword_cost_output_token_mal_lu_ad\n",
    "keyword_total_time_loop_mal_lu_ad = keyword_end_time_loop_mal_lu_ad - keyword_start_time_loop_mal_lu_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_lu_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_lu_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_lu_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_lu_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_lu_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_lu_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_lu_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "8a1ffff1-f7d9-4a7a-bb15-bcd40e96f031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:05:49.768541Z",
     "iopub.status.busy": "2025-06-11T16:05:49.768293Z",
     "iopub.status.idle": "2025-06-11T16:05:49.816299Z",
     "shell.execute_reply": "2025-06-11T16:05:49.815752Z",
     "shell.execute_reply.started": "2025-06-11T16:05:49.768523Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Lulu Hypermarket -...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trustworthy :2, reliable :2, authentic :1, tru...</td>\n",
       "      <td>Good experience : 50, Great experience : 30, W...</td>\n",
       "      <td>good service : 320, excellent service : 150, h...</td>\n",
       "      <td>Good designs: 12, Unique designs: 3, Beautiful...</td>\n",
       "      <td>Good collection : 20, Nice collection : 15, Va...</td>\n",
       "      <td>good discount :15, best discount :5, good deal...</td>\n",
       "      <td>less charges :2, best making charges :1, less ...</td>\n",
       "      <td>best price :15, good price :14, reasonable pri...</td>\n",
       "      <td>quality :10, good quality :8, excellent qualit...</td>\n",
       "      <td>exchange :5, exchanging :2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Lulu Hypermarket -...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>always trust Malabar Gold :1, trustworthy to b...</td>\n",
       "      <td>Good customer service : 5, Great customer serv...</td>\n",
       "      <td>very helpful and kind : 10, friendly and helpf...</td>\n",
       "      <td>Beautiful designs at Malabar: 2, Nice design a...</td>\n",
       "      <td>Variety of collections : 3, Wide variety of de...</td>\n",
       "      <td>giving good discount :3, giving the best disco...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>Chetan giving the best price :10, Chetan givin...</td>\n",
       "      <td>quality surpassed my expectations :1, quality ...</td>\n",
       "      <td>good price :1, generous discount :1, Best poli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Lulu Hypermarket -...  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Lulu Hypermarket -...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  trustworthy :2, reliable :2, authentic :1, tru...   \n",
       "1  always trust Malabar Gold :1, trustworthy to b...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good experience : 50, Great experience : 30, W...   \n",
       "1  Good customer service : 5, Great customer serv...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  good service : 320, excellent service : 150, h...   \n",
       "1  very helpful and kind : 10, friendly and helpf...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs: 12, Unique designs: 3, Beautiful...   \n",
       "1  Beautiful designs at Malabar: 2, Nice design a...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  Good collection : 20, Nice collection : 15, Va...   \n",
       "1  Variety of collections : 3, Wide variety of de...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount :15, best discount :5, good deal...   \n",
       "1  giving good discount :3, giving the best disco...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  less charges :2, best making charges :1, less ...   \n",
       "1                       No relevant positive phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :15, good price :14, reasonable pri...   \n",
       "1  Chetan giving the best price :10, Chetan givin...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :10, good quality :8, excellent qualit...   \n",
       "1  quality surpassed my expectations :1, quality ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                         exchange :5, exchanging :2  \n",
       "1  good price :1, generous discount :1, Best poli...  "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_lu_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_lu_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_lu_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_lu_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_lu_ad = pd.concat([positive_keywords_mal_lu_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_lu_ad = pd.concat([positive_keywords_mal_lu_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_lu_ad = positive_keywords_mal_lu_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_lu_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93673e9-0f5c-4bb1-8bb5-1f69be4f9047",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "45372c37-2c20-444e-8493-46e16ba3512b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:05:49.817475Z",
     "iopub.status.busy": "2025-06-11T16:05:49.817188Z",
     "iopub.status.idle": "2025-06-11T16:17:07.948784Z",
     "shell.execute_reply": "2025-06-11T16:17:07.948285Z",
     "shell.execute_reply.started": "2025-06-11T16:05:49.817450Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed 10 Iterations\n",
      "Total Execution time (in secs) - 678.1\n",
      "Total Input Tokens - 363872\n",
      "Total Input Cost = USD 3.64\n",
      "Total Output Tokens - 22514\n",
      "Total Output Cost = USD 0.68\n",
      "Total Cost = USD 4.32\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = [\n",
    "    'Customer Confidence', 'Store Experience', 'Store Staff', 'Product Design',\n",
    "    'Product Variety', 'Discount', 'Making Charge', 'Price', \n",
    "    'Product Quality', 'Jewellery Exchange'\n",
    "]\n",
    "\n",
    "keyword_counter_mal_mb = [0]\n",
    "keyword_input_token_mal_mb = 0\n",
    "keyword_output_token_mal_mb = 0\n",
    "keyword_start_time_loop_mal_mb = time.time()\n",
    "\n",
    "# Threading setup\n",
    "keyword_total_iterations = len(keyword_topics)\n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_mb[0] += 1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_mb = keyword_dataframes['mal_mb_final_sen_df_jul'][keyword_dataframes['mal_mb_final_sen_df_jul'][topic] == 1]['review_text'].tolist()\n",
    "    \n",
    "    # If there are positive comments, process them in chunks of 25\n",
    "    if filtered_comments_mal_mb:\n",
    "        # Loop through the filtered comments in batches of 25\n",
    "        for i in range(0, len(filtered_comments_mal_mb), 25):\n",
    "            # Get the current batch of 25 comments (or less if it's the last batch)\n",
    "            comment_batch = filtered_comments_mal_mb[i:i + 25]\n",
    "            # Call the positive_keywords function and store the result for each batch\n",
    "            keywords, input_tokens_loop, output_token_loop = positive_keywords(comment_batch, topic)\n",
    "            # Add the result to the output dictionary\n",
    "            keyword_positive_output_mal_mb.append(keywords)\n",
    "            keyword_input_token_mal_mb += input_tokens_loop\n",
    "            keyword_output_token_mal_mb += output_token_loop\n",
    "\n",
    "# Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_mb = time.time()\n",
    "keyword_cost_input_token_mal_mb = round((0.01 / 1000) * keyword_input_token_mal_mb, 2)\n",
    "keyword_cost_output_token_mal_mb = round((0.03 / 1000) * keyword_output_token_mal_mb, 2)\n",
    "keyword_total_cost_mal_mb = keyword_cost_input_token_mal_mb + keyword_cost_output_token_mal_mb\n",
    "keyword_total_time_loop_mal_mb = keyword_end_time_loop_mal_mb - keyword_start_time_loop_mal_mb\n",
    "\n",
    "# Display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed\", keyword_counter_mal_mb[0], \"Iterations\")\n",
    "print(\"Total Execution time (in secs) -\", round(keyword_total_time_loop_mal_mb, 1))\n",
    "print(\"Total Input Tokens -\", keyword_input_token_mal_mb)\n",
    "print(\"Total Input Cost = USD\", keyword_cost_input_token_mal_mb)\n",
    "print(\"Total Output Tokens -\", keyword_output_token_mal_mb)\n",
    "print(\"Total Output Cost = USD\", keyword_cost_output_token_mal_mb)\n",
    "print(\"Total Cost = USD\", round(keyword_total_cost_mal_mb, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "dd884f0f-e9aa-4920-b624-afd5172d8b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:17:07.949972Z",
     "iopub.status.busy": "2025-06-11T16:17:07.949597Z",
     "iopub.status.idle": "2025-06-11T16:17:09.539871Z",
     "shell.execute_reply": "2025-06-11T16:17:09.539333Z",
     "shell.execute_reply.started": "2025-06-11T16:17:07.949944Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Meena Bazar - Dubai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :2, Reliable :2, Genuine :2, Loyal :1, F...</td>\n",
       "      <td>Good experience :8, Great experience :6, Nice ...</td>\n",
       "      <td>helpful :5, friendly :3, patient :3, courteous...</td>\n",
       "      <td>designs :15, good designs :5, best design :2, ...</td>\n",
       "      <td>collection :10, options :3, variety :2, select...</td>\n",
       "      <td>discount :8, deal :5, offers :3, good discount...</td>\n",
       "      <td>discount :3, reduction :1, competitive :2, low...</td>\n",
       "      <td>best price :5, reasonable prices :2, great pri...</td>\n",
       "      <td>quality :8, good quality :3, excellent :2, top...</td>\n",
       "      <td>exchange :9, value :2, process :2, deal :1, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Meena Bazar - Dubai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust him with any purchase :1, Trust I have w...</td>\n",
       "      <td>Great shopping experience :2, Nice shopping ex...</td>\n",
       "      <td>very helpful :2, good service :2, excellent se...</td>\n",
       "      <td>good designs and good prices :1, designs were ...</td>\n",
       "      <td>great variety of jewelry collection :1, variou...</td>\n",
       "      <td>best possible discount :2, good discount on ma...</td>\n",
       "      <td>best reduction on making charge :1, discount o...</td>\n",
       "      <td>offered us the best possible price :1, helped ...</td>\n",
       "      <td>quality of the products exceeded my expectatio...</td>\n",
       "      <td>great value :1, excellent service :1, great de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Meena Bazar - Dubai  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Meena Bazar - Dubai  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :2, Reliable :2, Genuine :2, Loyal :1, F...   \n",
       "1  Trust him with any purchase :1, Trust I have w...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good experience :8, Great experience :6, Nice ...   \n",
       "1  Great shopping experience :2, Nice shopping ex...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :5, friendly :3, patient :3, courteous...   \n",
       "1  very helpful :2, good service :2, excellent se...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :15, good designs :5, best design :2, ...   \n",
       "1  good designs and good prices :1, designs were ...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection :10, options :3, variety :2, select...   \n",
       "1  great variety of jewelry collection :1, variou...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :8, deal :5, offers :3, good discount...   \n",
       "1  best possible discount :2, good discount on ma...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  discount :3, reduction :1, competitive :2, low...   \n",
       "1  best reduction on making charge :1, discount o...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :5, reasonable prices :2, great pri...   \n",
       "1  offered us the best possible price :1, helped ...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, good quality :3, excellent :2, top...   \n",
       "1  quality of the products exceeded my expectatio...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :9, value :2, process :2, deal :1, co...  \n",
       "1  great value :1, excellent service :1, great de...  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_mb = pd.concat([positive_keywords_mal_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_mb = pd.concat([positive_keywords_mal_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_mb = positive_keywords_mal_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ddd182-0bf3-4dfc-9cb6-79d969eb6286",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_sh_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "58a229ce-ea61-4838-8cac-e974361376bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:17:09.540826Z",
     "iopub.status.busy": "2025-06-11T16:17:09.540567Z",
     "iopub.status.idle": "2025-06-11T16:17:43.105927Z",
     "shell.execute_reply": "2025-06-11T16:17:43.105434Z",
     "shell.execute_reply.started": "2025-06-11T16:17:09.540810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  33.6\n",
      "Total Input Tokens -  51326\n",
      "Total Input Cost = USD  0.51\n",
      "Total Output Tokens -  770\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.53\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_sh_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_sh_ad=[0]\n",
    "keyword_input_token_mal_sh_ad = 0\n",
    "keyword_output_token_mal_sh_ad = 0\n",
    "keyword_start_time_loop_mal_sh_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_sh_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_sh_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_sh_ad = keyword_dataframes['mal_sh_ad_final_sen_df_jul'][keyword_dataframes['mal_sh_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_sh_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_sh_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_sh_ad.append(keywords)\n",
    "        keyword_input_token_mal_sh_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_sh_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_sh_ad = time.time()\n",
    "keyword_cost_input_token_mal_sh_ad = round((0.01/1000)*keyword_input_token_mal_sh_ad,2)\n",
    "keyword_cost_output_token_mal_sh_ad = round((0.03/1000)*keyword_output_token_mal_sh_ad,2)\n",
    "keyword_total_cost_mal_sh_ad = keyword_cost_input_token_mal_sh_ad + keyword_cost_output_token_mal_sh_ad\n",
    "keyword_total_time_loop_mal_sh_ad = keyword_end_time_loop_mal_sh_ad - keyword_start_time_loop_mal_sh_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_sh_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_sh_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_sh_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_sh_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_sh_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_sh_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_sh_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "66a789f6-faf5-42a1-bc61-c70cd3ba1ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:17:43.107031Z",
     "iopub.status.busy": "2025-06-11T16:17:43.106679Z",
     "iopub.status.idle": "2025-06-11T16:17:43.155409Z",
     "shell.execute_reply": "2025-06-11T16:17:43.154938Z",
     "shell.execute_reply.started": "2025-06-11T16:17:43.107002Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Shabia Musaffah</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustworthy :1, Credibility :1, Transparency :...</td>\n",
       "      <td>Good experience : 45, Great experience : 20, N...</td>\n",
       "      <td>Good service : 1000, Excellent service : 500, ...</td>\n",
       "      <td>Good design :30, Nice design :10, Best design ...</td>\n",
       "      <td>collection : 45, collections : 40, varieties :...</td>\n",
       "      <td>discount :5, deal :3, sale :2, offers :1, prom...</td>\n",
       "      <td>reasonable making charges :1, best rates :1</td>\n",
       "      <td>reasonable :3, best price :3, good price :3, f...</td>\n",
       "      <td>quality :5, Durable :1</td>\n",
       "      <td>exchange policy :1, gold exchange :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Shabia Musaffah</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Complete credibility :1, Trustworthy and for t...</td>\n",
       "      <td>Very good experience : 10, Had a good experien...</td>\n",
       "      <td>Very good service : 50, Good customer service ...</td>\n",
       "      <td>Very good designs :15, Very nice designs :3, B...</td>\n",
       "      <td>good collection : 10, nice collection : 8, bes...</td>\n",
       "      <td>good discount :2, nice deal :1, best discount ...</td>\n",
       "      <td>reasonable making charges :1, best rates in ma...</td>\n",
       "      <td>reasonable prices :1, best price gold :1, good...</td>\n",
       "      <td>great quality :1, high quality :2, excellent q...</td>\n",
       "      <td>exchange your gold without any deductions :1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Shabia Musaffah  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Shabia Musaffah  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trustworthy :1, Credibility :1, Transparency :...   \n",
       "1  Complete credibility :1, Trustworthy and for t...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good experience : 45, Great experience : 20, N...   \n",
       "1  Very good experience : 10, Had a good experien...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  Good service : 1000, Excellent service : 500, ...   \n",
       "1  Very good service : 50, Good customer service ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good design :30, Nice design :10, Best design ...   \n",
       "1  Very good designs :15, Very nice designs :3, B...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, collections : 40, varieties :...   \n",
       "1  good collection : 10, nice collection : 8, bes...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :5, deal :3, sale :2, offers :1, prom...   \n",
       "1  good discount :2, nice deal :1, best discount ...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0        reasonable making charges :1, best rates :1   \n",
       "1  reasonable making charges :1, best rates in ma...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :3, best price :3, good price :3, f...   \n",
       "1  reasonable prices :1, best price gold :1, good...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0                             quality :5, Durable :1   \n",
       "1  great quality :1, high quality :2, excellent q...   \n",
       "\n",
       "                             Jewellery Exchange  \n",
       "0          exchange policy :1, gold exchange :1  \n",
       "1  exchange your gold without any deductions :1  "
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_sh_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_sh_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_sh_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_sh_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_sh_ad = pd.concat([positive_keywords_mal_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_sh_ad = pd.concat([positive_keywords_mal_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_sh_ad = positive_keywords_mal_sh_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_sh_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15aa112-c626-47c0-970f-8433e766acc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_b2_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "4446f2d9-943c-41c2-b436-354a385c5d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:17:43.156296Z",
     "iopub.status.busy": "2025-06-11T16:17:43.156097Z",
     "iopub.status.idle": "2025-06-11T16:18:13.217346Z",
     "shell.execute_reply": "2025-06-11T16:18:13.216814Z",
     "shell.execute_reply.started": "2025-06-11T16:17:43.156277Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  30.1\n",
      "Total Input Tokens -  57161\n",
      "Total Input Cost = USD  0.57\n",
      "Total Output Tokens -  734\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.59\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_b2_af = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_b2_af=[0]\n",
    "keyword_input_token_mal_b2_af = 0\n",
    "keyword_output_token_mal_b2_af = 0\n",
    "keyword_start_time_loop_mal_b2_af = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b2_af, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b2_af[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b2_af = keyword_dataframes['mal_b2_af_final_sen_df_jul'][keyword_dataframes['mal_b2_af_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_b2_af:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_b2_af,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_b2_af.append(keywords)\n",
    "        keyword_input_token_mal_b2_af += input_tokens_loop\n",
    "        keyword_output_token_mal_b2_af += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b2_af = time.time()\n",
    "keyword_cost_input_token_mal_b2_af = round((0.01/1000)*keyword_input_token_mal_b2_af,2)\n",
    "keyword_cost_output_token_mal_b2_af = round((0.03/1000)*keyword_output_token_mal_b2_af,2)\n",
    "keyword_total_cost_mal_b2_af = keyword_cost_input_token_mal_b2_af + keyword_cost_output_token_mal_b2_af\n",
    "keyword_total_time_loop_mal_b2_af = keyword_end_time_loop_mal_b2_af - keyword_start_time_loop_mal_b2_af\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_b2_af[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_b2_af,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_b2_af)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_b2_af)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_b2_af)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_b2_af)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_b2_af,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "63fbb6dd-67de-41d9-9eee-7ec30cda0f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:18:13.218250Z",
     "iopub.status.busy": "2025-06-11T16:18:13.218043Z",
     "iopub.status.idle": "2025-06-11T16:18:13.269995Z",
     "shell.execute_reply": "2025-06-11T16:18:13.269484Z",
     "shell.execute_reply.started": "2025-06-11T16:18:13.218232Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Souq Al Kabeer Bui...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Trustable :2, Reliable :1, Honest :1...</td>\n",
       "      <td>Great : 15, Good : 10, Nice : 8, Excellent : 5...</td>\n",
       "      <td>good service : 320, very good : 120, excellent...</td>\n",
       "      <td>design : 20, designs : 15, model : 1</td>\n",
       "      <td>varieties :3, variety :3, selection :3, option...</td>\n",
       "      <td>good discount :10, best discount :4, additiona...</td>\n",
       "      <td>reasonable making charges:1, best making charge:1</td>\n",
       "      <td>good price :4, reasonable prices :3, best pric...</td>\n",
       "      <td>quality :3, good :2, premium :1, amazing :1</td>\n",
       "      <td>exchanging :2, old gold :2, new :2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Souq Al Kabeer Bui...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustable place to buy gold :1, Malabar Gold h...</td>\n",
       "      <td>Great experience : 20, Good experience : 15, N...</td>\n",
       "      <td>very good service : 30, excellent service by :...</td>\n",
       "      <td>beautiful designs : 2, good designs : 5, nice ...</td>\n",
       "      <td>lots of variety :2, wide variety :2, variety o...</td>\n",
       "      <td>good deal :8, best offer :2, amazing deal :2, ...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>make the most of your money :1, best pricing p...</td>\n",
       "      <td>good quality :2, premium quality :1, amazing q...</td>\n",
       "      <td>exchanging my old gold :1, exchanging old gold...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Souq Al Kabeer Bui...  Positive  keywords   \n",
       "1  Malabar Gold and Diamonds - Souq Al Kabeer Bui...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Trustable :2, Reliable :1, Honest :1...   \n",
       "1  Trustable place to buy gold :1, Malabar Gold h...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great : 15, Good : 10, Nice : 8, Excellent : 5...   \n",
       "1  Great experience : 20, Good experience : 15, N...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  good service : 320, very good : 120, excellent...   \n",
       "1  very good service : 30, excellent service by :...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0               design : 20, designs : 15, model : 1   \n",
       "1  beautiful designs : 2, good designs : 5, nice ...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  varieties :3, variety :3, selection :3, option...   \n",
       "1  lots of variety :2, wide variety :2, variety o...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount :10, best discount :4, additiona...   \n",
       "1  good deal :8, best offer :2, amazing deal :2, ...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  reasonable making charges:1, best making charge:1   \n",
       "1                       No relevant positive phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good price :4, reasonable prices :3, best pric...   \n",
       "1  make the most of your money :1, best pricing p...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0        quality :3, good :2, premium :1, amazing :1   \n",
       "1  good quality :2, premium quality :1, amazing q...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                 exchanging :2, old gold :2, new :2  \n",
       "1  exchanging my old gold :1, exchanging old gold...  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_b2_af = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_b2_af[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_b2_af:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b2_af'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_b2_af = pd.concat([positive_keywords_mal_b2_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_b2_af = pd.concat([positive_keywords_mal_b2_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_b2_af = positive_keywords_mal_b2_af.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_b2_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810fb98a-4dba-4bc1-9caf-577352aa7834",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mna_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "cb2f0745-fec7-4692-b9a4-d9fd64ca23dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:18:13.270932Z",
     "iopub.status.busy": "2025-06-11T16:18:13.270670Z",
     "iopub.status.idle": "2025-06-11T16:18:46.836849Z",
     "shell.execute_reply": "2025-06-11T16:18:46.836318Z",
     "shell.execute_reply.started": "2025-06-11T16:18:13.270909Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  33.6\n",
      "Total Input Tokens -  46524\n",
      "Total Input Cost = USD  0.47\n",
      "Total Output Tokens -  687\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.49\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mna_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mna_mb=[0]\n",
    "keyword_input_token_mna_mb = 0\n",
    "keyword_output_token_mna_mb = 0\n",
    "keyword_start_time_loop_mna_mb = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mna_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mna_mb[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mna_mb = keyword_dataframes['mna_mb_final_sen_df_jul'][keyword_dataframes['mna_mb_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mna_mb:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mna_mb,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mna_mb.append(keywords)\n",
    "        keyword_input_token_mna_mb += input_tokens_loop\n",
    "        keyword_output_token_mna_mb += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mna_mb = time.time()\n",
    "keyword_cost_input_token_mna_mb = round((0.01/1000)*keyword_input_token_mna_mb,2)\n",
    "keyword_cost_output_token_mna_mb = round((0.03/1000)*keyword_output_token_mna_mb,2)\n",
    "keyword_total_cost_mna_mb = keyword_cost_input_token_mna_mb + keyword_cost_output_token_mna_mb\n",
    "keyword_total_time_loop_mna_mb = keyword_end_time_loop_mna_mb - keyword_start_time_loop_mna_mb\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mna_mb[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mna_mb,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mna_mb)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mna_mb)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mna_mb)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mna_mb)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mna_mb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "7c0de61e-f846-42fb-8cef-d0a68784f36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:18:46.837863Z",
     "iopub.status.busy": "2025-06-11T16:18:46.837592Z",
     "iopub.status.idle": "2025-06-11T16:18:46.882625Z",
     "shell.execute_reply": "2025-06-11T16:18:46.882103Z",
     "shell.execute_reply.started": "2025-06-11T16:18:46.837843Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meena Jewellers - Meena Bazar</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trusted :3, trust :2, trustworthy :2, reliable...</td>\n",
       "      <td>professional : 10, helpful : 8, knowledgeable ...</td>\n",
       "      <td>professional : 10, helpful : 9, knowledgeable ...</td>\n",
       "      <td>unique :5, elegant :4, stylish :4, intricate :...</td>\n",
       "      <td>variety :8, collection :7, collections :5, des...</td>\n",
       "      <td>discount :3, deals :2</td>\n",
       "      <td>reasonable :3, best :3, decent :1, less :1, ve...</td>\n",
       "      <td>value : 8, reasonable : 6, transparent : 6, af...</td>\n",
       "      <td>craftsmanship :10, quality :9, authentic :3, t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meena Jewellers - Meena Bazar</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>trusted showroom :1, trust this place :1, trus...</td>\n",
       "      <td>great experience : 5, wonderful experience : 4...</td>\n",
       "      <td>very helpful staff : 3, extremely helpful and ...</td>\n",
       "      <td>best designs :5, excellent design :3, unique d...</td>\n",
       "      <td>wide variety :3, variety of designs :2, variet...</td>\n",
       "      <td>best discounts :2, great discount :2, best dea...</td>\n",
       "      <td>reasonable making charges :2, best making char...</td>\n",
       "      <td>value for money : 12, reasonable prices : 3, b...</td>\n",
       "      <td>quality of craftsmanship is excellent :3, craf...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Store Name Sentiment      Type  \\\n",
       "0  Meena Jewellers - Meena Bazar  Positive  keywords   \n",
       "1  Meena Jewellers - Meena Bazar  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  trusted :3, trust :2, trustworthy :2, reliable...   \n",
       "1  trusted showroom :1, trust this place :1, trus...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  professional : 10, helpful : 8, knowledgeable ...   \n",
       "1  great experience : 5, wonderful experience : 4...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  professional : 10, helpful : 9, knowledgeable ...   \n",
       "1  very helpful staff : 3, extremely helpful and ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique :5, elegant :4, stylish :4, intricate :...   \n",
       "1  best designs :5, excellent design :3, unique d...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :8, collection :7, collections :5, des...   \n",
       "1  wide variety :3, variety of designs :2, variet...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                              discount :3, deals :2   \n",
       "1  best discounts :2, great discount :2, best dea...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  reasonable :3, best :3, decent :1, less :1, ve...   \n",
       "1  reasonable making charges :2, best making char...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  value : 8, reasonable : 6, transparent : 6, af...   \n",
       "1  value for money : 12, reasonable prices : 3, b...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  craftsmanship :10, quality :9, authentic :3, t...                     \n",
       "1  quality of craftsmanship is excellent :3, craf...                     "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mna_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mna_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mna_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mna_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mna_mb = pd.concat([positive_keywords_mna_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mna_mb = pd.concat([positive_keywords_mna_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mna_mb = positive_keywords_mna_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mna_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a121ca8-835a-4fd2-801d-5c999b78bfb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### min_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "34d12c50-d436-448b-b1b0-788d41d68116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:18:46.883559Z",
     "iopub.status.busy": "2025-06-11T16:18:46.883306Z",
     "iopub.status.idle": "2025-06-11T16:19:22.953853Z",
     "shell.execute_reply": "2025-06-11T16:19:22.953308Z",
     "shell.execute_reply.started": "2025-06-11T16:18:46.883542Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  36.1\n",
      "Total Input Tokens -  66627\n",
      "Total Input Cost = USD  0.67\n",
      "Total Output Tokens -  842\n",
      "Total Output Cost = USD  0.03\n",
      "Total Cost = USD  0.7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_min_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_min_ak=[0]\n",
    "keyword_input_token_min_ak = 0\n",
    "keyword_output_token_min_ak = 0\n",
    "keyword_start_time_loop_min_ak = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_min_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_min_ak[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_min_ak = keyword_dataframes['min_ak_final_sen_df_jul'][keyword_dataframes['min_ak_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_min_ak:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_min_ak,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_min_ak.append(keywords)\n",
    "        keyword_input_token_min_ak += input_tokens_loop\n",
    "        keyword_output_token_min_ak += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_min_ak = time.time()\n",
    "keyword_cost_input_token_min_ak = round((0.01/1000)*keyword_input_token_min_ak,2)\n",
    "keyword_cost_output_token_min_ak = round((0.03/1000)*keyword_output_token_min_ak,2)\n",
    "keyword_total_cost_min_ak = keyword_cost_input_token_min_ak + keyword_cost_output_token_min_ak\n",
    "keyword_total_time_loop_min_ak = keyword_end_time_loop_min_ak - keyword_start_time_loop_min_ak\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_min_ak[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_min_ak,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_min_ak)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_min_ak)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_min_ak)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_min_ak)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_min_ak,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "57f0c138-d1a1-4551-a2cd-04af4f23ba31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:19:22.955035Z",
     "iopub.status.busy": "2025-06-11T16:19:22.954722Z",
     "iopub.status.idle": "2025-06-11T16:19:23.002936Z",
     "shell.execute_reply": "2025-06-11T16:19:23.002453Z",
     "shell.execute_reply.started": "2025-06-11T16:19:22.955012Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mint Jewels - Al Karama</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustworthy :5, Reliable :4, Genuine :3, Hones...</td>\n",
       "      <td>smooth transaction :5, great experience :4, ea...</td>\n",
       "      <td>accommodating : 50, friendly : 45, helpful : 4...</td>\n",
       "      <td>designs :3, craftsmanship :2, collection :2, s...</td>\n",
       "      <td>variety :4, collections :3, collection :3, ran...</td>\n",
       "      <td>Good Deal :10, Best Deal :5, Amazing Deal :2, ...</td>\n",
       "      <td>low making charge :2</td>\n",
       "      <td>best rate : 15, good price : 12, good rate : 1...</td>\n",
       "      <td>quality :8, good quality :4, top-notch :2, aut...</td>\n",
       "      <td>good rates :3, high value :2, best price :2, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mint Jewels - Al Karama</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy place to buy :1, Very trusted peop...</td>\n",
       "      <td>very smooth transaction :3, great experience w...</td>\n",
       "      <td>very accommodating staff : 10, friendly and ac...</td>\n",
       "      <td>great designs :1, very good designs :1, beauti...</td>\n",
       "      <td>good collections :5, great collection :3, stun...</td>\n",
       "      <td>Best deals in the market :1, Got a good deal a...</td>\n",
       "      <td>lower making charge :1, big difference compari...</td>\n",
       "      <td>best price for selling gold : 3, good price fo...</td>\n",
       "      <td>quality of the gold is exceptional :1, top-qua...</td>\n",
       "      <td>hassle-free transaction :4, smooth transaction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type  \\\n",
       "0  Mint Jewels - Al Karama  Positive  keywords   \n",
       "1  Mint Jewels - Al Karama  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trustworthy :5, Reliable :4, Genuine :3, Hones...   \n",
       "1  Trustworthy place to buy :1, Very trusted peop...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  smooth transaction :5, great experience :4, ea...   \n",
       "1  very smooth transaction :3, great experience w...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  accommodating : 50, friendly : 45, helpful : 4...   \n",
       "1  very accommodating staff : 10, friendly and ac...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :3, craftsmanship :2, collection :2, s...   \n",
       "1  great designs :1, very good designs :1, beauti...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :4, collections :3, collection :3, ran...   \n",
       "1  good collections :5, great collection :3, stun...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  Good Deal :10, Best Deal :5, Amazing Deal :2, ...   \n",
       "1  Best deals in the market :1, Got a good deal a...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                               low making charge :2   \n",
       "1  lower making charge :1, big difference compari...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best rate : 15, good price : 12, good rate : 1...   \n",
       "1  best price for selling gold : 3, good price fo...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, good quality :4, top-notch :2, aut...   \n",
       "1  quality of the gold is exceptional :1, top-qua...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  good rates :3, high value :2, best price :2, e...  \n",
       "1  hassle-free transaction :4, smooth transaction...  "
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_min_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_min_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_min_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'min_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_min_ak = pd.concat([positive_keywords_min_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_min_ak = pd.concat([positive_keywords_min_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_min_ak = positive_keywords_min_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_min_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1535d16f-d0df-4fa9-b84a-313dca6027c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "bea9b8c3-9e75-4890-af44-73f60a3198c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:19:23.003880Z",
     "iopub.status.busy": "2025-06-11T16:19:23.003568Z",
     "iopub.status.idle": "2025-06-11T16:19:58.074085Z",
     "shell.execute_reply": "2025-06-11T16:19:58.073555Z",
     "shell.execute_reply.started": "2025-06-11T16:19:23.003850Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  35.1\n",
      "Total Input Tokens -  50551\n",
      "Total Input Cost = USD  0.51\n",
      "Total Output Tokens -  813\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.53\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_ak=[0]\n",
    "keyword_input_token_joy_ak = 0\n",
    "keyword_output_token_joy_ak = 0\n",
    "keyword_start_time_loop_joy_ak = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_ak[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_ak = keyword_dataframes['joy_ak_final_sen_df_jul'][keyword_dataframes['joy_ak_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_ak:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_ak,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_ak.append(keywords)\n",
    "        keyword_input_token_joy_ak += input_tokens_loop\n",
    "        keyword_output_token_joy_ak += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_ak = time.time()\n",
    "keyword_cost_input_token_joy_ak = round((0.01/1000)*keyword_input_token_joy_ak,2)\n",
    "keyword_cost_output_token_joy_ak = round((0.03/1000)*keyword_output_token_joy_ak,2)\n",
    "keyword_total_cost_joy_ak = keyword_cost_input_token_joy_ak + keyword_cost_output_token_joy_ak\n",
    "keyword_total_time_loop_joy_ak = keyword_end_time_loop_joy_ak - keyword_start_time_loop_joy_ak\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_ak[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_ak,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_ak)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_ak)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_ak)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_ak)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_ak,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "091fcf46-c687-417b-8611-31bb7552bb63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:19:58.075177Z",
     "iopub.status.busy": "2025-06-11T16:19:58.074879Z",
     "iopub.status.idle": "2025-06-11T16:19:58.123781Z",
     "shell.execute_reply": "2025-06-11T16:19:58.123305Z",
     "shell.execute_reply.started": "2025-06-11T16:19:58.075155Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Al Karama</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Reliable :2, Trustable :1, Confident...</td>\n",
       "      <td>pleasant :3, welcoming :3, smooth :3, enjoyabl...</td>\n",
       "      <td>friendly : 50, helpful : 45, accommodating : 3...</td>\n",
       "      <td>Good designs: 15, Nice designs: 10, Excellent ...</td>\n",
       "      <td>Good collection : 30, Nice collection : 20, Wi...</td>\n",
       "      <td>discount :10, deal :8, offer :6, vouchers :1, ...</td>\n",
       "      <td>reasonable :2, low :1, discounted :1, less exp...</td>\n",
       "      <td>Good price :5, Affordable :4, Competitive pric...</td>\n",
       "      <td>Good Quality :8, High-quality :1, Best Quality...</td>\n",
       "      <td>exchange :5, purchase :2, sale :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Al Karama</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy and reliable brand :1, Trust in th...</td>\n",
       "      <td>pleasant experience :3, welcoming ambiance :2,...</td>\n",
       "      <td>very friendly staff : 10, helpful staff : 8, a...</td>\n",
       "      <td>Intricate designs: 2, Exquisite designs: 1, Un...</td>\n",
       "      <td>Variety of choices : 3, Wide variety of design...</td>\n",
       "      <td>good discount :5, best discount :3, great deal...</td>\n",
       "      <td>making charges are reasonable :2, low making c...</td>\n",
       "      <td>Value for money :3, Better price :2, Excellent...</td>\n",
       "      <td>Quality of the gold is impeccable :1, Quality ...</td>\n",
       "      <td>delightful experience :1, wonderful experience...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Al Karama  Positive  keywords   \n",
       "1  Joyalukkas Jewellery - Al Karama  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Reliable :2, Trustable :1, Confident...   \n",
       "1  Trustworthy and reliable brand :1, Trust in th...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant :3, welcoming :3, smooth :3, enjoyabl...   \n",
       "1  pleasant experience :3, welcoming ambiance :2,...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  friendly : 50, helpful : 45, accommodating : 3...   \n",
       "1  very friendly staff : 10, helpful staff : 8, a...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs: 15, Nice designs: 10, Excellent ...   \n",
       "1  Intricate designs: 2, Exquisite designs: 1, Un...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  Good collection : 30, Nice collection : 20, Wi...   \n",
       "1  Variety of choices : 3, Wide variety of design...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :10, deal :8, offer :6, vouchers :1, ...   \n",
       "1  good discount :5, best discount :3, great deal...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  reasonable :2, low :1, discounted :1, less exp...   \n",
       "1  making charges are reasonable :2, low making c...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  Good price :5, Affordable :4, Competitive pric...   \n",
       "1  Value for money :3, Better price :2, Excellent...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  Good Quality :8, High-quality :1, Best Quality...   \n",
       "1  Quality of the gold is impeccable :1, Quality ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                  exchange :5, purchase :2, sale :1  \n",
       "1  delightful experience :1, wonderful experience...  "
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_ak = pd.concat([positive_keywords_joy_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_ak = pd.concat([positive_keywords_joy_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_ak = positive_keywords_joy_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaae53b-67ab-4bb8-a13b-03d99ae89a22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### kan_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a24c1670-ac4c-4e4c-8b90-5aa19f5bc995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:19:58.124757Z",
     "iopub.status.busy": "2025-06-11T16:19:58.124445Z",
     "iopub.status.idle": "2025-06-11T16:20:21.173564Z",
     "shell.execute_reply": "2025-06-11T16:20:21.173011Z",
     "shell.execute_reply.started": "2025-06-11T16:19:58.124729Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  23.0\n",
      "Total Input Tokens -  25525\n",
      "Total Input Cost = USD  0.26\n",
      "Total Output Tokens -  767\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.28\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_kan_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_kan_mb=[0]\n",
    "keyword_input_token_kan_mb = 0\n",
    "keyword_output_token_kan_mb = 0\n",
    "keyword_start_time_loop_kan_mb = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_kan_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_kan_mb[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_kan_mb = keyword_dataframes['kan_mb_final_sen_df_jul'][keyword_dataframes['kan_mb_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_kan_mb:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_kan_mb,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_kan_mb.append(keywords)\n",
    "        keyword_input_token_kan_mb += input_tokens_loop\n",
    "        keyword_output_token_kan_mb += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_kan_mb = time.time()\n",
    "keyword_cost_input_token_kan_mb = round((0.01/1000)*keyword_input_token_kan_mb,2)\n",
    "keyword_cost_output_token_kan_mb = round((0.03/1000)*keyword_output_token_kan_mb,2)\n",
    "keyword_total_cost_kan_mb = keyword_cost_input_token_kan_mb + keyword_cost_output_token_kan_mb\n",
    "keyword_total_time_loop_kan_mb = keyword_end_time_loop_kan_mb - keyword_start_time_loop_kan_mb\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_kan_mb[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_kan_mb,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_kan_mb)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_kan_mb)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_kan_mb)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_kan_mb)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_kan_mb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "280db089-c313-4855-8dba-c10bed71b701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:20:21.174828Z",
     "iopub.status.busy": "2025-06-11T16:20:21.174411Z",
     "iopub.status.idle": "2025-06-11T16:20:21.222430Z",
     "shell.execute_reply": "2025-06-11T16:20:21.221966Z",
     "shell.execute_reply.started": "2025-06-11T16:20:21.174799Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kanz Jewellers</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustworthy :1, Authenticity :1, Genuine :1</td>\n",
       "      <td>good experience : 10, great experience : 9, am...</td>\n",
       "      <td>helpful : 45, excellent : 40, good : 35, polit...</td>\n",
       "      <td>Good design :5, Best design :4, Unique design ...</td>\n",
       "      <td>variety :3, range :2, selection :2, choice :1,...</td>\n",
       "      <td>Good deal :9, Good discount :6, Great discount...</td>\n",
       "      <td>affordable :2, low :1, best :1, favorable :1</td>\n",
       "      <td>best price :5, good price :4, affordable price...</td>\n",
       "      <td>quality :3, top-notch :2, excellent :1, great :1</td>\n",
       "      <td>favorable making rates:1, comprehensive gold e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kanz Jewellers</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Genuinely a trustworthy jeweller :1, Authentic...</td>\n",
       "      <td>pleasant shopping experience : 2, very good ex...</td>\n",
       "      <td>very helpful : 20, excellent service : 18, goo...</td>\n",
       "      <td>Good designs :3, Best designs :2, Unique &amp; ele...</td>\n",
       "      <td>nice variety :1, wide collection :1, amazing c...</td>\n",
       "      <td>Good deal with jasvinder singh :3, Gave us a p...</td>\n",
       "      <td>affordable making charge :1, low making charge...</td>\n",
       "      <td>best value for our purchase :1, great value fo...</td>\n",
       "      <td>excellent product quality :1, top-notch qualit...</td>\n",
       "      <td>exchange my existing gold chain:1, benefiting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store Name Sentiment      Type  \\\n",
       "0  Kanz Jewellers  Positive  keywords   \n",
       "1  Kanz Jewellers  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0        Trustworthy :1, Authenticity :1, Genuine :1   \n",
       "1  Genuinely a trustworthy jeweller :1, Authentic...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience : 10, great experience : 9, am...   \n",
       "1  pleasant shopping experience : 2, very good ex...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 45, excellent : 40, good : 35, polit...   \n",
       "1  very helpful : 20, excellent service : 18, goo...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good design :5, Best design :4, Unique design ...   \n",
       "1  Good designs :3, Best designs :2, Unique & ele...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :3, range :2, selection :2, choice :1,...   \n",
       "1  nice variety :1, wide collection :1, amazing c...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  Good deal :9, Good discount :6, Great discount...   \n",
       "1  Good deal with jasvinder singh :3, Gave us a p...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0       affordable :2, low :1, best :1, favorable :1   \n",
       "1  affordable making charge :1, low making charge...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :5, good price :4, affordable price...   \n",
       "1  best value for our purchase :1, great value fo...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0   quality :3, top-notch :2, excellent :1, great :1   \n",
       "1  excellent product quality :1, top-notch qualit...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  favorable making rates:1, comprehensive gold e...  \n",
       "1  exchange my existing gold chain:1, benefiting ...  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_kan_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_kan_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_kan_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'kan_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_kan_mb = pd.concat([positive_keywords_kan_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_kan_mb = pd.concat([positive_keywords_kan_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_kan_mb = positive_keywords_kan_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_kan_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe854f-3a4d-4485-9a89-24d844b262d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### agd_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "18ba4c49-6f53-40c1-af52-1b67ed2ffb69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:20:21.223712Z",
     "iopub.status.busy": "2025-06-11T16:20:21.223246Z",
     "iopub.status.idle": "2025-06-11T16:20:46.275746Z",
     "shell.execute_reply": "2025-06-11T16:20:46.275182Z",
     "shell.execute_reply.started": "2025-06-11T16:20:21.223692Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  25.0\n",
      "Total Input Tokens -  19168\n",
      "Total Input Cost = USD  0.19\n",
      "Total Output Tokens -  705\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.21\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_agd_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_agd_mb=[0]\n",
    "keyword_input_token_agd_mb = 0\n",
    "keyword_output_token_agd_mb = 0\n",
    "keyword_start_time_loop_agd_mb = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_agd_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_agd_mb[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_agd_mb = keyword_dataframes['agd_mb_final_sen_df_jul'][keyword_dataframes['agd_mb_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_agd_mb:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_agd_mb,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_agd_mb.append(keywords)\n",
    "        keyword_input_token_agd_mb += input_tokens_loop\n",
    "        keyword_output_token_agd_mb += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_agd_mb = time.time()\n",
    "keyword_cost_input_token_agd_mb = round((0.01/1000)*keyword_input_token_agd_mb,2)\n",
    "keyword_cost_output_token_agd_mb = round((0.03/1000)*keyword_output_token_agd_mb,2)\n",
    "keyword_total_cost_agd_mb = keyword_cost_input_token_agd_mb + keyword_cost_output_token_agd_mb\n",
    "keyword_total_time_loop_agd_mb = keyword_end_time_loop_agd_mb - keyword_start_time_loop_agd_mb\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_agd_mb[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_agd_mb,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_agd_mb)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_agd_mb)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_agd_mb)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_agd_mb)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_agd_mb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "1e25adc6-da93-4b60-8741-afc63d2ec8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:20:46.276959Z",
     "iopub.status.busy": "2025-06-11T16:20:46.276601Z",
     "iopub.status.idle": "2025-06-11T16:20:46.323204Z",
     "shell.execute_reply": "2025-06-11T16:20:46.322739Z",
     "shell.execute_reply.started": "2025-06-11T16:20:46.276929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arakkal Gold and Diamonds LLC - Meena Bazar - ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trusted :3, Trustable :1, Genuine :1, Honesty ...</td>\n",
       "      <td>Good experience :10, Wonderful experience :5, ...</td>\n",
       "      <td>helpful :10, patient :3, knowledgeable :3, fri...</td>\n",
       "      <td>Good design :5, Unique designs :3, Best design...</td>\n",
       "      <td>collection : 30, varieties : 2, variety : 1, i...</td>\n",
       "      <td>discount :5, discounts :4, deals :2, offers :1...</td>\n",
       "      <td>reasonable :2, 0% :2</td>\n",
       "      <td>best price: 18, good price: 8, fair price: 2, ...</td>\n",
       "      <td>Good quality:3, Best quality:3, Quality:2, Exc...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arakkal Gold and Diamonds LLC - Meena Bazar - ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Most trustworthy people :1, Very trustworthy :...</td>\n",
       "      <td>Very good experience :3, Had a great experienc...</td>\n",
       "      <td>very helpful :5, very nice service :3, very go...</td>\n",
       "      <td>Very beautiful designs :1, Very unique designs...</td>\n",
       "      <td>Nice collection : 6, Good collection : 6, Grea...</td>\n",
       "      <td>best discount :4, good discount :2, amazing di...</td>\n",
       "      <td>0% making charge :2, reasonable making charges :1</td>\n",
       "      <td>best price: 18, good price: 8, fair price: 2, ...</td>\n",
       "      <td>Quality of the gold:1, High-quality jewelry:1,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Arakkal Gold and Diamonds LLC - Meena Bazar - ...  Positive  keywords   \n",
       "1  Arakkal Gold and Diamonds LLC - Meena Bazar - ...  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trusted :3, Trustable :1, Genuine :1, Honesty ...   \n",
       "1  Most trustworthy people :1, Very trustworthy :...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good experience :10, Wonderful experience :5, ...   \n",
       "1  Very good experience :3, Had a great experienc...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :10, patient :3, knowledgeable :3, fri...   \n",
       "1  very helpful :5, very nice service :3, very go...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good design :5, Unique designs :3, Best design...   \n",
       "1  Very beautiful designs :1, Very unique designs...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 30, varieties : 2, variety : 1, i...   \n",
       "1  Nice collection : 6, Good collection : 6, Grea...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :5, discounts :4, deals :2, offers :1...   \n",
       "1  best discount :4, good discount :2, amazing di...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                               reasonable :2, 0% :2   \n",
       "1  0% making charge :2, reasonable making charges :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price: 18, good price: 8, fair price: 2, ...   \n",
       "1  best price: 18, good price: 8, fair price: 2, ...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  Good quality:3, Best quality:3, Quality:2, Exc...                     \n",
       "1  Quality of the gold:1, High-quality jewelry:1,...                     "
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_agd_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_agd_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_agd_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'agd_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_agd_mb = pd.concat([positive_keywords_agd_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_agd_mb = pd.concat([positive_keywords_agd_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_agd_mb = positive_keywords_agd_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_agd_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ecc3c-1ef6-420f-9f44-51ed2b900010",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### bhi_dec_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "7ad5188c-17b0-4570-96e9-c74bfd682411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:20:46.324364Z",
     "iopub.status.busy": "2025-06-11T16:20:46.323813Z",
     "iopub.status.idle": "2025-06-11T16:20:56.350451Z",
     "shell.execute_reply": "2025-06-11T16:20:56.349963Z",
     "shell.execute_reply.started": "2025-06-11T16:20:46.324345Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.0\n",
      "Total Input Tokens -  5799\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  304\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_bhi_dec_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_bhi_dec_ga=[0]\n",
    "keyword_input_token_bhi_dec_ga = 0\n",
    "keyword_output_token_bhi_dec_ga = 0\n",
    "keyword_start_time_loop_bhi_dec_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_bhi_dec_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_bhi_dec_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_bhi_dec_ga = keyword_dataframes['bhi_dec_ga_final_sen_df_jul'][keyword_dataframes['bhi_dec_ga_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_bhi_dec_ga:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_bhi_dec_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_bhi_dec_ga.append(keywords)\n",
    "        keyword_input_token_bhi_dec_ga += input_tokens_loop\n",
    "        keyword_output_token_bhi_dec_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_bhi_dec_ga = time.time()\n",
    "keyword_cost_input_token_bhi_dec_ga = round((0.01/1000)*keyword_input_token_bhi_dec_ga,2)\n",
    "keyword_cost_output_token_bhi_dec_ga = round((0.03/1000)*keyword_output_token_bhi_dec_ga,2)\n",
    "keyword_total_cost_bhi_dec_ga = keyword_cost_input_token_bhi_dec_ga + keyword_cost_output_token_bhi_dec_ga\n",
    "keyword_total_time_loop_bhi_dec_ga = keyword_end_time_loop_bhi_dec_ga - keyword_start_time_loop_bhi_dec_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_bhi_dec_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_bhi_dec_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_bhi_dec_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_bhi_dec_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_bhi_dec_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_bhi_dec_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_bhi_dec_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "fa7e1ce2-3372-4d27-90d2-0e030693521c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:20:56.351666Z",
     "iopub.status.busy": "2025-06-11T16:20:56.351256Z",
     "iopub.status.idle": "2025-06-11T16:20:56.392799Z",
     "shell.execute_reply": "2025-06-11T16:20:56.392223Z",
     "shell.execute_reply.started": "2025-06-11T16:20:56.351646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bhindi Jewellers-Decatur, GA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trustworthy :1, reliable :1</td>\n",
       "      <td>wonderful :1, great :1, amazing :1, good :1</td>\n",
       "      <td>helpful :5, sweet :3, professional :1, excelle...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>good price :1, lower :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bhindi Jewellers-Decatur, GA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Perfect place to buy gold and jewelry :1</td>\n",
       "      <td>very good experience :1, great experience :1, ...</td>\n",
       "      <td>very helpful :3, very sweet :2, very kind :2, ...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>able to lower the price :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Store Name Sentiment      Type  \\\n",
       "0  Bhindi Jewellers-Decatur, GA  Positive  keywords   \n",
       "1  Bhindi Jewellers-Decatur, GA  Positive   phrases   \n",
       "\n",
       "                        Customer Confidence  \\\n",
       "0               trustworthy :1, reliable :1   \n",
       "1  Perfect place to buy gold and jewelry :1   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0        wonderful :1, great :1, amazing :1, good :1   \n",
       "1  very good experience :1, great experience :1, ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  helpful :5, sweet :3, professional :1, excelle...                  \n",
       "1  very helpful :3, very sweet :2, very kind :2, ...                  \n",
       "\n",
       "                          Product Variety Discount Making Charge  \\\n",
       "0  No relevant positive keywords/ phrases                          \n",
       "1  No relevant positive keywords/ phrases                          \n",
       "\n",
       "                        Price                         Product Quality  \\\n",
       "0     good price :1, lower :1  No relevant positive keywords/ phrases   \n",
       "1  able to lower the price :1  No relevant positive keywords/ phrases   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_bhi_dec_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_bhi_dec_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_bhi_dec_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'bhi_dec_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_bhi_dec_ga = pd.concat([positive_keywords_bhi_dec_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_bhi_dec_ga = pd.concat([positive_keywords_bhi_dec_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_bhi_dec_ga = positive_keywords_bhi_dec_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_bhi_dec_ga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905fd32e-80c9-43df-b5b7-c11781bedecc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### eve_joh_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "e84f7eb6-fd48-4ba1-9640-2b29fa87cd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:21:13.284479Z",
     "iopub.status.busy": "2025-06-11T16:21:13.284078Z",
     "iopub.status.idle": "2025-06-11T16:21:13.299613Z",
     "shell.execute_reply": "2025-06-11T16:21:13.299009Z",
     "shell.execute_reply.started": "2025-06-11T16:21:13.284448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  0.0\n",
      "Total Input Tokens -  0\n",
      "Total Input Cost = USD  0.0\n",
      "Total Output Tokens -  0\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_eve_joh_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_eve_joh_ga=[0]\n",
    "keyword_input_token_eve_joh_ga = 0\n",
    "keyword_output_token_eve_joh_ga = 0\n",
    "keyword_start_time_loop_eve_joh_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_eve_joh_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_eve_joh_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_eve_joh_ga = keyword_dataframes['eve_joh_ga_final_sen_df_jul'][keyword_dataframes['eve_joh_ga_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_eve_joh_ga:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_eve_joh_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_eve_joh_ga.append(keywords)\n",
    "        keyword_input_token_eve_joh_ga += input_tokens_loop\n",
    "        keyword_output_token_eve_joh_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_eve_joh_ga = time.time()\n",
    "keyword_cost_input_token_eve_joh_ga = round((0.01/1000)*keyword_input_token_eve_joh_ga,2)\n",
    "keyword_cost_output_token_eve_joh_ga = round((0.03/1000)*keyword_output_token_eve_joh_ga,2)\n",
    "keyword_total_cost_eve_joh_ga = keyword_cost_input_token_eve_joh_ga + keyword_cost_output_token_eve_joh_ga\n",
    "keyword_total_time_loop_eve_joh_ga = keyword_end_time_loop_eve_joh_ga - keyword_start_time_loop_eve_joh_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_eve_joh_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_eve_joh_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_eve_joh_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_eve_joh_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_eve_joh_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_eve_joh_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_eve_joh_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "faf10c96-b319-4ea9-99ba-7a2de889c134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:21:20.423796Z",
     "iopub.status.busy": "2025-06-11T16:21:20.423312Z",
     "iopub.status.idle": "2025-06-11T16:21:20.446821Z",
     "shell.execute_reply": "2025-06-11T16:21:20.446028Z",
     "shell.execute_reply.started": "2025-06-11T16:21:20.423773Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Type, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16051/166648047.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mrow_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mpositive_keywords_eve_joh_ga\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositive_keywords_eve_joh_ga\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mpositive_keywords_eve_joh_ga\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_keywords_eve_joh_ga\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mpositive_keywords_eve_joh_ga\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot insert \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert Type, already exists"
     ]
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_eve_joh_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_eve_joh_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_eve_joh_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'eve_joh_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_eve_joh_ga = pd.concat([positive_keywords_eve_joh_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_eve_joh_ga = pd.concat([positive_keywords_eve_joh_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_eve_joh_ga = positive_keywords_eve_joh_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_eve_joh_ga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe140f-adfd-4e4b-9910-6e2d98d8a2c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_bol_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "b56d0257-4a7f-4138-9c55-620ed7a9e6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:21:25.982202Z",
     "iopub.status.busy": "2025-06-11T16:21:25.981887Z",
     "iopub.status.idle": "2025-06-11T16:21:44.023468Z",
     "shell.execute_reply": "2025-06-11T16:21:44.022913Z",
     "shell.execute_reply.started": "2025-06-11T16:21:25.982183Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  18.0\n",
      "Total Input Tokens -  15498\n",
      "Total Input Cost = USD  0.15\n",
      "Total Output Tokens -  525\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.17\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_jar_bol_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_bol_il=[0]\n",
    "keyword_input_token_jar_bol_il = 0\n",
    "keyword_output_token_jar_bol_il = 0\n",
    "keyword_start_time_loop_jar_bol_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_bol_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_bol_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_bol_il = keyword_dataframes['jar_bol_il_final_sen_df_jul'][keyword_dataframes['jar_bol_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_jar_bol_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_jar_bol_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_jar_bol_il.append(keywords)\n",
    "        keyword_input_token_jar_bol_il += input_tokens_loop\n",
    "        keyword_output_token_jar_bol_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_bol_il = time.time()\n",
    "keyword_cost_input_token_jar_bol_il = round((0.01/1000)*keyword_input_token_jar_bol_il,2)\n",
    "keyword_cost_output_token_jar_bol_il = round((0.03/1000)*keyword_output_token_jar_bol_il,2)\n",
    "keyword_total_cost_jar_bol_il = keyword_cost_input_token_jar_bol_il + keyword_cost_output_token_jar_bol_il\n",
    "keyword_total_time_loop_jar_bol_il = keyword_end_time_loop_jar_bol_il - keyword_start_time_loop_jar_bol_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_bol_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_bol_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_bol_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_bol_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_bol_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_bol_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_bol_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "e73f657b-0303-444d-a719-1e07781c67a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:21:44.024720Z",
     "iopub.status.busy": "2025-06-11T16:21:44.024416Z",
     "iopub.status.idle": "2025-06-11T16:21:44.070241Z",
     "shell.execute_reply": "2025-06-11T16:21:44.069802Z",
     "shell.execute_reply.started": "2025-06-11T16:21:44.024697Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Bolingbrook, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>great experience :5, amazing experience :4, aw...</td>\n",
       "      <td>helpful :15, knowledgeable :10, friendly :9, p...</td>\n",
       "      <td>custom design:1, gorgeous:1, beautiful:1</td>\n",
       "      <td>selection :3, variety :1, options :1</td>\n",
       "      <td>deal :2, price :1</td>\n",
       "      <td></td>\n",
       "      <td>affordable :1, budget :1, fair pricing :1, pri...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>trade in :1, upsize :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Bolingbrook, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>great customer service :4, very helpful :3, hi...</td>\n",
       "      <td>great customer service :5, amazing experience ...</td>\n",
       "      <td>fantastic job sketching:1, made it look beauti...</td>\n",
       "      <td>great selection :2, impressive selection :1, v...</td>\n",
       "      <td>amazing deals :1, best deal possible :1</td>\n",
       "      <td></td>\n",
       "      <td>in our budget :1, worth coming to check out :1...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>trade in and upsize your certified diamonds :1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store Name Sentiment      Type  \\\n",
       "0  Jared-Bolingbrook, IL  Positive  keywords   \n",
       "1  Jared-Bolingbrook, IL  Positive   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience :5, amazing experience :4, aw...   \n",
       "1  great customer service :4, very helpful :3, hi...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :15, knowledgeable :10, friendly :9, p...   \n",
       "1  great customer service :5, amazing experience ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0           custom design:1, gorgeous:1, beautiful:1   \n",
       "1  fantastic job sketching:1, made it look beauti...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0               selection :3, variety :1, options :1   \n",
       "1  great selection :2, impressive selection :1, v...   \n",
       "\n",
       "                                  Discount Making Charge  \\\n",
       "0                        deal :2, price :1                 \n",
       "1  amazing deals :1, best deal possible :1                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  affordable :1, budget :1, fair pricing :1, pri...   \n",
       "1  in our budget :1, worth coming to check out :1...   \n",
       "\n",
       "                          Product Quality  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                               Jewellery Exchange  \n",
       "0                          trade in :1, upsize :1  \n",
       "1  trade in and upsize your certified diamonds :1  "
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_jar_bol_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_jar_bol_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_jar_bol_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_bol_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_jar_bol_il = pd.concat([positive_keywords_jar_bol_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_jar_bol_il = pd.concat([positive_keywords_jar_bol_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_jar_bol_il = positive_keywords_jar_bol_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_jar_bol_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54c231-3cd3-4a64-97e8-8c6069cb7040",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_ver_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "c13228e7-2ab8-4a21-89f9-030fe414643e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:21:44.071057Z",
     "iopub.status.busy": "2025-06-11T16:21:44.070883Z",
     "iopub.status.idle": "2025-06-11T16:21:55.100587Z",
     "shell.execute_reply": "2025-06-11T16:21:55.099878Z",
     "shell.execute_reply.started": "2025-06-11T16:21:44.071041Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  11.0\n",
      "Total Input Tokens -  7697\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  311\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.09\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_jar_ver_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_ver_il=[0]\n",
    "keyword_input_token_jar_ver_il = 0\n",
    "keyword_output_token_jar_ver_il = 0\n",
    "keyword_start_time_loop_jar_ver_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_ver_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_ver_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_ver_il = keyword_dataframes['jar_ver_il_final_sen_df_jul'][keyword_dataframes['jar_ver_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_jar_ver_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_jar_ver_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_jar_ver_il.append(keywords)\n",
    "        keyword_input_token_jar_ver_il += input_tokens_loop\n",
    "        keyword_output_token_jar_ver_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_ver_il = time.time()\n",
    "keyword_cost_input_token_jar_ver_il = round((0.01/1000)*keyword_input_token_jar_ver_il,2)\n",
    "keyword_cost_output_token_jar_ver_il = round((0.03/1000)*keyword_output_token_jar_ver_il,2)\n",
    "keyword_total_cost_jar_ver_il = keyword_cost_input_token_jar_ver_il + keyword_cost_output_token_jar_ver_il\n",
    "keyword_total_time_loop_jar_ver_il = keyword_end_time_loop_jar_ver_il - keyword_start_time_loop_jar_ver_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_ver_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_ver_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_ver_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_ver_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_ver_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_ver_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_ver_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "966fc721-8eb3-4181-9363-d9475f8421e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:21:55.102374Z",
     "iopub.status.busy": "2025-06-11T16:21:55.102175Z",
     "iopub.status.idle": "2025-06-11T16:21:55.138933Z",
     "shell.execute_reply": "2025-06-11T16:21:55.138299Z",
     "shell.execute_reply.started": "2025-06-11T16:21:55.102356Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Vernon Hills, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :2, Reliable :1, Honest :1</td>\n",
       "      <td>helpful :10, great :9, amazing :5, wonderful :...</td>\n",
       "      <td>helpful :15, knowledgeable :6, patient :5, fri...</td>\n",
       "      <td></td>\n",
       "      <td>options :2, selection :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>top quality:1, excellent:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Vernon Hills, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Always going to Jared :1, Highly recommend :1,...</td>\n",
       "      <td>great experience :6, wonderful experience :3, ...</td>\n",
       "      <td>very helpful :5, extremely helpful :2, very kn...</td>\n",
       "      <td></td>\n",
       "      <td>excellent selection to choose from :1, many op...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>quality is as exceptional:1, quality of this r...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Store Name Sentiment      Type  \\\n",
       "0  Jared-Vernon Hills, IL  Positive  keywords   \n",
       "1  Jared-Vernon Hills, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                   Trust :2, Reliable :1, Honest :1   \n",
       "1  Always going to Jared :1, Highly recommend :1,...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  helpful :10, great :9, amazing :5, wonderful :...   \n",
       "1  great experience :6, wonderful experience :3, ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  helpful :15, knowledgeable :6, patient :5, fri...                  \n",
       "1  very helpful :5, extremely helpful :2, very kn...                  \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0                           options :2, selection :1                          \n",
       "1  excellent selection to choose from :1, many op...                          \n",
       "\n",
       "  Price                                    Product Quality Jewellery Exchange  \n",
       "0                               top quality:1, excellent:1                     \n",
       "1        quality is as exceptional:1, quality of this r...                     "
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_jar_ver_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_jar_ver_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_jar_ver_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_ver_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_jar_ver_il = pd.concat([positive_keywords_jar_ver_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_jar_ver_il = pd.concat([positive_keywords_jar_ver_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_jar_ver_il = positive_keywords_jar_ver_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_jar_ver_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be6a51-f15f-471f-a03e-d62e133730f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_lom_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "f2b6933c-c94d-4685-a1de-474bf4b0a6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:21:55.140358Z",
     "iopub.status.busy": "2025-06-11T16:21:55.139848Z",
     "iopub.status.idle": "2025-06-11T16:22:12.185823Z",
     "shell.execute_reply": "2025-06-11T16:22:12.185266Z",
     "shell.execute_reply.started": "2025-06-11T16:21:55.140331Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.0\n",
      "Total Input Tokens -  11461\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  436\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_jar_lom_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_lom_il=[0]\n",
    "keyword_input_token_jar_lom_il = 0\n",
    "keyword_output_token_jar_lom_il = 0\n",
    "keyword_start_time_loop_jar_lom_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_lom_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_lom_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_lom_il = keyword_dataframes['jar_lom_il_final_sen_df_jul'][keyword_dataframes['jar_lom_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_jar_lom_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_jar_lom_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_jar_lom_il.append(keywords)\n",
    "        keyword_input_token_jar_lom_il += input_tokens_loop\n",
    "        keyword_output_token_jar_lom_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_lom_il = time.time()\n",
    "keyword_cost_input_token_jar_lom_il = round((0.01/1000)*keyword_input_token_jar_lom_il,2)\n",
    "keyword_cost_output_token_jar_lom_il = round((0.03/1000)*keyword_output_token_jar_lom_il,2)\n",
    "keyword_total_cost_jar_lom_il = keyword_cost_input_token_jar_lom_il + keyword_cost_output_token_jar_lom_il\n",
    "keyword_total_time_loop_jar_lom_il = keyword_end_time_loop_jar_lom_il - keyword_start_time_loop_jar_lom_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_lom_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_lom_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_lom_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_lom_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_lom_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_lom_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_lom_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "5e44d9a7-e7dc-47ae-b0eb-482e543a5f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:12.186869Z",
     "iopub.status.busy": "2025-06-11T16:22:12.186539Z",
     "iopub.status.idle": "2025-06-11T16:22:12.227094Z",
     "shell.execute_reply": "2025-06-11T16:22:12.226622Z",
     "shell.execute_reply.started": "2025-06-11T16:22:12.186845Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Lombard, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Honesty :1, Trust :1</td>\n",
       "      <td>helpful :8, knowledgeable :4, friendly :4, wel...</td>\n",
       "      <td>helpful :10, knowledgeable :5, friendly :5, at...</td>\n",
       "      <td>cookie cutter :2, top notch :2</td>\n",
       "      <td>selections :2, options :1, choices :1, selecti...</td>\n",
       "      <td>discount :1, 25% off :1</td>\n",
       "      <td></td>\n",
       "      <td>budget :2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Lombard, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Loyal customer for the past five years :1, Con...</td>\n",
       "      <td>great experience :5, wonderful experience :3, ...</td>\n",
       "      <td>very helpful and knowledgeable :2, helpful and...</td>\n",
       "      <td>perfect engagement ring :2</td>\n",
       "      <td>many different options of jewelry :1, great se...</td>\n",
       "      <td>small discount on the appraisal :1, couldn’t p...</td>\n",
       "      <td></td>\n",
       "      <td>well within our budget :1, extremely tight tim...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Store Name Sentiment      Type  \\\n",
       "0  Jared-Lombard, IL  Positive  keywords   \n",
       "1  Jared-Lombard, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                               Honesty :1, Trust :1   \n",
       "1  Loyal customer for the past five years :1, Con...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  helpful :8, knowledgeable :4, friendly :4, wel...   \n",
       "1  great experience :5, wonderful experience :3, ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :10, knowledgeable :5, friendly :5, at...   \n",
       "1  very helpful and knowledgeable :2, helpful and...   \n",
       "\n",
       "                   Product Design  \\\n",
       "0  cookie cutter :2, top notch :2   \n",
       "1      perfect engagement ring :2   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  selections :2, options :1, choices :1, selecti...   \n",
       "1  many different options of jewelry :1, great se...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0                            discount :1, 25% off :1                 \n",
       "1  small discount on the appraisal :1, couldn’t p...                 \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                                          budget :2                   \n",
       "1  well within our budget :1, extremely tight tim...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_jar_lom_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_jar_lom_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_jar_lom_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_lom_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_jar_lom_il = pd.concat([positive_keywords_jar_lom_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_jar_lom_il = pd.concat([positive_keywords_jar_lom_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_jar_lom_il = positive_keywords_jar_lom_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_jar_lom_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9014b9-b7bf-4764-bbe5-2c79b2f4b61d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_orl_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "976fe3a5-f5ba-4604-b592-416ce4e25527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:12.228246Z",
     "iopub.status.busy": "2025-06-11T16:22:12.227825Z",
     "iopub.status.idle": "2025-06-11T16:22:25.260891Z",
     "shell.execute_reply": "2025-06-11T16:22:25.260334Z",
     "shell.execute_reply.started": "2025-06-11T16:22:12.228219Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  13.0\n",
      "Total Input Tokens -  14405\n",
      "Total Input Cost = USD  0.14\n",
      "Total Output Tokens -  467\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.15\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_jar_orl_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_orl_il=[0]\n",
    "keyword_input_token_jar_orl_il = 0\n",
    "keyword_output_token_jar_orl_il = 0\n",
    "keyword_start_time_loop_jar_orl_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_orl_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_orl_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_orl_il = keyword_dataframes['jar_orl_il_final_sen_df_jul'][keyword_dataframes['jar_orl_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_jar_orl_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_jar_orl_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_jar_orl_il.append(keywords)\n",
    "        keyword_input_token_jar_orl_il += input_tokens_loop\n",
    "        keyword_output_token_jar_orl_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_orl_il = time.time()\n",
    "keyword_cost_input_token_jar_orl_il = round((0.01/1000)*keyword_input_token_jar_orl_il,2)\n",
    "keyword_cost_output_token_jar_orl_il = round((0.03/1000)*keyword_output_token_jar_orl_il,2)\n",
    "keyword_total_cost_jar_orl_il = keyword_cost_input_token_jar_orl_il + keyword_cost_output_token_jar_orl_il\n",
    "keyword_total_time_loop_jar_orl_il = keyword_end_time_loop_jar_orl_il - keyword_start_time_loop_jar_orl_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_orl_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_orl_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_orl_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_orl_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_orl_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_orl_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_orl_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "b125c56b-f829-40f6-8006-15fe2ba40be9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:25.262056Z",
     "iopub.status.busy": "2025-06-11T16:22:25.261684Z",
     "iopub.status.idle": "2025-06-11T16:22:25.304568Z",
     "shell.execute_reply": "2025-06-11T16:22:25.304104Z",
     "shell.execute_reply.started": "2025-06-11T16:22:25.262026Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Orland Park, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Honest :2, Trustworthy :1, Sincere :1, Knowled...</td>\n",
       "      <td>clean :2, organized :1, inviting :1, welcoming :1</td>\n",
       "      <td>helpful :10, knowledgeable :5, professional :4...</td>\n",
       "      <td></td>\n",
       "      <td>selection :3, variety :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>budget :1, prices :1</td>\n",
       "      <td>quality :3, exceptional :1, stunning :1</td>\n",
       "      <td>trade :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Orland Park, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy opinions :1, Real deal :1, Represe...</td>\n",
       "      <td>pleasant experience :2, amazing experience :2,...</td>\n",
       "      <td>great service :3, amazing experience :3, excel...</td>\n",
       "      <td></td>\n",
       "      <td>great selection :1, amazing selection :1, wide...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>great price :1, budget price :1, beat these pr...</td>\n",
       "      <td>quality of the jewelry is exceptional :1, impr...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store Name Sentiment      Type  \\\n",
       "0  Jared-Orland Park, IL  Positive  keywords   \n",
       "1  Jared-Orland Park, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Honest :2, Trustworthy :1, Sincere :1, Knowled...   \n",
       "1  Trustworthy opinions :1, Real deal :1, Represe...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  clean :2, organized :1, inviting :1, welcoming :1   \n",
       "1  pleasant experience :2, amazing experience :2,...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  helpful :10, knowledgeable :5, professional :4...                  \n",
       "1  great service :3, amazing experience :3, excel...                  \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0                           selection :3, variety :1                          \n",
       "1  great selection :1, amazing selection :1, wide...                          \n",
       "\n",
       "                                               Price  \\\n",
       "0                               budget :1, prices :1   \n",
       "1  great price :1, budget price :1, beat these pr...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0            quality :3, exceptional :1, stunning :1   \n",
       "1  quality of the jewelry is exceptional :1, impr...   \n",
       "\n",
       "                       Jewellery Exchange  \n",
       "0                                trade :1  \n",
       "1  No relevant positive keywords/ phrases  "
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_jar_orl_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_jar_orl_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_jar_orl_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_orl_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_jar_orl_il = pd.concat([positive_keywords_jar_orl_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_jar_orl_il = pd.concat([positive_keywords_jar_orl_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_jar_orl_il = positive_keywords_jar_orl_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_jar_orl_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7340c-cffa-4520-adc0-241637cf4771",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_aur_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "0ce8807a-6f6f-4997-b366-45aa0ffb38cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:25.305655Z",
     "iopub.status.busy": "2025-06-11T16:22:25.305361Z",
     "iopub.status.idle": "2025-06-11T16:22:38.837781Z",
     "shell.execute_reply": "2025-06-11T16:22:38.837258Z",
     "shell.execute_reply.started": "2025-06-11T16:22:25.305629Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  13.5\n",
      "Total Input Tokens -  9574\n",
      "Total Input Cost = USD  0.1\n",
      "Total Output Tokens -  374\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.11\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_jar_aur_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_aur_il=[0]\n",
    "keyword_input_token_jar_aur_il = 0\n",
    "keyword_output_token_jar_aur_il = 0\n",
    "keyword_start_time_loop_jar_aur_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_aur_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_aur_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_aur_il = keyword_dataframes['jar_aur_il_final_sen_df_jul'][keyword_dataframes['jar_aur_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_jar_aur_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_jar_aur_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_jar_aur_il.append(keywords)\n",
    "        keyword_input_token_jar_aur_il += input_tokens_loop\n",
    "        keyword_output_token_jar_aur_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_aur_il = time.time()\n",
    "keyword_cost_input_token_jar_aur_il = round((0.01/1000)*keyword_input_token_jar_aur_il,2)\n",
    "keyword_cost_output_token_jar_aur_il = round((0.03/1000)*keyword_output_token_jar_aur_il,2)\n",
    "keyword_total_cost_jar_aur_il = keyword_cost_input_token_jar_aur_il + keyword_cost_output_token_jar_aur_il\n",
    "keyword_total_time_loop_jar_aur_il = keyword_end_time_loop_jar_aur_il - keyword_start_time_loop_jar_aur_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_aur_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_aur_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_aur_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_aur_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_aur_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_aur_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_aur_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "d5f9df62-e066-46ad-a96e-fb168da40665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:38.839754Z",
     "iopub.status.busy": "2025-06-11T16:22:38.839495Z",
     "iopub.status.idle": "2025-06-11T16:22:38.877650Z",
     "shell.execute_reply": "2025-06-11T16:22:38.877171Z",
     "shell.execute_reply.started": "2025-06-11T16:22:38.839734Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Aurora, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Professional :1, Knowledge :1, Quality :1</td>\n",
       "      <td>helpful :5, friendly :4, welcoming :3, attenti...</td>\n",
       "      <td>helpful :10, knowledgeable :5, friendly :5, pr...</td>\n",
       "      <td></td>\n",
       "      <td>options :2, collection :2, selection :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>great price :1</td>\n",
       "      <td>quality :2, high-quality :1, expertise :1, imp...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Aurora, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Life time jewelers :1, Class A experience :1</td>\n",
       "      <td>great customer service :3, exceptional custome...</td>\n",
       "      <td>great customer service :4, exceptional custome...</td>\n",
       "      <td></td>\n",
       "      <td>extensive collection :1, great collection :1, ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>The quality, atmosphere and ambiance was outst...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store Name Sentiment      Type  \\\n",
       "0  Jared-Aurora, IL  Positive  keywords   \n",
       "1  Jared-Aurora, IL  Positive   phrases   \n",
       "\n",
       "                            Customer Confidence  \\\n",
       "0     Professional :1, Knowledge :1, Quality :1   \n",
       "1  Life time jewelers :1, Class A experience :1   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  helpful :5, friendly :4, welcoming :3, attenti...   \n",
       "1  great customer service :3, exceptional custome...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  helpful :10, knowledgeable :5, friendly :5, pr...                  \n",
       "1  great customer service :4, exceptional custome...                  \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0            options :2, collection :2, selection :1                          \n",
       "1  extensive collection :1, great collection :1, ...                          \n",
       "\n",
       "                          Price  \\\n",
       "0                great price :1   \n",
       "1  No relevant positive phrases   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  quality :2, high-quality :1, expertise :1, imp...                     \n",
       "1  The quality, atmosphere and ambiance was outst...                     "
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_jar_aur_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_jar_aur_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_jar_aur_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_aur_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_jar_aur_il = pd.concat([positive_keywords_jar_aur_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_jar_aur_il = pd.concat([positive_keywords_jar_aur_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_jar_aur_il = positive_keywords_jar_aur_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_jar_aur_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e1fcd-bea8-4fec-8700-39523989f890",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_alg_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "bd5cad82-9689-4647-abec-3afc137f35dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:38.878937Z",
     "iopub.status.busy": "2025-06-11T16:22:38.878464Z",
     "iopub.status.idle": "2025-06-11T16:22:49.907337Z",
     "shell.execute_reply": "2025-06-11T16:22:49.906852Z",
     "shell.execute_reply.started": "2025-06-11T16:22:38.878908Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  11.0\n",
      "Total Input Tokens -  10892\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  360\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_jar_alg_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_alg_il=[0]\n",
    "keyword_input_token_jar_alg_il = 0\n",
    "keyword_output_token_jar_alg_il = 0\n",
    "keyword_start_time_loop_jar_alg_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_alg_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_alg_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_alg_il = keyword_dataframes['jar_alg_il_final_sen_df_jul'][keyword_dataframes['jar_alg_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_jar_alg_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_jar_alg_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_jar_alg_il.append(keywords)\n",
    "        keyword_input_token_jar_alg_il += input_tokens_loop\n",
    "        keyword_output_token_jar_alg_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_alg_il = time.time()\n",
    "keyword_cost_input_token_jar_alg_il = round((0.01/1000)*keyword_input_token_jar_alg_il,2)\n",
    "keyword_cost_output_token_jar_alg_il = round((0.03/1000)*keyword_output_token_jar_alg_il,2)\n",
    "keyword_total_cost_jar_alg_il = keyword_cost_input_token_jar_alg_il + keyword_cost_output_token_jar_alg_il\n",
    "keyword_total_time_loop_jar_alg_il = keyword_end_time_loop_jar_alg_il - keyword_start_time_loop_jar_alg_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_alg_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_alg_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_alg_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_alg_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_alg_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_alg_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_alg_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "524ae4d0-d127-46b1-bb39-888abccc48ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:49.908355Z",
     "iopub.status.busy": "2025-06-11T16:22:49.908039Z",
     "iopub.status.idle": "2025-06-11T16:22:49.944093Z",
     "shell.execute_reply": "2025-06-11T16:22:49.943607Z",
     "shell.execute_reply.started": "2025-06-11T16:22:49.908329Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Algonquin, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Knowledgeable :3, Recommended :2, Trusted :1, ...</td>\n",
       "      <td>friendly : 10, helpful : 9, welcoming : 3, kno...</td>\n",
       "      <td>helpful :15, friendly :12, knowledgeable :8, p...</td>\n",
       "      <td></td>\n",
       "      <td>options :3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Exceptional :1, Fantastic :1, Excellent :1, Sp...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Algonquin, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Shop with confidence :1, Highly recommend this...</td>\n",
       "      <td>great experience : 5, amazing staff : 3, wonde...</td>\n",
       "      <td>extremely helpful :3, very helpful :3, super f...</td>\n",
       "      <td></td>\n",
       "      <td>many options :2, wonderful choices :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Exceptional quality of work :1, Quality of the...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Jared-Algonquin, IL  Positive  keywords   \n",
       "1  Jared-Algonquin, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Knowledgeable :3, Recommended :2, Trusted :1, ...   \n",
       "1  Shop with confidence :1, Highly recommend this...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  friendly : 10, helpful : 9, welcoming : 3, kno...   \n",
       "1  great experience : 5, amazing staff : 3, wonde...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  helpful :15, friendly :12, knowledgeable :8, p...                  \n",
       "1  extremely helpful :3, very helpful :3, super f...                  \n",
       "\n",
       "                         Product Variety Discount Making Charge Price  \\\n",
       "0                             options :3                                \n",
       "1  many options :2, wonderful choices :1                                \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  Exceptional :1, Fantastic :1, Excellent :1, Sp...                     \n",
       "1  Exceptional quality of work :1, Quality of the...                     "
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_jar_alg_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_jar_alg_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_jar_alg_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_alg_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_jar_alg_il = pd.concat([positive_keywords_jar_alg_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_jar_alg_il = pd.concat([positive_keywords_jar_alg_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_jar_alg_il = positive_keywords_jar_alg_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_jar_alg_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29936709-c900-4cca-8aee-926b3c17b163",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jar_sch_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "3f5d13c8-7e4e-4312-967e-2a3c652e1dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:22:49.944921Z",
     "iopub.status.busy": "2025-06-11T16:22:49.944710Z",
     "iopub.status.idle": "2025-06-11T16:23:05.981325Z",
     "shell.execute_reply": "2025-06-11T16:23:05.980784Z",
     "shell.execute_reply.started": "2025-06-11T16:22:49.944904Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  16.0\n",
      "Total Input Tokens -  17086\n",
      "Total Input Cost = USD  0.17\n",
      "Total Output Tokens -  519\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.19\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_jar_sch_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_sch_il=[0]\n",
    "keyword_input_token_jar_sch_il = 0\n",
    "keyword_output_token_jar_sch_il = 0\n",
    "keyword_start_time_loop_jar_sch_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_sch_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_sch_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_sch_il = keyword_dataframes['jar_sch_il_final_sen_df_jul'][keyword_dataframes['jar_sch_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_jar_sch_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_jar_sch_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_jar_sch_il.append(keywords)\n",
    "        keyword_input_token_jar_sch_il += input_tokens_loop\n",
    "        keyword_output_token_jar_sch_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_sch_il = time.time()\n",
    "keyword_cost_input_token_jar_sch_il = round((0.01/1000)*keyword_input_token_jar_sch_il,2)\n",
    "keyword_cost_output_token_jar_sch_il = round((0.03/1000)*keyword_output_token_jar_sch_il,2)\n",
    "keyword_total_cost_jar_sch_il = keyword_cost_input_token_jar_sch_il + keyword_cost_output_token_jar_sch_il\n",
    "keyword_total_time_loop_jar_sch_il = keyword_end_time_loop_jar_sch_il - keyword_start_time_loop_jar_sch_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_sch_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_sch_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_sch_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_sch_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_sch_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_sch_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_sch_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "186fc7d7-26b0-4dde-babd-10a40239aec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:23:05.982289Z",
     "iopub.status.busy": "2025-06-11T16:23:05.982013Z",
     "iopub.status.idle": "2025-06-11T16:23:06.025384Z",
     "shell.execute_reply": "2025-06-11T16:23:06.024858Z",
     "shell.execute_reply.started": "2025-06-11T16:23:05.982263Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Schaumburg, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Knowledgeable :2, Professional :1, Honest :1</td>\n",
       "      <td>Great experience :5, Wonderful experience :4, ...</td>\n",
       "      <td>helpful : 30, knowledgeable : 8, kind : 8, pat...</td>\n",
       "      <td>custom design:2, unique vision:1, design ideas...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>reasonable :1, Great Prices :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Schaumburg, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Definitely found my jewelry spot :1, Made sure...</td>\n",
       "      <td>Great staff :1, Made us feel comfortable :1, M...</td>\n",
       "      <td>great to work with : 2, went out of their way ...</td>\n",
       "      <td>beautifully crafted:1, turned out so beautiful...</td>\n",
       "      <td>Great selection of diamonds and gemstones :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>reasonable price :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Store Name Sentiment      Type  \\\n",
       "0  Jared-Schaumburg, IL  Positive  keywords   \n",
       "1  Jared-Schaumburg, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0       Knowledgeable :2, Professional :1, Honest :1   \n",
       "1  Definitely found my jewelry spot :1, Made sure...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great experience :5, Wonderful experience :4, ...   \n",
       "1  Great staff :1, Made us feel comfortable :1, M...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 30, knowledgeable : 8, kind : 8, pat...   \n",
       "1  great to work with : 2, went out of their way ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  custom design:2, unique vision:1, design ideas...   \n",
       "1  beautifully crafted:1, turned out so beautiful...   \n",
       "\n",
       "                                Product Variety  \\\n",
       "0        No relevant positive keywords/ phrases   \n",
       "1  Great selection of diamonds and gemstones :1   \n",
       "\n",
       "                                 Discount Making Charge  \\\n",
       "0  No relevant positive keywords/ phrases                 \n",
       "1  No relevant positive keywords/ phrases                 \n",
       "\n",
       "                            Price                         Product Quality  \\\n",
       "0  reasonable :1, Great Prices :1  No relevant positive keywords/ phrases   \n",
       "1             reasonable price :1  No relevant positive keywords/ phrases   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_jar_sch_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_jar_sch_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_jar_sch_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_sch_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_jar_sch_il = pd.concat([positive_keywords_jar_sch_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_jar_sch_il = pd.concat([positive_keywords_jar_sch_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_jar_sch_il = positive_keywords_jar_sch_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_jar_sch_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124e385-546a-4843-8fce-dd09910dcac3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_suw_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "3b60aef7-f065-45bd-a624-490d1d0dde68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:23:06.026248Z",
     "iopub.status.busy": "2025-06-11T16:23:06.026058Z",
     "iopub.status.idle": "2025-06-11T16:23:39.593494Z",
     "shell.execute_reply": "2025-06-11T16:23:39.592874Z",
     "shell.execute_reply.started": "2025-06-11T16:23:06.026232Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  33.6\n",
      "Total Input Tokens -  110925\n",
      "Total Input Cost = USD  1.11\n",
      "Total Output Tokens -  801\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_suw_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_suw_ga=[0]\n",
    "keyword_input_token_joy_suw_ga = 0\n",
    "keyword_output_token_joy_suw_ga = 0\n",
    "keyword_start_time_loop_joy_suw_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_suw_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_suw_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_suw_ga = keyword_dataframes['joy_suw_ga_final_sen_df_jul'][keyword_dataframes['joy_suw_ga_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_suw_ga:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_suw_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_suw_ga.append(keywords)\n",
    "        keyword_input_token_joy_suw_ga += input_tokens_loop\n",
    "        keyword_output_token_joy_suw_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_suw_ga = time.time()\n",
    "keyword_cost_input_token_joy_suw_ga = round((0.01/1000)*keyword_input_token_joy_suw_ga,2)\n",
    "keyword_cost_output_token_joy_suw_ga = round((0.03/1000)*keyword_output_token_joy_suw_ga,2)\n",
    "keyword_total_cost_joy_suw_ga = keyword_cost_input_token_joy_suw_ga + keyword_cost_output_token_joy_suw_ga\n",
    "keyword_total_time_loop_joy_suw_ga = keyword_end_time_loop_joy_suw_ga - keyword_start_time_loop_joy_suw_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_suw_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_suw_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_suw_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_suw_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_suw_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_suw_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_suw_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "5122f435-9bc0-43c9-b2e9-264fe2712c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:23:39.594523Z",
     "iopub.status.busy": "2025-06-11T16:23:39.594248Z",
     "iopub.status.idle": "2025-06-11T16:23:39.643406Z",
     "shell.execute_reply": "2025-06-11T16:23:39.642970Z",
     "shell.execute_reply.started": "2025-06-11T16:23:39.594505Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Suwanee, GA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Recommend :3, Reliable :2, Trust :2, Depend :1...</td>\n",
       "      <td>Great experience : 20, Good experience : 15, P...</td>\n",
       "      <td>helpful : 98, patient : 85, friendly : 75, pol...</td>\n",
       "      <td>good designs: 15, beautiful designs: 10, lates...</td>\n",
       "      <td>collection : 78, variety : 15, options : 12, r...</td>\n",
       "      <td>discount :5, deal :5, offers :2, price :2, pri...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>reasonable :8, affordable :3, competitive :3, ...</td>\n",
       "      <td>quality :8, good quality :4, excellent quality...</td>\n",
       "      <td>exchange :8, exchanging :3, change :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Suwanee, GA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Highly recommend this place to buy gold :1, I ...</td>\n",
       "      <td>Great shopping experience : 5, Wonderful shopp...</td>\n",
       "      <td>very helpful and patient : 10, extremely helpf...</td>\n",
       "      <td>love their designs: 2, beautiful piece of jewe...</td>\n",
       "      <td>wide variety : 5, wide range : 4, huge collect...</td>\n",
       "      <td>good discount :3, good deal :3, best deal :2, ...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>best price :8, good price :7, reasonable price...</td>\n",
       "      <td>quality gold jewelries :1, quality of their pr...</td>\n",
       "      <td>exchange gold jewelry :2, helped us exchange :...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Suwanee, GA  Positive  keywords   \n",
       "1  Joyalukkas Jewellery-Suwanee, GA  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Recommend :3, Reliable :2, Trust :2, Depend :1...   \n",
       "1  Highly recommend this place to buy gold :1, I ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great experience : 20, Good experience : 15, P...   \n",
       "1  Great shopping experience : 5, Wonderful shopp...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 98, patient : 85, friendly : 75, pol...   \n",
       "1  very helpful and patient : 10, extremely helpf...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  good designs: 15, beautiful designs: 10, lates...   \n",
       "1  love their designs: 2, beautiful piece of jewe...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 78, variety : 15, options : 12, r...   \n",
       "1  wide variety : 5, wide range : 4, huge collect...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :5, deal :5, offers :2, price :2, pri...   \n",
       "1  good discount :3, good deal :3, best deal :2, ...   \n",
       "\n",
       "                            Making Charge  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :8, affordable :3, competitive :3, ...   \n",
       "1  best price :8, good price :7, reasonable price...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, good quality :4, excellent quality...   \n",
       "1  quality gold jewelries :1, quality of their pr...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0              exchange :8, exchanging :3, change :1  \n",
       "1  exchange gold jewelry :2, helped us exchange :...  "
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_suw_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_suw_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_suw_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_suw_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_suw_ga = pd.concat([positive_keywords_joy_suw_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_suw_ga = pd.concat([positive_keywords_joy_suw_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_suw_ga = positive_keywords_joy_suw_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_suw_ga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185c1e4-741a-460c-9ec4-4b705c52315d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "7b79646d-e9b4-4cf5-b1b2-efd99c61cd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:23:39.644425Z",
     "iopub.status.busy": "2025-06-11T16:23:39.644202Z",
     "iopub.status.idle": "2025-06-11T16:24:07.200842Z",
     "shell.execute_reply": "2025-06-11T16:24:07.200285Z",
     "shell.execute_reply.started": "2025-06-11T16:23:39.644407Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  27.5\n",
      "Total Input Tokens -  59389\n",
      "Total Input Cost = USD  0.59\n",
      "Total Output Tokens -  778\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.61\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_chi_il=[0]\n",
    "keyword_input_token_joy_chi_il = 0\n",
    "keyword_output_token_joy_chi_il = 0\n",
    "keyword_start_time_loop_joy_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_chi_il = keyword_dataframes['joy_chi_il_final_sen_df_jul'][keyword_dataframes['joy_chi_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_chi_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_chi_il.append(keywords)\n",
    "        keyword_input_token_joy_chi_il += input_tokens_loop\n",
    "        keyword_output_token_joy_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_chi_il = time.time()\n",
    "keyword_cost_input_token_joy_chi_il = round((0.01/1000)*keyword_input_token_joy_chi_il,2)\n",
    "keyword_cost_output_token_joy_chi_il = round((0.03/1000)*keyword_output_token_joy_chi_il,2)\n",
    "keyword_total_cost_joy_chi_il = keyword_cost_input_token_joy_chi_il + keyword_cost_output_token_joy_chi_il\n",
    "keyword_total_time_loop_joy_chi_il = keyword_end_time_loop_joy_chi_il - keyword_start_time_loop_joy_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "eba0b026-f0cd-4733-bb99-39925306abc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:24:07.201817Z",
     "iopub.status.busy": "2025-06-11T16:24:07.201602Z",
     "iopub.status.idle": "2025-06-11T16:24:07.249474Z",
     "shell.execute_reply": "2025-06-11T16:24:07.248996Z",
     "shell.execute_reply.started": "2025-06-11T16:24:07.201798Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Recommend :5, Knowledgeable :4, Trust :3, Reli...</td>\n",
       "      <td>good experience : 15, great experience : 14, w...</td>\n",
       "      <td>helpful : 50, patient : 20, friendly : 15, kno...</td>\n",
       "      <td>Good designs: 15, Great designs: 6, Nice desig...</td>\n",
       "      <td>varieties :3, variety :3, options :3, selectio...</td>\n",
       "      <td>discount :15, deal :10, offers :3, price :3, b...</td>\n",
       "      <td>discount :1, low :1</td>\n",
       "      <td>reasonable :5, affordable :4, fair :4, best :3...</td>\n",
       "      <td>high quality :4, good quality :4, best quality...</td>\n",
       "      <td>exchange rate:2, gold exchange:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Highly recommend this place :2, Best place to ...</td>\n",
       "      <td>great shopping experience : 4, wonderful shopp...</td>\n",
       "      <td>very helpful : 30, very patient : 10, very fri...</td>\n",
       "      <td>variety of designs: 2, exquisite designs: 2, e...</td>\n",
       "      <td>wide variety :2, diverse selection :1, variety...</td>\n",
       "      <td>good discount :4, best discount :2, special di...</td>\n",
       "      <td>good discount on the making charge :1, very lo...</td>\n",
       "      <td>reasonable prices :3, great price :3, best pri...</td>\n",
       "      <td>quality is top-notch :1, jewelry is premium :1...</td>\n",
       "      <td>great place to exchange gold:1, smooth and eff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Chicago, IL  Positive  keywords   \n",
       "1  Joyalukkas Jewellery-Chicago, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Recommend :5, Knowledgeable :4, Trust :3, Reli...   \n",
       "1  Highly recommend this place :2, Best place to ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience : 15, great experience : 14, w...   \n",
       "1  great shopping experience : 4, wonderful shopp...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, patient : 20, friendly : 15, kno...   \n",
       "1  very helpful : 30, very patient : 10, very fri...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs: 15, Great designs: 6, Nice desig...   \n",
       "1  variety of designs: 2, exquisite designs: 2, e...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  varieties :3, variety :3, options :3, selectio...   \n",
       "1  wide variety :2, diverse selection :1, variety...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :15, deal :10, offers :3, price :3, b...   \n",
       "1  good discount :4, best discount :2, special di...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                                discount :1, low :1   \n",
       "1  good discount on the making charge :1, very lo...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :5, affordable :4, fair :4, best :3...   \n",
       "1  reasonable prices :3, great price :3, best pri...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  high quality :4, good quality :4, best quality...   \n",
       "1  quality is top-notch :1, jewelry is premium :1...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                   exchange rate:2, gold exchange:1  \n",
       "1  great place to exchange gold:1, smooth and eff...  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_chi_il = pd.concat([positive_keywords_joy_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_chi_il = pd.concat([positive_keywords_joy_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_chi_il = positive_keywords_joy_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2431ab8-7348-4b01-9e58-2df784302765",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_hou_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "fc990962-7a93-4d80-a65e-9cb1ae8ebf8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:24:07.250594Z",
     "iopub.status.busy": "2025-06-11T16:24:07.250305Z",
     "iopub.status.idle": "2025-06-11T16:24:37.810877Z",
     "shell.execute_reply": "2025-06-11T16:24:37.810369Z",
     "shell.execute_reply.started": "2025-06-11T16:24:07.250546Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  30.6\n",
      "Total Input Tokens -  52675\n",
      "Total Input Cost = USD  0.53\n",
      "Total Output Tokens -  769\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.55\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_hou_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_hou_tx=[0]\n",
    "keyword_input_token_joy_hou_tx = 0\n",
    "keyword_output_token_joy_hou_tx = 0\n",
    "keyword_start_time_loop_joy_hou_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_hou_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_hou_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_hou_tx = keyword_dataframes['joy_hou_tx_final_sen_df_jul'][keyword_dataframes['joy_hou_tx_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_hou_tx:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_hou_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_hou_tx.append(keywords)\n",
    "        keyword_input_token_joy_hou_tx += input_tokens_loop\n",
    "        keyword_output_token_joy_hou_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_hou_tx = time.time()\n",
    "keyword_cost_input_token_joy_hou_tx = round((0.01/1000)*keyword_input_token_joy_hou_tx,2)\n",
    "keyword_cost_output_token_joy_hou_tx = round((0.03/1000)*keyword_output_token_joy_hou_tx,2)\n",
    "keyword_total_cost_joy_hou_tx = keyword_cost_input_token_joy_hou_tx + keyword_cost_output_token_joy_hou_tx\n",
    "keyword_total_time_loop_joy_hou_tx = keyword_end_time_loop_joy_hou_tx - keyword_start_time_loop_joy_hou_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_hou_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_hou_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_hou_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_hou_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_hou_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_hou_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_hou_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "b4841a3f-ee8d-4f50-9800-3d197c100717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:24:37.811782Z",
     "iopub.status.busy": "2025-06-11T16:24:37.811586Z",
     "iopub.status.idle": "2025-06-11T16:24:37.860542Z",
     "shell.execute_reply": "2025-06-11T16:24:37.860065Z",
     "shell.execute_reply.started": "2025-06-11T16:24:37.811764Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Houston, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Reliable :2, Honest :2, Transparent ...</td>\n",
       "      <td>Great experience : 15, Wonderful experience : ...</td>\n",
       "      <td>helpful : 98, patient : 72, friendly : 68, kno...</td>\n",
       "      <td>designs :10, design :8, intricate :2, elegant ...</td>\n",
       "      <td>variety :5, models :4, options :3, designs :3,...</td>\n",
       "      <td>good deal :10, great discount :6, good discoun...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>reasonable :7, good price :6, best price :5, a...</td>\n",
       "      <td>quality :6, good quality :3, great quality :2,...</td>\n",
       "      <td>exchange :10, exchanging :3, swap :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Houston, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy place to buy :1, Always trusted :1...</td>\n",
       "      <td>Great shopping experience : 4, Wonderful shopp...</td>\n",
       "      <td>very helpful : 45, very patient : 30, great cu...</td>\n",
       "      <td>good designs :3, awesome designs :2, amazing d...</td>\n",
       "      <td>wide variety :3, great selection :3, variety o...</td>\n",
       "      <td>great discounts :2, great deals going on :1, d...</td>\n",
       "      <td>great offer on making charges :1</td>\n",
       "      <td>reasonable prices :4, good prices :3, best pri...</td>\n",
       "      <td>high-quality, beautiful jewelry :1, quality of...</td>\n",
       "      <td>exchange process easy :1, smooth exchange proc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Houston, TX  Positive  keywords   \n",
       "1  Joyalukkas Jewellery-Houston, TX  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Reliable :2, Honest :2, Transparent ...   \n",
       "1  Trustworthy place to buy :1, Always trusted :1...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great experience : 15, Wonderful experience : ...   \n",
       "1  Great shopping experience : 4, Wonderful shopp...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 98, patient : 72, friendly : 68, kno...   \n",
       "1  very helpful : 45, very patient : 30, great cu...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :10, design :8, intricate :2, elegant ...   \n",
       "1  good designs :3, awesome designs :2, amazing d...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :5, models :4, options :3, designs :3,...   \n",
       "1  wide variety :3, great selection :3, variety o...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good deal :10, great discount :6, good discoun...   \n",
       "1  great discounts :2, great deals going on :1, d...   \n",
       "\n",
       "                            Making Charge  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1        great offer on making charges :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :7, good price :6, best price :5, a...   \n",
       "1  reasonable prices :4, good prices :3, best pri...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :6, good quality :3, great quality :2,...   \n",
       "1  high-quality, beautiful jewelry :1, quality of...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0               exchange :10, exchanging :3, swap :1  \n",
       "1  exchange process easy :1, smooth exchange proc...  "
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_hou_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_hou_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_hou_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_hou_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_hou_tx = pd.concat([positive_keywords_joy_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_hou_tx = pd.concat([positive_keywords_joy_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_hou_tx = positive_keywords_joy_hou_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_hou_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afcdc3b-f8df-4eeb-9406-b952031cdd50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### joy_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "d0a2d9d7-049e-4ae4-a50d-b5671c803493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:24:37.861454Z",
     "iopub.status.busy": "2025-06-11T16:24:37.861206Z",
     "iopub.status.idle": "2025-06-11T16:25:45.482145Z",
     "shell.execute_reply": "2025-06-11T16:25:45.481608Z",
     "shell.execute_reply.started": "2025-06-11T16:24:37.861436Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  67.6\n",
      "Total Input Tokens -  130944\n",
      "Total Input Cost = USD  1.31\n",
      "Total Output Tokens -  818\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.33\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_joy_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_fri_tx=[0]\n",
    "keyword_input_token_joy_fri_tx = 0\n",
    "keyword_output_token_joy_fri_tx = 0\n",
    "keyword_start_time_loop_joy_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_fri_tx = keyword_dataframes['joy_fri_tx_final_sen_df_jul'][keyword_dataframes['joy_fri_tx_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_joy_fri_tx:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_joy_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_joy_fri_tx.append(keywords)\n",
    "        keyword_input_token_joy_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_joy_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_fri_tx = time.time()\n",
    "keyword_cost_input_token_joy_fri_tx = round((0.01/1000)*keyword_input_token_joy_fri_tx,2)\n",
    "keyword_cost_output_token_joy_fri_tx = round((0.03/1000)*keyword_output_token_joy_fri_tx,2)\n",
    "keyword_total_cost_joy_fri_tx = keyword_cost_input_token_joy_fri_tx + keyword_cost_output_token_joy_fri_tx\n",
    "keyword_total_time_loop_joy_fri_tx = keyword_end_time_loop_joy_fri_tx - keyword_start_time_loop_joy_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "a039acb5-d87a-400a-bd95-213405a30919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:25:45.483197Z",
     "iopub.status.busy": "2025-06-11T16:25:45.482904Z",
     "iopub.status.idle": "2025-06-11T16:25:45.531242Z",
     "shell.execute_reply": "2025-06-11T16:25:45.530724Z",
     "shell.execute_reply.started": "2025-06-11T16:25:45.483174Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Trustworthy :2, Trusted :2, Confiden...</td>\n",
       "      <td>organized :1, clean :1, neat :1, spacious :1, ...</td>\n",
       "      <td>patient : 98, helpful : 95, friendly : 85, kno...</td>\n",
       "      <td>designs : 45, models : 8, craftsmanship : 1, v...</td>\n",
       "      <td>collection : 98, variety : 15, options : 12, m...</td>\n",
       "      <td>discount :10, deal :9, offers :4, sale :2, off :2</td>\n",
       "      <td>discount :1, deal :1, reasonable :1</td>\n",
       "      <td>reasonable :5, affordable :3, competitive :3, ...</td>\n",
       "      <td>high-quality :3, exceptional :3, quality :3, e...</td>\n",
       "      <td>good price :2, fair price :1, good rate :1, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy store to buy :1, Most trusted bran...</td>\n",
       "      <td>pleasant experience :3, wonderful experience :...</td>\n",
       "      <td>very patient and helpful : 10, very friendly a...</td>\n",
       "      <td>beautiful designs : 3, unique designs : 3, goo...</td>\n",
       "      <td>wide range : 6, wide variety : 5, vast collect...</td>\n",
       "      <td>good discount :5, best deal :4, additional dis...</td>\n",
       "      <td>detailed breakdown of the making charges :1, m...</td>\n",
       "      <td>reasonable price :5, best price :5, good price...</td>\n",
       "      <td>quality of their jewelry is exceptional :1, qu...</td>\n",
       "      <td>credit us for trading in old gold :1, exchange...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Frisco, TX  Positive  keywords   \n",
       "1  Joyalukkas Jewellery-Frisco, TX  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Trustworthy :2, Trusted :2, Confiden...   \n",
       "1  Trustworthy store to buy :1, Most trusted bran...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  organized :1, clean :1, neat :1, spacious :1, ...   \n",
       "1  pleasant experience :3, wonderful experience :...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 98, helpful : 95, friendly : 85, kno...   \n",
       "1  very patient and helpful : 10, very friendly a...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs : 45, models : 8, craftsmanship : 1, v...   \n",
       "1  beautiful designs : 3, unique designs : 3, goo...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 98, variety : 15, options : 12, m...   \n",
       "1  wide range : 6, wide variety : 5, vast collect...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :10, deal :9, offers :4, sale :2, off :2   \n",
       "1  good discount :5, best deal :4, additional dis...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                discount :1, deal :1, reasonable :1   \n",
       "1  detailed breakdown of the making charges :1, m...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :5, affordable :3, competitive :3, ...   \n",
       "1  reasonable price :5, best price :5, good price...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  high-quality :3, exceptional :3, quality :3, e...   \n",
       "1  quality of their jewelry is exceptional :1, qu...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  good price :2, fair price :1, good rate :1, re...  \n",
       "1  credit us for trading in old gold :1, exchange...  "
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_joy_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_joy_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_joy_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_joy_fri_tx = pd.concat([positive_keywords_joy_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_joy_fri_tx = pd.concat([positive_keywords_joy_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_joy_fri_tx = positive_keywords_joy_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_joy_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59a03ca-1222-41c0-82b0-67b4e9c258f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "bd87b4cf-97b5-4b3d-a160-639be510b129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:25:45.532207Z",
     "iopub.status.busy": "2025-06-11T16:25:45.531960Z",
     "iopub.status.idle": "2025-06-11T16:26:22.103989Z",
     "shell.execute_reply": "2025-06-11T16:26:22.103500Z",
     "shell.execute_reply.started": "2025-06-11T16:25:45.532185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  36.6\n",
      "Total Input Tokens -  77968\n",
      "Total Input Cost = USD  0.78\n",
      "Total Output Tokens -  823\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.8\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_chi_il=[0]\n",
    "keyword_input_token_mal_chi_il = 0\n",
    "keyword_output_token_mal_chi_il = 0\n",
    "keyword_start_time_loop_mal_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_chi_il = keyword_dataframes['mal_chi_il_final_sen_df_jul'][keyword_dataframes['mal_chi_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_chi_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_chi_il.append(keywords)\n",
    "        keyword_input_token_mal_chi_il += input_tokens_loop\n",
    "        keyword_output_token_mal_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_chi_il = time.time()\n",
    "keyword_cost_input_token_mal_chi_il = round((0.01/1000)*keyword_input_token_mal_chi_il,2)\n",
    "keyword_cost_output_token_mal_chi_il = round((0.03/1000)*keyword_output_token_mal_chi_il,2)\n",
    "keyword_total_cost_mal_chi_il = keyword_cost_input_token_mal_chi_il + keyword_cost_output_token_mal_chi_il\n",
    "keyword_total_time_loop_mal_chi_il = keyword_end_time_loop_mal_chi_il - keyword_start_time_loop_mal_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "18bfe952-360f-4ae5-a5a3-0980d731d9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:26:22.104960Z",
     "iopub.status.busy": "2025-06-11T16:26:22.104688Z",
     "iopub.status.idle": "2025-06-11T16:26:22.152946Z",
     "shell.execute_reply": "2025-06-11T16:26:22.152483Z",
     "shell.execute_reply.started": "2025-06-11T16:26:22.104942Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Genuine :2, Honest :2, Reliable :1, ...</td>\n",
       "      <td>great experience : 45, good experience : 20, a...</td>\n",
       "      <td>helpful : 98, patient : 56, friendly : 54, kno...</td>\n",
       "      <td>unique :5, beautiful :4, stunning :2, exquisit...</td>\n",
       "      <td>variety :5, options :5, selection :4, collecti...</td>\n",
       "      <td>good discount: 15, great deal: 10, best discou...</td>\n",
       "      <td>reasonable :1, discount :1</td>\n",
       "      <td>good price :15, best price :12, reasonable pri...</td>\n",
       "      <td>good quality :5, high quality :3, best quality...</td>\n",
       "      <td>exchange policy :2, exchanged :2, exchanging :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy place for gold :1, Reputation buil...</td>\n",
       "      <td>very good experience : 5, pleasant shopping ex...</td>\n",
       "      <td>very helpful and patient : 5, very friendly an...</td>\n",
       "      <td>unique designs :3, beautiful designs :3, stunn...</td>\n",
       "      <td>wide variety :2, lot of variety :2, variety of...</td>\n",
       "      <td>gave us a good discount: 8, gave us a great de...</td>\n",
       "      <td>best discount on making charges :1</td>\n",
       "      <td>gave us a good price :5, gave us the best pric...</td>\n",
       "      <td>quality of the product :1, quality of gold is ...</td>\n",
       "      <td>entire exchange process :1, exchanging gold je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Chicago, IL  Positive  keywords   \n",
       "1  Malabar Gold & Diamonds-Chicago, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Genuine :2, Honest :2, Reliable :1, ...   \n",
       "1  Trustworthy place for gold :1, Reputation buil...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience : 45, good experience : 20, a...   \n",
       "1  very good experience : 5, pleasant shopping ex...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 98, patient : 56, friendly : 54, kno...   \n",
       "1  very helpful and patient : 5, very friendly an...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique :5, beautiful :4, stunning :2, exquisit...   \n",
       "1  unique designs :3, beautiful designs :3, stunn...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :5, options :5, selection :4, collecti...   \n",
       "1  wide variety :2, lot of variety :2, variety of...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount: 15, great deal: 10, best discou...   \n",
       "1  gave us a good discount: 8, gave us a great de...   \n",
       "\n",
       "                        Making Charge  \\\n",
       "0          reasonable :1, discount :1   \n",
       "1  best discount on making charges :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good price :15, best price :12, reasonable pri...   \n",
       "1  gave us a good price :5, gave us the best pric...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  good quality :5, high quality :3, best quality...   \n",
       "1  quality of the product :1, quality of gold is ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange policy :2, exchanged :2, exchanging :...  \n",
       "1  entire exchange process :1, exchanging gold je...  "
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_chi_il = pd.concat([positive_keywords_mal_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_chi_il = pd.concat([positive_keywords_mal_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_chi_il = positive_keywords_mal_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea2f41-3a0e-4927-bbfe-90208461d590",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_nap_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "4788e25f-2060-4e59-83f3-f5f03407afff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:26:22.153881Z",
     "iopub.status.busy": "2025-06-11T16:26:22.153600Z",
     "iopub.status.idle": "2025-06-11T16:26:56.720121Z",
     "shell.execute_reply": "2025-06-11T16:26:56.719555Z",
     "shell.execute_reply.started": "2025-06-11T16:26:22.153857Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  34.6\n",
      "Total Input Tokens -  96426\n",
      "Total Input Cost = USD  0.96\n",
      "Total Output Tokens -  725\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.98\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_nap_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_nap_il=[0]\n",
    "keyword_input_token_mal_nap_il = 0\n",
    "keyword_output_token_mal_nap_il = 0\n",
    "keyword_start_time_loop_mal_nap_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_nap_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_nap_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_nap_il = keyword_dataframes['mal_nap_il_final_sen_df_jul'][keyword_dataframes['mal_nap_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_nap_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_nap_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_nap_il.append(keywords)\n",
    "        keyword_input_token_mal_nap_il += input_tokens_loop\n",
    "        keyword_output_token_mal_nap_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_nap_il = time.time()\n",
    "keyword_cost_input_token_mal_nap_il = round((0.01/1000)*keyword_input_token_mal_nap_il,2)\n",
    "keyword_cost_output_token_mal_nap_il = round((0.03/1000)*keyword_output_token_mal_nap_il,2)\n",
    "keyword_total_cost_mal_nap_il = keyword_cost_input_token_mal_nap_il + keyword_cost_output_token_mal_nap_il\n",
    "keyword_total_time_loop_mal_nap_il = keyword_end_time_loop_mal_nap_il - keyword_start_time_loop_mal_nap_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_nap_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_nap_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_nap_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_nap_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_nap_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_nap_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_nap_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "a262645a-ae45-4bd2-9282-32feabdf06d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:26:56.721313Z",
     "iopub.status.busy": "2025-06-11T16:26:56.720951Z",
     "iopub.status.idle": "2025-06-11T16:26:56.767369Z",
     "shell.execute_reply": "2025-06-11T16:26:56.766875Z",
     "shell.execute_reply.started": "2025-06-11T16:26:56.721285Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Naperville, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustworthy :2, Trusted :2, Recommend :2, Reco...</td>\n",
       "      <td>pleasant : 15, helpful : 10, friendly : 8, wel...</td>\n",
       "      <td>helpful : 98, patient : 85, friendly : 75, kno...</td>\n",
       "      <td>designs : 45, collection : 10, variety : 5, un...</td>\n",
       "      <td>collection : 45, selection : 15, variety : 10,...</td>\n",
       "      <td>discount :10, deal :9, price :3, offers :1, pr...</td>\n",
       "      <td></td>\n",
       "      <td>reasonable :5, affordable :3, fair :2, negotia...</td>\n",
       "      <td>high quality :3, quality :3, top-notch :2, exc...</td>\n",
       "      <td>exchange :10, helpful :8, patient :3, consider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Naperville, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy store :1, Trusted destination for ...</td>\n",
       "      <td>great experience : 20, wonderful experience : ...</td>\n",
       "      <td>very helpful : 40, very patient : 30, very fri...</td>\n",
       "      <td>nice designs : 3, beautiful designs : 3, great...</td>\n",
       "      <td>great collection : 10, good collection : 8, am...</td>\n",
       "      <td>good discount :5, great deal :4, best discount...</td>\n",
       "      <td></td>\n",
       "      <td>best price :10, good price :9, great price :8,...</td>\n",
       "      <td>quality and craftsmanship :1, high-quality gol...</td>\n",
       "      <td>helped with the exchange :2, helped me exchang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Naperville, IL  Positive  keywords   \n",
       "1  Malabar Gold & Diamonds-Naperville, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trustworthy :2, Trusted :2, Recommend :2, Reco...   \n",
       "1  Trustworthy store :1, Trusted destination for ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant : 15, helpful : 10, friendly : 8, wel...   \n",
       "1  great experience : 20, wonderful experience : ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 98, patient : 85, friendly : 75, kno...   \n",
       "1  very helpful : 40, very patient : 30, very fri...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs : 45, collection : 10, variety : 5, un...   \n",
       "1  nice designs : 3, beautiful designs : 3, great...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, selection : 15, variety : 10,...   \n",
       "1  great collection : 10, good collection : 8, am...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0  discount :10, deal :9, price :3, offers :1, pr...                 \n",
       "1  good discount :5, great deal :4, best discount...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :5, affordable :3, fair :2, negotia...   \n",
       "1  best price :10, good price :9, great price :8,...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  high quality :3, quality :3, top-notch :2, exc...   \n",
       "1  quality and craftsmanship :1, high-quality gol...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :10, helpful :8, patient :3, consider...  \n",
       "1  helped with the exchange :2, helped me exchang...  "
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_nap_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_nap_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_nap_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_nap_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_nap_il = pd.concat([positive_keywords_mal_nap_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_nap_il = pd.concat([positive_keywords_mal_nap_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_nap_il = positive_keywords_mal_nap_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_nap_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcba146-2513-4109-8bbd-0d06c10a3925",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ise_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "4e3ccbd2-e2ca-496c-b22b-23759a22d74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:26:56.768539Z",
     "iopub.status.busy": "2025-06-11T16:26:56.768070Z",
     "iopub.status.idle": "2025-06-11T16:27:43.355119Z",
     "shell.execute_reply": "2025-06-11T16:27:43.354511Z",
     "shell.execute_reply.started": "2025-06-11T16:26:56.768520Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  46.6\n",
      "Total Input Tokens -  108786\n",
      "Total Input Cost = USD  1.09\n",
      "Total Output Tokens -  818\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.11\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_ise_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_ise_nj=[0]\n",
    "keyword_input_token_mal_ise_nj = 0\n",
    "keyword_output_token_mal_ise_nj = 0\n",
    "keyword_start_time_loop_mal_ise_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ise_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ise_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ise_nj = keyword_dataframes['mal_ise_nj_final_sen_df_jul'][keyword_dataframes['mal_ise_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_ise_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_ise_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_ise_nj.append(keywords)\n",
    "        keyword_input_token_mal_ise_nj += input_tokens_loop\n",
    "        keyword_output_token_mal_ise_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ise_nj = time.time()\n",
    "keyword_cost_input_token_mal_ise_nj = round((0.01/1000)*keyword_input_token_mal_ise_nj,2)\n",
    "keyword_cost_output_token_mal_ise_nj = round((0.03/1000)*keyword_output_token_mal_ise_nj,2)\n",
    "keyword_total_cost_mal_ise_nj = keyword_cost_input_token_mal_ise_nj + keyword_cost_output_token_mal_ise_nj\n",
    "keyword_total_time_loop_mal_ise_nj = keyword_end_time_loop_mal_ise_nj - keyword_start_time_loop_mal_ise_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_ise_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_ise_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_ise_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_ise_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_ise_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_ise_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_ise_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "ec3af6db-49c7-4f5f-be65-458e1fc16dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:27:43.357963Z",
     "iopub.status.busy": "2025-06-11T16:27:43.357714Z",
     "iopub.status.idle": "2025-06-11T16:27:43.406832Z",
     "shell.execute_reply": "2025-06-11T16:27:43.406357Z",
     "shell.execute_reply.started": "2025-06-11T16:27:43.357946Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Iselin, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustworthy :1, Reliable :1, Transparency :1, ...</td>\n",
       "      <td>pleasant : 10, smooth : 8, enjoyable : 7, welc...</td>\n",
       "      <td>helpful : 150, patient : 100, friendly : 80, p...</td>\n",
       "      <td>good design :10, nice designs :8, great design...</td>\n",
       "      <td>wide selection :1, ample choices :1, good vari...</td>\n",
       "      <td>good discount: 10, great deal: 9, best deal: 6...</td>\n",
       "      <td>genuine making charge :1, good price :1</td>\n",
       "      <td>reasonable :8, best :7, good :6, great :5, fai...</td>\n",
       "      <td>quality :8, good quality :5, excellent quality...</td>\n",
       "      <td>exchange :10, refund :1, resale value :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Iselin, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy in their customer dealings :1, Kno...</td>\n",
       "      <td>great experience : 15, wonderful experience : ...</td>\n",
       "      <td>very helpful : 30, extremely helpful : 20, ver...</td>\n",
       "      <td>showing us so many stunning gold designs :1, b...</td>\n",
       "      <td>wide selection of jewelry :1, ample choices an...</td>\n",
       "      <td>gave us a good discount: 3, gave us a great de...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>reasonable price :5, best price :5, great pric...</td>\n",
       "      <td>quality of the jewelry is excellent :1, qualit...</td>\n",
       "      <td>great price :1, easy peasy :1, effortlessly ea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Iselin, NJ  Positive  keywords   \n",
       "1  Malabar Gold & Diamonds-Iselin, NJ  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trustworthy :1, Reliable :1, Transparency :1, ...   \n",
       "1  Trustworthy in their customer dealings :1, Kno...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant : 10, smooth : 8, enjoyable : 7, welc...   \n",
       "1  great experience : 15, wonderful experience : ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 150, patient : 100, friendly : 80, p...   \n",
       "1  very helpful : 30, extremely helpful : 20, ver...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  good design :10, nice designs :8, great design...   \n",
       "1  showing us so many stunning gold designs :1, b...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  wide selection :1, ample choices :1, good vari...   \n",
       "1  wide selection of jewelry :1, ample choices an...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount: 10, great deal: 9, best deal: 6...   \n",
       "1  gave us a good discount: 3, gave us a great de...   \n",
       "\n",
       "                             Making Charge  \\\n",
       "0  genuine making charge :1, good price :1   \n",
       "1             No relevant positive phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :8, best :7, good :6, great :5, fai...   \n",
       "1  reasonable price :5, best price :5, great pric...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, good quality :5, excellent quality...   \n",
       "1  quality of the jewelry is excellent :1, qualit...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0           exchange :10, refund :1, resale value :1  \n",
       "1  great price :1, easy peasy :1, effortlessly ea...  "
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_ise_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_ise_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_ise_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ise_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_ise_nj = pd.concat([positive_keywords_mal_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_ise_nj = pd.concat([positive_keywords_mal_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_ise_nj = positive_keywords_mal_ise_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_ise_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b80ae4-d784-47b1-bb29-5cfbdd9c56c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "d38c9187-9e7c-4ee7-87f5-2f02879a8d7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:27:43.407721Z",
     "iopub.status.busy": "2025-06-11T16:27:43.407446Z",
     "iopub.status.idle": "2025-06-11T16:28:17.974883Z",
     "shell.execute_reply": "2025-06-11T16:28:17.974358Z",
     "shell.execute_reply.started": "2025-06-11T16:27:43.407693Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  34.6\n",
      "Total Input Tokens -  113893\n",
      "Total Input Cost = USD  1.14\n",
      "Total Output Tokens -  833\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.16\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_fri_tx=[0]\n",
    "keyword_input_token_mal_fri_tx = 0\n",
    "keyword_output_token_mal_fri_tx = 0\n",
    "keyword_start_time_loop_mal_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_fri_tx = keyword_dataframes['mal_fri_tx_final_sen_df_jul'][keyword_dataframes['mal_fri_tx_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mal_fri_tx:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mal_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mal_fri_tx.append(keywords)\n",
    "        keyword_input_token_mal_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_mal_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_fri_tx = time.time()\n",
    "keyword_cost_input_token_mal_fri_tx = round((0.01/1000)*keyword_input_token_mal_fri_tx,2)\n",
    "keyword_cost_output_token_mal_fri_tx = round((0.03/1000)*keyword_output_token_mal_fri_tx,2)\n",
    "keyword_total_cost_mal_fri_tx = keyword_cost_input_token_mal_fri_tx + keyword_cost_output_token_mal_fri_tx\n",
    "keyword_total_time_loop_mal_fri_tx = keyword_end_time_loop_mal_fri_tx - keyword_start_time_loop_mal_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "a7ceab13-895e-4d16-9739-0e4d51359dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:28:17.975828Z",
     "iopub.status.busy": "2025-06-11T16:28:17.975575Z",
     "iopub.status.idle": "2025-06-11T16:28:18.023537Z",
     "shell.execute_reply": "2025-06-11T16:28:18.023047Z",
     "shell.execute_reply.started": "2025-06-11T16:28:17.975809Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Reliable :2, Trust :1, Trustworthy :1, Confide...</td>\n",
       "      <td>pleasant : 10, wonderful : 9, great : 8, nice ...</td>\n",
       "      <td>patient : 45, helpful : 40, friendly : 35, kin...</td>\n",
       "      <td>designs : 45, collections : 8, models : 5, cra...</td>\n",
       "      <td>variety : 5, collections : 4, selection : 3, o...</td>\n",
       "      <td>good discount :10, best deal :6, great discoun...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>best price :10, good price :9, reasonable pric...</td>\n",
       "      <td>quality :8, exceptional :5, well-made :2, impe...</td>\n",
       "      <td>exchange :7, helpful :6, good deal :2, transpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust the store and the quality :1, Reliable a...</td>\n",
       "      <td>great experience : 15, wonderful experience : ...</td>\n",
       "      <td>very patient and helpful : 10, very friendly a...</td>\n",
       "      <td>beautiful designs : 3, unique designs : 3, ama...</td>\n",
       "      <td>wide variety : 3, great collection : 3, lots o...</td>\n",
       "      <td>gave me good discount :3, got a good discount ...</td>\n",
       "      <td>helped me in reducing the price for making cha...</td>\n",
       "      <td>prices are reasonable :2, prices were reasonab...</td>\n",
       "      <td>quality is exceptional :3, quality of the gold...</td>\n",
       "      <td>helped with my exchange :2, very helpful with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Frisco, TX  Positive  keywords   \n",
       "1  Malabar Gold & Diamonds-Frisco, TX  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Reliable :2, Trust :1, Trustworthy :1, Confide...   \n",
       "1  Trust the store and the quality :1, Reliable a...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant : 10, wonderful : 9, great : 8, nice ...   \n",
       "1  great experience : 15, wonderful experience : ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 45, helpful : 40, friendly : 35, kin...   \n",
       "1  very patient and helpful : 10, very friendly a...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs : 45, collections : 8, models : 5, cra...   \n",
       "1  beautiful designs : 3, unique designs : 3, ama...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety : 5, collections : 4, selection : 3, o...   \n",
       "1  wide variety : 3, great collection : 3, lots o...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  good discount :10, best deal :6, great discoun...   \n",
       "1  gave me good discount :3, got a good discount ...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0             No relevant positive keywords/ phrases   \n",
       "1  helped me in reducing the price for making cha...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :10, good price :9, reasonable pric...   \n",
       "1  prices are reasonable :2, prices were reasonab...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, exceptional :5, well-made :2, impe...   \n",
       "1  quality is exceptional :3, quality of the gold...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :7, helpful :6, good deal :2, transpa...  \n",
       "1  helped with my exchange :2, very helpful with ...  "
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_fri_tx = pd.concat([positive_keywords_mal_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_fri_tx = pd.concat([positive_keywords_mal_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_fri_tx = positive_keywords_mal_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022cfc31-a6d0-46ec-ae62-dbe04b0f001c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mal_ric_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "693904eb-8f35-4c31-8f94-c606a00ab640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:28:18.024879Z",
     "iopub.status.busy": "2025-06-11T16:28:18.024304Z",
     "iopub.status.idle": "2025-06-11T16:32:33.457666Z",
     "shell.execute_reply": "2025-06-11T16:32:33.457146Z",
     "shell.execute_reply.started": "2025-06-11T16:28:18.024852Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed 10 Iterations\n",
      "Total Execution time (in secs) - 255.4\n",
      "Total Input Tokens - 162920\n",
      "Total Input Cost = USD 1.63\n",
      "Total Output Tokens - 8309\n",
      "Total Output Cost = USD 0.25\n",
      "Total Cost = USD 1.88\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mal_ric_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = [\n",
    "    'Customer Confidence', 'Store Experience', 'Store Staff', 'Product Design',\n",
    "    'Product Variety', 'Discount', 'Making Charge', 'Price', \n",
    "    'Product Quality', 'Jewellery Exchange'\n",
    "]\n",
    "\n",
    "keyword_counter_mal_ric_tx = [0]\n",
    "keyword_input_token_mal_ric_tx = 0\n",
    "keyword_output_token_mal_ric_tx = 0\n",
    "keyword_start_time_loop_mal_ric_tx = time.time()\n",
    "\n",
    "# Threading setup\n",
    "keyword_total_iterations = len(keyword_topics)\n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ric_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ric_tx[0] += 1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ric_tx = keyword_dataframes['mal_ric_tx_final_sen_df_jul'][keyword_dataframes['mal_ric_tx_final_sen_df_jul'][topic] == 1]['review_text'].tolist()\n",
    "    \n",
    "    # If there are positive comments, process them in chunks of 25\n",
    "    if filtered_comments_mal_ric_tx:\n",
    "        # Loop through the filtered comments in batches of 25\n",
    "        for i in range(0, len(filtered_comments_mal_ric_tx), 25):\n",
    "            # Get the current batch of 25 comments (or less if it's the last batch)\n",
    "            comment_batch = filtered_comments_mal_ric_tx[i:i + 25]\n",
    "            # Call the positive_keywords function and store the result for each batch\n",
    "            keywords, input_tokens_loop, output_token_loop = positive_keywords(comment_batch, topic)\n",
    "            # Add the result to the output dictionary\n",
    "            keyword_positive_output_mal_ric_tx.append(keywords)\n",
    "            keyword_input_token_mal_ric_tx += input_tokens_loop\n",
    "            keyword_output_token_mal_ric_tx += output_token_loop\n",
    "\n",
    "# Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ric_tx = time.time()\n",
    "keyword_cost_input_token_mal_ric_tx = round((0.01 / 1000) * keyword_input_token_mal_ric_tx, 2)\n",
    "keyword_cost_output_token_mal_ric_tx = round((0.03 / 1000) * keyword_output_token_mal_ric_tx, 2)\n",
    "keyword_total_cost_mal_ric_tx = keyword_cost_input_token_mal_ric_tx + keyword_cost_output_token_mal_ric_tx\n",
    "keyword_total_time_loop_mal_ric_tx = keyword_end_time_loop_mal_ric_tx - keyword_start_time_loop_mal_ric_tx\n",
    "\n",
    "# Display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed\", keyword_counter_mal_ric_tx[0], \"Iterations\")\n",
    "print(\"Total Execution time (in secs) -\", round(keyword_total_time_loop_mal_ric_tx, 1))\n",
    "print(\"Total Input Tokens -\", keyword_input_token_mal_ric_tx)\n",
    "print(\"Total Input Cost = USD\", keyword_cost_input_token_mal_ric_tx)\n",
    "print(\"Total Output Tokens -\", keyword_output_token_mal_ric_tx)\n",
    "print(\"Total Output Cost = USD\", keyword_cost_output_token_mal_ric_tx)\n",
    "print(\"Total Cost = USD\", round(keyword_total_cost_mal_ric_tx, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "61f6b8bf-a691-4af6-99df-d109d7c07596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:32:33.458613Z",
     "iopub.status.busy": "2025-06-11T16:32:33.458369Z",
     "iopub.status.idle": "2025-06-11T16:32:33.857641Z",
     "shell.execute_reply": "2025-06-11T16:32:33.857137Z",
     "shell.execute_reply.started": "2025-06-11T16:32:33.458582Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malani Jewellers-Richardson, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustworthy :2, Reliable :2, Confident :1, Aut...</td>\n",
       "      <td>pleasant :3, wonderful :3, amazing :3, awesome...</td>\n",
       "      <td>helpful :6, excellent :4, friendly :4, patient...</td>\n",
       "      <td>designs :10, intricate :1, beautiful :1, elega...</td>\n",
       "      <td>collection :12, varieties :2, selection :2, op...</td>\n",
       "      <td>discount :5, deal :5, offer :2, price :2, sale...</td>\n",
       "      <td></td>\n",
       "      <td>best price :6, good price :4, great price :3, ...</td>\n",
       "      <td>quality :8, high quality :4, good quality :3, ...</td>\n",
       "      <td>trade :1, exchange :1, sold :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malani Jewellers-Richardson, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy, patient, and always smiling :1, M...</td>\n",
       "      <td>pleasant experience :3, wonderful experience :...</td>\n",
       "      <td>very helpful :3, excellent service :2, great s...</td>\n",
       "      <td>newest designs :1, intricate designs :1, beaut...</td>\n",
       "      <td>great collection :4, excellent collections :2,...</td>\n",
       "      <td>good discount :3, best deal :3, amazing deal :...</td>\n",
       "      <td></td>\n",
       "      <td>gave us the best price :3, got the great price...</td>\n",
       "      <td>quality of the jewelry is exceptional :1, qual...</td>\n",
       "      <td>trade out my gold :1, entire process stress-fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Malani Jewellers-Richardson, TX  Positive  keywords   \n",
       "1  Malani Jewellers-Richardson, TX  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trustworthy :2, Reliable :2, Confident :1, Aut...   \n",
       "1  Trustworthy, patient, and always smiling :1, M...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant :3, wonderful :3, amazing :3, awesome...   \n",
       "1  pleasant experience :3, wonderful experience :...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :6, excellent :4, friendly :4, patient...   \n",
       "1  very helpful :3, excellent service :2, great s...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :10, intricate :1, beautiful :1, elega...   \n",
       "1  newest designs :1, intricate designs :1, beaut...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection :12, varieties :2, selection :2, op...   \n",
       "1  great collection :4, excellent collections :2,...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0  discount :5, deal :5, offer :2, price :2, sale...                 \n",
       "1  good discount :3, best deal :3, amazing deal :...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :6, good price :4, great price :3, ...   \n",
       "1  gave us the best price :3, got the great price...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, high quality :4, good quality :3, ...   \n",
       "1  quality of the jewelry is exceptional :1, qual...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                     trade :1, exchange :1, sold :1  \n",
       "1  trade out my gold :1, entire process stress-fr...  "
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mal_ric_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mal_ric_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mal_ric_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ric_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mal_ric_tx = pd.concat([positive_keywords_mal_ric_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mal_ric_tx = pd.concat([positive_keywords_mal_ric_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mal_ric_tx = positive_keywords_mal_ric_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mal_ric_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9688e15c-ff2e-4328-88b9-bbb63ddd5f4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### may_vie_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "abbe3aa8-5558-4228-b1dc-159d4796630d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:32:33.858968Z",
     "iopub.status.busy": "2025-06-11T16:32:33.858400Z",
     "iopub.status.idle": "2025-06-11T16:32:47.892383Z",
     "shell.execute_reply": "2025-06-11T16:32:47.891832Z",
     "shell.execute_reply.started": "2025-06-11T16:32:33.858936Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  14.0\n",
      "Total Input Tokens -  8808\n",
      "Total Input Cost = USD  0.09\n",
      "Total Output Tokens -  486\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_may_vie_va = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_may_vie_va=[0]\n",
    "keyword_input_token_may_vie_va = 0\n",
    "keyword_output_token_may_vie_va = 0\n",
    "keyword_start_time_loop_may_vie_va = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_may_vie_va, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_may_vie_va[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_may_vie_va = keyword_dataframes['may_vie_va_final_sen_df_jul'][keyword_dataframes['may_vie_va_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_may_vie_va:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_may_vie_va,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_may_vie_va.append(keywords)\n",
    "        keyword_input_token_may_vie_va += input_tokens_loop\n",
    "        keyword_output_token_may_vie_va += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_may_vie_va = time.time()\n",
    "keyword_cost_input_token_may_vie_va = round((0.01/1000)*keyword_input_token_may_vie_va,2)\n",
    "keyword_cost_output_token_may_vie_va = round((0.03/1000)*keyword_output_token_may_vie_va,2)\n",
    "keyword_total_cost_may_vie_va = keyword_cost_input_token_may_vie_va + keyword_cost_output_token_may_vie_va\n",
    "keyword_total_time_loop_may_vie_va = keyword_end_time_loop_may_vie_va - keyword_start_time_loop_may_vie_va\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_may_vie_va[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_may_vie_va,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_may_vie_va)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_may_vie_va)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_may_vie_va)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_may_vie_va)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_may_vie_va,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "8a6c075d-f369-4568-9601-684b055fd601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:32:47.893399Z",
     "iopub.status.busy": "2025-06-11T16:32:47.893084Z",
     "iopub.status.idle": "2025-06-11T16:32:47.936672Z",
     "shell.execute_reply": "2025-06-11T16:32:47.936127Z",
     "shell.execute_reply.started": "2025-06-11T16:32:47.893377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May Jewelers-Vienna, VA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trustworthy :1, Professional :1, Knowledgeable...</td>\n",
       "      <td>great experience :5, fantastic experience :2, ...</td>\n",
       "      <td>professional :3, helpful :3, knowledgeable :3,...</td>\n",
       "      <td>custom designs :1, handmade :1</td>\n",
       "      <td>selection :1, unique :1</td>\n",
       "      <td>deals :1</td>\n",
       "      <td></td>\n",
       "      <td>reasonable :1</td>\n",
       "      <td>Outstanding quality :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May Jewelers-Vienna, VA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy throughout the process :1, Always ...</td>\n",
       "      <td>very welcoming :1, truly welcomed :1, very kin...</td>\n",
       "      <td>great experience :3, highly recommended :2, fa...</td>\n",
       "      <td>design exactly what she wanted :1, custom desi...</td>\n",
       "      <td>access to any kind of gem :1, more subtle piec...</td>\n",
       "      <td>best deals in the area :1</td>\n",
       "      <td></td>\n",
       "      <td>much more reasonable compared to other jeweler...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type  \\\n",
       "0  May Jewelers-Vienna, VA  Positive  keywords   \n",
       "1  May Jewelers-Vienna, VA  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trustworthy :1, Professional :1, Knowledgeable...   \n",
       "1  Trustworthy throughout the process :1, Always ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience :5, fantastic experience :2, ...   \n",
       "1  very welcoming :1, truly welcomed :1, very kin...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  professional :3, helpful :3, knowledgeable :3,...   \n",
       "1  great experience :3, highly recommended :2, fa...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0                     custom designs :1, handmade :1   \n",
       "1  design exactly what she wanted :1, custom desi...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                            selection :1, unique :1   \n",
       "1  access to any kind of gem :1, more subtle piec...   \n",
       "\n",
       "                    Discount Making Charge  \\\n",
       "0                   deals :1                 \n",
       "1  best deals in the area :1                 \n",
       "\n",
       "                                               Price  \\\n",
       "0                                      reasonable :1   \n",
       "1  much more reasonable compared to other jeweler...   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0                  Outstanding quality :1                     \n",
       "1  No relevant positive keywords/ phrases                     "
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_may_vie_va = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_may_vie_va[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_may_vie_va:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'may_vie_va'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_may_vie_va = pd.concat([positive_keywords_may_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_may_vie_va = pd.concat([positive_keywords_may_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_may_vie_va = positive_keywords_may_vie_va.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_may_vie_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e29e6e-2e6c-4a32-956f-65e64cdaeae9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### son_ise_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "28e0f416-91e7-4957-8797-c915c9d5ab8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:32:47.937612Z",
     "iopub.status.busy": "2025-06-11T16:32:47.937332Z",
     "iopub.status.idle": "2025-06-11T16:33:10.484191Z",
     "shell.execute_reply": "2025-06-11T16:33:10.483661Z",
     "shell.execute_reply.started": "2025-06-11T16:32:47.937579Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  22.5\n",
      "Total Input Tokens -  20976\n",
      "Total Input Cost = USD  0.21\n",
      "Total Output Tokens -  670\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.23\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_son_ise_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_son_ise_nj=[0]\n",
    "keyword_input_token_son_ise_nj = 0\n",
    "keyword_output_token_son_ise_nj = 0\n",
    "keyword_start_time_loop_son_ise_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_son_ise_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_son_ise_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_son_ise_nj = keyword_dataframes['son_ise_nj_final_sen_df_jul'][keyword_dataframes['son_ise_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_son_ise_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_son_ise_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_son_ise_nj.append(keywords)\n",
    "        keyword_input_token_son_ise_nj += input_tokens_loop\n",
    "        keyword_output_token_son_ise_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_son_ise_nj = time.time()\n",
    "keyword_cost_input_token_son_ise_nj = round((0.01/1000)*keyword_input_token_son_ise_nj,2)\n",
    "keyword_cost_output_token_son_ise_nj = round((0.03/1000)*keyword_output_token_son_ise_nj,2)\n",
    "keyword_total_cost_son_ise_nj = keyword_cost_input_token_son_ise_nj + keyword_cost_output_token_son_ise_nj\n",
    "keyword_total_time_loop_son_ise_nj = keyword_end_time_loop_son_ise_nj - keyword_start_time_loop_son_ise_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_son_ise_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_son_ise_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_son_ise_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_son_ise_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_son_ise_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_son_ise_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_son_ise_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "792796fd-f14e-463d-a66a-990b387408ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:33:10.485568Z",
     "iopub.status.busy": "2025-06-11T16:33:10.484995Z",
     "iopub.status.idle": "2025-06-11T16:33:10.530476Z",
     "shell.execute_reply": "2025-06-11T16:33:10.530011Z",
     "shell.execute_reply.started": "2025-06-11T16:33:10.485539Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sona Jewelers-Iselin, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :5, Reliable :4, Honest :3, Dependable :...</td>\n",
       "      <td>great experience :10, wonderful experience :5,...</td>\n",
       "      <td>helpful : 50, patient : 20, knowledgeable : 15...</td>\n",
       "      <td>designs :5, good design :2, beautiful :2, stun...</td>\n",
       "      <td>variety :5, collections :5, selection :5, choi...</td>\n",
       "      <td>discount :3, deal :3</td>\n",
       "      <td></td>\n",
       "      <td>best price :5, good price :4, fair price :3, r...</td>\n",
       "      <td>quality :6, good :3, outstanding :2, best :2, ...</td>\n",
       "      <td>exchanging :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sona Jewelers-Iselin, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Always come again and again :3, Our favorite s...</td>\n",
       "      <td>great shopping experience :4, pleasant experie...</td>\n",
       "      <td>very helpful : 30, great service : 25, excelle...</td>\n",
       "      <td>beautiful jewelry :2, beautiful pieces :1, ama...</td>\n",
       "      <td>wide variety of selection :1, very large colle...</td>\n",
       "      <td>good deal :2, great deal :3, best deals :1</td>\n",
       "      <td></td>\n",
       "      <td>best price in town :1, very very good price :1...</td>\n",
       "      <td>quality is best :1, quality exceeded my expect...</td>\n",
       "      <td>exchanging our old gold :1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type  \\\n",
       "0  Sona Jewelers-Iselin, NJ  Positive  keywords   \n",
       "1  Sona Jewelers-Iselin, NJ  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :5, Reliable :4, Honest :3, Dependable :...   \n",
       "1  Always come again and again :3, Our favorite s...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience :10, wonderful experience :5,...   \n",
       "1  great shopping experience :4, pleasant experie...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, patient : 20, knowledgeable : 15...   \n",
       "1  very helpful : 30, great service : 25, excelle...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :5, good design :2, beautiful :2, stun...   \n",
       "1  beautiful jewelry :2, beautiful pieces :1, ama...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :5, collections :5, selection :5, choi...   \n",
       "1  wide variety of selection :1, very large colle...   \n",
       "\n",
       "                                     Discount Making Charge  \\\n",
       "0                        discount :3, deal :3                 \n",
       "1  good deal :2, great deal :3, best deals :1                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :5, good price :4, fair price :3, r...   \n",
       "1  best price in town :1, very very good price :1...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :6, good :3, outstanding :2, best :2, ...   \n",
       "1  quality is best :1, quality exceeded my expect...   \n",
       "\n",
       "           Jewellery Exchange  \n",
       "0               exchanging :1  \n",
       "1  exchanging our old gold :1  "
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_son_ise_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_son_ise_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_son_ise_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'son_ise_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_son_ise_nj = pd.concat([positive_keywords_son_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_son_ise_nj = pd.concat([positive_keywords_son_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_son_ise_nj = positive_keywords_son_ise_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_son_ise_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6ac85-268d-43b6-90b3-1a4830361d6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "9b9659d7-a162-42f6-8ba7-6769113cd764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:43:32.270857Z",
     "iopub.status.busy": "2025-06-11T16:43:32.270518Z",
     "iopub.status.idle": "2025-06-11T16:43:51.814043Z",
     "shell.execute_reply": "2025-06-11T16:43:51.813494Z",
     "shell.execute_reply.started": "2025-06-11T16:43:32.270835Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  19.5\n",
      "Total Input Tokens -  9192\n",
      "Total Input Cost = USD  0.09\n",
      "Total Output Tokens -  374\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_chi_il=[0]\n",
    "keyword_input_token_tif_chi_il = 0\n",
    "keyword_output_token_tif_chi_il = 0\n",
    "keyword_start_time_loop_tif_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_chi_il = keyword_dataframes['tif_chi_il_final_sen_df_jul'][keyword_dataframes['tif_chi_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_chi_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_chi_il.append(keywords)\n",
    "        keyword_input_token_tif_chi_il += input_tokens_loop\n",
    "        keyword_output_token_tif_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_chi_il = time.time()\n",
    "keyword_cost_input_token_tif_chi_il = round((0.01/1000)*keyword_input_token_tif_chi_il,2)\n",
    "keyword_cost_output_token_tif_chi_il = round((0.03/1000)*keyword_output_token_tif_chi_il,2)\n",
    "keyword_total_cost_tif_chi_il = keyword_cost_input_token_tif_chi_il + keyword_cost_output_token_tif_chi_il\n",
    "keyword_total_time_loop_tif_chi_il = keyword_end_time_loop_tif_chi_il - keyword_start_time_loop_tif_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "f51db6c1-3757-4ec0-98f8-448e173261a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:43:51.815649Z",
     "iopub.status.busy": "2025-06-11T16:43:51.815246Z",
     "iopub.status.idle": "2025-06-11T16:43:51.856819Z",
     "shell.execute_reply": "2025-06-11T16:43:51.856298Z",
     "shell.execute_reply.started": "2025-06-11T16:43:51.815628Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>welcoming :2, stunning :2, breathtaking :1, go...</td>\n",
       "      <td>helpful :4, kind :3, attentive :3, knowledgeab...</td>\n",
       "      <td>beautiful :1, exquisite :1</td>\n",
       "      <td>selection :2, options :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>affordable :1</td>\n",
       "      <td>Good product:1, Quality:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>stress-free experience :1, unforgettable exper...</td>\n",
       "      <td>great customer service :2, made me feel specia...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>large selection :1, huge selection :1, numerou...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>something special and affordable :1</td>\n",
       "      <td>the quality and look of my bracelet is STUNNING:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Chicago, IL  Positive  keywords   \n",
       "1  Tiffany & Co-Chicago, IL  Positive   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  welcoming :2, stunning :2, breathtaking :1, go...   \n",
       "1  stress-free experience :1, unforgettable exper...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :4, kind :3, attentive :3, knowledgeab...   \n",
       "1  great customer service :2, made me feel specia...   \n",
       "\n",
       "                 Product Design  \\\n",
       "0    beautiful :1, exquisite :1   \n",
       "1  No relevant positive phrases   \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0                           selection :2, options :1                          \n",
       "1  large selection :1, huge selection :1, numerou...                          \n",
       "\n",
       "                                 Price  \\\n",
       "0                        affordable :1   \n",
       "1  something special and affordable :1   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0                          Good product:1, Quality:1                     \n",
       "1  the quality and look of my bracelet is STUNNING:1                     "
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_chi_il = pd.concat([positive_keywords_tif_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_chi_il = pd.concat([positive_keywords_tif_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_chi_il = positive_keywords_tif_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f953d-9e4d-406a-b27b-af422d088fc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_nor_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "e0554185-dbb1-4b91-85b3-71ab2d47a897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:43:51.857976Z",
     "iopub.status.busy": "2025-06-11T16:43:51.857708Z",
     "iopub.status.idle": "2025-06-11T16:43:57.377104Z",
     "shell.execute_reply": "2025-06-11T16:43:57.376524Z",
     "shell.execute_reply.started": "2025-06-11T16:43:51.857950Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  5.5\n",
      "Total Input Tokens -  2443\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  166\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.02\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_nor_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_nor_il=[0]\n",
    "keyword_input_token_tif_nor_il = 0\n",
    "keyword_output_token_tif_nor_il = 0\n",
    "keyword_start_time_loop_tif_nor_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_nor_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_nor_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_nor_il = keyword_dataframes['tif_nor_il_final_sen_df_jul'][keyword_dataframes['tif_nor_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_nor_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_nor_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_nor_il.append(keywords)\n",
    "        keyword_input_token_tif_nor_il += input_tokens_loop\n",
    "        keyword_output_token_tif_nor_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_nor_il = time.time()\n",
    "keyword_cost_input_token_tif_nor_il = round((0.01/1000)*keyword_input_token_tif_nor_il,2)\n",
    "keyword_cost_output_token_tif_nor_il = round((0.03/1000)*keyword_output_token_tif_nor_il,2)\n",
    "keyword_total_cost_tif_nor_il = keyword_cost_input_token_tif_nor_il + keyword_cost_output_token_tif_nor_il\n",
    "keyword_total_time_loop_tif_nor_il = keyword_end_time_loop_tif_nor_il - keyword_start_time_loop_tif_nor_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_nor_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_nor_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_nor_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_nor_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_nor_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_nor_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_nor_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "eed6acfb-b5ca-4afc-9228-8059fc136f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:43:57.378889Z",
     "iopub.status.busy": "2025-06-11T16:43:57.378446Z",
     "iopub.status.idle": "2025-06-11T16:43:57.410552Z",
     "shell.execute_reply": "2025-06-11T16:43:57.410090Z",
     "shell.execute_reply.started": "2025-06-11T16:43:57.378868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Northbrook, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>beautiful store :1, Easy place :1, Nice place :1</td>\n",
       "      <td>helpful :1, professional :1, amazing :1, excep...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Northbrook, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>very positive experience :1</td>\n",
       "      <td>super helpful :1, was amazing :1, very positiv...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Northbrook, IL  Positive  keywords   \n",
       "1  Tiffany & Co-Northbrook, IL  Positive   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                   Store Experience  \\\n",
       "0  beautiful store :1, Easy place :1, Nice place :1   \n",
       "1                       very positive experience :1   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  helpful :1, professional :1, amazing :1, excep...                  \n",
       "1  super helpful :1, was amazing :1, very positiv...                  \n",
       "\n",
       "  Product Variety Discount Making Charge Price Product Quality  \\\n",
       "0                                                                \n",
       "1                                                                \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_nor_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_nor_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_nor_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_nor_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_nor_il = pd.concat([positive_keywords_tif_nor_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_nor_il = pd.concat([positive_keywords_tif_nor_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_nor_il = positive_keywords_tif_nor_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_nor_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b2f70-6c66-443c-91bf-a30f3271c451",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_sko_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "b66fb5b1-d55c-4532-82a1-fa9dd395fee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:47:31.615584Z",
     "iopub.status.busy": "2025-06-11T16:47:31.615092Z",
     "iopub.status.idle": "2025-06-11T16:47:38.638119Z",
     "shell.execute_reply": "2025-06-11T16:47:38.637614Z",
     "shell.execute_reply.started": "2025-06-11T16:47:31.615564Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  7.0\n",
      "Total Input Tokens -  4097\n",
      "Total Input Cost = USD  0.04\n",
      "Total Output Tokens -  221\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_sko_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_sko_il=[0]\n",
    "keyword_input_token_tif_sko_il = 0\n",
    "keyword_output_token_tif_sko_il = 0\n",
    "keyword_start_time_loop_tif_sko_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_sko_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_sko_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_sko_il = keyword_dataframes['tif_sko_il_final_sen_df_jul'][keyword_dataframes['tif_sko_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_sko_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_sko_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_sko_il.append(keywords)\n",
    "        keyword_input_token_tif_sko_il += input_tokens_loop\n",
    "        keyword_output_token_tif_sko_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_sko_il = time.time()\n",
    "keyword_cost_input_token_tif_sko_il = round((0.01/1000)*keyword_input_token_tif_sko_il,2)\n",
    "keyword_cost_output_token_tif_sko_il = round((0.03/1000)*keyword_output_token_tif_sko_il,2)\n",
    "keyword_total_cost_tif_sko_il = keyword_cost_input_token_tif_sko_il + keyword_cost_output_token_tif_sko_il\n",
    "keyword_total_time_loop_tif_sko_il = keyword_end_time_loop_tif_sko_il - keyword_start_time_loop_tif_sko_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_sko_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_sko_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_sko_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_sko_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_sko_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_sko_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_sko_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "63ea0971-35b4-4824-a989-d11120a75375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:47:38.639531Z",
     "iopub.status.busy": "2025-06-11T16:47:38.639286Z",
     "iopub.status.idle": "2025-06-11T16:47:38.670930Z",
     "shell.execute_reply": "2025-06-11T16:47:38.670435Z",
     "shell.execute_reply.started": "2025-06-11T16:47:38.639512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Skokie, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>beautiful :3, fantastic :2, nice :1, exception...</td>\n",
       "      <td>professional :1, kind :1, friendly :1, helpful :1</td>\n",
       "      <td>beautiful :3, silver :1, pearl :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Skokie, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>beautiful on :2, beautiful interior :1, great ...</td>\n",
       "      <td>fantastic job of customer care and service :1,...</td>\n",
       "      <td>beautiful single pearl silver hardware bracele...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Skokie, IL  Positive  keywords                       \n",
       "1  Tiffany & Co-Skokie, IL  Positive   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  beautiful :3, fantastic :2, nice :1, exception...   \n",
       "1  beautiful on :2, beautiful interior :1, great ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  professional :1, kind :1, friendly :1, helpful :1   \n",
       "1  fantastic job of customer care and service :1,...   \n",
       "\n",
       "                                      Product Design Product Variety Discount  \\\n",
       "0                  beautiful :3, silver :1, pearl :1                            \n",
       "1  beautiful single pearl silver hardware bracele...                            \n",
       "\n",
       "  Making Charge Price Product Quality Jewellery Exchange  \n",
       "0                                                         \n",
       "1                                                         "
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_sko_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_sko_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_sko_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_sko_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_sko_il = pd.concat([positive_keywords_tif_sko_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_sko_il = pd.concat([positive_keywords_tif_sko_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_sko_il = positive_keywords_tif_sko_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_sko_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c27fb-0e5d-4e3a-9781-29aa70eef0fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_eas_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "da2ed2c5-4230-4025-967e-b80b43fa53ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:47:38.671832Z",
     "iopub.status.busy": "2025-06-11T16:47:38.671585Z",
     "iopub.status.idle": "2025-06-11T16:47:49.701294Z",
     "shell.execute_reply": "2025-06-11T16:47:49.700733Z",
     "shell.execute_reply.started": "2025-06-11T16:47:38.671816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  11.0\n",
      "Total Input Tokens -  7310\n",
      "Total Input Cost = USD  0.07\n",
      "Total Output Tokens -  372\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_eas_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_eas_nj=[0]\n",
    "keyword_input_token_tif_eas_nj = 0\n",
    "keyword_output_token_tif_eas_nj = 0\n",
    "keyword_start_time_loop_tif_eas_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_eas_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_eas_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_eas_nj = keyword_dataframes['tif_eas_nj_final_sen_df_jul'][keyword_dataframes['tif_eas_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_eas_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_eas_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_eas_nj.append(keywords)\n",
    "        keyword_input_token_tif_eas_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_eas_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_eas_nj = time.time()\n",
    "keyword_cost_input_token_tif_eas_nj = round((0.01/1000)*keyword_input_token_tif_eas_nj,2)\n",
    "keyword_cost_output_token_tif_eas_nj = round((0.03/1000)*keyword_output_token_tif_eas_nj,2)\n",
    "keyword_total_cost_tif_eas_nj = keyword_cost_input_token_tif_eas_nj + keyword_cost_output_token_tif_eas_nj\n",
    "keyword_total_time_loop_tif_eas_nj = keyword_end_time_loop_tif_eas_nj - keyword_start_time_loop_tif_eas_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_eas_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_eas_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_eas_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_eas_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_eas_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_eas_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_eas_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "a1b91fa7-d7b2-4975-9360-1e57135c5744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:47:49.702716Z",
     "iopub.status.busy": "2025-06-11T16:47:49.702443Z",
     "iopub.status.idle": "2025-06-11T16:47:49.740545Z",
     "shell.execute_reply": "2025-06-11T16:47:49.740056Z",
     "shell.execute_reply.started": "2025-06-11T16:47:49.702698Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-East Rutherford, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :2, Reliable :1, Faithful :1, Personal :...</td>\n",
       "      <td>helpful :4, accommodating :1, welcoming :1, fr...</td>\n",
       "      <td>helpful :5, friendly :3, accommodating :1, pol...</td>\n",
       "      <td>unique :1, beautiful :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>reasonable :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-East Rutherford, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Integral part of our life milestones :1, Perso...</td>\n",
       "      <td>amazing experiences :1, great hospitality :1, ...</td>\n",
       "      <td>great hospitality :1, amazing experiences :1, ...</td>\n",
       "      <td>beautiful unique engagement rings :1, I was in...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Price was extremely reasonable :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-East Rutherford, NJ  Positive  keywords   \n",
       "1  Tiffany & Co-East Rutherford, NJ  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :2, Reliable :1, Faithful :1, Personal :...   \n",
       "1  Integral part of our life milestones :1, Perso...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  helpful :4, accommodating :1, welcoming :1, fr...   \n",
       "1  amazing experiences :1, great hospitality :1, ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :5, friendly :3, accommodating :1, pol...   \n",
       "1  great hospitality :1, amazing experiences :1, ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0                            unique :1, beautiful :1   \n",
       "1  beautiful unique engagement rings :1, I was in...   \n",
       "\n",
       "                          Product Variety Discount Making Charge  \\\n",
       "0  No relevant positive keywords/ phrases                          \n",
       "1  No relevant positive keywords/ phrases                          \n",
       "\n",
       "                               Price Product Quality Jewellery Exchange  \n",
       "0                      reasonable :1                                     \n",
       "1  Price was extremely reasonable :1                                     "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_eas_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_eas_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_eas_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_eas_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_eas_nj = pd.concat([positive_keywords_tif_eas_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_eas_nj = pd.concat([positive_keywords_tif_eas_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_eas_nj = positive_keywords_tif_eas_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_eas_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9d5fe-214d-427f-aebf-b60ec49b7743",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_red_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "bc5f35ec-3394-418e-b76b-235b181070c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:47:49.741502Z",
     "iopub.status.busy": "2025-06-11T16:47:49.741199Z",
     "iopub.status.idle": "2025-06-11T16:47:56.263606Z",
     "shell.execute_reply": "2025-06-11T16:47:56.263070Z",
     "shell.execute_reply.started": "2025-06-11T16:47:49.741474Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  6.5\n",
      "Total Input Tokens -  4101\n",
      "Total Input Cost = USD  0.04\n",
      "Total Output Tokens -  223\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_red_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_red_nj=[0]\n",
    "keyword_input_token_tif_red_nj = 0\n",
    "keyword_output_token_tif_red_nj = 0\n",
    "keyword_start_time_loop_tif_red_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_red_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_red_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_red_nj = keyword_dataframes['tif_red_nj_final_sen_df_jul'][keyword_dataframes['tif_red_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_red_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_red_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_red_nj.append(keywords)\n",
    "        keyword_input_token_tif_red_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_red_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_red_nj = time.time()\n",
    "keyword_cost_input_token_tif_red_nj = round((0.01/1000)*keyword_input_token_tif_red_nj,2)\n",
    "keyword_cost_output_token_tif_red_nj = round((0.03/1000)*keyword_output_token_tif_red_nj,2)\n",
    "keyword_total_cost_tif_red_nj = keyword_cost_input_token_tif_red_nj + keyword_cost_output_token_tif_red_nj\n",
    "keyword_total_time_loop_tif_red_nj = keyword_end_time_loop_tif_red_nj - keyword_start_time_loop_tif_red_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_red_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_red_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_red_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_red_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_red_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_red_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_red_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "f1fd2212-2e84-4cc7-af50-c62cc5fc204d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:47:56.264615Z",
     "iopub.status.busy": "2025-06-11T16:47:56.264340Z",
     "iopub.status.idle": "2025-06-11T16:47:56.299836Z",
     "shell.execute_reply": "2025-06-11T16:47:56.299384Z",
     "shell.execute_reply.started": "2025-06-11T16:47:56.264597Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Red Bank, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>professional :2, clean :1, friendly :1</td>\n",
       "      <td>professional :2, helpful :1, kind :1, easy goi...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inexpensive :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Red Bank, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>pleasant experience :1, no rush feeling :1</td>\n",
       "      <td>most pleasant experience :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inexpensive piece of jewelry :1</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Red Bank, NJ  Positive  keywords                       \n",
       "1  Tiffany & Co-Red Bank, NJ  Positive   phrases                       \n",
       "\n",
       "                             Store Experience  \\\n",
       "0      professional :2, clean :1, friendly :1   \n",
       "1  pleasant experience :1, no rush feeling :1   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  professional :2, helpful :1, kind :1, easy goi...   \n",
       "1                        most pleasant experience :1   \n",
       "\n",
       "                           Product Design Product Variety Discount  \\\n",
       "0  No relevant positive keywords/ phrases                            \n",
       "1  No relevant positive keywords/ phrases                            \n",
       "\n",
       "  Making Charge                            Price  \\\n",
       "0                                 inexpensive :1   \n",
       "1                inexpensive piece of jewelry :1   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0  No relevant positive keywords/ phrases                     \n",
       "1  No relevant positive keywords/ phrases                     "
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_red_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_red_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_red_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_red_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_red_nj = pd.concat([positive_keywords_tif_red_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_red_nj = pd.concat([positive_keywords_tif_red_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_red_nj = positive_keywords_tif_red_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_red_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e42f177-6844-478e-a4a9-99b4b75317f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_hac_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "5b66076d-19c2-4224-b72c-87b87f8fba0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:47:56.300744Z",
     "iopub.status.busy": "2025-06-11T16:47:56.300485Z",
     "iopub.status.idle": "2025-06-11T16:48:02.321020Z",
     "shell.execute_reply": "2025-06-11T16:48:02.320477Z",
     "shell.execute_reply.started": "2025-06-11T16:47:56.300728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  6.0\n",
      "Total Input Tokens -  2488\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  193\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.03\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_hac_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_hac_nj=[0]\n",
    "keyword_input_token_tif_hac_nj = 0\n",
    "keyword_output_token_tif_hac_nj = 0\n",
    "keyword_start_time_loop_tif_hac_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_hac_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_hac_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_hac_nj = keyword_dataframes['tif_hac_nj_final_sen_df_jul'][keyword_dataframes['tif_hac_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_hac_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_hac_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_hac_nj.append(keywords)\n",
    "        keyword_input_token_tif_hac_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_hac_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_hac_nj = time.time()\n",
    "keyword_cost_input_token_tif_hac_nj = round((0.01/1000)*keyword_input_token_tif_hac_nj,2)\n",
    "keyword_cost_output_token_tif_hac_nj = round((0.03/1000)*keyword_output_token_tif_hac_nj,2)\n",
    "keyword_total_cost_tif_hac_nj = keyword_cost_input_token_tif_hac_nj + keyword_cost_output_token_tif_hac_nj\n",
    "keyword_total_time_loop_tif_hac_nj = keyword_end_time_loop_tif_hac_nj - keyword_start_time_loop_tif_hac_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_hac_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_hac_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_hac_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_hac_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_hac_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_hac_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_hac_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "f7dd6a79-fea3-4c76-ae4d-17ca71fcf171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:48:02.322318Z",
     "iopub.status.busy": "2025-06-11T16:48:02.321836Z",
     "iopub.status.idle": "2025-06-11T16:48:02.352405Z",
     "shell.execute_reply": "2025-06-11T16:48:02.351907Z",
     "shell.execute_reply.started": "2025-06-11T16:48:02.322292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Hackensack, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>welcoming :1, luxury :1, elegant :1</td>\n",
       "      <td>knowledgeable :1, welcoming :1, friendly :1, p...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Hackensack, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>better experience :1, luxury retail experience...</td>\n",
       "      <td>personable and knowledgeable :1, service is to...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Hackensack, NJ  Positive  keywords                       \n",
       "1  Tiffany & Co-Hackensack, NJ  Positive   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0                welcoming :1, luxury :1, elegant :1   \n",
       "1  better experience :1, luxury retail experience...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  knowledgeable :1, welcoming :1, friendly :1, p...                  \n",
       "1  personable and knowledgeable :1, service is to...                  \n",
       "\n",
       "                          Product Variety Discount Making Charge Price  \\\n",
       "0  No relevant positive keywords/ phrases                                \n",
       "1  No relevant positive keywords/ phrases                                \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_hac_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_hac_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_hac_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_hac_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_hac_nj = pd.concat([positive_keywords_tif_hac_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_hac_nj = pd.concat([positive_keywords_tif_hac_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_hac_nj = positive_keywords_tif_hac_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_hac_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99654a74-eb75-42e5-a215-c2b500a7a6f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_sho_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "e124f898-5c85-45c7-9f4b-722fff5df720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:48:02.353336Z",
     "iopub.status.busy": "2025-06-11T16:48:02.353051Z",
     "iopub.status.idle": "2025-06-11T16:48:06.870835Z",
     "shell.execute_reply": "2025-06-11T16:48:06.870326Z",
     "shell.execute_reply.started": "2025-06-11T16:48:02.353317Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  4.5\n",
      "Total Input Tokens -  2292\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  152\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.02\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_sho_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_sho_nj=[0]\n",
    "keyword_input_token_tif_sho_nj = 0\n",
    "keyword_output_token_tif_sho_nj = 0\n",
    "keyword_start_time_loop_tif_sho_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_sho_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_sho_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_sho_nj = keyword_dataframes['tif_sho_nj_final_sen_df_jul'][keyword_dataframes['tif_sho_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_sho_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_sho_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_sho_nj.append(keywords)\n",
    "        keyword_input_token_tif_sho_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_sho_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_sho_nj = time.time()\n",
    "keyword_cost_input_token_tif_sho_nj = round((0.01/1000)*keyword_input_token_tif_sho_nj,2)\n",
    "keyword_cost_output_token_tif_sho_nj = round((0.03/1000)*keyword_output_token_tif_sho_nj,2)\n",
    "keyword_total_cost_tif_sho_nj = keyword_cost_input_token_tif_sho_nj + keyword_cost_output_token_tif_sho_nj\n",
    "keyword_total_time_loop_tif_sho_nj = keyword_end_time_loop_tif_sho_nj - keyword_start_time_loop_tif_sho_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_sho_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_sho_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_sho_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_sho_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_sho_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_sho_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_sho_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "0c572864-5f70-4ed8-9192-3b04379b0491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:48:06.872851Z",
     "iopub.status.busy": "2025-06-11T16:48:06.872592Z",
     "iopub.status.idle": "2025-06-11T16:48:06.900710Z",
     "shell.execute_reply": "2025-06-11T16:48:06.900246Z",
     "shell.execute_reply.started": "2025-06-11T16:48:06.872833Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Short Hills, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>wonderful :3, friendly :2, amazing :1, lovely ...</td>\n",
       "      <td>friendly :3, helpful :2, attentive :1, persona...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Short Hills, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>wonderful experience :1, great experience :1, ...</td>\n",
       "      <td>wonderful to work with :2, great care :1, exce...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Short Hills, NJ  Positive  keywords                       \n",
       "1  Tiffany & Co-Short Hills, NJ  Positive   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  wonderful :3, friendly :2, amazing :1, lovely ...   \n",
       "1  wonderful experience :1, great experience :1, ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  friendly :3, helpful :2, attentive :1, persona...                  \n",
       "1  wonderful to work with :2, great care :1, exce...                  \n",
       "\n",
       "  Product Variety Discount Making Charge Price Product Quality  \\\n",
       "0                                                                \n",
       "1                                                                \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_sho_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_sho_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_sho_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_sho_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_sho_nj = pd.concat([positive_keywords_tif_sho_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_sho_nj = pd.concat([positive_keywords_tif_sho_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_sho_nj = positive_keywords_tif_sho_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_sho_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380173a-5225-421b-912b-1248fb6fa615",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_par_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "6f8b61b2-a798-4b2a-8609-a293e76181f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:48:06.901818Z",
     "iopub.status.busy": "2025-06-11T16:48:06.901554Z",
     "iopub.status.idle": "2025-06-11T16:48:12.421128Z",
     "shell.execute_reply": "2025-06-11T16:48:12.420628Z",
     "shell.execute_reply.started": "2025-06-11T16:48:06.901795Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  5.5\n",
      "Total Input Tokens -  2351\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  143\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.02\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_par_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_par_nj=[0]\n",
    "keyword_input_token_tif_par_nj = 0\n",
    "keyword_output_token_tif_par_nj = 0\n",
    "keyword_start_time_loop_tif_par_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_par_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_par_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_par_nj = keyword_dataframes['tif_par_nj_final_sen_df_jul'][keyword_dataframes['tif_par_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_par_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_par_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_par_nj.append(keywords)\n",
    "        keyword_input_token_tif_par_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_par_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_par_nj = time.time()\n",
    "keyword_cost_input_token_tif_par_nj = round((0.01/1000)*keyword_input_token_tif_par_nj,2)\n",
    "keyword_cost_output_token_tif_par_nj = round((0.03/1000)*keyword_output_token_tif_par_nj,2)\n",
    "keyword_total_cost_tif_par_nj = keyword_cost_input_token_tif_par_nj + keyword_cost_output_token_tif_par_nj\n",
    "keyword_total_time_loop_tif_par_nj = keyword_end_time_loop_tif_par_nj - keyword_start_time_loop_tif_par_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_par_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_par_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_par_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_par_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_par_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_par_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_par_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "42af4a46-2846-4a88-bd42-9bac7a65944c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:48:12.422115Z",
     "iopub.status.busy": "2025-06-11T16:48:12.421903Z",
     "iopub.status.idle": "2025-06-11T16:48:12.459642Z",
     "shell.execute_reply": "2025-06-11T16:48:12.459006Z",
     "shell.execute_reply.started": "2025-06-11T16:48:12.422096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Paramus, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>friendly :2, helpful :1, huge :1, seating area...</td>\n",
       "      <td>friendly :2, helpful :1</td>\n",
       "      <td></td>\n",
       "      <td>variety :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Paramus, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>super friendly :1, great variety :1, lifetime ...</td>\n",
       "      <td>super friendly :1</td>\n",
       "      <td></td>\n",
       "      <td>great variety of items :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Paramus, NJ  Positive  keywords                       \n",
       "1  Tiffany & Co-Paramus, NJ  Positive   phrases                       \n",
       "\n",
       "                                    Store Experience              Store Staff  \\\n",
       "0  friendly :2, helpful :1, huge :1, seating area...  friendly :2, helpful :1   \n",
       "1  super friendly :1, great variety :1, lifetime ...        super friendly :1   \n",
       "\n",
       "  Product Design            Product Variety Discount Making Charge Price  \\\n",
       "0                                variety :1                                \n",
       "1                 great variety of items :1                                \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_par_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_par_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_par_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_par_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_par_nj = pd.concat([positive_keywords_tif_par_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_par_nj = pd.concat([positive_keywords_tif_par_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_par_nj = positive_keywords_tif_par_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_par_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3858d-c43f-4672-89bb-b02a899fdc5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_vie_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "e17cd5b2-df94-4ca7-a78a-4d6966e3645c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:49:40.121353Z",
     "iopub.status.busy": "2025-06-11T16:49:40.121003Z",
     "iopub.status.idle": "2025-06-11T16:49:48.646518Z",
     "shell.execute_reply": "2025-06-11T16:49:48.645981Z",
     "shell.execute_reply.started": "2025-06-11T16:49:40.121329Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  8.5\n",
      "Total Input Tokens -  5478\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  307\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_vie_va = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_vie_va=[0]\n",
    "keyword_input_token_tif_vie_va = 0\n",
    "keyword_output_token_tif_vie_va = 0\n",
    "keyword_start_time_loop_tif_vie_va = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_vie_va, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_vie_va[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_vie_va = keyword_dataframes['tif_vie_va_final_sen_df_jul'][keyword_dataframes['tif_vie_va_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_vie_va:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_vie_va,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_vie_va.append(keywords)\n",
    "        keyword_input_token_tif_vie_va += input_tokens_loop\n",
    "        keyword_output_token_tif_vie_va += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_vie_va = time.time()\n",
    "keyword_cost_input_token_tif_vie_va = round((0.01/1000)*keyword_input_token_tif_vie_va,2)\n",
    "keyword_cost_output_token_tif_vie_va = round((0.03/1000)*keyword_output_token_tif_vie_va,2)\n",
    "keyword_total_cost_tif_vie_va = keyword_cost_input_token_tif_vie_va + keyword_cost_output_token_tif_vie_va\n",
    "keyword_total_time_loop_tif_vie_va = keyword_end_time_loop_tif_vie_va - keyword_start_time_loop_tif_vie_va\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_vie_va[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_vie_va,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_vie_va)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_vie_va)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_vie_va)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_vie_va)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_vie_va,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "0fe7d81f-5f90-4e3e-8d0e-0ca61e632c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:49:48.647781Z",
     "iopub.status.busy": "2025-06-11T16:49:48.647497Z",
     "iopub.status.idle": "2025-06-11T16:49:48.683695Z",
     "shell.execute_reply": "2025-06-11T16:49:48.683200Z",
     "shell.execute_reply.started": "2025-06-11T16:49:48.647761Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Vienna, VA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Knowledgeable :1, Comfortable :1, Recommend :1</td>\n",
       "      <td>great experience :2, nice experience :1, very ...</td>\n",
       "      <td>knowledgeable :3, helpful :3, professional :2,...</td>\n",
       "      <td></td>\n",
       "      <td>collections :1, pieces :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Vienna, VA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Most knowledgeable and most patient :1, Convin...</td>\n",
       "      <td>silky smooth process :1, pleasure to come to t...</td>\n",
       "      <td>great experience :2, excellent customer servic...</td>\n",
       "      <td></td>\n",
       "      <td>variety of collections :1, classic pieces :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Vienna, VA  Positive  keywords   \n",
       "1  Tiffany & Co-Vienna, VA  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0     Knowledgeable :1, Comfortable :1, Recommend :1   \n",
       "1  Most knowledgeable and most patient :1, Convin...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience :2, nice experience :1, very ...   \n",
       "1  silky smooth process :1, pleasure to come to t...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  knowledgeable :3, helpful :3, professional :2,...                  \n",
       "1  great experience :2, excellent customer servic...                  \n",
       "\n",
       "                                Product Variety Discount Making Charge Price  \\\n",
       "0                     collections :1, pieces :1                                \n",
       "1  variety of collections :1, classic pieces :1                                \n",
       "\n",
       "  Product Quality                      Jewellery Exchange  \n",
       "0                  No relevant positive keywords/ phrases  \n",
       "1                  No relevant positive keywords/ phrases  "
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_vie_va = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_vie_va[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_vie_va:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_vie_va'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_vie_va = pd.concat([positive_keywords_tif_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_vie_va = pd.concat([positive_keywords_tif_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_vie_va = positive_keywords_tif_vie_va.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_vie_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76012a-7889-44c0-8d70-1693fa36c09b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tif_ric_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "c4b246d4-165f-4c02-9469-20086b3215ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:49:48.684697Z",
     "iopub.status.busy": "2025-06-11T16:49:48.684420Z",
     "iopub.status.idle": "2025-06-11T16:49:51.699795Z",
     "shell.execute_reply": "2025-06-11T16:49:51.699305Z",
     "shell.execute_reply.started": "2025-06-11T16:49:48.684679Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  3.0\n",
      "Total Input Tokens -  1492\n",
      "Total Input Cost = USD  0.01\n",
      "Total Output Tokens -  91\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.01\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tif_ric_va = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_ric_va=[0]\n",
    "keyword_input_token_tif_ric_va = 0\n",
    "keyword_output_token_tif_ric_va = 0\n",
    "keyword_start_time_loop_tif_ric_va = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_ric_va, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_ric_va[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_ric_va = keyword_dataframes['tif_ric_va_final_sen_df_jul'][keyword_dataframes['tif_ric_va_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tif_ric_va:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tif_ric_va,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tif_ric_va.append(keywords)\n",
    "        keyword_input_token_tif_ric_va += input_tokens_loop\n",
    "        keyword_output_token_tif_ric_va += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_ric_va = time.time()\n",
    "keyword_cost_input_token_tif_ric_va = round((0.01/1000)*keyword_input_token_tif_ric_va,2)\n",
    "keyword_cost_output_token_tif_ric_va = round((0.03/1000)*keyword_output_token_tif_ric_va,2)\n",
    "keyword_total_cost_tif_ric_va = keyword_cost_input_token_tif_ric_va + keyword_cost_output_token_tif_ric_va\n",
    "keyword_total_time_loop_tif_ric_va = keyword_end_time_loop_tif_ric_va - keyword_start_time_loop_tif_ric_va\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_ric_va[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_ric_va,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_ric_va)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_ric_va)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_ric_va)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_ric_va)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_ric_va,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "f477ec30-77a9-4fa6-94ca-152b12ca1385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:49:51.701312Z",
     "iopub.status.busy": "2025-06-11T16:49:51.700960Z",
     "iopub.status.idle": "2025-06-11T16:49:51.728975Z",
     "shell.execute_reply": "2025-06-11T16:49:51.728521Z",
     "shell.execute_reply.started": "2025-06-11T16:49:51.701292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Richmond, VA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>friendly :2, courteous :1, welcoming :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Richmond, VA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>Wonderful staff :1, Great customer service :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Richmond, VA  Positive  keywords                       \n",
       "1  Tiffany & Co-Richmond, VA  Positive   phrases                       \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                     Store Staff Product Design  \\\n",
       "0        friendly :2, courteous :1, welcoming :1                  \n",
       "1  Wonderful staff :1, Great customer service :1                  \n",
       "\n",
       "  Product Variety Discount Making Charge Price Product Quality  \\\n",
       "0                                                                \n",
       "1                                                                \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tif_ric_va = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tif_ric_va[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tif_ric_va:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_ric_va'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tif_ric_va = pd.concat([positive_keywords_tif_ric_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tif_ric_va = pd.concat([positive_keywords_tif_ric_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tif_ric_va = positive_keywords_tif_ric_va.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tif_ric_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886772a-fafb-46dd-8e46-bf98d7c3b6cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### vbj_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "7f6ec0c0-e0bd-418f-ae84-6192dba2fbaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:49:51.729841Z",
     "iopub.status.busy": "2025-06-11T16:49:51.729610Z",
     "iopub.status.idle": "2025-06-11T16:50:21.289648Z",
     "shell.execute_reply": "2025-06-11T16:50:21.289064Z",
     "shell.execute_reply.started": "2025-06-11T16:49:51.729824Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  29.6\n",
      "Total Input Tokens -  81468\n",
      "Total Input Cost = USD  0.81\n",
      "Total Output Tokens -  679\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.83\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_vbj_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_vbj_fri_tx=[0]\n",
    "keyword_input_token_vbj_fri_tx = 0\n",
    "keyword_output_token_vbj_fri_tx = 0\n",
    "keyword_start_time_loop_vbj_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_vbj_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_vbj_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_vbj_fri_tx = keyword_dataframes['vbj_fri_tx_final_sen_df_jul'][keyword_dataframes['vbj_fri_tx_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_vbj_fri_tx:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_vbj_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_vbj_fri_tx.append(keywords)\n",
    "        keyword_input_token_vbj_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_vbj_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_vbj_fri_tx = time.time()\n",
    "keyword_cost_input_token_vbj_fri_tx = round((0.01/1000)*keyword_input_token_vbj_fri_tx,2)\n",
    "keyword_cost_output_token_vbj_fri_tx = round((0.03/1000)*keyword_output_token_vbj_fri_tx,2)\n",
    "keyword_total_cost_vbj_fri_tx = keyword_cost_input_token_vbj_fri_tx + keyword_cost_output_token_vbj_fri_tx\n",
    "keyword_total_time_loop_vbj_fri_tx = keyword_end_time_loop_vbj_fri_tx - keyword_start_time_loop_vbj_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_vbj_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_vbj_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_vbj_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_vbj_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_vbj_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_vbj_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_vbj_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "8ea5574e-0374-4fc6-95c9-7742c91dc996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:50:21.290606Z",
     "iopub.status.busy": "2025-06-11T16:50:21.290310Z",
     "iopub.status.idle": "2025-06-11T16:50:21.336137Z",
     "shell.execute_reply": "2025-06-11T16:50:21.335627Z",
     "shell.execute_reply.started": "2025-06-11T16:50:21.290586Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VBJ Jewellers-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Reliable :2, Trustworthy :2, Confide...</td>\n",
       "      <td>great experience : 15, good experience : 10, w...</td>\n",
       "      <td>patient : 45, helpful : 40, friendly : 35, kno...</td>\n",
       "      <td>unique :3, exclusive :2, beautiful :2, stunnin...</td>\n",
       "      <td>collection : 78, variety : 8, options : 6, mod...</td>\n",
       "      <td>discount :4, deal :1</td>\n",
       "      <td></td>\n",
       "      <td>reasonable :5, competitive :4, transparent :4,...</td>\n",
       "      <td>quality :10, good quality :3, high quality :3,...</td>\n",
       "      <td>good rates :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBJ Jewellers-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted brand :2, Trusted place to buy :1, Tru...</td>\n",
       "      <td>great shopping experience : 4, wonderful shopp...</td>\n",
       "      <td>very patient and helpful : 10, very friendly a...</td>\n",
       "      <td>nice designs :2, unique and beautiful :1, stun...</td>\n",
       "      <td>great collection : 10, good collection : 9, ni...</td>\n",
       "      <td>amazing Aadi discount :1, good discount :1, ge...</td>\n",
       "      <td></td>\n",
       "      <td>reasonable rates :2, competitive prices :2, tr...</td>\n",
       "      <td>quality is fantastic :1, high-quality products...</td>\n",
       "      <td>exchange old jewelry for new :1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type  \\\n",
       "0  VBJ Jewellers-Frisco, TX  Positive  keywords   \n",
       "1  VBJ Jewellers-Frisco, TX  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Reliable :2, Trustworthy :2, Confide...   \n",
       "1  Trusted brand :2, Trusted place to buy :1, Tru...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience : 15, good experience : 10, w...   \n",
       "1  great shopping experience : 4, wonderful shopp...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 45, helpful : 40, friendly : 35, kno...   \n",
       "1  very patient and helpful : 10, very friendly a...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique :3, exclusive :2, beautiful :2, stunnin...   \n",
       "1  nice designs :2, unique and beautiful :1, stun...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 78, variety : 8, options : 6, mod...   \n",
       "1  great collection : 10, good collection : 9, ni...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0                               discount :4, deal :1                 \n",
       "1  amazing Aadi discount :1, good discount :1, ge...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :5, competitive :4, transparent :4,...   \n",
       "1  reasonable rates :2, competitive prices :2, tr...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :10, good quality :3, high quality :3,...   \n",
       "1  quality is fantastic :1, high-quality products...   \n",
       "\n",
       "                Jewellery Exchange  \n",
       "0                    good rates :1  \n",
       "1  exchange old jewelry for new :1  "
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_vbj_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_vbj_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_vbj_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'vbj_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_vbj_fri_tx = pd.concat([positive_keywords_vbj_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_vbj_fri_tx = pd.concat([positive_keywords_vbj_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_vbj_fri_tx = positive_keywords_vbj_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_vbj_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd45d76a-57ef-4646-add9-5485bd5e1228",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "0c587d2e-624e-4eb5-8765-119c1b10ff1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:50:21.337161Z",
     "iopub.status.busy": "2025-06-11T16:50:21.336887Z",
     "iopub.status.idle": "2025-06-11T16:50:58.908008Z",
     "shell.execute_reply": "2025-06-11T16:50:58.907520Z",
     "shell.execute_reply.started": "2025-06-11T16:50:21.337135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  37.6\n",
      "Total Input Tokens -  41898\n",
      "Total Input Cost = USD  0.42\n",
      "Total Output Tokens -  647\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.44\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_chi_il=[0]\n",
    "keyword_input_token_tan_chi_il = 0\n",
    "keyword_output_token_tan_chi_il = 0\n",
    "keyword_start_time_loop_tan_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_chi_il = keyword_dataframes['tan_chi_il_final_sen_df_jul'][keyword_dataframes['tan_chi_il_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_chi_il:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_chi_il.append(keywords)\n",
    "        keyword_input_token_tan_chi_il += input_tokens_loop\n",
    "        keyword_output_token_tan_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_chi_il = time.time()\n",
    "keyword_cost_input_token_tan_chi_il = round((0.01/1000)*keyword_input_token_tan_chi_il,2)\n",
    "keyword_cost_output_token_tan_chi_il = round((0.03/1000)*keyword_output_token_tan_chi_il,2)\n",
    "keyword_total_cost_tan_chi_il = keyword_cost_input_token_tan_chi_il + keyword_cost_output_token_tan_chi_il\n",
    "keyword_total_time_loop_tan_chi_il = keyword_end_time_loop_tan_chi_il - keyword_start_time_loop_tan_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "f90b5944-fee7-4c03-9c21-0dc6e29e4437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:50:58.909030Z",
     "iopub.status.busy": "2025-06-11T16:50:58.908705Z",
     "iopub.status.idle": "2025-06-11T16:50:58.953887Z",
     "shell.execute_reply": "2025-06-11T16:50:58.953397Z",
     "shell.execute_reply.started": "2025-06-11T16:50:58.909008Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trusted :2, trust :2, trustworthy :2, confiden...</td>\n",
       "      <td>pleasant : 5, welcoming : 4, grand : 2, beauti...</td>\n",
       "      <td>helpful : 50, patient : 30, friendly : 25, att...</td>\n",
       "      <td>unique :5, trendy :3, beautiful :3, awesome :2...</td>\n",
       "      <td>collection : 45, variety : 10, options : 5, ra...</td>\n",
       "      <td>discount :5, offers :3, additional discounts :...</td>\n",
       "      <td>reasonable price :2</td>\n",
       "      <td>reasonable :4, transparent :3, affordable :2, ...</td>\n",
       "      <td>quality :3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Chicago, IL</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>trusted brand near to purchase :1, trustworthy...</td>\n",
       "      <td>great experience : 10, wonderful experience : ...</td>\n",
       "      <td>very helpful : 15, very patient : 10, very fri...</td>\n",
       "      <td>great designs :4, unique designs :3, beautiful...</td>\n",
       "      <td>wide collection : 3, unique collections : 3, g...</td>\n",
       "      <td>get the best discount :1, securing additional ...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>reasonable price :4, transparent with the pric...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Chicago, IL  Positive  keywords   \n",
       "1  Tanishq-Chicago, IL  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  trusted :2, trust :2, trustworthy :2, confiden...   \n",
       "1  trusted brand near to purchase :1, trustworthy...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant : 5, welcoming : 4, grand : 2, beauti...   \n",
       "1  great experience : 10, wonderful experience : ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, patient : 30, friendly : 25, att...   \n",
       "1  very helpful : 15, very patient : 10, very fri...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique :5, trendy :3, beautiful :3, awesome :2...   \n",
       "1  great designs :4, unique designs :3, beautiful...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, variety : 10, options : 5, ra...   \n",
       "1  wide collection : 3, unique collections : 3, g...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :5, offers :3, additional discounts :...   \n",
       "1  get the best discount :1, securing additional ...   \n",
       "\n",
       "                  Making Charge  \\\n",
       "0           reasonable price :2   \n",
       "1  No relevant positive phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :4, transparent :3, affordable :2, ...   \n",
       "1  reasonable price :4, transparent with the pric...   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0                              quality :3                     \n",
       "1  No relevant positive keywords/ phrases                     "
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_chi_il = pd.concat([positive_keywords_tan_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_chi_il = pd.concat([positive_keywords_tan_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_chi_il = positive_keywords_tan_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d894ea-d0ff-49d1-8170-322d97c6b35d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "1d94bfbd-4c35-42fb-b438-7bf6d168e55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:54:14.267871Z",
     "iopub.status.busy": "2025-06-11T16:54:14.267549Z",
     "iopub.status.idle": "2025-06-11T16:54:58.357721Z",
     "shell.execute_reply": "2025-06-11T16:54:58.357154Z",
     "shell.execute_reply.started": "2025-06-11T16:54:14.267848Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  44.1\n",
      "Total Input Tokens -  89141\n",
      "Total Input Cost = USD  0.89\n",
      "Total Output Tokens -  726\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.91\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_fri_tx=[0]\n",
    "keyword_input_token_tan_fri_tx = 0\n",
    "keyword_output_token_tan_fri_tx = 0\n",
    "keyword_start_time_loop_tan_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_fri_tx = keyword_dataframes['tan_fri_tx_final_sen_df_jul'][keyword_dataframes['tan_fri_tx_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_fri_tx:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_fri_tx.append(keywords)\n",
    "        keyword_input_token_tan_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_tan_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_fri_tx = time.time()\n",
    "keyword_cost_input_token_tan_fri_tx = round((0.01/1000)*keyword_input_token_tan_fri_tx,2)\n",
    "keyword_cost_output_token_tan_fri_tx = round((0.03/1000)*keyword_output_token_tan_fri_tx,2)\n",
    "keyword_total_cost_tan_fri_tx = keyword_cost_input_token_tan_fri_tx + keyword_cost_output_token_tan_fri_tx\n",
    "keyword_total_time_loop_tan_fri_tx = keyword_end_time_loop_tan_fri_tx - keyword_start_time_loop_tan_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "2e9255d8-5541-47e8-b946-2b3670bc2d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:54:58.359164Z",
     "iopub.status.busy": "2025-06-11T16:54:58.358851Z",
     "iopub.status.idle": "2025-06-11T16:54:58.403864Z",
     "shell.execute_reply": "2025-06-11T16:54:58.403405Z",
     "shell.execute_reply.started": "2025-06-11T16:54:58.359144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Reliable :2, Genuine :2, Transparent...</td>\n",
       "      <td>great experience : 50, good experience : 30, e...</td>\n",
       "      <td>patient : 45, helpful : 40, knowledgeable : 20...</td>\n",
       "      <td>unique :3, beautiful :3, stunning :2, exquisit...</td>\n",
       "      <td>varieties :5, options :4, variety :3, selectio...</td>\n",
       "      <td>discount :5, discounts :4, deal :2, promotions...</td>\n",
       "      <td></td>\n",
       "      <td>reasonable :3, competitive :2, affordable :2, ...</td>\n",
       "      <td>craftsmanship :5, quality :5, attention to det...</td>\n",
       "      <td>exchange :3, exchanging :2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Frisco, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Environment of trust :2, Trustworthy and relia...</td>\n",
       "      <td>wonderful experience : 20, very good experienc...</td>\n",
       "      <td>very patient and helpful : 8, extremely helpfu...</td>\n",
       "      <td>beautiful designs :3, unique jewelry :2, stunn...</td>\n",
       "      <td>wide variety :3, lots of collections :3, great...</td>\n",
       "      <td>extra discount :2, good discounts :1, great di...</td>\n",
       "      <td></td>\n",
       "      <td>within our budget :3, fit our budget :1, suite...</td>\n",
       "      <td>quality of the products exceeded my expectatio...</td>\n",
       "      <td>jewelry exchange :2, exchanging old jewelry :1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Frisco, TX  Positive  keywords   \n",
       "1  Tanishq-Frisco, TX  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Reliable :2, Genuine :2, Transparent...   \n",
       "1  Environment of trust :2, Trustworthy and relia...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience : 50, good experience : 30, e...   \n",
       "1  wonderful experience : 20, very good experienc...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 45, helpful : 40, knowledgeable : 20...   \n",
       "1  very patient and helpful : 8, extremely helpfu...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique :3, beautiful :3, stunning :2, exquisit...   \n",
       "1  beautiful designs :3, unique jewelry :2, stunn...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  varieties :5, options :4, variety :3, selectio...   \n",
       "1  wide variety :3, lots of collections :3, great...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0  discount :5, discounts :4, deal :2, promotions...                 \n",
       "1  extra discount :2, good discounts :1, great di...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable :3, competitive :2, affordable :2, ...   \n",
       "1  within our budget :3, fit our budget :1, suite...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  craftsmanship :5, quality :5, attention to det...   \n",
       "1  quality of the products exceeded my expectatio...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                         exchange :3, exchanging :2  \n",
       "1  jewelry exchange :2, exchanging old jewelry :1...  "
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_fri_tx = pd.concat([positive_keywords_tan_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_fri_tx = pd.concat([positive_keywords_tan_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_fri_tx = positive_keywords_tan_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19749091-1a0c-464f-8492-87c6dbe507c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_hou_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "e780a830-fe23-45e5-85fa-f529021b6d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:54:58.404792Z",
     "iopub.status.busy": "2025-06-11T16:54:58.404530Z",
     "iopub.status.idle": "2025-06-11T16:55:22.955449Z",
     "shell.execute_reply": "2025-06-11T16:55:22.954880Z",
     "shell.execute_reply.started": "2025-06-11T16:54:58.404773Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  24.5\n",
      "Total Input Tokens -  38989\n",
      "Total Input Cost = USD  0.39\n",
      "Total Output Tokens -  713\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.41\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_hou_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_hou_tx=[0]\n",
    "keyword_input_token_tan_hou_tx = 0\n",
    "keyword_output_token_tan_hou_tx = 0\n",
    "keyword_start_time_loop_tan_hou_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_hou_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_hou_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_hou_tx = keyword_dataframes['tan_hou_tx_final_sen_df_jul'][keyword_dataframes['tan_hou_tx_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_hou_tx:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_hou_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_hou_tx.append(keywords)\n",
    "        keyword_input_token_tan_hou_tx += input_tokens_loop\n",
    "        keyword_output_token_tan_hou_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_hou_tx = time.time()\n",
    "keyword_cost_input_token_tan_hou_tx = round((0.01/1000)*keyword_input_token_tan_hou_tx,2)\n",
    "keyword_cost_output_token_tan_hou_tx = round((0.03/1000)*keyword_output_token_tan_hou_tx,2)\n",
    "keyword_total_cost_tan_hou_tx = keyword_cost_input_token_tan_hou_tx + keyword_cost_output_token_tan_hou_tx\n",
    "keyword_total_time_loop_tan_hou_tx = keyword_end_time_loop_tan_hou_tx - keyword_start_time_loop_tan_hou_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_hou_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_hou_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_hou_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_hou_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_hou_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_hou_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_hou_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "38ba8c50-ddce-402a-bb00-7c2a7b063986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:55:22.957455Z",
     "iopub.status.busy": "2025-06-11T16:55:22.957027Z",
     "iopub.status.idle": "2025-06-11T16:55:23.003722Z",
     "shell.execute_reply": "2025-06-11T16:55:23.003216Z",
     "shell.execute_reply.started": "2025-06-11T16:55:22.957434Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Houston, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :4, Reliable :2, Honest :1, Authenticity...</td>\n",
       "      <td>great experience : 15, pleasant experience : 8...</td>\n",
       "      <td>patient : 25, helpful : 24, knowledgeable : 15...</td>\n",
       "      <td>unique designs: 5, beautiful design: 3, tradit...</td>\n",
       "      <td>collection : 45, variety : 12, selection : 6, ...</td>\n",
       "      <td>discount :2, offers :2, gold coin :2</td>\n",
       "      <td></td>\n",
       "      <td>transparent :4, reasonable :3, competitive :2,...</td>\n",
       "      <td>high quality :3, amazing quality :2, top notch...</td>\n",
       "      <td>jewelry exchange :2, Gold Exchange :2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Houston, TX</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust regarding to jewellery :3, Trustworthy p...</td>\n",
       "      <td>great store : 3, beautiful store : 2, lovely e...</td>\n",
       "      <td>very patient : 10, very helpful : 8, extremely...</td>\n",
       "      <td>diverse range of designs: 3, wide range of des...</td>\n",
       "      <td>wide variety : 3, wide range : 3, huge variety...</td>\n",
       "      <td>explained the offers and discounts clearly :2,...</td>\n",
       "      <td></td>\n",
       "      <td>transparent with pricing :3, reasonable prices...</td>\n",
       "      <td>commitment to quality :2, quality of the gold ...</td>\n",
       "      <td>trade in jewelry :1, worked a lot with the ‘je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Houston, TX  Positive  keywords   \n",
       "1  Tanishq-Houston, TX  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :4, Reliable :2, Honest :1, Authenticity...   \n",
       "1  Trust regarding to jewellery :3, Trustworthy p...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience : 15, pleasant experience : 8...   \n",
       "1  great store : 3, beautiful store : 2, lovely e...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 25, helpful : 24, knowledgeable : 15...   \n",
       "1  very patient : 10, very helpful : 8, extremely...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique designs: 5, beautiful design: 3, tradit...   \n",
       "1  diverse range of designs: 3, wide range of des...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, variety : 12, selection : 6, ...   \n",
       "1  wide variety : 3, wide range : 3, huge variety...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0               discount :2, offers :2, gold coin :2                 \n",
       "1  explained the offers and discounts clearly :2,...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  transparent :4, reasonable :3, competitive :2,...   \n",
       "1  transparent with pricing :3, reasonable prices...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  high quality :3, amazing quality :2, top notch...   \n",
       "1  commitment to quality :2, quality of the gold ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0              jewelry exchange :2, Gold Exchange :2  \n",
       "1  trade in jewelry :1, worked a lot with the ‘je...  "
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_hou_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_hou_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_hou_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_hou_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_hou_tx = pd.concat([positive_keywords_tan_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_hou_tx = pd.concat([positive_keywords_tan_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_hou_tx = positive_keywords_tan_hou_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_hou_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3dcb8-983f-4759-92f6-11f24cee1de0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_new_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "65b0b3cc-deb4-4bb6-b116-30491e8fc19f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:55:23.004890Z",
     "iopub.status.busy": "2025-06-11T16:55:23.004477Z",
     "iopub.status.idle": "2025-06-11T16:55:51.061993Z",
     "shell.execute_reply": "2025-06-11T16:55:51.061473Z",
     "shell.execute_reply.started": "2025-06-11T16:55:23.004870Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  28.1\n",
      "Total Input Tokens -  50312\n",
      "Total Input Cost = USD  0.5\n",
      "Total Output Tokens -  767\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.52\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_new_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_new_nj=[0]\n",
    "keyword_input_token_tan_new_nj = 0\n",
    "keyword_output_token_tan_new_nj = 0\n",
    "keyword_start_time_loop_tan_new_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_new_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_new_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_new_nj = keyword_dataframes['tan_new_nj_final_sen_df_jul'][keyword_dataframes['tan_new_nj_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_new_nj:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_new_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_new_nj.append(keywords)\n",
    "        keyword_input_token_tan_new_nj += input_tokens_loop\n",
    "        keyword_output_token_tan_new_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_new_nj = time.time()\n",
    "keyword_cost_input_token_tan_new_nj = round((0.01/1000)*keyword_input_token_tan_new_nj,2)\n",
    "keyword_cost_output_token_tan_new_nj = round((0.03/1000)*keyword_output_token_tan_new_nj,2)\n",
    "keyword_total_cost_tan_new_nj = keyword_cost_input_token_tan_new_nj + keyword_cost_output_token_tan_new_nj\n",
    "keyword_total_time_loop_tan_new_nj = keyword_end_time_loop_tan_new_nj - keyword_start_time_loop_tan_new_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_new_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_new_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_new_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_new_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_new_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_new_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_new_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "24cfb976-d72e-49e8-9db9-9813a9254d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:55:51.063313Z",
     "iopub.status.busy": "2025-06-11T16:55:51.062797Z",
     "iopub.status.idle": "2025-06-11T16:55:51.107839Z",
     "shell.execute_reply": "2025-06-11T16:55:51.107385Z",
     "shell.execute_reply.started": "2025-06-11T16:55:51.063292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-New Jersey, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Transparency :2, Trusted :2, Authent...</td>\n",
       "      <td>pleasant :5, wonderful :5, great :4, exception...</td>\n",
       "      <td>helpful : 50, patient : 30, polite : 10, frien...</td>\n",
       "      <td>exclusive designs: 8, beautiful design: 4, ama...</td>\n",
       "      <td>collection : 20, variety : 5, selection : 4, o...</td>\n",
       "      <td>discount :5, discount benefits :1, discount of...</td>\n",
       "      <td></td>\n",
       "      <td>budget :6, transparent pricing :2, best prices...</td>\n",
       "      <td>quality :4, top quality :2, high-quality :2, g...</td>\n",
       "      <td>transparent :2, seamless :2, helpful :2, excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-New Jersey, NJ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Brand you can trust :1, Trusted source for my ...</td>\n",
       "      <td>great experience :10, wonderful experience :8,...</td>\n",
       "      <td>very helpful : 15, extremely helpful : 10, ver...</td>\n",
       "      <td>exclusive jewelry designs: 2, beautiful piece ...</td>\n",
       "      <td>great collection : 8, wide range : 3, good col...</td>\n",
       "      <td>great discount :2, best discount :1, 5% discou...</td>\n",
       "      <td></td>\n",
       "      <td>fit my budget :2, within our budget :2, transp...</td>\n",
       "      <td>quality and transparency is 100% guaranteed :1...</td>\n",
       "      <td>gold jewelry exchange was handled seamlessly :...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Store Name Sentiment      Type  \\\n",
       "0  Tanishq-New Jersey, NJ  Positive  keywords   \n",
       "1  Tanishq-New Jersey, NJ  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Transparency :2, Trusted :2, Authent...   \n",
       "1  Brand you can trust :1, Trusted source for my ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant :5, wonderful :5, great :4, exception...   \n",
       "1  great experience :10, wonderful experience :8,...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, patient : 30, polite : 10, frien...   \n",
       "1  very helpful : 15, extremely helpful : 10, ver...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  exclusive designs: 8, beautiful design: 4, ama...   \n",
       "1  exclusive jewelry designs: 2, beautiful piece ...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 20, variety : 5, selection : 4, o...   \n",
       "1  great collection : 8, wide range : 3, good col...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0  discount :5, discount benefits :1, discount of...                 \n",
       "1  great discount :2, best discount :1, 5% discou...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  budget :6, transparent pricing :2, best prices...   \n",
       "1  fit my budget :2, within our budget :2, transp...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :4, top quality :2, high-quality :2, g...   \n",
       "1  quality and transparency is 100% guaranteed :1...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  transparent :2, seamless :2, helpful :2, excha...  \n",
       "1  gold jewelry exchange was handled seamlessly :...  "
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_new_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_new_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_new_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_new_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_new_nj = pd.concat([positive_keywords_tan_new_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_new_nj = pd.concat([positive_keywords_tan_new_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_new_nj = positive_keywords_tan_new_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_new_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc843fb7-9903-4f7e-89f8-3c36e1539e66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_bar_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "582b43c0-dae4-4533-92b3-7cdc4e875fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:55:51.108748Z",
     "iopub.status.busy": "2025-06-11T16:55:51.108505Z",
     "iopub.status.idle": "2025-06-11T16:56:28.180625Z",
     "shell.execute_reply": "2025-06-11T16:56:28.180051Z",
     "shell.execute_reply.started": "2025-06-11T16:55:51.108730Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  37.1\n",
      "Total Input Tokens -  104729\n",
      "Total Input Cost = USD  1.05\n",
      "Total Output Tokens -  805\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_bar_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_bar_db=[0]\n",
    "keyword_input_token_tan_bar_db = 0\n",
    "keyword_output_token_tan_bar_db = 0\n",
    "keyword_start_time_loop_tan_bar_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_bar_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_bar_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_bar_db = keyword_dataframes['tan_bar_db_final_sen_df_jul'][keyword_dataframes['tan_bar_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_bar_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_bar_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_bar_db.append(keywords)\n",
    "        keyword_input_token_tan_bar_db += input_tokens_loop\n",
    "        keyword_output_token_tan_bar_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_bar_db = time.time()\n",
    "keyword_cost_input_token_tan_bar_db = round((0.01/1000)*keyword_input_token_tan_bar_db,2)\n",
    "keyword_cost_output_token_tan_bar_db = round((0.03/1000)*keyword_output_token_tan_bar_db,2)\n",
    "keyword_total_cost_tan_bar_db = keyword_cost_input_token_tan_bar_db + keyword_cost_output_token_tan_bar_db\n",
    "keyword_total_time_loop_tan_bar_db = keyword_end_time_loop_tan_bar_db - keyword_start_time_loop_tan_bar_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_bar_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_bar_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_bar_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_bar_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_bar_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_bar_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_bar_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "5a4220c8-8149-4177-9d21-bc234e7204e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:56:28.181658Z",
     "iopub.status.busy": "2025-06-11T16:56:28.181392Z",
     "iopub.status.idle": "2025-06-11T16:56:28.228669Z",
     "shell.execute_reply": "2025-06-11T16:56:28.228137Z",
     "shell.execute_reply.started": "2025-06-11T16:56:28.181639Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Al Barsha, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :5, Reliable :4, Trusted :3, Authentic :...</td>\n",
       "      <td>Great : 20, Excellent : 15, Amazing : 12, Wond...</td>\n",
       "      <td>helpful : 78, patient : 45, knowledgeable : 43...</td>\n",
       "      <td>unique designs: 15, good designs: 10, beautifu...</td>\n",
       "      <td>collection : 78, collections : 60, variety : 1...</td>\n",
       "      <td>discount :10, offers :8, deal :5, schemes :2, ...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>best prices: 3, good price: 3, competitive rat...</td>\n",
       "      <td>quality :8, purest :2, purity :2, craftsmanshi...</td>\n",
       "      <td>exchange offer :2, exchange process :2, exchan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Al Barsha, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy place :2, Trusted shop to buy :2, ...</td>\n",
       "      <td>Great experience : 30, Wonderful experience : ...</td>\n",
       "      <td>very helpful : 30, excellent service : 28, gre...</td>\n",
       "      <td>latest and unique designs: 1, perfect design: ...</td>\n",
       "      <td>good collection : 10, nice collection : 9, ama...</td>\n",
       "      <td>amazing discount :2, best offers :2, great dis...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>amazing price: 2, within our budget: 2, right ...</td>\n",
       "      <td>excellent quality :2, high-quality jewelry :2,...</td>\n",
       "      <td>exchange offer :2, exchange process very smoot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Al Barsha, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-Al Barsha, DB  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :5, Reliable :4, Trusted :3, Authentic :...   \n",
       "1  Trustworthy place :2, Trusted shop to buy :2, ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great : 20, Excellent : 15, Amazing : 12, Wond...   \n",
       "1  Great experience : 30, Wonderful experience : ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 78, patient : 45, knowledgeable : 43...   \n",
       "1  very helpful : 30, excellent service : 28, gre...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique designs: 15, good designs: 10, beautifu...   \n",
       "1  latest and unique designs: 1, perfect design: ...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 78, collections : 60, variety : 1...   \n",
       "1  good collection : 10, nice collection : 9, ama...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :10, offers :8, deal :5, schemes :2, ...   \n",
       "1  amazing discount :2, best offers :2, great dis...   \n",
       "\n",
       "                            Making Charge  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best prices: 3, good price: 3, competitive rat...   \n",
       "1  amazing price: 2, within our budget: 2, right ...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, purest :2, purity :2, craftsmanshi...   \n",
       "1  excellent quality :2, high-quality jewelry :2,...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange offer :2, exchange process :2, exchan...  \n",
       "1  exchange offer :2, exchange process very smoot...  "
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_bar_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_bar_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_bar_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_bar_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_bar_db = pd.concat([positive_keywords_tan_bar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_bar_db = pd.concat([positive_keywords_tan_bar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_bar_db = positive_keywords_tan_bar_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_bar_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a3cb4-b7eb-488d-9901-975e699ddaf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_fah_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "871931c7-ef2a-45ad-8fbb-073c9491718c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:56:28.229868Z",
     "iopub.status.busy": "2025-06-11T16:56:28.229371Z",
     "iopub.status.idle": "2025-06-11T16:57:09.810843Z",
     "shell.execute_reply": "2025-06-11T16:57:09.810302Z",
     "shell.execute_reply.started": "2025-06-11T16:56:28.229848Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  41.6\n",
      "Total Input Tokens -  120588\n",
      "Total Input Cost = USD  1.21\n",
      "Total Output Tokens -  789\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  1.23\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_fah_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_fah_db=[0]\n",
    "keyword_input_token_tan_fah_db = 0\n",
    "keyword_output_token_tan_fah_db = 0\n",
    "keyword_start_time_loop_tan_fah_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_fah_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_fah_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_fah_db = keyword_dataframes['tan_fah_db_final_sen_df_jul'][keyword_dataframes['tan_fah_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_fah_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_fah_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_fah_db.append(keywords)\n",
    "        keyword_input_token_tan_fah_db += input_tokens_loop\n",
    "        keyword_output_token_tan_fah_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_fah_db = time.time()\n",
    "keyword_cost_input_token_tan_fah_db = round((0.01/1000)*keyword_input_token_tan_fah_db,2)\n",
    "keyword_cost_output_token_tan_fah_db = round((0.03/1000)*keyword_output_token_tan_fah_db,2)\n",
    "keyword_total_cost_tan_fah_db = keyword_cost_input_token_tan_fah_db + keyword_cost_output_token_tan_fah_db\n",
    "keyword_total_time_loop_tan_fah_db = keyword_end_time_loop_tan_fah_db - keyword_start_time_loop_tan_fah_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_fah_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_fah_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_fah_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_fah_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_fah_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_fah_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_fah_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "595de275-d935-4664-b6ff-389f8d640ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:57:09.812670Z",
     "iopub.status.busy": "2025-06-11T16:57:09.812428Z",
     "iopub.status.idle": "2025-06-11T16:57:09.859855Z",
     "shell.execute_reply": "2025-06-11T16:57:09.859403Z",
     "shell.execute_reply.started": "2025-06-11T16:57:09.812652Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Al Fahidi, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :5, Reliable :3, Trusted :3, Trustable :...</td>\n",
       "      <td>good experience : 20, nice experience : 15, gr...</td>\n",
       "      <td>helpful : 50, friendly : 40, patient : 30, pol...</td>\n",
       "      <td>design : 98, designs : 95, unique : 10, elegan...</td>\n",
       "      <td>variety :3, wide range :3, different ornaments...</td>\n",
       "      <td>discount : 8, deal : 7, offers : 5, discounts ...</td>\n",
       "      <td>less :3, good :2</td>\n",
       "      <td>best price :4, competitive prices :2, reasonab...</td>\n",
       "      <td>quality :10, product :8, good :5, exceptional ...</td>\n",
       "      <td>exchange policy :3, exchange offer :2, exchang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Al Fahidi, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted must visit :2, Most trustable brand :2...</td>\n",
       "      <td>awesome experience : 3, amazing experience : 3...</td>\n",
       "      <td>very helpful and patient : 10, extremely helpf...</td>\n",
       "      <td>nice design : 20, beautiful designs : 10, amaz...</td>\n",
       "      <td>wide range of collections :2, wide variety of ...</td>\n",
       "      <td>great discounts : 3, best deal : 3, additional...</td>\n",
       "      <td>good making charges :2, less making charges :2</td>\n",
       "      <td>transparent and competitive pricing :2, within...</td>\n",
       "      <td>quality product :3, good product :3, product q...</td>\n",
       "      <td>flexible exchange policies :1, hassle-free exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Al Fahidi, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-Al Fahidi, DB  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :5, Reliable :3, Trusted :3, Trustable :...   \n",
       "1  Trusted must visit :2, Most trustable brand :2...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience : 20, nice experience : 15, gr...   \n",
       "1  awesome experience : 3, amazing experience : 3...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, friendly : 40, patient : 30, pol...   \n",
       "1  very helpful and patient : 10, extremely helpf...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  design : 98, designs : 95, unique : 10, elegan...   \n",
       "1  nice design : 20, beautiful designs : 10, amaz...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :3, wide range :3, different ornaments...   \n",
       "1  wide range of collections :2, wide variety of ...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount : 8, deal : 7, offers : 5, discounts ...   \n",
       "1  great discounts : 3, best deal : 3, additional...   \n",
       "\n",
       "                                    Making Charge  \\\n",
       "0                                less :3, good :2   \n",
       "1  good making charges :2, less making charges :2   \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :4, competitive prices :2, reasonab...   \n",
       "1  transparent and competitive pricing :2, within...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :10, product :8, good :5, exceptional ...   \n",
       "1  quality product :3, good product :3, product q...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange policy :3, exchange offer :2, exchang...  \n",
       "1  flexible exchange policies :1, hassle-free exp...  "
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_fah_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_fah_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_fah_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_fah_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_fah_db = pd.concat([positive_keywords_tan_fah_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_fah_db = pd.concat([positive_keywords_tan_fah_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_fah_db = positive_keywords_tan_fah_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_fah_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d4e67-990b-4458-9207-a8916920c1d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_kar_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "0744ab9b-632b-4a45-83af-c37a445c150b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:57:09.861112Z",
     "iopub.status.busy": "2025-06-11T16:57:09.860640Z",
     "iopub.status.idle": "2025-06-11T16:57:35.913457Z",
     "shell.execute_reply": "2025-06-11T16:57:35.912961Z",
     "shell.execute_reply.started": "2025-06-11T16:57:09.861084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  26.0\n",
      "Total Input Tokens -  68297\n",
      "Total Input Cost = USD  0.68\n",
      "Total Output Tokens -  734\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_kar_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_kar_db=[0]\n",
    "keyword_input_token_tan_kar_db = 0\n",
    "keyword_output_token_tan_kar_db = 0\n",
    "keyword_start_time_loop_tan_kar_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_kar_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_kar_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_kar_db = keyword_dataframes['tan_kar_db_final_sen_df_jul'][keyword_dataframes['tan_kar_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_kar_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_kar_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_kar_db.append(keywords)\n",
    "        keyword_input_token_tan_kar_db += input_tokens_loop\n",
    "        keyword_output_token_tan_kar_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_kar_db = time.time()\n",
    "keyword_cost_input_token_tan_kar_db = round((0.01/1000)*keyword_input_token_tan_kar_db,2)\n",
    "keyword_cost_output_token_tan_kar_db = round((0.03/1000)*keyword_output_token_tan_kar_db,2)\n",
    "keyword_total_cost_tan_kar_db = keyword_cost_input_token_tan_kar_db + keyword_cost_output_token_tan_kar_db\n",
    "keyword_total_time_loop_tan_kar_db = keyword_end_time_loop_tan_kar_db - keyword_start_time_loop_tan_kar_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_kar_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_kar_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_kar_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_kar_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_kar_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_kar_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_kar_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "9dbaafc2-3491-48d5-8961-5015dc9d27c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:57:35.914242Z",
     "iopub.status.busy": "2025-06-11T16:57:35.914050Z",
     "iopub.status.idle": "2025-06-11T16:57:35.959888Z",
     "shell.execute_reply": "2025-06-11T16:57:35.959448Z",
     "shell.execute_reply.started": "2025-06-11T16:57:35.914225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Al Karama, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Trusted :3, Transparency :2, Genuine...</td>\n",
       "      <td>pleasant : 10, friendly : 9, helpful : 8, welc...</td>\n",
       "      <td>helpful : 50, friendly : 45, patient : 40, pro...</td>\n",
       "      <td>designs : 45, unique : 10, beautiful : 9, eleg...</td>\n",
       "      <td>collection : 95, collections : 60, variety : 5...</td>\n",
       "      <td>discount :6, offers :5, deal :3, discounted :2...</td>\n",
       "      <td></td>\n",
       "      <td>Fair :5, Reasonable :3, Genuine :2, Value :2, ...</td>\n",
       "      <td>quality :10, excellent :5, good quality :3, be...</td>\n",
       "      <td>exchange :6, exchanged :3, buying :2, old gold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Al Karama, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trustworthy service :2, Trusted name of Tanish...</td>\n",
       "      <td>great experience : 15, amazing experience : 12...</td>\n",
       "      <td>excellent customer service : 25, great service...</td>\n",
       "      <td>amazing designs : 4, good designs : 4, beautif...</td>\n",
       "      <td>wide range : 3, wide variety : 2, amazing coll...</td>\n",
       "      <td>special discount :3, good discount :2, best of...</td>\n",
       "      <td></td>\n",
       "      <td>fair prices :3, reasonable price :3, value for...</td>\n",
       "      <td>quality of the products is excellent :1, quali...</td>\n",
       "      <td>buying and exchanging :1, best place to buy an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Al Karama, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-Al Karama, DB  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Trusted :3, Transparency :2, Genuine...   \n",
       "1  Trustworthy service :2, Trusted name of Tanish...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant : 10, friendly : 9, helpful : 8, welc...   \n",
       "1  great experience : 15, amazing experience : 12...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, friendly : 45, patient : 40, pro...   \n",
       "1  excellent customer service : 25, great service...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs : 45, unique : 10, beautiful : 9, eleg...   \n",
       "1  amazing designs : 4, good designs : 4, beautif...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 95, collections : 60, variety : 5...   \n",
       "1  wide range : 3, wide variety : 2, amazing coll...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0  discount :6, offers :5, deal :3, discounted :2...                 \n",
       "1  special discount :3, good discount :2, best of...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  Fair :5, Reasonable :3, Genuine :2, Value :2, ...   \n",
       "1  fair prices :3, reasonable price :3, value for...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :10, excellent :5, good quality :3, be...   \n",
       "1  quality of the products is excellent :1, quali...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :6, exchanged :3, buying :2, old gold...  \n",
       "1  buying and exchanging :1, best place to buy an...  "
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_kar_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_kar_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_kar_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_kar_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_kar_db = pd.concat([positive_keywords_tan_kar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_kar_db = pd.concat([positive_keywords_tan_kar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_kar_db = positive_keywords_tan_kar_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_kar_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4510d54-0f20-49c6-9ca6-21e2c1c45896",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_ham_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "5008e87e-8e35-42cf-a71b-22e4bf3136dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:57:35.961153Z",
     "iopub.status.busy": "2025-06-11T16:57:35.960651Z",
     "iopub.status.idle": "2025-06-11T16:58:09.527710Z",
     "shell.execute_reply": "2025-06-11T16:58:09.527173Z",
     "shell.execute_reply.started": "2025-06-11T16:57:35.961125Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  33.6\n",
      "Total Input Tokens -  46403\n",
      "Total Input Cost = USD  0.46\n",
      "Total Output Tokens -  757\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.48\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_ham_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_ham_ad=[0]\n",
    "keyword_input_token_tan_ham_ad = 0\n",
    "keyword_output_token_tan_ham_ad = 0\n",
    "keyword_start_time_loop_tan_ham_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_ham_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_ham_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_ham_ad = keyword_dataframes['tan_ham_ad_final_sen_df_jul'][keyword_dataframes['tan_ham_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_ham_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_ham_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_ham_ad.append(keywords)\n",
    "        keyword_input_token_tan_ham_ad += input_tokens_loop\n",
    "        keyword_output_token_tan_ham_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_ham_ad = time.time()\n",
    "keyword_cost_input_token_tan_ham_ad = round((0.01/1000)*keyword_input_token_tan_ham_ad,2)\n",
    "keyword_cost_output_token_tan_ham_ad = round((0.03/1000)*keyword_output_token_tan_ham_ad,2)\n",
    "keyword_total_cost_tan_ham_ad = keyword_cost_input_token_tan_ham_ad + keyword_cost_output_token_tan_ham_ad\n",
    "keyword_total_time_loop_tan_ham_ad = keyword_end_time_loop_tan_ham_ad - keyword_start_time_loop_tan_ham_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_ham_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_ham_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_ham_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_ham_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_ham_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_ham_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_ham_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "78395aeb-7a56-4613-a0ed-c695669f945d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:58:09.528786Z",
     "iopub.status.busy": "2025-06-11T16:58:09.528517Z",
     "iopub.status.idle": "2025-06-11T16:58:09.576976Z",
     "shell.execute_reply": "2025-06-11T16:58:09.576485Z",
     "shell.execute_reply.started": "2025-06-11T16:58:09.528766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Hamdan Bin Mohammed Street, AD</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :5, Reliable :3, Genuine :2, Authentic :...</td>\n",
       "      <td>pleasant : 5, welcoming : 4, comfortable : 4, ...</td>\n",
       "      <td>helpful : 35, knowledgeable : 20, friendly : 1...</td>\n",
       "      <td>unique :8, beautiful :7, good :6, excellent :4...</td>\n",
       "      <td>collection : 50, variety : 5, selection : 4, o...</td>\n",
       "      <td>discount :5, offers :4, deal :3, price :1, off...</td>\n",
       "      <td>reasonable :2, affordable :1, economic :1, les...</td>\n",
       "      <td>discount :2, price :2, offers :1, charges :1, ...</td>\n",
       "      <td>quality :8, high quality :5, good quality :3, ...</td>\n",
       "      <td>exchange deductions :2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Hamdan Bin Mohammed Street, AD</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust of TaTa :4, You can trust the Tata brand...</td>\n",
       "      <td>pleasant experience : 4, welcoming atmosphere ...</td>\n",
       "      <td>very helpful and pleasant : 2, very helpful an...</td>\n",
       "      <td>very good designs :3, unique designs :3, beaut...</td>\n",
       "      <td>great collection : 6, nice collection : 6, goo...</td>\n",
       "      <td>best discount :1, good offers :1, lot of disco...</td>\n",
       "      <td>reasonable making charge :2, affordable making...</td>\n",
       "      <td>good prices :1, price offers :1, value for mon...</td>\n",
       "      <td>quality of their products :2, quality of the j...</td>\n",
       "      <td>0% exchange deductions :2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Hamdan Bin Mohammed Street, AD  Positive  keywords   \n",
       "1  Tanishq Jewellers-Hamdan Bin Mohammed Street, AD  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :5, Reliable :3, Genuine :2, Authentic :...   \n",
       "1  Trust of TaTa :4, You can trust the Tata brand...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pleasant : 5, welcoming : 4, comfortable : 4, ...   \n",
       "1  pleasant experience : 4, welcoming atmosphere ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 35, knowledgeable : 20, friendly : 1...   \n",
       "1  very helpful and pleasant : 2, very helpful an...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique :8, beautiful :7, good :6, excellent :4...   \n",
       "1  very good designs :3, unique designs :3, beaut...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 50, variety : 5, selection : 4, o...   \n",
       "1  great collection : 6, nice collection : 6, goo...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :5, offers :4, deal :3, price :1, off...   \n",
       "1  best discount :1, good offers :1, lot of disco...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  reasonable :2, affordable :1, economic :1, les...   \n",
       "1  reasonable making charge :2, affordable making...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  discount :2, price :2, offers :1, charges :1, ...   \n",
       "1  good prices :1, price offers :1, value for mon...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :8, high quality :5, good quality :3, ...   \n",
       "1  quality of their products :2, quality of the j...   \n",
       "\n",
       "          Jewellery Exchange  \n",
       "0     exchange deductions :2  \n",
       "1  0% exchange deductions :2  "
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_ham_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_ham_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_ham_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_ham_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_ham_ad = pd.concat([positive_keywords_tan_ham_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_ham_ad = pd.concat([positive_keywords_tan_ham_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_ham_ad = positive_keywords_tan_ham_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_ham_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dba906-ade0-452b-9e76-77329d439de8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_mee_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "ad27ae48-e5d9-414f-a08b-b2cba3e2e98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:58:09.578180Z",
     "iopub.status.busy": "2025-06-11T16:58:09.577716Z",
     "iopub.status.idle": "2025-06-11T16:58:40.139612Z",
     "shell.execute_reply": "2025-06-11T16:58:40.139107Z",
     "shell.execute_reply.started": "2025-06-11T16:58:09.578161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  30.6\n",
      "Total Input Tokens -  75503\n",
      "Total Input Cost = USD  0.76\n",
      "Total Output Tokens -  705\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.78\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_mee_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_mee_db=[0]\n",
    "keyword_input_token_tan_mee_db = 0\n",
    "keyword_output_token_tan_mee_db = 0\n",
    "keyword_start_time_loop_tan_mee_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_mee_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_mee_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_mee_db = keyword_dataframes['tan_mee_db_final_sen_df_jul'][keyword_dataframes['tan_mee_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_mee_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_mee_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_mee_db.append(keywords)\n",
    "        keyword_input_token_tan_mee_db += input_tokens_loop\n",
    "        keyword_output_token_tan_mee_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_mee_db = time.time()\n",
    "keyword_cost_input_token_tan_mee_db = round((0.01/1000)*keyword_input_token_tan_mee_db,2)\n",
    "keyword_cost_output_token_tan_mee_db = round((0.03/1000)*keyword_output_token_tan_mee_db,2)\n",
    "keyword_total_cost_tan_mee_db = keyword_cost_input_token_tan_mee_db + keyword_cost_output_token_tan_mee_db\n",
    "keyword_total_time_loop_tan_mee_db = keyword_end_time_loop_tan_mee_db - keyword_start_time_loop_tan_mee_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_mee_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_mee_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_mee_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_mee_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_mee_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_mee_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_mee_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "1df0fa91-893f-4f37-a405-4d2f4cdeafee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:58:40.140899Z",
     "iopub.status.busy": "2025-06-11T16:58:40.140444Z",
     "iopub.status.idle": "2025-06-11T16:58:40.189386Z",
     "shell.execute_reply": "2025-06-11T16:58:40.188817Z",
     "shell.execute_reply.started": "2025-06-11T16:58:40.140869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Meena Bazar, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trust :5, reliable :3, genuine :3, honesty :3,...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>patient : 15, helpful : 12, friendly : 10, kno...</td>\n",
       "      <td>unique designs: 3, beautiful design: 3, good d...</td>\n",
       "      <td>collection : 45, variety : 8, range : 5, optio...</td>\n",
       "      <td>offers :8, discount :2, deal :2, savings :1, m...</td>\n",
       "      <td>best making :1</td>\n",
       "      <td>Reasonable :3, Best :2, Genuine :1, Economical...</td>\n",
       "      <td>Good quality :3, High quality :3, Best quality...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Meena Bazar, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>earned our trust :2, trust of Tata :2, trust T...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>very helpful and patient : 3, very friendly an...</td>\n",
       "      <td>very unique designs: 2, beautiful collection: ...</td>\n",
       "      <td>vast collection : 2, wide range : 2, amazing c...</td>\n",
       "      <td>Dubai Shopping Festival offers :2, best making...</td>\n",
       "      <td>best making charges :1</td>\n",
       "      <td>Reasonable price :2, Best price :2, Good price...</td>\n",
       "      <td>High-quality jewellery :2, Good quality gold :...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Meena Bazar, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-Meena Bazar, DB  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  trust :5, reliable :3, genuine :3, honesty :3,...   \n",
       "1  earned our trust :2, trust of Tata :2, trust T...   \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 15, helpful : 12, friendly : 10, kno...   \n",
       "1  very helpful and patient : 3, very friendly an...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique designs: 3, beautiful design: 3, good d...   \n",
       "1  very unique designs: 2, beautiful collection: ...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, variety : 8, range : 5, optio...   \n",
       "1  vast collection : 2, wide range : 2, amazing c...   \n",
       "\n",
       "                                            Discount           Making Charge  \\\n",
       "0  offers :8, discount :2, deal :2, savings :1, m...          best making :1   \n",
       "1  Dubai Shopping Festival offers :2, best making...  best making charges :1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  Reasonable :3, Best :2, Genuine :1, Economical...   \n",
       "1  Reasonable price :2, Best price :2, Good price...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  Good quality :3, High quality :3, Best quality...   \n",
       "1  High-quality jewellery :2, Good quality gold :...   \n",
       "\n",
       "                       Jewellery Exchange  \n",
       "0  No relevant positive keywords/ phrases  \n",
       "1  No relevant positive keywords/ phrases  "
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_mee_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_mee_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_mee_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_mee_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_mee_db = pd.concat([positive_keywords_tan_mee_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_mee_db = pd.concat([positive_keywords_tan_mee_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_mee_db = positive_keywords_tan_mee_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_mee_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae48fe-aade-431b-9564-40242456dd71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_sil_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "cfc8228b-b8d4-40ef-834b-00efb061b73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:58:40.190289Z",
     "iopub.status.busy": "2025-06-11T16:58:40.190085Z",
     "iopub.status.idle": "2025-06-11T16:59:17.762418Z",
     "shell.execute_reply": "2025-06-11T16:59:17.761880Z",
     "shell.execute_reply.started": "2025-06-11T16:58:40.190272Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  37.6\n",
      "Total Input Tokens -  69271\n",
      "Total Input Cost = USD  0.69\n",
      "Total Output Tokens -  771\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.71\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_sil_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_sil_db=[0]\n",
    "keyword_input_token_tan_sil_db = 0\n",
    "keyword_output_token_tan_sil_db = 0\n",
    "keyword_start_time_loop_tan_sil_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_sil_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_sil_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_sil_db = keyword_dataframes['tan_sil_db_final_sen_df_jul'][keyword_dataframes['tan_sil_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_sil_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_sil_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_sil_db.append(keywords)\n",
    "        keyword_input_token_tan_sil_db += input_tokens_loop\n",
    "        keyword_output_token_tan_sil_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_sil_db = time.time()\n",
    "keyword_cost_input_token_tan_sil_db = round((0.01/1000)*keyword_input_token_tan_sil_db,2)\n",
    "keyword_cost_output_token_tan_sil_db = round((0.03/1000)*keyword_output_token_tan_sil_db,2)\n",
    "keyword_total_cost_tan_sil_db = keyword_cost_input_token_tan_sil_db + keyword_cost_output_token_tan_sil_db\n",
    "keyword_total_time_loop_tan_sil_db = keyword_end_time_loop_tan_sil_db - keyword_start_time_loop_tan_sil_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_sil_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_sil_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_sil_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_sil_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_sil_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_sil_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_sil_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "03536c35-2289-4029-824f-accf78dae5c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:59:17.763602Z",
     "iopub.status.busy": "2025-06-11T16:59:17.763308Z",
     "iopub.status.idle": "2025-06-11T16:59:17.811234Z",
     "shell.execute_reply": "2025-06-11T16:59:17.810796Z",
     "shell.execute_reply.started": "2025-06-11T16:59:17.763563Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Silicon Central, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :5, Trusted :4, Reliable :2, Honest :1, ...</td>\n",
       "      <td>Great Experience : 45, Good Experience : 30, W...</td>\n",
       "      <td>helpful : 78, friendly : 45, professional : 35...</td>\n",
       "      <td>designs : 50, unique : 8, elegant : 7, exquisi...</td>\n",
       "      <td>variety :5, options :4, selection :3, range :2...</td>\n",
       "      <td>discount :7, offers :5, discounted :2, offer :...</td>\n",
       "      <td>lesser making charges :1</td>\n",
       "      <td>reasonable price: 3, affordable prices: 1, val...</td>\n",
       "      <td>quality :15, high quality :4, superior quality...</td>\n",
       "      <td>exchange :5, exchanged :4, full value :1, buy :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Silicon Central, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust of TATA :2, Name to be trusted :2, Trust...</td>\n",
       "      <td>Amazing shopping experience : 5, Seamless shop...</td>\n",
       "      <td>very helpful : 20, extremely helpful : 10, ver...</td>\n",
       "      <td>excellent designs : 6, unique designs : 4, ele...</td>\n",
       "      <td>wide variety :2, variety of designs :2, variet...</td>\n",
       "      <td>good discount :3, great discount :2, genuine d...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>fit in the budget: 2, within budget: 1, at you...</td>\n",
       "      <td>Amazing quality :2, best for the quality :2, i...</td>\n",
       "      <td>exchanged at full value :1, adjusted the amoun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Silicon Central, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-Silicon Central, DB  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :5, Trusted :4, Reliable :2, Honest :1, ...   \n",
       "1  Trust of TATA :2, Name to be trusted :2, Trust...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great Experience : 45, Good Experience : 30, W...   \n",
       "1  Amazing shopping experience : 5, Seamless shop...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 78, friendly : 45, professional : 35...   \n",
       "1  very helpful : 20, extremely helpful : 10, ver...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs : 50, unique : 8, elegant : 7, exquisi...   \n",
       "1  excellent designs : 6, unique designs : 4, ele...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  variety :5, options :4, selection :3, range :2...   \n",
       "1  wide variety :2, variety of designs :2, variet...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  discount :7, offers :5, discounted :2, offer :...   \n",
       "1  good discount :3, great discount :2, genuine d...   \n",
       "\n",
       "                  Making Charge  \\\n",
       "0      lesser making charges :1   \n",
       "1  No relevant positive phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  reasonable price: 3, affordable prices: 1, val...   \n",
       "1  fit in the budget: 2, within budget: 1, at you...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :15, high quality :4, superior quality...   \n",
       "1  Amazing quality :2, best for the quality :2, i...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0   exchange :5, exchanged :4, full value :1, buy :1  \n",
       "1  exchanged at full value :1, adjusted the amoun...  "
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_sil_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_sil_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_sil_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_sil_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_sil_db = pd.concat([positive_keywords_tan_sil_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_sil_db = pd.concat([positive_keywords_tan_sil_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_sil_db = positive_keywords_tan_sil_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_sil_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629dacaf-ba7f-4ad0-8e53-14d40657af21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mia_awm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "facc370a-ed48-47c9-9d19-ed44d60a0721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:03:02.702057Z",
     "iopub.status.busy": "2025-06-11T17:03:02.701718Z",
     "iopub.status.idle": "2025-06-11T17:03:09.227748Z",
     "shell.execute_reply": "2025-06-11T17:03:09.227081Z",
     "shell.execute_reply.started": "2025-06-11T17:03:02.702037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  6.5\n",
      "Total Input Tokens -  2357\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  174\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.03\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mia_awm_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mia_awm_ad=[0]\n",
    "keyword_input_token_mia_awm_ad = 0\n",
    "keyword_output_token_mia_awm_ad = 0\n",
    "keyword_start_time_loop_mia_awm_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mia_awm_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mia_awm_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mia_awm_ad = keyword_dataframes['mia_awm_ad_final_sen_df_jul'][keyword_dataframes['mia_awm_ad_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mia_awm_ad:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mia_awm_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mia_awm_ad.append(keywords)\n",
    "        keyword_input_token_mia_awm_ad += input_tokens_loop\n",
    "        keyword_output_token_mia_awm_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mia_awm_ad = time.time()\n",
    "keyword_cost_input_token_mia_awm_ad = round((0.01/1000)*keyword_input_token_mia_awm_ad,2)\n",
    "keyword_cost_output_token_mia_awm_ad = round((0.03/1000)*keyword_output_token_mia_awm_ad,2)\n",
    "keyword_total_cost_mia_awm_ad = keyword_cost_input_token_mia_awm_ad + keyword_cost_output_token_mia_awm_ad\n",
    "keyword_total_time_loop_mia_awm_ad = keyword_end_time_loop_mia_awm_ad - keyword_start_time_loop_mia_awm_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mia_awm_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mia_awm_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mia_awm_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mia_awm_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mia_awm_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mia_awm_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mia_awm_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "bc570573-fe0c-431b-ad2b-9a0b45db3288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:03:09.229289Z",
     "iopub.status.busy": "2025-06-11T17:03:09.228988Z",
     "iopub.status.idle": "2025-06-11T17:03:09.268288Z",
     "shell.execute_reply": "2025-06-11T17:03:09.267655Z",
     "shell.execute_reply.started": "2025-06-11T17:03:09.229262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mia-Al Wahda Mall, AD</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>good experience :2</td>\n",
       "      <td>service :8, staff :2</td>\n",
       "      <td></td>\n",
       "      <td>collection :6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mia-Al Wahda Mall, AD</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>Great service by Tahseen :1, Good service by m...</td>\n",
       "      <td></td>\n",
       "      <td>good collection :2, Nice collection :2, Superb...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Mia-Al Wahda Mall, AD  Positive  keywords                       \n",
       "1  Mia-Al Wahda Mall, AD  Positive   phrases                       \n",
       "\n",
       "               Store Experience  \\\n",
       "0            good experience :2   \n",
       "1  No relevant positive phrases   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0                               service :8, staff :2                  \n",
       "1  Great service by Tahseen :1, Good service by m...                  \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0                                      collection :6                          \n",
       "1  good collection :2, Nice collection :2, Superb...                          \n",
       "\n",
       "  Price Product Quality Jewellery Exchange  \n",
       "0                                           \n",
       "1                                           "
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mia_awm_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mia_awm_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mia_awm_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mia_awm_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mia_awm_ad = pd.concat([positive_keywords_mia_awm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mia_awm_ad = pd.concat([positive_keywords_mia_awm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mia_awm_ad = positive_keywords_mia_awm_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mia_awm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3205a3f-6e5a-4a93-be97-48b7eab42cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a32f95a-cd23-48a7-bbd0-a632a4393a2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mia_bur_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "841b4ed3-74d7-4a3f-b271-ea6db6fc8ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:03:43.048311Z",
     "iopub.status.busy": "2025-06-11T17:03:43.047881Z",
     "iopub.status.idle": "2025-06-11T17:04:01.093135Z",
     "shell.execute_reply": "2025-06-11T17:04:01.092552Z",
     "shell.execute_reply.started": "2025-06-11T17:03:43.048282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  18.0\n",
      "Total Input Tokens -  20921\n",
      "Total Input Cost = USD  0.21\n",
      "Total Output Tokens -  559\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.23\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_mia_bur_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mia_bur_db=[0]\n",
    "keyword_input_token_mia_bur_db = 0\n",
    "keyword_output_token_mia_bur_db = 0\n",
    "keyword_start_time_loop_mia_bur_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mia_bur_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mia_bur_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mia_bur_db = keyword_dataframes['mia_bur_db_final_sen_df_jul'][keyword_dataframes['mia_bur_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_mia_bur_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_mia_bur_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_mia_bur_db.append(keywords)\n",
    "        keyword_input_token_mia_bur_db += input_tokens_loop\n",
    "        keyword_output_token_mia_bur_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mia_bur_db = time.time()\n",
    "keyword_cost_input_token_mia_bur_db = round((0.01/1000)*keyword_input_token_mia_bur_db,2)\n",
    "keyword_cost_output_token_mia_bur_db = round((0.03/1000)*keyword_output_token_mia_bur_db,2)\n",
    "keyword_total_cost_mia_bur_db = keyword_cost_input_token_mia_bur_db + keyword_cost_output_token_mia_bur_db\n",
    "keyword_total_time_loop_mia_bur_db = keyword_end_time_loop_mia_bur_db - keyword_start_time_loop_mia_bur_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mia_bur_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mia_bur_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mia_bur_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mia_bur_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mia_bur_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mia_bur_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mia_bur_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "411d82ae-7cbd-42d6-a339-b9b91287cef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:04:01.094407Z",
     "iopub.status.busy": "2025-06-11T17:04:01.094137Z",
     "iopub.status.idle": "2025-06-11T17:04:01.137453Z",
     "shell.execute_reply": "2025-06-11T17:04:01.136933Z",
     "shell.execute_reply.started": "2025-06-11T17:04:01.094387Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mia-Burjuman, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Transparency :1</td>\n",
       "      <td>good experience :10, wonderful experience :8, ...</td>\n",
       "      <td>helpful : 45, friendly : 20, patient : 18, pol...</td>\n",
       "      <td>designs :5, unique :3, modern :2, elegant :1, ...</td>\n",
       "      <td>collection : 45, collections : 20, variety : 3...</td>\n",
       "      <td>discount :4, offers :2, voucher :1</td>\n",
       "      <td></td>\n",
       "      <td>good price:3, reasonable cost:1, genuine prici...</td>\n",
       "      <td>good quality:1, quality:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mia-Burjuman, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>very good experience :3, had a great experienc...</td>\n",
       "      <td>very helpful : 10, excellent service : 8, grea...</td>\n",
       "      <td>modern designs :2, unique designs :2, delicate...</td>\n",
       "      <td>nice collection : 8, good collection : 7, grea...</td>\n",
       "      <td>gave me 10% discount :1, Anniversary discount ...</td>\n",
       "      <td></td>\n",
       "      <td>Worth the money:2, Worth spending money:1, gre...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store Name Sentiment      Type           Customer Confidence  \\\n",
       "0  Mia-Burjuman, DB  Positive  keywords               Transparency :1   \n",
       "1  Mia-Burjuman, DB  Positive   phrases  No relevant positive phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  good experience :10, wonderful experience :8, ...   \n",
       "1  very good experience :3, had a great experienc...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 45, friendly : 20, patient : 18, pol...   \n",
       "1  very helpful : 10, excellent service : 8, grea...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :5, unique :3, modern :2, elegant :1, ...   \n",
       "1  modern designs :2, unique designs :2, delicate...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, collections : 20, variety : 3...   \n",
       "1  nice collection : 8, good collection : 7, grea...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0                 discount :4, offers :2, voucher :1                 \n",
       "1  gave me 10% discount :1, Anniversary discount ...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  good price:3, reasonable cost:1, genuine prici...   \n",
       "1  Worth the money:2, Worth spending money:1, gre...   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0               good quality:1, quality:1                     \n",
       "1  No relevant positive keywords/ phrases                     "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_mia_bur_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_mia_bur_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_mia_bur_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mia_bur_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_mia_bur_db = pd.concat([positive_keywords_mia_bur_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_mia_bur_db = pd.concat([positive_keywords_mia_bur_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_mia_bur_db = positive_keywords_mia_bur_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_mia_bur_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893f394-3e45-42dc-b079-f1c038a43014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c606d70-1914-4d72-acdc-aa9581ccdbe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_am_om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "9d0ed06b-162d-45a1-afd3-9c835c6cf427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:04:19.403397Z",
     "iopub.status.busy": "2025-06-11T17:04:19.403071Z",
     "iopub.status.idle": "2025-06-11T17:04:31.434083Z",
     "shell.execute_reply": "2025-06-11T17:04:31.433598Z",
     "shell.execute_reply.started": "2025-06-11T17:04:19.403375Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  12.0\n",
      "Total Input Tokens -  8017\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  432\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.09\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_am_om = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_am_om=[0]\n",
    "keyword_input_token_tan_am_om = 0\n",
    "keyword_output_token_tan_am_om = 0\n",
    "keyword_start_time_loop_tan_am_om = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_am_om, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_am_om[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_am_om = keyword_dataframes['tan_am_om_final_sen_df_jul'][keyword_dataframes['tan_am_om_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_am_om:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_am_om,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_am_om.append(keywords)\n",
    "        keyword_input_token_tan_am_om += input_tokens_loop\n",
    "        keyword_output_token_tan_am_om += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_am_om = time.time()\n",
    "keyword_cost_input_token_tan_am_om = round((0.01/1000)*keyword_input_token_tan_am_om,2)\n",
    "keyword_cost_output_token_tan_am_om = round((0.03/1000)*keyword_output_token_tan_am_om,2)\n",
    "keyword_total_cost_tan_am_om = keyword_cost_input_token_tan_am_om + keyword_cost_output_token_tan_am_om\n",
    "keyword_total_time_loop_tan_am_om = keyword_end_time_loop_tan_am_om - keyword_start_time_loop_tan_am_om\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_am_om[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_am_om,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_am_om)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_am_om)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_am_om)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_am_om)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_am_om,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "c57d8bf9-59d8-4ccc-91b8-d3c29a387733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:04:31.435551Z",
     "iopub.status.busy": "2025-06-11T17:04:31.435244Z",
     "iopub.status.idle": "2025-06-11T17:04:31.476830Z",
     "shell.execute_reply": "2025-06-11T17:04:31.476285Z",
     "shell.execute_reply.started": "2025-06-11T17:04:31.435532Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Avenues Mall, OM</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>great experience :8, good ambiance :2, wonderf...</td>\n",
       "      <td>helpful :5, patient :4, friendly :3, polite :3...</td>\n",
       "      <td>designs :5, collection :2, unique :2, exquisit...</td>\n",
       "      <td>collection :10, variety :2, selection :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>reasonable :1, affordable :1</td>\n",
       "      <td>craftsmanship :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Avenues Mall, OM</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>Overall an excellent customer experience :1, O...</td>\n",
       "      <td>very helpful :3, very patient :2, very friendl...</td>\n",
       "      <td>Beautiful designs :1, Designs are fabulous :1,...</td>\n",
       "      <td>best collection :3, good collection :2, wide v...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>affordable range of prices :1</td>\n",
       "      <td>quality of craftsmanship :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Avenues Mall, OM  Positive  keywords   \n",
       "1  Tanishq Jewellers-Avenues Mall, OM  Positive   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  great experience :8, good ambiance :2, wonderf...   \n",
       "1  Overall an excellent customer experience :1, O...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :5, patient :4, friendly :3, polite :3...   \n",
       "1  very helpful :3, very patient :2, very friendl...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :5, collection :2, unique :2, exquisit...   \n",
       "1  Beautiful designs :1, Designs are fabulous :1,...   \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0           collection :10, variety :2, selection :1                          \n",
       "1  best collection :3, good collection :2, wide v...                          \n",
       "\n",
       "                           Price              Product Quality  \\\n",
       "0   reasonable :1, affordable :1             craftsmanship :1   \n",
       "1  affordable range of prices :1  quality of craftsmanship :1   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_am_om = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_am_om[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_am_om:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_am_om'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_am_om = pd.concat([positive_keywords_tan_am_om, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_am_om = pd.concat([positive_keywords_tan_am_om, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_am_om = positive_keywords_tan_am_om.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_am_om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521c561-2d1b-4ae5-8d3f-a58cb09cbf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c75f9b4f-0817-486b-adeb-a0a20149a6bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_atl_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "5ac3f68e-cb77-4fdc-b195-d4f41c2e2be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:06:01.411237Z",
     "iopub.status.busy": "2025-06-11T17:06:01.410726Z",
     "iopub.status.idle": "2025-06-11T17:06:18.950471Z",
     "shell.execute_reply": "2025-06-11T17:06:18.949981Z",
     "shell.execute_reply.started": "2025-06-11T17:06:01.411215Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.5\n",
      "Total Input Tokens -  21352\n",
      "Total Input Cost = USD  0.21\n",
      "Total Output Tokens -  580\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.23\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_atl_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_atl_ga=[0]\n",
    "keyword_input_token_tan_atl_ga = 0\n",
    "keyword_output_token_tan_atl_ga = 0\n",
    "keyword_start_time_loop_tan_atl_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_atl_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_atl_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_atl_ga = keyword_dataframes['tan_atl_ga_final_sen_df_jul'][keyword_dataframes['tan_atl_ga_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_atl_ga:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_atl_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_atl_ga.append(keywords)\n",
    "        keyword_input_token_tan_atl_ga += input_tokens_loop\n",
    "        keyword_output_token_tan_atl_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_atl_ga = time.time()\n",
    "keyword_cost_input_token_tan_atl_ga = round((0.01/1000)*keyword_input_token_tan_atl_ga,2)\n",
    "keyword_cost_output_token_tan_atl_ga = round((0.03/1000)*keyword_output_token_tan_atl_ga,2)\n",
    "keyword_total_cost_tan_atl_ga = keyword_cost_input_token_tan_atl_ga + keyword_cost_output_token_tan_atl_ga\n",
    "keyword_total_time_loop_tan_atl_ga = keyword_end_time_loop_tan_atl_ga - keyword_start_time_loop_tan_atl_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_atl_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_atl_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_atl_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_atl_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_atl_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_atl_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_atl_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "9c3848a6-df10-4001-882a-9d6eb2bb7f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:06:18.951688Z",
     "iopub.status.busy": "2025-06-11T17:06:18.951373Z",
     "iopub.status.idle": "2025-06-11T17:06:18.994063Z",
     "shell.execute_reply": "2025-06-11T17:06:18.993601Z",
     "shell.execute_reply.started": "2025-06-11T17:06:18.951667Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Atlanta, GA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :1, Reliable :1</td>\n",
       "      <td>Great :15, Nice :10, Wonderful :8, Awesome :7,...</td>\n",
       "      <td>patient : 45, helpful : 44, friendly : 20, kno...</td>\n",
       "      <td>unique designs: 3, elegant: 2, exquisite: 2, s...</td>\n",
       "      <td>collection : 45, selection : 8, variety : 4, m...</td>\n",
       "      <td>great discounts:1, good offers:1, best deals:1</td>\n",
       "      <td></td>\n",
       "      <td>Fair :2, Good :1, Easy :1</td>\n",
       "      <td>quality :5, high quality :3, excellent :1, aut...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Atlanta, GA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Return customer with 100% satisfaction :1, As ...</td>\n",
       "      <td>Great experience :10, Wonderful experience :5,...</td>\n",
       "      <td>very patient : 15, very helpful : 12, extremel...</td>\n",
       "      <td>trendy and elegant designs: 1, one of a kind a...</td>\n",
       "      <td>great collection : 8, nice collection : 7, bea...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td></td>\n",
       "      <td>Fair pricing :2, Price is really good :1, Easy...</td>\n",
       "      <td>quality is very good :1, quality gold :1, gold...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Atlanta, GA  Positive  keywords   \n",
       "1  Tanishq-Atlanta, GA  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                              Trust :1, Reliable :1   \n",
       "1  Return customer with 100% satisfaction :1, As ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great :15, Nice :10, Wonderful :8, Awesome :7,...   \n",
       "1  Great experience :10, Wonderful experience :5,...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 45, helpful : 44, friendly : 20, kno...   \n",
       "1  very patient : 15, very helpful : 12, extremel...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique designs: 3, elegant: 2, exquisite: 2, s...   \n",
       "1  trendy and elegant designs: 1, one of a kind a...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, selection : 8, variety : 4, m...   \n",
       "1  great collection : 8, nice collection : 7, bea...   \n",
       "\n",
       "                                         Discount Making Charge  \\\n",
       "0  great discounts:1, good offers:1, best deals:1                 \n",
       "1                    No relevant positive phrases                 \n",
       "\n",
       "                                               Price  \\\n",
       "0                          Fair :2, Good :1, Easy :1   \n",
       "1  Fair pricing :2, Price is really good :1, Easy...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  quality :5, high quality :3, excellent :1, aut...                     \n",
       "1  quality is very good :1, quality gold :1, gold...                     "
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_atl_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_atl_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_atl_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_atl_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_atl_ga = pd.concat([positive_keywords_tan_atl_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_atl_ga = pd.concat([positive_keywords_tan_atl_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_atl_ga = positive_keywords_tan_atl_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_atl_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3adcbc8-15d4-4362-b3b5-83abf1a340a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a94f81f-3c29-43ae-a4b4-fe1b60d04421",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_fc_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "d8e51e35-a14f-4279-b91c-29f2ee7eb448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:07:35.380825Z",
     "iopub.status.busy": "2025-06-11T17:07:35.380259Z",
     "iopub.status.idle": "2025-06-11T17:07:48.913544Z",
     "shell.execute_reply": "2025-06-11T17:07:48.913041Z",
     "shell.execute_reply.started": "2025-06-11T17:07:35.380799Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  13.5\n",
      "Total Input Tokens -  7748\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  437\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.09\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_fc_qa = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_fc_qa=[0]\n",
    "keyword_input_token_tan_fc_qa = 0\n",
    "keyword_output_token_tan_fc_qa = 0\n",
    "keyword_start_time_loop_tan_fc_qa = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_fc_qa, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_fc_qa[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_fc_qa = keyword_dataframes['tan_fc_qa_final_sen_df_jul'][keyword_dataframes['tan_fc_qa_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_fc_qa:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_fc_qa,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_fc_qa.append(keywords)\n",
    "        keyword_input_token_tan_fc_qa += input_tokens_loop\n",
    "        keyword_output_token_tan_fc_qa += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_fc_qa = time.time()\n",
    "keyword_cost_input_token_tan_fc_qa = round((0.01/1000)*keyword_input_token_tan_fc_qa,2)\n",
    "keyword_cost_output_token_tan_fc_qa = round((0.03/1000)*keyword_output_token_tan_fc_qa,2)\n",
    "keyword_total_cost_tan_fc_qa = keyword_cost_input_token_tan_fc_qa + keyword_cost_output_token_tan_fc_qa\n",
    "keyword_total_time_loop_tan_fc_qa = keyword_end_time_loop_tan_fc_qa - keyword_start_time_loop_tan_fc_qa\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_fc_qa[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_fc_qa,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_fc_qa)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_fc_qa)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_fc_qa)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_fc_qa)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_fc_qa,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "82f07844-0ef3-4d16-8740-e169cfabeeda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:07:48.914579Z",
     "iopub.status.busy": "2025-06-11T17:07:48.914374Z",
     "iopub.status.idle": "2025-06-11T17:07:48.963463Z",
     "shell.execute_reply": "2025-06-11T17:07:48.962956Z",
     "shell.execute_reply.started": "2025-06-11T17:07:48.914546Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Festival City, QA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>Helpful :2, Patient :2, Knowledgeable :2, Coop...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>collection :4</td>\n",
       "      <td>good discount :1</td>\n",
       "      <td>lowest making charges :1</td>\n",
       "      <td>great prices :1</td>\n",
       "      <td>Excellent :1, quality :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Festival City, QA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>Assisted us very well :1, Excellent service :1...</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>good range :1, nice collection :1, wonderful c...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>quality of gold :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Festival City, QA  Positive  keywords   \n",
       "1  Tanishq Jewellers-Festival City, QA  Positive   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  Helpful :2, Patient :2, Knowledgeable :2, Coop...   \n",
       "1  Assisted us very well :1, Excellent service :1...   \n",
       "\n",
       "                           Product Design  \\\n",
       "0  No relevant positive keywords/ phrases   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                                      collection :4   \n",
       "1  good range :1, nice collection :1, wonderful c...   \n",
       "\n",
       "                       Discount                 Making Charge  \\\n",
       "0              good discount :1      lowest making charges :1   \n",
       "1  No relevant positive phrases  No relevant positive phrases   \n",
       "\n",
       "                                    Price           Product Quality  \\\n",
       "0                         great prices :1  Excellent :1, quality :1   \n",
       "1  No relevant positive keywords/ phrases        quality of gold :1   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_fc_qa = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_fc_qa[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_fc_qa:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_fc_qa'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_fc_qa = pd.concat([positive_keywords_tan_fc_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_fc_qa = pd.concat([positive_keywords_tan_fc_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_fc_qa = positive_keywords_tan_fc_qa.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_fc_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5addb23-7d63-4de2-8513-b012cb471c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "734f2042-4f95-4aed-bab0-7d9c83928a8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_gs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "dd7791d6-089b-4cfa-b016-a5ea425309de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:08:01.441250Z",
     "iopub.status.busy": "2025-06-11T17:08:01.440929Z",
     "iopub.status.idle": "2025-06-11T17:08:32.999277Z",
     "shell.execute_reply": "2025-06-11T17:08:32.998773Z",
     "shell.execute_reply.started": "2025-06-11T17:08:01.441228Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  31.6\n",
      "Total Input Tokens -  72048\n",
      "Total Input Cost = USD  0.72\n",
      "Total Output Tokens -  838\n",
      "Total Output Cost = USD  0.03\n",
      "Total Cost = USD  0.75\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_gs_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_gs_db=[0]\n",
    "keyword_input_token_tan_gs_db = 0\n",
    "keyword_output_token_tan_gs_db = 0\n",
    "keyword_start_time_loop_tan_gs_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_gs_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_gs_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_gs_db = keyword_dataframes['tan_gs_db_final_sen_df_jul'][keyword_dataframes['tan_gs_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_gs_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_gs_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_gs_db.append(keywords)\n",
    "        keyword_input_token_tan_gs_db += input_tokens_loop\n",
    "        keyword_output_token_tan_gs_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_gs_db = time.time()\n",
    "keyword_cost_input_token_tan_gs_db = round((0.01/1000)*keyword_input_token_tan_gs_db,2)\n",
    "keyword_cost_output_token_tan_gs_db = round((0.03/1000)*keyword_output_token_tan_gs_db,2)\n",
    "keyword_total_cost_tan_gs_db = keyword_cost_input_token_tan_gs_db + keyword_cost_output_token_tan_gs_db\n",
    "keyword_total_time_loop_tan_gs_db = keyword_end_time_loop_tan_gs_db - keyword_start_time_loop_tan_gs_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_gs_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_gs_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_gs_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_gs_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_gs_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_gs_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_gs_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "57b5b0d0-caa4-4ec1-8b54-636b94cc37fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:08:33.000706Z",
     "iopub.status.busy": "2025-06-11T17:08:33.000402Z",
     "iopub.status.idle": "2025-06-11T17:08:33.049496Z",
     "shell.execute_reply": "2025-06-11T17:08:33.049019Z",
     "shell.execute_reply.started": "2025-06-11T17:08:33.000687Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Gold Souk, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :5, Trusted :4, Reliable :2, Authentic :...</td>\n",
       "      <td>Good experience : 20, Great experience : 15, W...</td>\n",
       "      <td>helpful : 50, polite : 20, friendly : 18, pati...</td>\n",
       "      <td>Good designs :10, Beautiful designs :8, Excell...</td>\n",
       "      <td>Good collection :10, Nice collection :8, Amazi...</td>\n",
       "      <td>deal :5, offers :4, discount :4, discounts :3,...</td>\n",
       "      <td>reasonable manufacturing :1</td>\n",
       "      <td>good prices: 2, best price: 2, honest prices: ...</td>\n",
       "      <td>good quality :5, high-quality :4, premium qual...</td>\n",
       "      <td>exchange :6, gold exchange :3, exchange progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Gold Souk, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust with your eyes closed :1, Trustworthy pl...</td>\n",
       "      <td>Good experience overall : 2, Great experience ...</td>\n",
       "      <td>very helpful : 10, extremely helpful : 8, very...</td>\n",
       "      <td>Beautifully designed jewelry :2, High-quality,...</td>\n",
       "      <td>wide variety of designs :3, wide range of coll...</td>\n",
       "      <td>great deal :2, good deal :2, amazing offers :2...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>comparable rate with Indian Markets: 1, good p...</td>\n",
       "      <td>quality of the jewelry was excellent :1, produ...</td>\n",
       "      <td>great exchange program :1, offer on Exchange o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Gold Souk, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-Gold Souk, DB  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :5, Trusted :4, Reliable :2, Authentic :...   \n",
       "1  Trust with your eyes closed :1, Trustworthy pl...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good experience : 20, Great experience : 15, W...   \n",
       "1  Good experience overall : 2, Great experience ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 50, polite : 20, friendly : 18, pati...   \n",
       "1  very helpful : 10, extremely helpful : 8, very...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs :10, Beautiful designs :8, Excell...   \n",
       "1  Beautifully designed jewelry :2, High-quality,...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  Good collection :10, Nice collection :8, Amazi...   \n",
       "1  wide variety of designs :3, wide range of coll...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  deal :5, offers :4, discount :4, discounts :3,...   \n",
       "1  great deal :2, good deal :2, amazing offers :2...   \n",
       "\n",
       "                  Making Charge  \\\n",
       "0   reasonable manufacturing :1   \n",
       "1  No relevant positive phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  good prices: 2, best price: 2, honest prices: ...   \n",
       "1  comparable rate with Indian Markets: 1, good p...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  good quality :5, high-quality :4, premium qual...   \n",
       "1  quality of the jewelry was excellent :1, produ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  exchange :6, gold exchange :3, exchange progra...  \n",
       "1  great exchange program :1, offer on Exchange o...  "
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_gs_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_gs_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_gs_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_gs_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_gs_db = pd.concat([positive_keywords_tan_gs_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_gs_db = pd.concat([positive_keywords_tan_gs_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_gs_db = positive_keywords_tan_gs_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_gs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccbd26-ba03-453c-9c69-f6800be99d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f4cbf0a-3343-45c2-9e04-45a0a6551b6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_lul_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "c3c40cba-976c-468f-8546-578c80ee4e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:08:33.050495Z",
     "iopub.status.busy": "2025-06-11T17:08:33.050164Z",
     "iopub.status.idle": "2025-06-11T17:08:52.093622Z",
     "shell.execute_reply": "2025-06-11T17:08:52.092986Z",
     "shell.execute_reply.started": "2025-06-11T17:08:33.050473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  19.0\n",
      "Total Input Tokens -  17521\n",
      "Total Input Cost = USD  0.18\n",
      "Total Output Tokens -  684\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.2\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_lul_qa = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_lul_qa=[0]\n",
    "keyword_input_token_tan_lul_qa = 0\n",
    "keyword_output_token_tan_lul_qa = 0\n",
    "keyword_start_time_loop_tan_lul_qa = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_lul_qa, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_lul_qa[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_lul_qa = keyword_dataframes['tan_lul_qa_final_sen_df_jul'][keyword_dataframes['tan_lul_qa_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_lul_qa:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_lul_qa,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_lul_qa.append(keywords)\n",
    "        keyword_input_token_tan_lul_qa += input_tokens_loop\n",
    "        keyword_output_token_tan_lul_qa += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_lul_qa = time.time()\n",
    "keyword_cost_input_token_tan_lul_qa = round((0.01/1000)*keyword_input_token_tan_lul_qa,2)\n",
    "keyword_cost_output_token_tan_lul_qa = round((0.03/1000)*keyword_output_token_tan_lul_qa,2)\n",
    "keyword_total_cost_tan_lul_qa = keyword_cost_input_token_tan_lul_qa + keyword_cost_output_token_tan_lul_qa\n",
    "keyword_total_time_loop_tan_lul_qa = keyword_end_time_loop_tan_lul_qa - keyword_start_time_loop_tan_lul_qa\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_lul_qa[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_lul_qa,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_lul_qa)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_lul_qa)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_lul_qa)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_lul_qa)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_lul_qa,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "61a810a8-f8ad-46da-87ae-b0e4d3846d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:08:52.094853Z",
     "iopub.status.busy": "2025-06-11T17:08:52.094439Z",
     "iopub.status.idle": "2025-06-11T17:08:52.140531Z",
     "shell.execute_reply": "2025-06-11T17:08:52.140031Z",
     "shell.execute_reply.started": "2025-06-11T17:08:52.094825Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Lulu Hypermarket, QA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :2, Transparency :2, Trusted :1, Reliabl...</td>\n",
       "      <td>Nice experience :5, Good experience :4, Great ...</td>\n",
       "      <td>helpful :8, friendly :7, patient :6, polite :3...</td>\n",
       "      <td>Good designs:3, Elegant designs:2, New Design:...</td>\n",
       "      <td>varieties :2, variety :1, range :1, assortment :1</td>\n",
       "      <td>special discount:2, offers:2</td>\n",
       "      <td></td>\n",
       "      <td>transparent :2, offers :2</td>\n",
       "      <td>top-notch :1, high-quality :1, superior :1, ex...</td>\n",
       "      <td>exchange :3, rate :1, resale :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Lulu Hypermarket, QA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Legacy of trust and reliability :1, Transparen...</td>\n",
       "      <td>Shopping experience :3, Very good experience :...</td>\n",
       "      <td>very friendly and patient :2, very helpful and...</td>\n",
       "      <td>Designs are good:1, Accurate matching design:1...</td>\n",
       "      <td>wide varieties of design :1, wide variety :1, ...</td>\n",
       "      <td>special discount for QatarEnergy umbrella:1, n...</td>\n",
       "      <td></td>\n",
       "      <td>transparent about pricing :1, transparency in ...</td>\n",
       "      <td>superior quality and finish :1, high-quality j...</td>\n",
       "      <td>exchange process went smooth :1, provided very...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Lulu Hypermarket, QA  Positive  keywords   \n",
       "1  Tanishq Jewellers-Lulu Hypermarket, QA  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :2, Transparency :2, Trusted :1, Reliabl...   \n",
       "1  Legacy of trust and reliability :1, Transparen...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Nice experience :5, Good experience :4, Great ...   \n",
       "1  Shopping experience :3, Very good experience :...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :8, friendly :7, patient :6, polite :3...   \n",
       "1  very friendly and patient :2, very helpful and...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  Good designs:3, Elegant designs:2, New Design:...   \n",
       "1  Designs are good:1, Accurate matching design:1...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  varieties :2, variety :1, range :1, assortment :1   \n",
       "1  wide varieties of design :1, wide variety :1, ...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0                       special discount:2, offers:2                 \n",
       "1  special discount for QatarEnergy umbrella:1, n...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0                          transparent :2, offers :2   \n",
       "1  transparent about pricing :1, transparency in ...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  top-notch :1, high-quality :1, superior :1, ex...   \n",
       "1  superior quality and finish :1, high-quality j...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                    exchange :3, rate :1, resale :1  \n",
       "1  exchange process went smooth :1, provided very...  "
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_lul_qa = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_lul_qa[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_lul_qa:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_lul_qa'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_lul_qa = pd.concat([positive_keywords_tan_lul_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_lul_qa = pd.concat([positive_keywords_tan_lul_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_lul_qa = positive_keywords_tan_lul_qa.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_lul_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca010ee-b7fc-47bb-973f-4e9e80c9f961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c809cc9-0383-49b2-b5a4-b37c01e90b0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_mank_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "4c19075b-9970-44af-abd1-74f365ce3263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:09:08.178831Z",
     "iopub.status.busy": "2025-06-11T17:09:08.178322Z",
     "iopub.status.idle": "2025-06-11T17:09:24.716447Z",
     "shell.execute_reply": "2025-06-11T17:09:24.715822Z",
     "shell.execute_reply.started": "2025-06-11T17:09:08.178811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  16.5\n",
      "Total Input Tokens -  8813\n",
      "Total Input Cost = USD  0.09\n",
      "Total Output Tokens -  488\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_mank_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_mank_db=[0]\n",
    "keyword_input_token_tan_mank_db = 0\n",
    "keyword_output_token_tan_mank_db = 0\n",
    "keyword_start_time_loop_tan_mank_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_mank_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_mank_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_mank_db = keyword_dataframes['tan_mank_db_final_sen_df_jul'][keyword_dataframes['tan_mank_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_mank_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_mank_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_mank_db.append(keywords)\n",
    "        keyword_input_token_tan_mank_db += input_tokens_loop\n",
    "        keyword_output_token_tan_mank_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_mank_db = time.time()\n",
    "keyword_cost_input_token_tan_mank_db = round((0.01/1000)*keyword_input_token_tan_mank_db,2)\n",
    "keyword_cost_output_token_tan_mank_db = round((0.03/1000)*keyword_output_token_tan_mank_db,2)\n",
    "keyword_total_cost_tan_mank_db = keyword_cost_input_token_tan_mank_db + keyword_cost_output_token_tan_mank_db\n",
    "keyword_total_time_loop_tan_mank_db = keyword_end_time_loop_tan_mank_db - keyword_start_time_loop_tan_mank_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_mank_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_mank_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_mank_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_mank_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_mank_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_mank_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_mank_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "2bd8d367-45a8-442b-afb0-cce5c034d00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:09:24.717854Z",
     "iopub.status.busy": "2025-06-11T17:09:24.717567Z",
     "iopub.status.idle": "2025-06-11T17:09:24.767590Z",
     "shell.execute_reply": "2025-06-11T17:09:24.766959Z",
     "shell.execute_reply.started": "2025-06-11T17:09:24.717830Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-UW Mall Al Mankhool, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>transparency :1</td>\n",
       "      <td>Great experience :4, Amazing experience :3, Ex...</td>\n",
       "      <td>helpful :8, excellent :4, courteous :3, patien...</td>\n",
       "      <td>unique :1, exquisite :1</td>\n",
       "      <td>collection :5, options :1, array :1</td>\n",
       "      <td>offers :2, deal :1</td>\n",
       "      <td>competitive making charges :1</td>\n",
       "      <td>transparent :1, competitive :1</td>\n",
       "      <td>quality products:1, jewellery quality:1, high ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-UW Mall Al Mankhool, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>Highly recommend :3, Must visit :2, Looking fo...</td>\n",
       "      <td>very helpful :3, excellent service :2, excepti...</td>\n",
       "      <td>unique jewellery designs :1, exquisite and uni...</td>\n",
       "      <td>diverse collection :1, beautiful &amp; unique coll...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>Pricing was transparent and competitive :1</td>\n",
       "      <td>quality products:1, jewellery quality is excep...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-UW Mall Al Mankhool, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-UW Mall Al Mankhool, DB  Positive   phrases   \n",
       "\n",
       "  Customer Confidence                                   Store Experience  \\\n",
       "0     transparency :1  Great experience :4, Amazing experience :3, Ex...   \n",
       "1                      Highly recommend :3, Must visit :2, Looking fo...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful :8, excellent :4, courteous :3, patien...   \n",
       "1  very helpful :3, excellent service :2, excepti...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0                            unique :1, exquisite :1   \n",
       "1  unique jewellery designs :1, exquisite and uni...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                collection :5, options :1, array :1   \n",
       "1  diverse collection :1, beautiful & unique coll...   \n",
       "\n",
       "                       Discount                  Making Charge  \\\n",
       "0            offers :2, deal :1  competitive making charges :1   \n",
       "1  No relevant positive phrases   No relevant positive phrases   \n",
       "\n",
       "                                        Price  \\\n",
       "0              transparent :1, competitive :1   \n",
       "1  Pricing was transparent and competitive :1   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  quality products:1, jewellery quality:1, high ...                     \n",
       "1  quality products:1, jewellery quality is excep...                     "
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_mank_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_mank_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_mank_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_mank_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_mank_db = pd.concat([positive_keywords_tan_mank_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_mank_db = pd.concat([positive_keywords_tan_mank_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_mank_db = positive_keywords_tan_mank_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_mank_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab66337-de22-4e7c-a281-eb8c4a80e9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b2b032c-1f39-49a5-9235-5f9cf516975b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_rol_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "239587dd-d43c-43e7-8efe-fd4c213ef798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:09:28.281971Z",
     "iopub.status.busy": "2025-06-11T17:09:28.281388Z",
     "iopub.status.idle": "2025-06-11T17:09:50.831287Z",
     "shell.execute_reply": "2025-06-11T17:09:50.830721Z",
     "shell.execute_reply.started": "2025-06-11T17:09:28.281939Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  22.5\n",
      "Total Input Tokens -  21758\n",
      "Total Input Cost = USD  0.22\n",
      "Total Output Tokens -  627\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.24\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_rol_sh = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_rol_sh=[0]\n",
    "keyword_input_token_tan_rol_sh = 0\n",
    "keyword_output_token_tan_rol_sh = 0\n",
    "keyword_start_time_loop_tan_rol_sh = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_rol_sh, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_rol_sh[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_rol_sh = keyword_dataframes['tan_rol_sh_final_sen_df_jul'][keyword_dataframes['tan_rol_sh_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_rol_sh:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_rol_sh,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_rol_sh.append(keywords)\n",
    "        keyword_input_token_tan_rol_sh += input_tokens_loop\n",
    "        keyword_output_token_tan_rol_sh += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_rol_sh = time.time()\n",
    "keyword_cost_input_token_tan_rol_sh = round((0.01/1000)*keyword_input_token_tan_rol_sh,2)\n",
    "keyword_cost_output_token_tan_rol_sh = round((0.03/1000)*keyword_output_token_tan_rol_sh,2)\n",
    "keyword_total_cost_tan_rol_sh = keyword_cost_input_token_tan_rol_sh + keyword_cost_output_token_tan_rol_sh\n",
    "keyword_total_time_loop_tan_rol_sh = keyword_end_time_loop_tan_rol_sh - keyword_start_time_loop_tan_rol_sh\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_rol_sh[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_rol_sh,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_rol_sh)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_rol_sh)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_rol_sh)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_rol_sh)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_rol_sh,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "80983a67-a987-4ab8-8a4e-68f34bae3d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:09:50.832710Z",
     "iopub.status.busy": "2025-06-11T17:09:50.832284Z",
     "iopub.status.idle": "2025-06-11T17:09:50.877870Z",
     "shell.execute_reply": "2025-06-11T17:09:50.877427Z",
     "shell.execute_reply.started": "2025-06-11T17:09:50.832691Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Rolla, SH</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :3, Trusted :1, Trustable :1, Transparen...</td>\n",
       "      <td>Nice :5, Amazing :4, Wonderful :4, Great :4, E...</td>\n",
       "      <td>helpful : 20, professional : 15, friendly : 14...</td>\n",
       "      <td>designs :15, collection :5, unique :3, elegant...</td>\n",
       "      <td>collection : 45, collections : 20, variety : 3...</td>\n",
       "      <td>discount :3, offers :1</td>\n",
       "      <td></td>\n",
       "      <td>best price :1, Best prices :1</td>\n",
       "      <td>quality :5, craftsmanship :2, pure :1, high-qu...</td>\n",
       "      <td>exchange :4, value :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Rolla, SH</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Best place to buy jewellery with trust of Tata...</td>\n",
       "      <td>Nice place to shop :1, Very good shopping expe...</td>\n",
       "      <td>excellent service : 10, very good service : 8,...</td>\n",
       "      <td>excellent designs :3, wonderful designs :3, am...</td>\n",
       "      <td>good collection : 10, nice collection : 8, ama...</td>\n",
       "      <td>discount options :1, current discount offers :1</td>\n",
       "      <td></td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>good quality :3, quality of the jewellery :1, ...</td>\n",
       "      <td>lifetime exchange :1, exchanging my old gold :...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Rolla, SH  Positive  keywords   \n",
       "1  Tanishq Jewellers-Rolla, SH  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :3, Trusted :1, Trustable :1, Transparen...   \n",
       "1  Best place to buy jewellery with trust of Tata...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Nice :5, Amazing :4, Wonderful :4, Great :4, E...   \n",
       "1  Nice place to shop :1, Very good shopping expe...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 20, professional : 15, friendly : 14...   \n",
       "1  excellent service : 10, very good service : 8,...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :15, collection :5, unique :3, elegant...   \n",
       "1  excellent designs :3, wonderful designs :3, am...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 45, collections : 20, variety : 3...   \n",
       "1  good collection : 10, nice collection : 8, ama...   \n",
       "\n",
       "                                          Discount Making Charge  \\\n",
       "0                           discount :3, offers :1                 \n",
       "1  discount options :1, current discount offers :1                 \n",
       "\n",
       "                           Price  \\\n",
       "0  best price :1, Best prices :1   \n",
       "1   No relevant positive phrases   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  quality :5, craftsmanship :2, pure :1, high-qu...   \n",
       "1  good quality :3, quality of the jewellery :1, ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                              exchange :4, value :1  \n",
       "1  lifetime exchange :1, exchanging my old gold :...  "
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_rol_sh = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_rol_sh[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_rol_sh:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_rol_sh'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_rol_sh = pd.concat([positive_keywords_tan_rol_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_rol_sh = pd.concat([positive_keywords_tan_rol_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_rol_sh = positive_keywords_tan_rol_sh.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_rol_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4313fa-80e6-42e0-949c-52a592385f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f015c0d5-967d-4b4b-a129-cc45aca4183a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_rse_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "552607b0-1225-402f-9d44-27bcf447edf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:09:50.878857Z",
     "iopub.status.busy": "2025-06-11T17:09:50.878664Z",
     "iopub.status.idle": "2025-06-11T17:10:07.415922Z",
     "shell.execute_reply": "2025-06-11T17:10:07.415410Z",
     "shell.execute_reply.started": "2025-06-11T17:09:50.878840Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  16.5\n",
      "Total Input Tokens -  15108\n",
      "Total Input Cost = USD  0.15\n",
      "Total Output Tokens -  505\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.17\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_rse_wa = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_rse_wa=[0]\n",
    "keyword_input_token_tan_rse_wa = 0\n",
    "keyword_output_token_tan_rse_wa = 0\n",
    "keyword_start_time_loop_tan_rse_wa = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_rse_wa, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_rse_wa[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_rse_wa = keyword_dataframes['tan_rse_wa_final_sen_df_jul'][keyword_dataframes['tan_rse_wa_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_rse_wa:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_rse_wa,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_rse_wa.append(keywords)\n",
    "        keyword_input_token_tan_rse_wa += input_tokens_loop\n",
    "        keyword_output_token_tan_rse_wa += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_rse_wa = time.time()\n",
    "keyword_cost_input_token_tan_rse_wa = round((0.01/1000)*keyword_input_token_tan_rse_wa,2)\n",
    "keyword_cost_output_token_tan_rse_wa = round((0.03/1000)*keyword_output_token_tan_rse_wa,2)\n",
    "keyword_total_cost_tan_rse_wa = keyword_cost_input_token_tan_rse_wa + keyword_cost_output_token_tan_rse_wa\n",
    "keyword_total_time_loop_tan_rse_wa = keyword_end_time_loop_tan_rse_wa - keyword_start_time_loop_tan_rse_wa\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_rse_wa[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_rse_wa,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_rse_wa)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_rse_wa)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_rse_wa)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_rse_wa)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_rse_wa,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "fee8ac28-a632-437b-9269-cdc09480ef8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:10:07.417224Z",
     "iopub.status.busy": "2025-06-11T17:10:07.416945Z",
     "iopub.status.idle": "2025-06-11T17:10:07.466134Z",
     "shell.execute_reply": "2025-06-11T17:10:07.465625Z",
     "shell.execute_reply.started": "2025-06-11T17:10:07.417193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Redmond Seattle, WA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Genuine :1, Reliable :1</td>\n",
       "      <td>Good experience :5, Pleasant experience :3, Wo...</td>\n",
       "      <td>patient : 15, helpful : 14, polite : 8, profes...</td>\n",
       "      <td>designs :15, collection :8, variety :3, crafts...</td>\n",
       "      <td>collection : 30, variety : 5, selection : 3, d...</td>\n",
       "      <td>offers :1, discounts :1</td>\n",
       "      <td></td>\n",
       "      <td>reasonable :1</td>\n",
       "      <td>quality :3, excellent :2, amazing :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Redmond Seattle, WA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant positive keywords/ phrases</td>\n",
       "      <td>Great shopping experience :2, Delightful exper...</td>\n",
       "      <td>very helpful : 5, incredibly helpful : 3, very...</td>\n",
       "      <td>beautiful designs :1, different designs :1, la...</td>\n",
       "      <td>great collection : 8, stunning collection : 4,...</td>\n",
       "      <td>explained us in detail about the offers / disc...</td>\n",
       "      <td></td>\n",
       "      <td>helped with prices :1, prices were reasonable :1</td>\n",
       "      <td>good quality workmanship :1, high quality :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Redmond Seattle, WA  Positive  keywords   \n",
       "1  Tanishq-Redmond Seattle, WA  Positive   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0                 Genuine :1, Reliable :1   \n",
       "1  No relevant positive keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Good experience :5, Pleasant experience :3, Wo...   \n",
       "1  Great shopping experience :2, Delightful exper...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient : 15, helpful : 14, polite : 8, profes...   \n",
       "1  very helpful : 5, incredibly helpful : 3, very...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :15, collection :8, variety :3, crafts...   \n",
       "1  beautiful designs :1, different designs :1, la...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  collection : 30, variety : 5, selection : 3, d...   \n",
       "1  great collection : 8, stunning collection : 4,...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0                            offers :1, discounts :1                 \n",
       "1  explained us in detail about the offers / disc...                 \n",
       "\n",
       "                                              Price  \\\n",
       "0                                     reasonable :1   \n",
       "1  helped with prices :1, prices were reasonable :1   \n",
       "\n",
       "                                Product Quality Jewellery Exchange  \n",
       "0          quality :3, excellent :2, amazing :1                     \n",
       "1  good quality workmanship :1, high quality :1                     "
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_rse_wa = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_rse_wa[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_rse_wa:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_rse_wa'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_rse_wa = pd.concat([positive_keywords_tan_rse_wa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_rse_wa = pd.concat([positive_keywords_tan_rse_wa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_rse_wa = positive_keywords_tan_rse_wa.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_rse_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a33e02-2e89-4f25-b2b8-dfd10e127ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19852b93-09c3-44bd-8a6b-36d0cc5dd229",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_sc_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "dbf4af48-d5ac-4869-b99a-aadd035ae789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:10:13.744030Z",
     "iopub.status.busy": "2025-06-11T17:10:13.743503Z",
     "iopub.status.idle": "2025-06-11T17:10:38.793213Z",
     "shell.execute_reply": "2025-06-11T17:10:38.792697Z",
     "shell.execute_reply.started": "2025-06-11T17:10:13.743992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  25.0\n",
      "Total Input Tokens -  13500\n",
      "Total Input Cost = USD  0.14\n",
      "Total Output Tokens -  541\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.16\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_sc_ca = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_sc_ca=[0]\n",
    "keyword_input_token_tan_sc_ca = 0\n",
    "keyword_output_token_tan_sc_ca = 0\n",
    "keyword_start_time_loop_tan_sc_ca = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_sc_ca, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_sc_ca[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_sc_ca = keyword_dataframes['tan_sc_ca_final_sen_df_jul'][keyword_dataframes['tan_sc_ca_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_sc_ca:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_sc_ca,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_sc_ca.append(keywords)\n",
    "        keyword_input_token_tan_sc_ca += input_tokens_loop\n",
    "        keyword_output_token_tan_sc_ca += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_sc_ca = time.time()\n",
    "keyword_cost_input_token_tan_sc_ca = round((0.01/1000)*keyword_input_token_tan_sc_ca,2)\n",
    "keyword_cost_output_token_tan_sc_ca = round((0.03/1000)*keyword_output_token_tan_sc_ca,2)\n",
    "keyword_total_cost_tan_sc_ca = keyword_cost_input_token_tan_sc_ca + keyword_cost_output_token_tan_sc_ca\n",
    "keyword_total_time_loop_tan_sc_ca = keyword_end_time_loop_tan_sc_ca - keyword_start_time_loop_tan_sc_ca\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_sc_ca[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_sc_ca,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_sc_ca)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_sc_ca)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_sc_ca)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_sc_ca)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_sc_ca,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "6d2702c2-173a-4fd6-8b9b-6e380a45f6bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:10:38.794456Z",
     "iopub.status.busy": "2025-06-11T17:10:38.794174Z",
     "iopub.status.idle": "2025-06-11T17:10:38.835211Z",
     "shell.execute_reply": "2025-06-11T17:10:38.834739Z",
     "shell.execute_reply.started": "2025-06-11T17:10:38.794436Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Santa Clara, CA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trusted :2, Trust :2, Guaranteed :1, Certifica...</td>\n",
       "      <td>Ambience :3, Atmosphere :2, Showroom :2, Spaci...</td>\n",
       "      <td>patient :5, knowledgeable :5, friendly :4, hel...</td>\n",
       "      <td>designs :6, innovative :1, classic :1, stunnin...</td>\n",
       "      <td>variety :3, wide variety :2, huge collections ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>affordable :1, fair :1, reasonable :1</td>\n",
       "      <td>Quality :3, High-quality :2, Outstanding :2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Santa Clara, CA</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Most trusted brand :1, Trustworthy shopping en...</td>\n",
       "      <td>Beautiful store :4, Amazing experience :3, Won...</td>\n",
       "      <td>incredibly kind and attentive :2, above and be...</td>\n",
       "      <td>beautiful designs :2, excellent designs :1, in...</td>\n",
       "      <td>wide variety of gold and diamond jewellery :1,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>great prices :1, surprisingly affordable exper...</td>\n",
       "      <td>Quality of the jewelry is outstanding :2, High...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Santa Clara, CA  Positive  keywords   \n",
       "1  Tanishq-Santa Clara, CA  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trusted :2, Trust :2, Guaranteed :1, Certifica...   \n",
       "1  Most trusted brand :1, Trustworthy shopping en...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Ambience :3, Atmosphere :2, Showroom :2, Spaci...   \n",
       "1  Beautiful store :4, Amazing experience :3, Won...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  patient :5, knowledgeable :5, friendly :4, hel...   \n",
       "1  incredibly kind and attentive :2, above and be...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  designs :6, innovative :1, classic :1, stunnin...   \n",
       "1  beautiful designs :2, excellent designs :1, in...   \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0  variety :3, wide variety :2, huge collections ...                          \n",
       "1  wide variety of gold and diamond jewellery :1,...                          \n",
       "\n",
       "                                               Price  \\\n",
       "0              affordable :1, fair :1, reasonable :1   \n",
       "1  great prices :1, surprisingly affordable exper...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0        Quality :3, High-quality :2, Outstanding :2                     \n",
       "1  Quality of the jewelry is outstanding :2, High...                     "
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_sc_ca = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_sc_ca[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_sc_ca:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_sc_ca'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_sc_ca = pd.concat([positive_keywords_tan_sc_ca, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_sc_ca = pd.concat([positive_keywords_tan_sc_ca, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_sc_ca = positive_keywords_tan_sc_ca.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_sc_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c0e7e-f46d-4174-928d-508d214598f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0a213b0-4019-4ad2-a968-59db78387ead",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_sc_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "fd754bb9-2e42-45f3-9942-30b5308d9fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:10:47.257908Z",
     "iopub.status.busy": "2025-06-11T17:10:47.257573Z",
     "iopub.status.idle": "2025-06-11T17:11:08.302644Z",
     "shell.execute_reply": "2025-06-11T17:11:08.302068Z",
     "shell.execute_reply.started": "2025-06-11T17:10:47.257887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  21.0\n",
      "Total Input Tokens -  22188\n",
      "Total Input Cost = USD  0.22\n",
      "Total Output Tokens -  662\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.24\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_sc_sh = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_sc_sh=[0]\n",
    "keyword_input_token_tan_sc_sh = 0\n",
    "keyword_output_token_tan_sc_sh = 0\n",
    "keyword_start_time_loop_tan_sc_sh = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_sc_sh, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_sc_sh[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_sc_sh = keyword_dataframes['tan_sc_sh_final_sen_df_jul'][keyword_dataframes['tan_sc_sh_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_sc_sh:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_sc_sh,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_sc_sh.append(keywords)\n",
    "        keyword_input_token_tan_sc_sh += input_tokens_loop\n",
    "        keyword_output_token_tan_sc_sh += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_sc_sh = time.time()\n",
    "keyword_cost_input_token_tan_sc_sh = round((0.01/1000)*keyword_input_token_tan_sc_sh,2)\n",
    "keyword_cost_output_token_tan_sc_sh = round((0.03/1000)*keyword_output_token_tan_sc_sh,2)\n",
    "keyword_total_cost_tan_sc_sh = keyword_cost_input_token_tan_sc_sh + keyword_cost_output_token_tan_sc_sh\n",
    "keyword_total_time_loop_tan_sc_sh = keyword_end_time_loop_tan_sc_sh - keyword_start_time_loop_tan_sc_sh\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_sc_sh[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_sc_sh,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_sc_sh)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_sc_sh)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_sc_sh)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_sc_sh)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_sc_sh,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "a99b4227-78d9-40f0-ac85-d7bf7f45e2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:11:08.303845Z",
     "iopub.status.busy": "2025-06-11T17:11:08.303577Z",
     "iopub.status.idle": "2025-06-11T17:11:08.348599Z",
     "shell.execute_reply": "2025-06-11T17:11:08.348133Z",
     "shell.execute_reply.started": "2025-06-11T17:11:08.303825Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Sharjah Central, SH</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust :1, Genuine :1, Assurance :1, Guaranteed...</td>\n",
       "      <td>Great experience : 8, Wonderful experience : 6...</td>\n",
       "      <td>helpful : 30, friendly : 25, cooperative : 15,...</td>\n",
       "      <td>unique :5, elegant :2, creative :1, exquisite ...</td>\n",
       "      <td>collection : 45, variety : 3</td>\n",
       "      <td>discount :3, offers :2</td>\n",
       "      <td></td>\n",
       "      <td>best price :2, great prices :1, good price :1,...</td>\n",
       "      <td>good quality:4, quality:3, best quality:1</td>\n",
       "      <td>gold exchange:3, old gold:2, value:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Sharjah Central, SH</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trust Tanishq :1, Tata assurance :1, Purity is...</td>\n",
       "      <td>Very good experience : 4, Excellent shopping e...</td>\n",
       "      <td>very helpful : 10, extremely helpful : 5, very...</td>\n",
       "      <td>good designs :3, amazing designs :2, unique de...</td>\n",
       "      <td>Nice collection : 10, Good collection : 9, Ver...</td>\n",
       "      <td>good discounts :1, best offers :1, 10% discoun...</td>\n",
       "      <td></td>\n",
       "      <td>best prices :1, price offered :1, matched my t...</td>\n",
       "      <td>quality of the product:1, exceeded my expectat...</td>\n",
       "      <td>best value for old gold:1, good gold exchange ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Sharjah Central, SH  Positive  keywords   \n",
       "1  Tanishq Jewellers-Sharjah Central, SH  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Trust :1, Genuine :1, Assurance :1, Guaranteed...   \n",
       "1  Trust Tanishq :1, Tata assurance :1, Purity is...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Great experience : 8, Wonderful experience : 6...   \n",
       "1  Very good experience : 4, Excellent shopping e...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  helpful : 30, friendly : 25, cooperative : 15,...   \n",
       "1  very helpful : 10, extremely helpful : 5, very...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  unique :5, elegant :2, creative :1, exquisite ...   \n",
       "1  good designs :3, amazing designs :2, unique de...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                       collection : 45, variety : 3   \n",
       "1  Nice collection : 10, Good collection : 9, Ver...   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0                             discount :3, offers :2                 \n",
       "1  good discounts :1, best offers :1, 10% discoun...                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  best price :2, great prices :1, good price :1,...   \n",
       "1  best prices :1, price offered :1, matched my t...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0          good quality:4, quality:3, best quality:1   \n",
       "1  quality of the product:1, exceeded my expectat...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0               gold exchange:3, old gold:2, value:1  \n",
       "1  best value for old gold:1, good gold exchange ...  "
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_sc_sh = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_sc_sh[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_sc_sh:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_sc_sh'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_sc_sh = pd.concat([positive_keywords_tan_sc_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_sc_sh = pd.concat([positive_keywords_tan_sc_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_sc_sh = positive_keywords_tan_sc_sh.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_sc_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cffc49-4f8d-4251-840a-85de469e62e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf031e2-9766-4f5f-85a0-2fb018ff5a0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### tan_taj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "c1e369b7-4757-40c1-8cad-14852d427fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:11:17.903303Z",
     "iopub.status.busy": "2025-06-11T17:11:17.903010Z",
     "iopub.status.idle": "2025-06-11T17:11:35.444612Z",
     "shell.execute_reply": "2025-06-11T17:11:35.443915Z",
     "shell.execute_reply.started": "2025-06-11T17:11:17.903284Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.5\n",
      "Total Input Tokens -  8773\n",
      "Total Input Cost = USD  0.09\n",
      "Total Output Tokens -  459\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_positive_output_tan_taj_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_taj_db=[0]\n",
    "keyword_input_token_tan_taj_db = 0\n",
    "keyword_output_token_tan_taj_db = 0\n",
    "keyword_start_time_loop_tan_taj_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_taj_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_taj_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_taj_db = keyword_dataframes['tan_taj_db_final_sen_df_jul'][keyword_dataframes['tan_taj_db_final_sen_df_jul'][topic]==1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are positive comments, call the positive_keywords function\n",
    "    if filtered_comments_tan_taj_db:\n",
    "        # Call the positive_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = positive_keywords(filtered_comments_tan_taj_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_positive_output_tan_taj_db.append(keywords)\n",
    "        keyword_input_token_tan_taj_db += input_tokens_loop\n",
    "        keyword_output_token_tan_taj_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_taj_db = time.time()\n",
    "keyword_cost_input_token_tan_taj_db = round((0.01/1000)*keyword_input_token_tan_taj_db,2)\n",
    "keyword_cost_output_token_tan_taj_db = round((0.03/1000)*keyword_output_token_tan_taj_db,2)\n",
    "keyword_total_cost_tan_taj_db = keyword_cost_input_token_tan_taj_db + keyword_cost_output_token_tan_taj_db\n",
    "keyword_total_time_loop_tan_taj_db = keyword_end_time_loop_tan_taj_db - keyword_start_time_loop_tan_taj_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_taj_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_taj_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_taj_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_taj_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_taj_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_taj_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_taj_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "9a631eed-f3d9-4ae7-aebc-0c9e68987077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:11:35.446373Z",
     "iopub.status.busy": "2025-06-11T17:11:35.445869Z",
     "iopub.status.idle": "2025-06-11T17:11:35.494500Z",
     "shell.execute_reply": "2025-06-11T17:11:35.493928Z",
     "shell.execute_reply.started": "2025-06-11T17:11:35.446345Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Taj, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Transparent :2, Trust :1, Loyal :1</td>\n",
       "      <td>ambience :3, environment :1, place :1, store :...</td>\n",
       "      <td>friendly :4, knowledgeable :3, polite :3, prof...</td>\n",
       "      <td>designs :5, jewellery :2</td>\n",
       "      <td>collection :22, variety :2</td>\n",
       "      <td>discounts :1, tax refund :1</td>\n",
       "      <td>transparent :2</td>\n",
       "      <td></td>\n",
       "      <td>exceptional :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Taj, DB</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Always we trust tata :1, Tanishq's policies ar...</td>\n",
       "      <td>nice experience :2, amazing place :1, awesome ...</td>\n",
       "      <td>exceptional service :3, very good service :2, ...</td>\n",
       "      <td>Beautiful designs :2, Beautiful solitaire desi...</td>\n",
       "      <td>Superb collection :2, Nice collections :5, Bea...</td>\n",
       "      <td>No relevant positive phrases</td>\n",
       "      <td>transparent about their making charges :1</td>\n",
       "      <td></td>\n",
       "      <td>quality is exceptional :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Taj, DB  Positive  keywords   \n",
       "1  Tanishq Jewellers-Taj, DB  Positive   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                 Transparent :2, Trust :1, Loyal :1   \n",
       "1  Always we trust tata :1, Tanishq's policies ar...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  ambience :3, environment :1, place :1, store :...   \n",
       "1  nice experience :2, amazing place :1, awesome ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  friendly :4, knowledgeable :3, polite :3, prof...   \n",
       "1  exceptional service :3, very good service :2, ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0                           designs :5, jewellery :2   \n",
       "1  Beautiful designs :2, Beautiful solitaire desi...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                         collection :22, variety :2   \n",
       "1  Superb collection :2, Nice collections :5, Bea...   \n",
       "\n",
       "                       Discount                              Making Charge  \\\n",
       "0   discounts :1, tax refund :1                             transparent :2   \n",
       "1  No relevant positive phrases  transparent about their making charges :1   \n",
       "\n",
       "  Price            Product Quality Jewellery Exchange  \n",
       "0                   exceptional :1                     \n",
       "1        quality is exceptional :1                     "
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "positive_keywords_tan_taj_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    positive_keywords_tan_taj_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_positive_output_tan_taj_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_taj_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'Positive'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            positive_keywords_tan_taj_db = pd.concat([positive_keywords_tan_taj_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            positive_keywords_tan_taj_db = pd.concat([positive_keywords_tan_taj_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "positive_keywords_tan_taj_db = positive_keywords_tan_taj_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "positive_keywords_tan_taj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3167d8d-e97e-48e0-b8e0-a7f67d8c22b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e36e67f5-52d3-454b-994a-0eacf871fda1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Total Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf03176c-47c2-4a0e-a56d-0c14f198411c",
   "metadata": {
    "tags": []
   },
   "source": [
    "keyword_positive_total_cost = keyword_total_cost_bhi_ak+keyword_total_cost_joy_ab+keyword_total_cost_joy_st_af+keyword_total_cost_joy_dm_ad+keyword_total_cost_joy_mz_ad+keyword_total_cost_joy_sh_ad+keyword_total_cost_mal_sc+keyword_total_cost_mal_ab+keyword_total_cost_mal_b1_af+keyword_total_cost_mal_ak+keyword_total_cost_mal_aw_ad+keyword_total_cost_mal_dm_ad+keyword_total_cost_mal_b1_ad+keyword_total_cost_mal_b2_ad+keyword_total_cost_mal_lu_ad+keyword_total_cost_mal_mb+keyword_total_cost_mal_sh_ad+keyword_total_cost_mal_b2_af+keyword_total_cost_mna_mb+keyword_total_cost_min_ak+keyword_total_cost_joy_ak+keyword_total_cost_kan_mb+keyword_total_cost_agd_mb+keyword_total_cost_bhi_dec_ga+keyword_total_cost_jar_bol_il+keyword_total_cost_jar_ver_il+keyword_total_cost_jar_lom_il+keyword_total_cost_jar_orl_il+keyword_total_cost_jar_aur_il+keyword_total_cost_jar_alg_il+keyword_total_cost_jar_sch_il+keyword_total_cost_joy_suw_ga+keyword_total_cost_joy_chi_il+keyword_total_cost_joy_hou_tx+keyword_total_cost_joy_fri_tx+keyword_total_cost_mal_chi_il+keyword_total_cost_mal_nap_il+keyword_total_cost_mal_ise_nj+keyword_total_cost_mal_fri_tx+keyword_total_cost_mal_ric_tx+keyword_total_cost_may_vie_va+keyword_total_cost_son_ise_nj+keyword_total_cost_tif_chi_il+keyword_total_cost_tif_nor_il+keyword_total_cost_tif_sko_il+keyword_total_cost_tif_eas_nj+keyword_total_cost_tif_sho_nj+keyword_total_cost_tif_vie_va+keyword_total_cost_vbj_fri_tx+keyword_total_cost_tan_chi_il+keyword_total_cost_tan_fri_tx+keyword_total_cost_tan_hou_tx+keyword_total_cost_tan_new_nj+keyword_total_cost_tan_bar_db+keyword_total_cost_tan_fah_db+keyword_total_cost_tan_kar_db+keyword_total_cost_tan_ham_ad+keyword_total_cost_tan_mee_db+keyword_total_cost_tan_sil_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033772f1-ecd7-49be-abb8-1672ed9b4a5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "keyword_positive_total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71563d-7b14-42d1-bd67-27b59ff09dbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Combined_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "2a5ee510-43d7-4a5a-a84f-b5ae8bd025b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:14:00.638372Z",
     "iopub.status.busy": "2025-06-11T17:14:00.637786Z",
     "iopub.status.idle": "2025-06-11T17:14:00.675349Z",
     "shell.execute_reply": "2025-06-11T17:14:00.674808Z",
     "shell.execute_reply.started": "2025-06-11T17:14:00.638342Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_positive_keywords = pd.DataFrame()\n",
    "\n",
    "positive_keyword_df_list = [\n",
    "                            \"positive_keywords_agd_mb\",\n",
    "                            \"positive_keywords_bhi_ak\",\n",
    "                            \"positive_keywords_bhi_dec_ga\",\n",
    "                            \"positive_keywords_eve_joh_ga\",\n",
    "                            \"positive_keywords_jar_alg_il\",\n",
    "                            \"positive_keywords_jar_aur_il\",\n",
    "                            \"positive_keywords_jar_bol_il\",\n",
    "                            \"positive_keywords_jar_lom_il\",\n",
    "                            \"positive_keywords_jar_orl_il\",\n",
    "                            \"positive_keywords_jar_sch_il\",\n",
    "                            \"positive_keywords_jar_ver_il\",\n",
    "                            \"positive_keywords_joy_ab\",\n",
    "                            \"positive_keywords_joy_ak\",\n",
    "                            \"positive_keywords_joy_chi_il\",\n",
    "                            \"positive_keywords_joy_dm_ad\",\n",
    "                            \"positive_keywords_joy_fri_tx\",\n",
    "                            \"positive_keywords_joy_hou_tx\",\n",
    "                            \"positive_keywords_joy_mz_ad\",\n",
    "                            \"positive_keywords_joy_sh_ad\",\n",
    "                            \"positive_keywords_joy_st_af\",\n",
    "                            \"positive_keywords_joy_suw_ga\",\n",
    "                            \"positive_keywords_kan_mb\",\n",
    "                            \"positive_keywords_mal_ab\",\n",
    "                            \"positive_keywords_mal_ak\",\n",
    "                            \"positive_keywords_mal_aw_ad\",\n",
    "                            \"positive_keywords_mal_b1_ad\",\n",
    "                            \"positive_keywords_mal_b1_af\",\n",
    "                            \"positive_keywords_mal_b2_ad\",\n",
    "                            \"positive_keywords_mal_b2_af\",\n",
    "                            \"positive_keywords_mal_chi_il\",\n",
    "                            \"positive_keywords_mal_dm_ad\",\n",
    "                            \"positive_keywords_mal_fri_tx\",\n",
    "                            \"positive_keywords_mal_ise_nj\",\n",
    "                            \"positive_keywords_mal_lu_ad\",\n",
    "                            \"positive_keywords_mal_mb\",\n",
    "                            \"positive_keywords_mal_nap_il\",\n",
    "                            \"positive_keywords_mal_ric_tx\",\n",
    "                            \"positive_keywords_mal_sc\",\n",
    "                            \"positive_keywords_mal_sh_ad\",\n",
    "                            \"positive_keywords_may_vie_va\",\n",
    "                            \"positive_keywords_mia_awm_ad\",\n",
    "                            \"positive_keywords_mia_bur_db\",\n",
    "                            \"positive_keywords_min_ak\",\n",
    "                            \"positive_keywords_mna_mb\",\n",
    "                            \"positive_keywords_son_ise_nj\",\n",
    "                            \"positive_keywords_tan_am_om\",\n",
    "                            \"positive_keywords_tan_atl_ga\",\n",
    "                            \"positive_keywords_tan_bar_db\",\n",
    "                            \"positive_keywords_tan_chi_il\",\n",
    "                            \"positive_keywords_tan_fah_db\",\n",
    "                            \"positive_keywords_tan_fc_qa\",\n",
    "                            \"positive_keywords_tan_fri_tx\",\n",
    "                            \"positive_keywords_tan_gs_db\",\n",
    "                            \"positive_keywords_tan_ham_ad\",\n",
    "                            \"positive_keywords_tan_hou_tx\",\n",
    "                            \"positive_keywords_tan_kar_db\",\n",
    "                            \"positive_keywords_tan_lul_qa\",\n",
    "                            \"positive_keywords_tan_mank_db\",\n",
    "                            \"positive_keywords_tan_mee_db\",\n",
    "                            \"positive_keywords_tan_new_nj\",\n",
    "                            \"positive_keywords_tan_rol_sh\",\n",
    "                            \"positive_keywords_tan_rse_wa\",\n",
    "                            \"positive_keywords_tan_sc_ca\",\n",
    "                            \"positive_keywords_tan_sc_sh\",\n",
    "                            \"positive_keywords_tan_sil_db\",\n",
    "                            \"positive_keywords_tan_taj_db\",\n",
    "                            \"positive_keywords_tif_chi_il\",\n",
    "                            \"positive_keywords_tif_eas_nj\",\n",
    "                            \"positive_keywords_tif_hac_nj\",\n",
    "                            \"positive_keywords_tif_nor_il\",\n",
    "                            \"positive_keywords_tif_par_nj\",\n",
    "                            \"positive_keywords_tif_red_nj\",\n",
    "                            \"positive_keywords_tif_ric_va\",\n",
    "                            \"positive_keywords_tif_sho_nj\",\n",
    "                            \"positive_keywords_tif_sko_il\",\n",
    "                            \"positive_keywords_tif_vie_va\",\n",
    "                            \"positive_keywords_vbj_fri_tx\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "for df_name in positive_keyword_df_list:\n",
    "    combined_df_positive_keywords = pd.concat([combined_df_positive_keywords, eval(df_name)], ignore_index=True)\n",
    "\n",
    "combined_df_positive_keywords.reset_index(drop=True, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "eb33e5c1-3fb4-4aaf-acae-ec3c8a760f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:14:21.458668Z",
     "iopub.status.busy": "2025-06-11T17:14:21.458305Z",
     "iopub.status.idle": "2025-06-11T17:14:21.540773Z",
     "shell.execute_reply": "2025-06-11T17:14:21.540144Z",
     "shell.execute_reply.started": "2025-06-11T17:14:21.458647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_positive_keywords.to_excel(\"temp/combined_df_positive_keywords_current.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271c1ce-a014-4c13-bf19-b78e9d3e9e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ece20416-9ea7-4758-a421-3c5a1cc1efdc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Negative Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b330a1-e1d5-4177-9f90-6ad3792de418",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### bhi_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "b28ea6c7-697d-4e50-8950-91eaa76ccc99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:16:55.701155Z",
     "iopub.status.busy": "2025-06-12T00:16:55.700659Z",
     "iopub.status.idle": "2025-06-12T00:17:15.238149Z",
     "shell.execute_reply": "2025-06-12T00:17:15.237654Z",
     "shell.execute_reply.started": "2025-06-12T00:16:55.701135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  19.5\n",
      "Total Input Tokens -  12715\n",
      "Total Input Cost = USD  0.13\n",
      "Total Output Tokens -  694\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.15\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_bhi_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_bhi_ak=[0]\n",
    "keyword_input_token_bhi_ak = 0\n",
    "keyword_output_token_bhi_ak = 0\n",
    "keyword_start_time_loop_bhi_ak = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_bhi_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_bhi_ak[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_bhi_ak = keyword_dataframes['bhi_ak_final_sen_df_jul'][keyword_dataframes['bhi_ak_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_bhi_ak:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_bhi_ak,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_bhi_ak.append(keywords)\n",
    "        keyword_input_token_bhi_ak += input_tokens_loop\n",
    "        keyword_output_token_bhi_ak += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_bhi_ak = time.time()\n",
    "keyword_cost_input_token_bhi_ak = round((0.01/1000)*keyword_input_token_bhi_ak,2)\n",
    "keyword_cost_output_token_bhi_ak = round((0.03/1000)*keyword_output_token_bhi_ak,2)\n",
    "keyword_total_cost_bhi_ak = keyword_cost_input_token_bhi_ak + keyword_cost_output_token_bhi_ak\n",
    "keyword_total_time_loop_bhi_ak = keyword_end_time_loop_bhi_ak - keyword_start_time_loop_bhi_ak\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_bhi_ak[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_bhi_ak,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_bhi_ak)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_bhi_ak)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_bhi_ak)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_bhi_ak)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_bhi_ak,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "d2012b6e-05d2-4082-89da-61111cc563f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:17:15.239616Z",
     "iopub.status.busy": "2025-06-12T00:17:15.239321Z",
     "iopub.status.idle": "2025-06-12T00:17:15.284156Z",
     "shell.execute_reply": "2025-06-12T00:17:15.283665Z",
     "shell.execute_reply.started": "2025-06-12T00:17:15.239590Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>scam :1, rude :1, shocking :1, questionable :1...</td>\n",
       "      <td>delay :1, worst :1, bad :1, terrible :1, carel...</td>\n",
       "      <td>careless :1, not good :1, bad experience :1, t...</td>\n",
       "      <td>defective :1, poor-quality :1, limited selecti...</td>\n",
       "      <td>limited selection:1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>highest making charges:2, much higher:1, limit...</td>\n",
       "      <td>unbearable :1, limitless :1, shocking :1, huge...</td>\n",
       "      <td>low quality :1, defective :1, poor-quality :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bhima Jewellers - Al Karama</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>never do a scheme with this jewellers :1, hidi...</td>\n",
       "      <td>Delay at the billing point :1, bad experience ...</td>\n",
       "      <td>sales representatie didn’t told me :1, Miss gu...</td>\n",
       "      <td>broke within just a month :1, broke again :1, ...</td>\n",
       "      <td>very limited selection of replacement designs:...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>loot it in making charges:1, making charges ar...</td>\n",
       "      <td>making charges are limitless :1, cost of makin...</td>\n",
       "      <td>broke within just a month :1, not connecting t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type  \\\n",
       "0  Bhima Jewellers - Al Karama  negative  keywords   \n",
       "1  Bhima Jewellers - Al Karama  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  scam :1, rude :1, shocking :1, questionable :1...   \n",
       "1  never do a scheme with this jewellers :1, hidi...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  delay :1, worst :1, bad :1, terrible :1, carel...   \n",
       "1  Delay at the billing point :1, bad experience ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  careless :1, not good :1, bad experience :1, t...   \n",
       "1  sales representatie didn’t told me :1, Miss gu...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0  defective :1, poor-quality :1, limited selecti...   \n",
       "1  broke within just a month :1, broke again :1, ...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                                limited selection:1   \n",
       "1  very limited selection of replacement designs:...   \n",
       "\n",
       "                                 Discount  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  highest making charges:2, much higher:1, limit...   \n",
       "1  loot it in making charges:1, making charges ar...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  unbearable :1, limitless :1, shocking :1, huge...   \n",
       "1  making charges are limitless :1, cost of makin...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0      low quality :1, defective :1, poor-quality :1                     \n",
       "1  broke within just a month :1, not connecting t...                     "
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_bhi_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_bhi_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_bhi_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'bhi_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_bhi_ak = pd.concat([negative_keywords_bhi_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_bhi_ak = pd.concat([negative_keywords_bhi_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_bhi_ak = negative_keywords_bhi_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_bhi_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306eea7e-f579-4ea3-8f9b-c824ec529ec9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "27290ab7-d024-409f-9890-096263c33f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:17:15.285265Z",
     "iopub.status.busy": "2025-06-12T00:17:15.284798Z",
     "iopub.status.idle": "2025-06-12T00:17:29.815958Z",
     "shell.execute_reply": "2025-06-12T00:17:29.815453Z",
     "shell.execute_reply.started": "2025-06-12T00:17:15.285246Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  14.5\n",
      "Total Input Tokens -  7166\n",
      "Total Input Cost = USD  0.07\n",
      "Total Output Tokens -  440\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_ab = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_ab=[0]\n",
    "keyword_input_token_joy_ab = 0\n",
    "keyword_output_token_joy_ab = 0\n",
    "keyword_start_time_loop_joy_ab = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_ab, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_ab[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_ab = keyword_dataframes['joy_ab_final_sen_df_jul'][keyword_dataframes['joy_ab_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_ab:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_ab,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_ab.append(keywords)\n",
    "        keyword_input_token_joy_ab += input_tokens_loop\n",
    "        keyword_output_token_joy_ab += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_ab = time.time()\n",
    "keyword_cost_input_token_joy_ab = round((0.01/1000)*keyword_input_token_joy_ab,2)\n",
    "keyword_cost_output_token_joy_ab = round((0.03/1000)*keyword_output_token_joy_ab,2)\n",
    "keyword_total_cost_joy_ab = keyword_cost_input_token_joy_ab + keyword_cost_output_token_joy_ab\n",
    "keyword_total_time_loop_joy_ab = keyword_end_time_loop_joy_ab - keyword_start_time_loop_joy_ab\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_ab[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_ab,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_ab)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_ab)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_ab)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_ab)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_ab,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "9c7b76b8-fdd7-48ad-867d-672ade537c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:17:29.817716Z",
     "iopub.status.busy": "2025-06-12T00:17:29.817232Z",
     "iopub.status.idle": "2025-06-12T00:17:29.860710Z",
     "shell.execute_reply": "2025-06-12T00:17:29.860209Z",
     "shell.execute_reply.started": "2025-06-12T00:17:29.817698Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Al Barsha</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Not trustworthy:1, manipulated:1, wrong inform...</td>\n",
       "      <td>waiting :1, improve :1, unwelcoming :1, indiff...</td>\n",
       "      <td>lazy :1, inexperienced :1, unwelcoming :1, ind...</td>\n",
       "      <td>old designs:1</td>\n",
       "      <td>collections :1, models :1</td>\n",
       "      <td>No discount :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>too expensive:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Al Barsha</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>using paid services to increase its Shop Ratin...</td>\n",
       "      <td>waiting longtime :1, service is need to improv...</td>\n",
       "      <td>very lazy staff :1, inexperienced staff :1, un...</td>\n",
       "      <td>Very old designs:1</td>\n",
       "      <td>little more collections :1, mode models :1</td>\n",
       "      <td>need more discount :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>come with a lot of money:1, it’s too expensive:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Al Barsha  negative  keywords   \n",
       "1  Joyalukkas Jewellery - Al Barsha  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  Not trustworthy:1, manipulated:1, wrong inform...   \n",
       "1  using paid services to increase its Shop Ratin...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  waiting :1, improve :1, unwelcoming :1, indiff...   \n",
       "1  waiting longtime :1, service is need to improv...   \n",
       "\n",
       "                                         Store Staff      Product Design  \\\n",
       "0  lazy :1, inexperienced :1, unwelcoming :1, ind...       old designs:1   \n",
       "1  very lazy staff :1, inexperienced staff :1, un...  Very old designs:1   \n",
       "\n",
       "                              Product Variety               Discount  \\\n",
       "0                   collections :1, models :1         No discount :1   \n",
       "1  little more collections :1, mode models :1  need more discount :1   \n",
       "\n",
       "                            Making Charge  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                              Price Product Quality  \\\n",
       "0                                   too expensive:1                   \n",
       "1  come with a lot of money:1, it’s too expensive:1                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_ab = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_ab[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_ab:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_ab'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_ab = pd.concat([negative_keywords_joy_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_ab = pd.concat([negative_keywords_joy_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_ab = negative_keywords_joy_ab.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b465bee7-3a48-496f-968d-dfae70d21d9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_st_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "ed1247e0-d885-4333-a603-12475ae74144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:17:29.861837Z",
     "iopub.status.busy": "2025-06-12T00:17:29.861515Z",
     "iopub.status.idle": "2025-06-12T00:17:49.398836Z",
     "shell.execute_reply": "2025-06-12T00:17:49.398280Z",
     "shell.execute_reply.started": "2025-06-12T00:17:29.861816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  19.5\n",
      "Total Input Tokens -  9318\n",
      "Total Input Cost = USD  0.09\n",
      "Total Output Tokens -  602\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.11\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_st_af = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_st_af=[0]\n",
    "keyword_input_token_joy_st_af = 0\n",
    "keyword_output_token_joy_st_af = 0\n",
    "keyword_start_time_loop_joy_st_af = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_st_af, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_st_af[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_st_af = keyword_dataframes['joy_st_af_final_sen_df_jul'][keyword_dataframes['joy_st_af_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_st_af:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_st_af,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_st_af.append(keywords)\n",
    "        keyword_input_token_joy_st_af += input_tokens_loop\n",
    "        keyword_output_token_joy_st_af += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_st_af = time.time()\n",
    "keyword_cost_input_token_joy_st_af = round((0.01/1000)*keyword_input_token_joy_st_af,2)\n",
    "keyword_cost_output_token_joy_st_af = round((0.03/1000)*keyword_output_token_joy_st_af,2)\n",
    "keyword_total_cost_joy_st_af = keyword_cost_input_token_joy_st_af + keyword_cost_output_token_joy_st_af\n",
    "keyword_total_time_loop_joy_st_af = keyword_end_time_loop_joy_st_af - keyword_start_time_loop_joy_st_af\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_st_af[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_st_af,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_st_af)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_st_af)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_st_af)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_st_af)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_st_af,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "a355e0e6-8446-416e-a1f9-90cd7309f250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:17:49.399893Z",
     "iopub.status.busy": "2025-06-12T00:17:49.399589Z",
     "iopub.status.idle": "2025-06-12T00:17:49.448774Z",
     "shell.execute_reply": "2025-06-12T00:17:49.448267Z",
     "shell.execute_reply.started": "2025-06-12T00:17:49.399872Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Al Fahidi st - Al Fahidi</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>crowd :1, mess :1, slow :1, suffocating :1, ti...</td>\n",
       "      <td>unprofessional :1, inefficient :1, compromised...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>ok ok :1, more updated :1, more design :1</td>\n",
       "      <td>enough discount:1, more discount:1</td>\n",
       "      <td>high :5, exorbitant :2, unreasonable :1, less ...</td>\n",
       "      <td>overprice:1, expensive:1, higher:1</td>\n",
       "      <td>broken :1, poor soldering :1, quality problems...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Al Fahidi st - Al Fahidi</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>store itself is a mess :1, suffocating crowd :...</td>\n",
       "      <td>more focused on google reviews than attending ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>Improve your nosepin collection :1, expecting ...</td>\n",
       "      <td>didn't give enough discount:1, need more disco...</td>\n",
       "      <td>making charges are very high :2, making charge...</td>\n",
       "      <td>question their prices:1, improvement on pricing:1</td>\n",
       "      <td>bracelet was broken just after 2 months :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Al Fahidi st - Al Fahidi  negative  keywords   \n",
       "1  Joyalukkas Jewellery - Al Fahidi st - Al Fahidi  negative   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  crowd :1, mess :1, slow :1, suffocating :1, ti...   \n",
       "1  store itself is a mess :1, suffocating crowd :...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  unprofessional :1, inefficient :1, compromised...   \n",
       "1  more focused on google reviews than attending ...   \n",
       "\n",
       "                           Product Design  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0          ok ok :1, more updated :1, more design :1   \n",
       "1  Improve your nosepin collection :1, expecting ...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                 enough discount:1, more discount:1   \n",
       "1  didn't give enough discount:1, need more disco...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  high :5, exorbitant :2, unreasonable :1, less ...   \n",
       "1  making charges are very high :2, making charge...   \n",
       "\n",
       "                                               Price  \\\n",
       "0                 overprice:1, expensive:1, higher:1   \n",
       "1  question their prices:1, improvement on pricing:1   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  broken :1, poor soldering :1, quality problems...                     \n",
       "1         bracelet was broken just after 2 months :1                     "
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_st_af = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_st_af[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_st_af:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_st_af'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_st_af = pd.concat([negative_keywords_joy_st_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_st_af = pd.concat([negative_keywords_joy_st_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_st_af = negative_keywords_joy_st_af.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_st_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56973986-ccfe-4b30-a45c-42a60ee11caa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_dm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "dc6de147-2852-466a-9650-9fa09779845c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:17:49.449921Z",
     "iopub.status.busy": "2025-06-12T00:17:49.449657Z",
     "iopub.status.idle": "2025-06-12T00:18:08.987937Z",
     "shell.execute_reply": "2025-06-12T00:18:08.987413Z",
     "shell.execute_reply.started": "2025-06-12T00:17:49.449896Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  19.5\n",
      "Total Input Tokens -  7798\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  550\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_dm_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_dm_ad=[0]\n",
    "keyword_input_token_joy_dm_ad = 0\n",
    "keyword_output_token_joy_dm_ad = 0\n",
    "keyword_start_time_loop_joy_dm_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_dm_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_dm_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_dm_ad = keyword_dataframes['joy_dm_ad_final_sen_df_jul'][keyword_dataframes['joy_dm_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_dm_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_dm_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_dm_ad.append(keywords)\n",
    "        keyword_input_token_joy_dm_ad += input_tokens_loop\n",
    "        keyword_output_token_joy_dm_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_dm_ad = time.time()\n",
    "keyword_cost_input_token_joy_dm_ad = round((0.01/1000)*keyword_input_token_joy_dm_ad,2)\n",
    "keyword_cost_output_token_joy_dm_ad = round((0.03/1000)*keyword_output_token_joy_dm_ad,2)\n",
    "keyword_total_cost_joy_dm_ad = keyword_cost_input_token_joy_dm_ad + keyword_cost_output_token_joy_dm_ad\n",
    "keyword_total_time_loop_joy_dm_ad = keyword_end_time_loop_joy_dm_ad - keyword_start_time_loop_joy_dm_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_dm_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_dm_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_dm_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_dm_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_dm_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_dm_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_dm_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "402f81cc-d561-443b-9514-a77909854d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:08.988903Z",
     "iopub.status.busy": "2025-06-12T00:18:08.988633Z",
     "iopub.status.idle": "2025-06-12T00:18:09.034416Z",
     "shell.execute_reply": "2025-06-12T00:18:09.033958Z",
     "shell.execute_reply.started": "2025-06-12T00:18:08.988885Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>misleading :1, loss :1, not recommended :1, no...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>ego :2, arrogance :1, conceited :1, unprofessi...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>limited :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>not correct:2, reduced:1, less:1, unhappy:1</td>\n",
       "      <td>non bargaining :1, reduce :1</td>\n",
       "      <td>become white:2, bad experience:2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>didn't allowed to take the jewellery :1, gold ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>don't have any courtesy to how to talk and tre...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>choices/ options seemed a bit limited :1, Coll...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>calculation given for making charges is not co...</td>\n",
       "      <td>good price :1, ask again money :1, reduce the ...</td>\n",
       "      <td>it's become white:2, don't sure about their pr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi  negative  keywords   \n",
       "1  Joyalukkas Jewellery - Dalma Plaza - Abu Dhabi  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  misleading :1, loss :1, not recommended :1, no...   \n",
       "1  didn't allowed to take the jewellery :1, gold ...   \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  ego :2, arrogance :1, conceited :1, unprofessi...   \n",
       "1  don't have any courtesy to how to talk and tre...   \n",
       "\n",
       "                           Product Design  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                                         limited :1   \n",
       "1  choices/ options seemed a bit limited :1, Coll...   \n",
       "\n",
       "                                 Discount  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0        not correct:2, reduced:1, less:1, unhappy:1   \n",
       "1  calculation given for making charges is not co...   \n",
       "\n",
       "                                               Price  \\\n",
       "0                       non bargaining :1, reduce :1   \n",
       "1  good price :1, ask again money :1, reduce the ...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0                   become white:2, bad experience:2                     \n",
       "1  it's become white:2, don't sure about their pr...                     "
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_dm_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_dm_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_dm_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_dm_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_dm_ad = pd.concat([negative_keywords_joy_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_dm_ad = pd.concat([negative_keywords_joy_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_dm_ad = negative_keywords_joy_dm_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_dm_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f785b-a91b-4d50-878c-3cbb27fd5faa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_mz_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "97a49d26-cb34-4ae8-ac3c-09f067b6ae93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:09.035307Z",
     "iopub.status.busy": "2025-06-12T00:18:09.035063Z",
     "iopub.status.idle": "2025-06-12T00:18:29.074644Z",
     "shell.execute_reply": "2025-06-12T00:18:29.074120Z",
     "shell.execute_reply.started": "2025-06-12T00:18:09.035290Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  20.0\n",
      "Total Input Tokens -  8264\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  595\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_mz_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_mz_ad=[0]\n",
    "keyword_input_token_joy_mz_ad = 0\n",
    "keyword_output_token_joy_mz_ad = 0\n",
    "keyword_start_time_loop_joy_mz_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_mz_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_mz_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_mz_ad = keyword_dataframes['joy_mz_ad_final_sen_df_jul'][keyword_dataframes['joy_mz_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_mz_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_mz_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_mz_ad.append(keywords)\n",
    "        keyword_input_token_joy_mz_ad += input_tokens_loop\n",
    "        keyword_output_token_joy_mz_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_mz_ad = time.time()\n",
    "keyword_cost_input_token_joy_mz_ad = round((0.01/1000)*keyword_input_token_joy_mz_ad,2)\n",
    "keyword_cost_output_token_joy_mz_ad = round((0.03/1000)*keyword_output_token_joy_mz_ad,2)\n",
    "keyword_total_cost_joy_mz_ad = keyword_cost_input_token_joy_mz_ad + keyword_cost_output_token_joy_mz_ad\n",
    "keyword_total_time_loop_joy_mz_ad = keyword_end_time_loop_joy_mz_ad - keyword_start_time_loop_joy_mz_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_mz_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_mz_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_mz_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_mz_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_mz_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_mz_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_mz_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "66b88bed-3695-4006-8224-a6306388c621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:29.077176Z",
     "iopub.status.busy": "2025-06-12T00:18:29.076799Z",
     "iopub.status.idle": "2025-06-12T00:18:29.122608Z",
     "shell.execute_reply": "2025-06-12T00:18:29.122128Z",
     "shell.execute_reply.started": "2025-06-12T00:18:29.077156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Madinat Zayed Shopping ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>tricks :1, blame :1</td>\n",
       "      <td>bad service: 2, rude: 2, worst: 2, disinterest...</td>\n",
       "      <td>rude :4, disinterested :1, dishonest :1, horri...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>fake offers:1</td>\n",
       "      <td>fake offers:1, extra charges:1</td>\n",
       "      <td>extra charges: 2, expensive: 1, over amount: 1...</td>\n",
       "      <td>broken :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Madinat Zayed Shopping ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>say different amount :2, mistake is from them ...</td>\n",
       "      <td>waited there for almost 30 mins: 1, waited for...</td>\n",
       "      <td>staff was so rude :1, very rudely attitude :1,...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>50% off form making charge but same product ma...</td>\n",
       "      <td>making charge of an item it was 6% now there i...</td>\n",
       "      <td>deduct 4%: 1, lie about gold price: 1, promisi...</td>\n",
       "      <td>yellow ish brownish :1, broken piece :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Madinat Zayed Shopping ...  negative  keywords   \n",
       "1  Joyalukkas Jewellery - Madinat Zayed Shopping ...  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                                tricks :1, blame :1   \n",
       "1  say different amount :2, mistake is from them ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  bad service: 2, rude: 2, worst: 2, disinterest...   \n",
       "1  waited there for almost 30 mins: 1, waited for...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :4, disinterested :1, dishonest :1, horri...                  \n",
       "1  staff was so rude :1, very rudely attitude :1,...                  \n",
       "\n",
       "                          Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                                      fake offers:1   \n",
       "1  50% off form making charge but same product ma...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                     fake offers:1, extra charges:1   \n",
       "1  making charge of an item it was 6% now there i...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  extra charges: 2, expensive: 1, over amount: 1...   \n",
       "1  deduct 4%: 1, lie about gold price: 1, promisi...   \n",
       "\n",
       "                           Product Quality Jewellery Exchange  \n",
       "0                                broken :1                     \n",
       "1  yellow ish brownish :1, broken piece :1                     "
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_mz_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_mz_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_mz_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_mz_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_mz_ad = pd.concat([negative_keywords_joy_mz_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_mz_ad = pd.concat([negative_keywords_joy_mz_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_mz_ad = negative_keywords_joy_mz_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_mz_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24324fb8-5413-4c21-96d7-92568e2b06b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_sh_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "cd1e28d7-eaec-466d-979e-94b87a061e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:29.123394Z",
     "iopub.status.busy": "2025-06-12T00:18:29.123213Z",
     "iopub.status.idle": "2025-06-12T00:18:46.661435Z",
     "shell.execute_reply": "2025-06-12T00:18:46.660863Z",
     "shell.execute_reply.started": "2025-06-12T00:18:29.123378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.5\n",
      "Total Input Tokens -  8308\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  524\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_sh_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_sh_ad=[0]\n",
    "keyword_input_token_joy_sh_ad = 0\n",
    "keyword_output_token_joy_sh_ad = 0\n",
    "keyword_start_time_loop_joy_sh_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_sh_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_sh_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_sh_ad = keyword_dataframes['joy_sh_ad_final_sen_df_jul'][keyword_dataframes['joy_sh_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_sh_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_sh_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_sh_ad.append(keywords)\n",
    "        keyword_input_token_joy_sh_ad += input_tokens_loop\n",
    "        keyword_output_token_joy_sh_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_sh_ad = time.time()\n",
    "keyword_cost_input_token_joy_sh_ad = round((0.01/1000)*keyword_input_token_joy_sh_ad,2)\n",
    "keyword_cost_output_token_joy_sh_ad = round((0.03/1000)*keyword_output_token_joy_sh_ad,2)\n",
    "keyword_total_cost_joy_sh_ad = keyword_cost_input_token_joy_sh_ad + keyword_cost_output_token_joy_sh_ad\n",
    "keyword_total_time_loop_joy_sh_ad = keyword_end_time_loop_joy_sh_ad - keyword_start_time_loop_joy_sh_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_sh_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_sh_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_sh_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_sh_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_sh_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_sh_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_sh_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "4f6e39cf-d41f-45cc-a1a4-ab09f9484f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:46.662425Z",
     "iopub.status.busy": "2025-06-12T00:18:46.662227Z",
     "iopub.status.idle": "2025-06-12T00:18:46.707031Z",
     "shell.execute_reply": "2025-06-12T00:18:46.706496Z",
     "shell.execute_reply.started": "2025-06-12T00:18:46.662407Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Shabia - Abu Dhabi</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>no resell :2, scam :1, fishy :1, lost :1, tran...</td>\n",
       "      <td>Slow bill :2, bad service :2, very bad :2, wor...</td>\n",
       "      <td>unprofessional :1, dismissive :1, arrogant :1,...</td>\n",
       "      <td>twisted design:1, uncomfortable:1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>high :1</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Shabia - Abu Dhabi</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>didn't find an estimate :1, no resell value :1...</td>\n",
       "      <td>very Slow bill payment :1, spend the time more...</td>\n",
       "      <td>doesn’t respect customers :2, don’t even give ...</td>\n",
       "      <td>started coming apart:1, pricking my neck:1, ha...</td>\n",
       "      <td>Not much collections :1, No light weight items :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>Making charge is very high :1</td>\n",
       "      <td></td>\n",
       "      <td>started coming apart :1, pricking my neck :1, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Shabia - Abu Dhabi  negative  keywords   \n",
       "1  Joyalukkas Jewellery - Shabia - Abu Dhabi  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  no resell :2, scam :1, fishy :1, lost :1, tran...   \n",
       "1  didn't find an estimate :1, no resell value :1...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  Slow bill :2, bad service :2, very bad :2, wor...   \n",
       "1  very Slow bill payment :1, spend the time more...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  unprofessional :1, dismissive :1, arrogant :1,...   \n",
       "1  doesn’t respect customers :2, don’t even give ...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0                  twisted design:1, uncomfortable:1   \n",
       "1  started coming apart:1, pricking my neck:1, ha...   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0             No relevant negative keywords/ phrases   \n",
       "1  Not much collections :1, No light weight items :1   \n",
       "\n",
       "                                 Discount                  Making Charge  \\\n",
       "0  No relevant negative keywords/ phrases                        high :1   \n",
       "1  No relevant negative keywords/ phrases  Making charge is very high :1   \n",
       "\n",
       "  Price                                    Product Quality Jewellery Exchange  \n",
       "0                   No relevant negative keywords/ phrases                     \n",
       "1        started coming apart :1, pricking my neck :1, ...                     "
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_sh_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_sh_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_sh_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_sh_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_sh_ad = pd.concat([negative_keywords_joy_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_sh_ad = pd.concat([negative_keywords_joy_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_sh_ad = negative_keywords_joy_sh_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_sh_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad802d-0425-4d7e-8e79-fc94d77a7973",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "8e11d9be-1e46-420e-aaa3-bd8c695dffe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:46.708194Z",
     "iopub.status.busy": "2025-06-12T00:18:46.707891Z",
     "iopub.status.idle": "2025-06-12T00:18:58.737714Z",
     "shell.execute_reply": "2025-06-12T00:18:58.737170Z",
     "shell.execute_reply.started": "2025-06-12T00:18:46.708167Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  12.0\n",
      "Total Input Tokens -  6610\n",
      "Total Input Cost = USD  0.07\n",
      "Total Output Tokens -  439\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_sc = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_sc=[0]\n",
    "keyword_input_token_mal_sc = 0\n",
    "keyword_output_token_mal_sc = 0\n",
    "keyword_start_time_loop_mal_sc = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_sc, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_sc[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_sc = keyword_dataframes['mal_sc_final_sen_df_jul'][keyword_dataframes['mal_sc_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_sc:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_sc,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_sc.append(keywords)\n",
    "        keyword_input_token_mal_sc += input_tokens_loop\n",
    "        keyword_output_token_mal_sc += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_sc = time.time()\n",
    "keyword_cost_input_token_mal_sc = round((0.01/1000)*keyword_input_token_mal_sc,2)\n",
    "keyword_cost_output_token_mal_sc = round((0.03/1000)*keyword_output_token_mal_sc,2)\n",
    "keyword_total_cost_mal_sc = keyword_cost_input_token_mal_sc + keyword_cost_output_token_mal_sc\n",
    "keyword_total_time_loop_mal_sc = keyword_end_time_loop_mal_sc - keyword_start_time_loop_mal_sc\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_sc[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_sc,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_sc)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_sc)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_sc)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_sc)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_sc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "aa319d4f-e597-497b-b4e7-e0ca6d029a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:58.738627Z",
     "iopub.status.busy": "2025-06-12T00:18:58.738417Z",
     "iopub.status.idle": "2025-06-12T00:18:58.776193Z",
     "shell.execute_reply": "2025-06-12T00:18:58.775642Z",
     "shell.execute_reply.started": "2025-06-12T00:18:58.738610Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>misleading :1, unprofessional :1, cheated :1, ...</td>\n",
       "      <td>waited :2, wasted :1, disappointing :1, irrita...</td>\n",
       "      <td>rude :2, ignored :1, not bothered :1, smirk :1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no-discount :1, refused :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>higher priced:1, budget:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>doesn't know how to deal with customers :1, do...</td>\n",
       "      <td>wait for 15 days :1, waited and wasted few min...</td>\n",
       "      <td>no other staffs too couldn’t see us :1, just I...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>offered me 50 AED discount on making charge :1...</td>\n",
       "      <td>I felt I paid lil more on making charges:1, ma...</td>\n",
       "      <td>quoted higher priced products:1, judged based ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds - Silicon Oasis Central  negative  keywords   \n",
       "1  Malabar Gold & Diamonds - Silicon Oasis Central  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  misleading :1, unprofessional :1, cheated :1, ...   \n",
       "1  doesn't know how to deal with customers :1, do...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  waited :2, wasted :1, disappointing :1, irrita...   \n",
       "1  wait for 15 days :1, waited and wasted few min...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :2, ignored :1, not bothered :1, smirk :1...                  \n",
       "1  no other staffs too couldn’t see us :1, just I...                  \n",
       "\n",
       "  Product Variety                                           Discount  \\\n",
       "0                                         no-discount :1, refused :1   \n",
       "1                  offered me 50 AED discount on making charge :1...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0             No relevant negative keywords/ phrases   \n",
       "1  I felt I paid lil more on making charges:1, ma...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                          higher priced:1, budget:1                   \n",
       "1  quoted higher priced products:1, judged based ...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_sc = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_sc[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_sc:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_sc'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_sc = pd.concat([negative_keywords_mal_sc, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_sc = pd.concat([negative_keywords_mal_sc, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_sc = negative_keywords_mal_sc.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec87c5-cb60-4939-a9fe-2c8e88750e8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "81ae822a-0831-45af-8572-b809336c7eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:18:58.777105Z",
     "iopub.status.busy": "2025-06-12T00:18:58.776855Z",
     "iopub.status.idle": "2025-06-12T00:19:19.318326Z",
     "shell.execute_reply": "2025-06-12T00:19:19.317792Z",
     "shell.execute_reply.started": "2025-06-12T00:18:58.777087Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  20.5\n",
      "Total Input Tokens -  10389\n",
      "Total Input Cost = USD  0.1\n",
      "Total Output Tokens -  645\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_ab = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_ab=[0]\n",
    "keyword_input_token_mal_ab = 0\n",
    "keyword_output_token_mal_ab = 0\n",
    "keyword_start_time_loop_mal_ab = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ab, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ab[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ab = keyword_dataframes['mal_ab_final_sen_df_jul'][keyword_dataframes['mal_ab_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_ab:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_ab,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_ab.append(keywords)\n",
    "        keyword_input_token_mal_ab += input_tokens_loop\n",
    "        keyword_output_token_mal_ab += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ab = time.time()\n",
    "keyword_cost_input_token_mal_ab = round((0.01/1000)*keyword_input_token_mal_ab,2)\n",
    "keyword_cost_output_token_mal_ab = round((0.03/1000)*keyword_output_token_mal_ab,2)\n",
    "keyword_total_cost_mal_ab = keyword_cost_input_token_mal_ab + keyword_cost_output_token_mal_ab\n",
    "keyword_total_time_loop_mal_ab = keyword_end_time_loop_mal_ab - keyword_start_time_loop_mal_ab\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_ab[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_ab,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_ab)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_ab)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_ab)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_ab)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_ab,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "df6bf9d1-7f6f-4a58-a5a8-35c63fdccad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:19:19.319367Z",
     "iopub.status.busy": "2025-06-12T00:19:19.319097Z",
     "iopub.status.idle": "2025-06-12T00:19:19.367037Z",
     "shell.execute_reply": "2025-06-12T00:19:19.366499Z",
     "shell.execute_reply.started": "2025-06-12T00:19:19.319348Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Barsha - Dubai</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>scam :1, deceived :1, cheated :1, lied :1, unp...</td>\n",
       "      <td>cold person: 2, unwelcoming: 2, bad experience...</td>\n",
       "      <td>rude :2, unprofessional :2, lazy :1, cold :1, ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>poor collection:1, more options:1</td>\n",
       "      <td>not happy:1, not giving:1</td>\n",
       "      <td>high making :3, fake :1</td>\n",
       "      <td>high :2, negotiate :1, discounts :1, reduced :...</td>\n",
       "      <td>cracked :2, old :1, used :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Barsha - Dubai</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>scam customers :1, seller assured me :1, lied ...</td>\n",
       "      <td>not even attended: 1, not a very nice gesture:...</td>\n",
       "      <td>very rude and unprofessional staff :1, no one ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>very poor collection for kids earings:1, don't...</td>\n",
       "      <td>asked many times for discounts:1, not giving g...</td>\n",
       "      <td>making charges they are taking these days :1, ...</td>\n",
       "      <td>exponentially high side :1, making cost is ver...</td>\n",
       "      <td>not cracked :1, will not crack :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Barsha - Dubai  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Barsha - Dubai  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  scam :1, deceived :1, cheated :1, lied :1, unp...   \n",
       "1  scam customers :1, seller assured me :1, lied ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  cold person: 2, unwelcoming: 2, bad experience...   \n",
       "1  not even attended: 1, not a very nice gesture:...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :2, unprofessional :2, lazy :1, cold :1, ...   \n",
       "1  very rude and unprofessional staff :1, no one ...   \n",
       "\n",
       "                           Product Design  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                  poor collection:1, more options:1   \n",
       "1  very poor collection for kids earings:1, don't...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                          not happy:1, not giving:1   \n",
       "1  asked many times for discounts:1, not giving g...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                            high making :3, fake :1   \n",
       "1  making charges they are taking these days :1, ...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  high :2, negotiate :1, discounts :1, reduced :...   \n",
       "1  exponentially high side :1, making cost is ver...   \n",
       "\n",
       "                     Product Quality Jewellery Exchange  \n",
       "0        cracked :2, old :1, used :1                     \n",
       "1  not cracked :1, will not crack :1                     "
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_ab = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_ab[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_ab:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ab'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_ab = pd.concat([negative_keywords_mal_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_ab = pd.concat([negative_keywords_mal_ab, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_ab = negative_keywords_mal_ab.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e220d5-ac57-4c90-9a3b-9dac363cf9d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_b1_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "99fc0127-1db6-44d5-9115-55b344124561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:19:19.368217Z",
     "iopub.status.busy": "2025-06-12T00:19:19.367908Z",
     "iopub.status.idle": "2025-06-12T00:19:34.403116Z",
     "shell.execute_reply": "2025-06-12T00:19:34.402478Z",
     "shell.execute_reply.started": "2025-06-12T00:19:19.368190Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  15.0\n",
      "Total Input Tokens -  7856\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  500\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.09\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_b1_af = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_b1_af=[0]\n",
    "keyword_input_token_mal_b1_af = 0\n",
    "keyword_output_token_mal_b1_af = 0\n",
    "keyword_start_time_loop_mal_b1_af = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b1_af, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b1_af[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b1_af = keyword_dataframes['mal_b1_af_final_sen_df_jul'][keyword_dataframes['mal_b1_af_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_b1_af:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_b1_af,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_b1_af.append(keywords)\n",
    "        keyword_input_token_mal_b1_af += input_tokens_loop\n",
    "        keyword_output_token_mal_b1_af += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b1_af = time.time()\n",
    "keyword_cost_input_token_mal_b1_af = round((0.01/1000)*keyword_input_token_mal_b1_af,2)\n",
    "keyword_cost_output_token_mal_b1_af = round((0.03/1000)*keyword_output_token_mal_b1_af,2)\n",
    "keyword_total_cost_mal_b1_af = keyword_cost_input_token_mal_b1_af + keyword_cost_output_token_mal_b1_af\n",
    "keyword_total_time_loop_mal_b1_af = keyword_end_time_loop_mal_b1_af - keyword_start_time_loop_mal_b1_af\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_b1_af[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_b1_af,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_b1_af)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_b1_af)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_b1_af)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_b1_af)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_b1_af,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "a8319513-2b4e-4667-a6b9-5feb85fd1320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:19:34.404271Z",
     "iopub.status.busy": "2025-06-12T00:19:34.403947Z",
     "iopub.status.idle": "2025-06-12T00:19:34.452958Z",
     "shell.execute_reply": "2025-06-12T00:19:34.452386Z",
     "shell.execute_reply.started": "2025-06-12T00:19:34.404243Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street -...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>shattered trust:1, betrayed:1, cheated:1, dism...</td>\n",
       "      <td>unfriendly :3, unprofessional :1, lazy :1, arr...</td>\n",
       "      <td>unfriendly :2, unprofessional :1, lazy :1, arr...</td>\n",
       "      <td>less designs :1</td>\n",
       "      <td></td>\n",
       "      <td>more discount:2, bonus money:1, false commitme...</td>\n",
       "      <td></td>\n",
       "      <td>expensive:1, loss:1</td>\n",
       "      <td></td>\n",
       "      <td>can't exchange:1, only in Dubai:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street -...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>payment was delayed:1, shattered my trust in y...</td>\n",
       "      <td>very unprofessional staff :1, not a pleasant s...</td>\n",
       "      <td>passing customer to each other :2, hesitant to...</td>\n",
       "      <td>No relevant negative phrases</td>\n",
       "      <td></td>\n",
       "      <td>store needs to add more discount:2, not provid...</td>\n",
       "      <td></td>\n",
       "      <td>huge loss:1, financial loss:1, too expensive:1</td>\n",
       "      <td></td>\n",
       "      <td>told me we can't exchange:1, you can exchange ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Fahidi Street -...  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Fahidi Street -...  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  shattered trust:1, betrayed:1, cheated:1, dism...   \n",
       "1  payment was delayed:1, shattered my trust in y...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unfriendly :3, unprofessional :1, lazy :1, arr...   \n",
       "1  very unprofessional staff :1, not a pleasant s...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  unfriendly :2, unprofessional :1, lazy :1, arr...   \n",
       "1  passing customer to each other :2, hesitant to...   \n",
       "\n",
       "                 Product Design Product Variety  \\\n",
       "0               less designs :1                   \n",
       "1  No relevant negative phrases                   \n",
       "\n",
       "                                            Discount Making Charge  \\\n",
       "0  more discount:2, bonus money:1, false commitme...                 \n",
       "1  store needs to add more discount:2, not provid...                 \n",
       "\n",
       "                                            Price Product Quality  \\\n",
       "0                             expensive:1, loss:1                   \n",
       "1  huge loss:1, financial loss:1, too expensive:1                   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                  can't exchange:1, only in Dubai:1  \n",
       "1  told me we can't exchange:1, you can exchange ...  "
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_b1_af = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_b1_af[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_b1_af:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b1_af'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_b1_af = pd.concat([negative_keywords_mal_b1_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_b1_af = pd.concat([negative_keywords_mal_b1_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_b1_af = negative_keywords_mal_b1_af.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_b1_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e07758-437d-4527-b774-ce732a8175e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "ddbb48e9-2592-4581-8f30-f39f188dfbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:19:34.454108Z",
     "iopub.status.busy": "2025-06-12T00:19:34.453756Z",
     "iopub.status.idle": "2025-06-12T00:19:52.997838Z",
     "shell.execute_reply": "2025-06-12T00:19:52.997257Z",
     "shell.execute_reply.started": "2025-06-12T00:19:34.454079Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  18.5\n",
      "Total Input Tokens -  9552\n",
      "Total Input Cost = USD  0.1\n",
      "Total Output Tokens -  676\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_ak=[0]\n",
    "keyword_input_token_mal_ak = 0\n",
    "keyword_output_token_mal_ak = 0\n",
    "keyword_start_time_loop_mal_ak = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ak[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ak = keyword_dataframes['mal_ak_final_sen_df_jul'][keyword_dataframes['mal_ak_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_ak:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_ak,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_ak.append(keywords)\n",
    "        keyword_input_token_mal_ak += input_tokens_loop\n",
    "        keyword_output_token_mal_ak += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ak = time.time()\n",
    "keyword_cost_input_token_mal_ak = round((0.01/1000)*keyword_input_token_mal_ak,2)\n",
    "keyword_cost_output_token_mal_ak = round((0.03/1000)*keyword_output_token_mal_ak,2)\n",
    "keyword_total_cost_mal_ak = keyword_cost_input_token_mal_ak + keyword_cost_output_token_mal_ak\n",
    "keyword_total_time_loop_mal_ak = keyword_end_time_loop_mal_ak - keyword_start_time_loop_mal_ak\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_ak[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_ak,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_ak)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_ak)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_ak)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_ak)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_ak,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "89bf48aa-f025-4b84-80c3-1e857b95b805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:19:52.999244Z",
     "iopub.status.busy": "2025-06-12T00:19:52.998705Z",
     "iopub.status.idle": "2025-06-12T00:19:53.085981Z",
     "shell.execute_reply": "2025-06-12T00:19:53.085288Z",
     "shell.execute_reply.started": "2025-06-12T00:19:52.999223Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Karama - Dubai</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>unacceptable :1, overpriced :1, frustrating :1...</td>\n",
       "      <td>poor service: 3, bad experience: 2, waiting: 2...</td>\n",
       "      <td>unattentive :2, disinterested :1, reluctant :1...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>fewer collections :1</td>\n",
       "      <td>no discount :1, more discount :1, overpriced :...</td>\n",
       "      <td>high :3, no negotiation :1, more % :1</td>\n",
       "      <td>increased :1, high :1, overpriced :1, differen...</td>\n",
       "      <td>broke:2, poor quality:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Karama - Dubai</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>not honor a price we agree on :1, do not negot...</td>\n",
       "      <td>nobody assist us: 1, no one attended to me: 1,...</td>\n",
       "      <td>very weird look :1, didn't even look at the in...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative phrases</td>\n",
       "      <td>no discount :1, more discount :1, do not negot...</td>\n",
       "      <td>making charge is very high :1, quite more % of...</td>\n",
       "      <td>increased gold prices :1, making charges is hi...</td>\n",
       "      <td>links snapped:1, broke within 2 months:1, brok...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Karama - Dubai  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Karama - Dubai  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  unacceptable :1, overpriced :1, frustrating :1...   \n",
       "1  not honor a price we agree on :1, do not negot...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  poor service: 3, bad experience: 2, waiting: 2...   \n",
       "1  nobody assist us: 1, no one attended to me: 1,...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  unattentive :2, disinterested :1, reluctant :1...   \n",
       "1  very weird look :1, didn't even look at the in...   \n",
       "\n",
       "                           Product Design               Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases          fewer collections :1   \n",
       "1  No relevant negative keywords/ phrases  No relevant negative phrases   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  no discount :1, more discount :1, overpriced :...   \n",
       "1  no discount :1, more discount :1, do not negot...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0              high :3, no negotiation :1, more % :1   \n",
       "1  making charge is very high :1, quite more % of...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  increased :1, high :1, overpriced :1, differen...   \n",
       "1  increased gold prices :1, making charges is hi...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0                            broke:2, poor quality:1                     \n",
       "1  links snapped:1, broke within 2 months:1, brok...                     "
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_ak = pd.concat([negative_keywords_mal_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_ak = pd.concat([negative_keywords_mal_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_ak = negative_keywords_mal_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37dd9f1-1fe4-40fc-b6c5-4f79d4e49df2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_aw_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "ddbe4a8f-d2fa-491e-a7fb-e77a84d65698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:19:53.087506Z",
     "iopub.status.busy": "2025-06-12T00:19:53.087149Z",
     "iopub.status.idle": "2025-06-12T00:20:02.617595Z",
     "shell.execute_reply": "2025-06-12T00:20:02.617088Z",
     "shell.execute_reply.started": "2025-06-12T00:19:53.087473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  9.5\n",
      "Total Input Tokens -  4530\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  288\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_aw_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_aw_ad=[0]\n",
    "keyword_input_token_mal_aw_ad = 0\n",
    "keyword_output_token_mal_aw_ad = 0\n",
    "keyword_start_time_loop_mal_aw_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_aw_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_aw_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_aw_ad = keyword_dataframes['mal_aw_ad_final_sen_df_jul'][keyword_dataframes['mal_aw_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_aw_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_aw_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_aw_ad.append(keywords)\n",
    "        keyword_input_token_mal_aw_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_aw_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_aw_ad = time.time()\n",
    "keyword_cost_input_token_mal_aw_ad = round((0.01/1000)*keyword_input_token_mal_aw_ad,2)\n",
    "keyword_cost_output_token_mal_aw_ad = round((0.03/1000)*keyword_output_token_mal_aw_ad,2)\n",
    "keyword_total_cost_mal_aw_ad = keyword_cost_input_token_mal_aw_ad + keyword_cost_output_token_mal_aw_ad\n",
    "keyword_total_time_loop_mal_aw_ad = keyword_end_time_loop_mal_aw_ad - keyword_start_time_loop_mal_aw_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_aw_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_aw_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_aw_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_aw_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_aw_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_aw_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_aw_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "b27286ae-0c90-4c46-bc7f-1ce43ae418b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:02.618920Z",
     "iopub.status.busy": "2025-06-12T00:20:02.618376Z",
     "iopub.status.idle": "2025-06-12T00:20:02.656680Z",
     "shell.execute_reply": "2025-06-12T00:20:02.656209Z",
     "shell.execute_reply.started": "2025-06-12T00:20:02.618897Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Wahda Mall - Ab...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>system delay:1, attitude:1</td>\n",
       "      <td>rude :1, disrespected :1, attitude :1, unhappy...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Wahda Mall - Ab...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>billing took more than 1 hour:1, get the item ...</td>\n",
       "      <td>Worst staff ever :1, treats customers with no ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Al Wahda Mall - Ab...  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Al Wahda Mall - Ab...  negative   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0                         system delay:1, attitude:1   \n",
       "1  billing took more than 1 hour:1, get the item ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :1, disrespected :1, attitude :1, unhappy...                  \n",
       "1  Worst staff ever :1, treats customers with no ...                  \n",
       "\n",
       "  Product Variety Discount                           Making Charge Price  \\\n",
       "0                           No relevant negative keywords/ phrases         \n",
       "1                           No relevant negative keywords/ phrases         \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_aw_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_aw_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_aw_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_aw_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_aw_ad = pd.concat([negative_keywords_mal_aw_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_aw_ad = pd.concat([negative_keywords_mal_aw_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_aw_ad = negative_keywords_mal_aw_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_aw_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07e72a-e222-445d-964f-c8d4fa1abf06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_dm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "60efab48-c965-4c87-b689-43db223f17b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:02.657916Z",
     "iopub.status.busy": "2025-06-12T00:20:02.657466Z",
     "iopub.status.idle": "2025-06-12T00:20:11.180184Z",
     "shell.execute_reply": "2025-06-12T00:20:11.179678Z",
     "shell.execute_reply.started": "2025-06-12T00:20:02.657888Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  8.5\n",
      "Total Input Tokens -  2645\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  263\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_dm_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_dm_ad=[0]\n",
    "keyword_input_token_mal_dm_ad = 0\n",
    "keyword_output_token_mal_dm_ad = 0\n",
    "keyword_start_time_loop_mal_dm_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_dm_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_dm_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_dm_ad = keyword_dataframes['mal_dm_ad_final_sen_df_jul'][keyword_dataframes['mal_dm_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_dm_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_dm_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_dm_ad.append(keywords)\n",
    "        keyword_input_token_mal_dm_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_dm_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_dm_ad = time.time()\n",
    "keyword_cost_input_token_mal_dm_ad = round((0.01/1000)*keyword_input_token_mal_dm_ad,2)\n",
    "keyword_cost_output_token_mal_dm_ad = round((0.03/1000)*keyword_output_token_mal_dm_ad,2)\n",
    "keyword_total_cost_mal_dm_ad = keyword_cost_input_token_mal_dm_ad + keyword_cost_output_token_mal_dm_ad\n",
    "keyword_total_time_loop_mal_dm_ad = keyword_end_time_loop_mal_dm_ad - keyword_start_time_loop_mal_dm_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_dm_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_dm_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_dm_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_dm_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_dm_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_dm_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_dm_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "41e0ae3b-9a1a-4884-ba15-ac721a32b004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:11.181170Z",
     "iopub.status.busy": "2025-06-12T00:20:11.180893Z",
     "iopub.status.idle": "2025-06-12T00:20:11.211743Z",
     "shell.execute_reply": "2025-06-12T00:20:11.211317Z",
     "shell.execute_reply.started": "2025-06-12T00:20:11.181153Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Dalma Mall - Abu D...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>waiting :2, disappointing :2, unattended :1, i...</td>\n",
       "      <td>bad service :2, disappointing :2, bad experien...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high make:1, making charge:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Dalma Mall - Abu D...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>waited for 10 mints and left :1, no one asked ...</td>\n",
       "      <td>no one asked for any supports :1, staff standi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>making charge little high:1, 200% making charg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Dalma Mall - Abu D...  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Dalma Mall - Abu D...  negative   phrases   \n",
       "\n",
       "  Customer Confidence                                   Store Experience  \\\n",
       "0                      waiting :2, disappointing :2, unattended :1, i...   \n",
       "1                      waited for 10 mints and left :1, no one asked ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  bad service :2, disappointing :2, bad experien...                  \n",
       "1  no one asked for any supports :1, staff standi...                  \n",
       "\n",
       "  Product Variety Discount                                      Making Charge  \\\n",
       "0                                                high make:1, making charge:1   \n",
       "1                           making charge little high:1, 200% making charg...   \n",
       "\n",
       "  Price Product Quality Jewellery Exchange  \n",
       "0                                           \n",
       "1                                           "
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_dm_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_dm_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_dm_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_dm_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_dm_ad = pd.concat([negative_keywords_mal_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_dm_ad = pd.concat([negative_keywords_mal_dm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_dm_ad = negative_keywords_mal_dm_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_dm_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7eb51-de7b-469f-846e-c922534fc38c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_b1_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "181ec82c-559f-4de4-976c-93828c563830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:11.212670Z",
     "iopub.status.busy": "2025-06-12T00:20:11.212403Z",
     "iopub.status.idle": "2025-06-12T00:20:23.742819Z",
     "shell.execute_reply": "2025-06-12T00:20:23.742319Z",
     "shell.execute_reply.started": "2025-06-12T00:20:11.212651Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  12.5\n",
      "Total Input Tokens -  5550\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  306\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_b1_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_b1_ad=[0]\n",
    "keyword_input_token_mal_b1_ad = 0\n",
    "keyword_output_token_mal_b1_ad = 0\n",
    "keyword_start_time_loop_mal_b1_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b1_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b1_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b1_ad = keyword_dataframes['mal_b1_ad_final_sen_df_jul'][keyword_dataframes['mal_b1_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_b1_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_b1_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_b1_ad.append(keywords)\n",
    "        keyword_input_token_mal_b1_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_b1_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b1_ad = time.time()\n",
    "keyword_cost_input_token_mal_b1_ad = round((0.01/1000)*keyword_input_token_mal_b1_ad,2)\n",
    "keyword_cost_output_token_mal_b1_ad = round((0.03/1000)*keyword_output_token_mal_b1_ad,2)\n",
    "keyword_total_cost_mal_b1_ad = keyword_cost_input_token_mal_b1_ad + keyword_cost_output_token_mal_b1_ad\n",
    "keyword_total_time_loop_mal_b1_ad = keyword_end_time_loop_mal_b1_ad - keyword_start_time_loop_mal_b1_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_b1_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_b1_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_b1_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_b1_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_b1_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_b1_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_b1_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "a701c5bc-35f2-4fb7-8fb5-149619cfbb80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:23.743723Z",
     "iopub.status.busy": "2025-06-12T00:20:23.743474Z",
     "iopub.status.idle": "2025-06-12T00:20:23.784883Z",
     "shell.execute_reply": "2025-06-12T00:20:23.784362Z",
     "shell.execute_reply.started": "2025-06-12T00:20:23.743705Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street ( Br...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>disinterested :1, not friendly :1</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>maximum discount:1</td>\n",
       "      <td>high :2, unbelievable :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street ( Br...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>Sales person was disinterested in us :1, manag...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>didn't got maximum discount:1</td>\n",
       "      <td>way too high :1, too high :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Hamdan Street ( Br...  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Hamdan Street ( Br...  negative   phrases   \n",
       "\n",
       "  Customer Confidence                        Store Experience  \\\n",
       "0                      No relevant negative keywords/ phrases   \n",
       "1                      No relevant negative keywords/ phrases   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0                  disinterested :1, not friendly :1                  \n",
       "1  Sales person was disinterested in us :1, manag...                  \n",
       "\n",
       "                          Product Variety                       Discount  \\\n",
       "0  No relevant negative keywords/ phrases             maximum discount:1   \n",
       "1  No relevant negative keywords/ phrases  didn't got maximum discount:1   \n",
       "\n",
       "                  Making Charge                                   Price  \\\n",
       "0      high :2, unbelievable :1  No relevant negative keywords/ phrases   \n",
       "1  way too high :1, too high :1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                     \n",
       "1  No relevant negative keywords/ phrases                     "
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_b1_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_b1_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_b1_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b1_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_b1_ad = pd.concat([negative_keywords_mal_b1_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_b1_ad = pd.concat([negative_keywords_mal_b1_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_b1_ad = negative_keywords_mal_b1_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_b1_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d0ff3-f11a-43c5-9be5-dfaf6d48303f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_b2_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "f663e171-d9cb-467d-8267-ac5b3fca6484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:23.786093Z",
     "iopub.status.busy": "2025-06-12T00:20:23.785663Z",
     "iopub.status.idle": "2025-06-12T00:20:34.312673Z",
     "shell.execute_reply": "2025-06-12T00:20:34.312123Z",
     "shell.execute_reply.started": "2025-06-12T00:20:23.786066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.5\n",
      "Total Input Tokens -  5352\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  367\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_b2_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_b2_ad=[0]\n",
    "keyword_input_token_mal_b2_ad = 0\n",
    "keyword_output_token_mal_b2_ad = 0\n",
    "keyword_start_time_loop_mal_b2_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b2_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b2_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b2_ad = keyword_dataframes['mal_b2_ad_final_sen_df_jul'][keyword_dataframes['mal_b2_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_b2_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_b2_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_b2_ad.append(keywords)\n",
    "        keyword_input_token_mal_b2_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_b2_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b2_ad = time.time()\n",
    "keyword_cost_input_token_mal_b2_ad = round((0.01/1000)*keyword_input_token_mal_b2_ad,2)\n",
    "keyword_cost_output_token_mal_b2_ad = round((0.03/1000)*keyword_output_token_mal_b2_ad,2)\n",
    "keyword_total_cost_mal_b2_ad = keyword_cost_input_token_mal_b2_ad + keyword_cost_output_token_mal_b2_ad\n",
    "keyword_total_time_loop_mal_b2_ad = keyword_end_time_loop_mal_b2_ad - keyword_start_time_loop_mal_b2_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_b2_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_b2_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_b2_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_b2_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_b2_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_b2_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_b2_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "95632d96-3204-4189-abe6-6a945b36797f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:34.316470Z",
     "iopub.status.busy": "2025-06-12T00:20:34.316142Z",
     "iopub.status.idle": "2025-06-12T00:20:34.352253Z",
     "shell.execute_reply": "2025-06-12T00:20:34.351717Z",
     "shell.execute_reply.started": "2025-06-12T00:20:34.316450Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street (Bra...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>congested :1, disappointing :1, uncomfortable ...</td>\n",
       "      <td>rude :1, attitude issue :1, not friendly :1, b...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>higher :2, high :1</td>\n",
       "      <td>expensive: 2, additional: 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Hamdan Street (Bra...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>congested place :1, no chairs :1, no toilettes...</td>\n",
       "      <td>very rude with customers :1, don’t even look a...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>making charges are bit higher comparatively :1...</td>\n",
       "      <td>expensive gifts: 2, rising gold prices: 1, inc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Hamdan Street (Bra...  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Hamdan Street (Bra...  negative   phrases   \n",
       "\n",
       "  Customer Confidence                                   Store Experience  \\\n",
       "0                      congested :1, disappointing :1, uncomfortable ...   \n",
       "1                      congested place :1, no chairs :1, no toilettes...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :1, attitude issue :1, not friendly :1, b...                  \n",
       "1  very rude with customers :1, don’t even look a...                  \n",
       "\n",
       "                          Product Variety Discount  \\\n",
       "0  No relevant negative keywords/ phrases            \n",
       "1  No relevant negative keywords/ phrases            \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                                 higher :2, high :1   \n",
       "1  making charges are bit higher comparatively :1...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                        expensive: 2, additional: 1                   \n",
       "1  expensive gifts: 2, rising gold prices: 1, inc...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_b2_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_b2_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_b2_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b2_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_b2_ad = pd.concat([negative_keywords_mal_b2_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_b2_ad = pd.concat([negative_keywords_mal_b2_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_b2_ad = negative_keywords_mal_b2_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_b2_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7ca5d-eed4-434e-9dbd-df3d3a8ef456",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_lu_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "7c510f79-61ab-4aa8-8029-f127083ac4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:34.353335Z",
     "iopub.status.busy": "2025-06-12T00:20:34.352949Z",
     "iopub.status.idle": "2025-06-12T00:20:51.894239Z",
     "shell.execute_reply": "2025-06-12T00:20:51.893623Z",
     "shell.execute_reply.started": "2025-06-12T00:20:34.353315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.5\n",
      "Total Input Tokens -  6762\n",
      "Total Input Cost = USD  0.07\n",
      "Total Output Tokens -  496\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_lu_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_lu_ad=[0]\n",
    "keyword_input_token_mal_lu_ad = 0\n",
    "keyword_output_token_mal_lu_ad = 0\n",
    "keyword_start_time_loop_mal_lu_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_lu_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_lu_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_lu_ad = keyword_dataframes['mal_lu_ad_final_sen_df_jul'][keyword_dataframes['mal_lu_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_lu_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_lu_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_lu_ad.append(keywords)\n",
    "        keyword_input_token_mal_lu_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_lu_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_lu_ad = time.time()\n",
    "keyword_cost_input_token_mal_lu_ad = round((0.01/1000)*keyword_input_token_mal_lu_ad,2)\n",
    "keyword_cost_output_token_mal_lu_ad = round((0.03/1000)*keyword_output_token_mal_lu_ad,2)\n",
    "keyword_total_cost_mal_lu_ad = keyword_cost_input_token_mal_lu_ad + keyword_cost_output_token_mal_lu_ad\n",
    "keyword_total_time_loop_mal_lu_ad = keyword_end_time_loop_mal_lu_ad - keyword_start_time_loop_mal_lu_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_lu_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_lu_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_lu_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_lu_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_lu_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_lu_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_lu_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "d86bbb6a-3565-47eb-ac3b-b212b62e21ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:51.895493Z",
     "iopub.status.busy": "2025-06-12T00:20:51.895214Z",
     "iopub.status.idle": "2025-06-12T00:20:51.939350Z",
     "shell.execute_reply": "2025-06-12T00:20:51.938755Z",
     "shell.execute_reply.started": "2025-06-12T00:20:51.895465Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Lulu Hypermarket -...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>fake reviews:1, scam:1, doubt:1</td>\n",
       "      <td>crowded :1, poorly managed :1, worst :1, unhap...</td>\n",
       "      <td>bad behaviour :1, poor service :1, not good :1...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>gift voucher :2, making charges :2</td>\n",
       "      <td>high :1, reduce :1, better :1, increase :1</td>\n",
       "      <td></td>\n",
       "      <td>burned :1, soldering :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Lulu Hypermarket -...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>I suspect all are fake reviews:1, I personally...</td>\n",
       "      <td>Very crowded jewellery shop :1, have to stand ...</td>\n",
       "      <td>Staff attitudes vary bad :1, Christeena thomas...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>gift voucher scam :1, not useful :1, increase ...</td>\n",
       "      <td>way to high :1, reduce more in making charge :...</td>\n",
       "      <td></td>\n",
       "      <td>burn of soldering :1, doesnt look like the sam...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Lulu Hypermarket -...  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Lulu Hypermarket -...  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                    fake reviews:1, scam:1, doubt:1   \n",
       "1  I suspect all are fake reviews:1, I personally...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  crowded :1, poorly managed :1, worst :1, unhap...   \n",
       "1  Very crowded jewellery shop :1, have to stand ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  bad behaviour :1, poor service :1, not good :1...                  \n",
       "1  Staff attitudes vary bad :1, Christeena thomas...                  \n",
       "\n",
       "                          Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                 gift voucher :2, making charges :2   \n",
       "1  gift voucher scam :1, not useful :1, increase ...   \n",
       "\n",
       "                                       Making Charge Price  \\\n",
       "0         high :1, reduce :1, better :1, increase :1         \n",
       "1  way to high :1, reduce more in making charge :...         \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0                            burned :1, soldering :1                     \n",
       "1  burn of soldering :1, doesnt look like the sam...                     "
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_lu_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_lu_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_lu_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_lu_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_lu_ad = pd.concat([negative_keywords_mal_lu_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_lu_ad = pd.concat([negative_keywords_mal_lu_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_lu_ad = negative_keywords_mal_lu_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_lu_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47285b03-cdc4-4db5-9968-1b06c52b90bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "21758afb-55e8-4046-a577-3d8b2e3e4174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:51.940386Z",
     "iopub.status.busy": "2025-06-12T00:20:51.940159Z",
     "iopub.status.idle": "2025-06-12T00:21:09.480568Z",
     "shell.execute_reply": "2025-06-12T00:21:09.479989Z",
     "shell.execute_reply.started": "2025-06-12T00:20:51.940368Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.5\n",
      "Total Input Tokens -  9387\n",
      "Total Input Cost = USD  0.09\n",
      "Total Output Tokens -  612\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.11\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_mb=[0]\n",
    "keyword_input_token_mal_mb = 0\n",
    "keyword_output_token_mal_mb = 0\n",
    "keyword_start_time_loop_mal_mb = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_mb[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_mb = keyword_dataframes['mal_mb_final_sen_df_jul'][keyword_dataframes['mal_mb_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_mb:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_mb,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_mb.append(keywords)\n",
    "        keyword_input_token_mal_mb += input_tokens_loop\n",
    "        keyword_output_token_mal_mb += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_mb = time.time()\n",
    "keyword_cost_input_token_mal_mb = round((0.01/1000)*keyword_input_token_mal_mb,2)\n",
    "keyword_cost_output_token_mal_mb = round((0.03/1000)*keyword_output_token_mal_mb,2)\n",
    "keyword_total_cost_mal_mb = keyword_cost_input_token_mal_mb + keyword_cost_output_token_mal_mb\n",
    "keyword_total_time_loop_mal_mb = keyword_end_time_loop_mal_mb - keyword_start_time_loop_mal_mb\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_mb[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_mb,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_mb)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_mb)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_mb)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_mb)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_mb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "a715decb-280d-47c5-9cd4-f1bb6509e5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:09.481538Z",
     "iopub.status.busy": "2025-06-12T00:21:09.481268Z",
     "iopub.status.idle": "2025-06-12T00:21:09.525121Z",
     "shell.execute_reply": "2025-06-12T00:21:09.524606Z",
     "shell.execute_reply.started": "2025-06-12T00:21:09.481518Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Meena Bazar - Dubai</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>liars :1, scammers :1, can't trust :1, unrelia...</td>\n",
       "      <td>bad service: 2, horrible experience: 1, pathet...</td>\n",
       "      <td>unhelpful :1, disinterested :1, rude :1, casua...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no discounts:1</td>\n",
       "      <td>high :2, reducing :1, justification :1, ruthle...</td>\n",
       "      <td>expensive: 2, costly: 1, increased: 1, more: 1...</td>\n",
       "      <td>flimsy:1, broke:2</td>\n",
       "      <td>Bad Experience:1, Bad service:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Meena Bazar - Dubai</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>charged ₹7500 for international transaction :1...</td>\n",
       "      <td>long wait for billing: 1, not attended properl...</td>\n",
       "      <td>not attended properly :1, busy on their social...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>More expensive and no discounts:1</td>\n",
       "      <td>making changes are high :1, reduce the making ...</td>\n",
       "      <td>Costed us a lot of money: 1, Expect to pay mor...</td>\n",
       "      <td>it broke:1, that also broke:1</td>\n",
       "      <td>deduct from old gold weight and price:1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Meena Bazar - Dubai  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Meena Bazar - Dubai  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  liars :1, scammers :1, can't trust :1, unrelia...   \n",
       "1  charged ₹7500 for international transaction :1...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  bad service: 2, horrible experience: 1, pathet...   \n",
       "1  long wait for billing: 1, not attended properl...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  unhelpful :1, disinterested :1, rude :1, casua...                  \n",
       "1  not attended properly :1, busy on their social...                  \n",
       "\n",
       "  Product Variety                           Discount  \\\n",
       "0                                     no discounts:1   \n",
       "1                  More expensive and no discounts:1   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  high :2, reducing :1, justification :1, ruthle...   \n",
       "1  making changes are high :1, reduce the making ...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  expensive: 2, costly: 1, increased: 1, more: 1...   \n",
       "1  Costed us a lot of money: 1, Expect to pay mor...   \n",
       "\n",
       "                 Product Quality                       Jewellery Exchange  \n",
       "0              flimsy:1, broke:2          Bad Experience:1, Bad service:1  \n",
       "1  it broke:1, that also broke:1  deduct from old gold weight and price:1  "
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_mb = pd.concat([negative_keywords_mal_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_mb = pd.concat([negative_keywords_mal_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_mb = negative_keywords_mal_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e3174-9950-4a80-ba40-017fba34fe1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_sh_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "0e7a4286-949a-4b70-b284-77ff8ab85add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:09.526809Z",
     "iopub.status.busy": "2025-06-12T00:21:09.526495Z",
     "iopub.status.idle": "2025-06-12T00:21:28.061665Z",
     "shell.execute_reply": "2025-06-12T00:21:28.061135Z",
     "shell.execute_reply.started": "2025-06-12T00:21:09.526788Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  18.5\n",
      "Total Input Tokens -  8437\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  631\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_sh_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_sh_ad=[0]\n",
    "keyword_input_token_mal_sh_ad = 0\n",
    "keyword_output_token_mal_sh_ad = 0\n",
    "keyword_start_time_loop_mal_sh_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_sh_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_sh_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_sh_ad = keyword_dataframes['mal_sh_ad_final_sen_df_jul'][keyword_dataframes['mal_sh_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_sh_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_sh_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_sh_ad.append(keywords)\n",
    "        keyword_input_token_mal_sh_ad += input_tokens_loop\n",
    "        keyword_output_token_mal_sh_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_sh_ad = time.time()\n",
    "keyword_cost_input_token_mal_sh_ad = round((0.01/1000)*keyword_input_token_mal_sh_ad,2)\n",
    "keyword_cost_output_token_mal_sh_ad = round((0.03/1000)*keyword_output_token_mal_sh_ad,2)\n",
    "keyword_total_cost_mal_sh_ad = keyword_cost_input_token_mal_sh_ad + keyword_cost_output_token_mal_sh_ad\n",
    "keyword_total_time_loop_mal_sh_ad = keyword_end_time_loop_mal_sh_ad - keyword_start_time_loop_mal_sh_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_sh_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_sh_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_sh_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_sh_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_sh_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_sh_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_sh_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "b9bf4e72-917b-448a-b00b-e83863fd0ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:28.062803Z",
     "iopub.status.busy": "2025-06-12T00:21:28.062436Z",
     "iopub.status.idle": "2025-06-12T00:21:28.107485Z",
     "shell.execute_reply": "2025-06-12T00:21:28.107027Z",
     "shell.execute_reply.started": "2025-06-12T00:21:28.062773Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Shabia Musaffah</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>refused :2, never accept :1, not updated :1, r...</td>\n",
       "      <td>unhelpful :1, uninterested :1, disappointing :...</td>\n",
       "      <td>unhelpful :1, uninterested :1, poor :1, vague ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>no discount:1, haggle:1</td>\n",
       "      <td>high :2, expensive :2, price :1, deduction :1,...</td>\n",
       "      <td>EXPENSIVE:1, overpriced:1, high:1, difference:...</td>\n",
       "      <td></td>\n",
       "      <td>refused :1, can't take :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Shabia Musaffah</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>never take back :1, not updated the same when ...</td>\n",
       "      <td>very poor customer service :1, nobody was atte...</td>\n",
       "      <td>never good behaviour with costumer :1, nobody ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>had to haggle hard for discount:1, buy gold wi...</td>\n",
       "      <td>making charge is too price :1, making charges ...</td>\n",
       "      <td>making charges too high:1, many a times more t...</td>\n",
       "      <td></td>\n",
       "      <td>tried to exchange today but they refused :1, M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Shabia Musaffah  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Shabia Musaffah  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  refused :2, never accept :1, not updated :1, r...   \n",
       "1  never take back :1, not updated the same when ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unhelpful :1, uninterested :1, disappointing :...   \n",
       "1  very poor customer service :1, nobody was atte...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  unhelpful :1, uninterested :1, poor :1, vague ...   \n",
       "1  never good behaviour with costumer :1, nobody ...   \n",
       "\n",
       "                           Product Design  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                          Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                            no discount:1, haggle:1   \n",
       "1  had to haggle hard for discount:1, buy gold wi...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  high :2, expensive :2, price :1, deduction :1,...   \n",
       "1  making charge is too price :1, making charges ...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0  EXPENSIVE:1, overpriced:1, high:1, difference:...                   \n",
       "1  making charges too high:1, many a times more t...                   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                          refused :1, can't take :1  \n",
       "1  tried to exchange today but they refused :1, M...  "
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_sh_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_sh_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_sh_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_sh_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_sh_ad = pd.concat([negative_keywords_mal_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_sh_ad = pd.concat([negative_keywords_mal_sh_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_sh_ad = negative_keywords_mal_sh_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_sh_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2838ee29-8f65-40aa-be9f-7788dc94af65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_b2_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "c079395e-ccc1-4b9d-a211-ac25a188a09a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:28.108359Z",
     "iopub.status.busy": "2025-06-12T00:21:28.108148Z",
     "iopub.status.idle": "2025-06-12T00:21:35.128363Z",
     "shell.execute_reply": "2025-06-12T00:21:35.127853Z",
     "shell.execute_reply.started": "2025-06-12T00:21:28.108341Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  7.0\n",
      "Total Input Tokens -  3115\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  208\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_b2_af = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_b2_af=[0]\n",
    "keyword_input_token_mal_b2_af = 0\n",
    "keyword_output_token_mal_b2_af = 0\n",
    "keyword_start_time_loop_mal_b2_af = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_b2_af, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_b2_af[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_b2_af = keyword_dataframes['mal_b2_af_final_sen_df_jul'][keyword_dataframes['mal_b2_af_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_b2_af:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_b2_af,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_b2_af.append(keywords)\n",
    "        keyword_input_token_mal_b2_af += input_tokens_loop\n",
    "        keyword_output_token_mal_b2_af += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_b2_af = time.time()\n",
    "keyword_cost_input_token_mal_b2_af = round((0.01/1000)*keyword_input_token_mal_b2_af,2)\n",
    "keyword_cost_output_token_mal_b2_af = round((0.03/1000)*keyword_output_token_mal_b2_af,2)\n",
    "keyword_total_cost_mal_b2_af = keyword_cost_input_token_mal_b2_af + keyword_cost_output_token_mal_b2_af\n",
    "keyword_total_time_loop_mal_b2_af = keyword_end_time_loop_mal_b2_af - keyword_start_time_loop_mal_b2_af\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_b2_af[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_b2_af,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_b2_af)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_b2_af)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_b2_af)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_b2_af)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_b2_af,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "7cefb94d-3552-4681-a125-37d57fa9b733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:35.129302Z",
     "iopub.status.busy": "2025-06-12T00:21:35.129031Z",
     "iopub.status.idle": "2025-06-12T00:21:35.161545Z",
     "shell.execute_reply": "2025-06-12T00:21:35.161090Z",
     "shell.execute_reply.started": "2025-06-12T00:21:35.129284Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold and Diamonds - Souq Al Kabeer Bui...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>worst level :1, don’t value :1</td>\n",
       "      <td>irresponsible:2, worst:1, bad:1, unacceptable:...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold and Diamonds - Souq Al Kabeer Bui...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>treat customers like beggars :1</td>\n",
       "      <td>rush to bill for their own customers:1, treat ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold and Diamonds - Souq Al Kabeer Bui...  negative  keywords   \n",
       "1  Malabar Gold and Diamonds - Souq Al Kabeer Bui...  negative   phrases   \n",
       "\n",
       "  Customer Confidence                 Store Experience  \\\n",
       "0                       worst level :1, don’t value :1   \n",
       "1                      treat customers like beggars :1   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  irresponsible:2, worst:1, bad:1, unacceptable:...                  \n",
       "1  rush to bill for their own customers:1, treat ...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                    Price Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                                     \n",
       "1  No relevant negative keywords/ phrases                                     "
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_b2_af = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_b2_af[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_b2_af:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_b2_af'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_b2_af = pd.concat([negative_keywords_mal_b2_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_b2_af = pd.concat([negative_keywords_mal_b2_af, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_b2_af = negative_keywords_mal_b2_af.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_b2_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18e3c9-5f5b-4fb1-bbec-492a40341ff1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mna_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "9fb7e5cd-99c2-47c3-b4a9-e5017f7872a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:35.162659Z",
     "iopub.status.busy": "2025-06-12T00:21:35.162310Z",
     "iopub.status.idle": "2025-06-12T00:21:44.187403Z",
     "shell.execute_reply": "2025-06-12T00:21:44.186888Z",
     "shell.execute_reply.started": "2025-06-12T00:21:35.162634Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  9.0\n",
      "Total Input Tokens -  3046\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  229\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mna_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mna_mb=[0]\n",
    "keyword_input_token_mna_mb = 0\n",
    "keyword_output_token_mna_mb = 0\n",
    "keyword_start_time_loop_mna_mb = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mna_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mna_mb[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mna_mb = keyword_dataframes['mna_mb_final_sen_df_jul'][keyword_dataframes['mna_mb_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mna_mb:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mna_mb,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mna_mb.append(keywords)\n",
    "        keyword_input_token_mna_mb += input_tokens_loop\n",
    "        keyword_output_token_mna_mb += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mna_mb = time.time()\n",
    "keyword_cost_input_token_mna_mb = round((0.01/1000)*keyword_input_token_mna_mb,2)\n",
    "keyword_cost_output_token_mna_mb = round((0.03/1000)*keyword_output_token_mna_mb,2)\n",
    "keyword_total_cost_mna_mb = keyword_cost_input_token_mna_mb + keyword_cost_output_token_mna_mb\n",
    "keyword_total_time_loop_mna_mb = keyword_end_time_loop_mna_mb - keyword_start_time_loop_mna_mb\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mna_mb[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mna_mb,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mna_mb)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mna_mb)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mna_mb)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mna_mb)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mna_mb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "56ebb4be-2a79-4cdb-9f07-a36d5d0ee47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:44.188744Z",
     "iopub.status.busy": "2025-06-12T00:21:44.188311Z",
     "iopub.status.idle": "2025-06-12T00:21:44.220819Z",
     "shell.execute_reply": "2025-06-12T00:21:44.220335Z",
     "shell.execute_reply.started": "2025-06-12T00:21:44.188721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meena Jewellers - Meena Bazar</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>Pathetic service:1, waited:1</td>\n",
       "      <td>impatient :1, attitude :1, no regard :1, bad s...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meena Jewellers - Meena Bazar</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>no regard for new customers:1, no one to attend:1</td>\n",
       "      <td>service you like it's a waste of time :1, no o...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Meena Jewellers - Meena Bazar  negative  keywords                       \n",
       "1  Meena Jewellers - Meena Bazar  negative   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0                       Pathetic service:1, waited:1   \n",
       "1  no regard for new customers:1, no one to attend:1   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  impatient :1, attitude :1, no regard :1, bad s...                  \n",
       "1  service you like it's a waste of time :1, no o...                  \n",
       "\n",
       "  Product Variety Discount                           Making Charge  \\\n",
       "0                           No relevant negative keywords/ phrases   \n",
       "1                           No relevant negative keywords/ phrases   \n",
       "\n",
       "                                    Price Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                                     \n",
       "1  No relevant negative keywords/ phrases                                     "
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mna_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mna_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mna_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mna_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mna_mb = pd.concat([negative_keywords_mna_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mna_mb = pd.concat([negative_keywords_mna_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mna_mb = negative_keywords_mna_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mna_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169f04b-865c-4b62-a3e2-f46a61f0e1de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### min_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "0aeceec4-b98e-42b9-a8fb-1c023514a12f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:44.221977Z",
     "iopub.status.busy": "2025-06-12T00:21:44.221648Z",
     "iopub.status.idle": "2025-06-12T00:21:56.752683Z",
     "shell.execute_reply": "2025-06-12T00:21:56.752153Z",
     "shell.execute_reply.started": "2025-06-12T00:21:44.221957Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  12.5\n",
      "Total Input Tokens -  5843\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  450\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_min_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_min_ak=[0]\n",
    "keyword_input_token_min_ak = 0\n",
    "keyword_output_token_min_ak = 0\n",
    "keyword_start_time_loop_min_ak = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_min_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_min_ak[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_min_ak = keyword_dataframes['min_ak_final_sen_df_jul'][keyword_dataframes['min_ak_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_min_ak:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_min_ak,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_min_ak.append(keywords)\n",
    "        keyword_input_token_min_ak += input_tokens_loop\n",
    "        keyword_output_token_min_ak += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_min_ak = time.time()\n",
    "keyword_cost_input_token_min_ak = round((0.01/1000)*keyword_input_token_min_ak,2)\n",
    "keyword_cost_output_token_min_ak = round((0.03/1000)*keyword_output_token_min_ak,2)\n",
    "keyword_total_cost_min_ak = keyword_cost_input_token_min_ak + keyword_cost_output_token_min_ak\n",
    "keyword_total_time_loop_min_ak = keyword_end_time_loop_min_ak - keyword_start_time_loop_min_ak\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_min_ak[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_min_ak,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_min_ak)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_min_ak)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_min_ak)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_min_ak)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_min_ak,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "1b3b1445-72fa-4fac-b876-bb873dac10d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:56.753727Z",
     "iopub.status.busy": "2025-06-12T00:21:56.753455Z",
     "iopub.status.idle": "2025-06-12T00:21:56.793975Z",
     "shell.execute_reply": "2025-06-12T00:21:56.793498Z",
     "shell.execute_reply.started": "2025-06-12T00:21:56.753708Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mint Jewels - Al Karama</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>unprofessional :2, dishonest :1, aggressive :1...</td>\n",
       "      <td>unorganized system :1, unprofessional manner :...</td>\n",
       "      <td>aggressive :1, yelling :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>low discount:1</td>\n",
       "      <td></td>\n",
       "      <td>high price: 3, incorrect rates: 1, lowest pric...</td>\n",
       "      <td>old :1, milk spots :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mint Jewels - Al Karama</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>no proper testing system :1, incorrect rate co...</td>\n",
       "      <td>no testing machines :1, incorrect rate codes :...</td>\n",
       "      <td>demeanour turned aggressive :1, Transparency a...</td>\n",
       "      <td></td>\n",
       "      <td>add more for buying gold: 1</td>\n",
       "      <td>more discount:1</td>\n",
       "      <td></td>\n",
       "      <td>extremely high: 1, price could be better: 1, p...</td>\n",
       "      <td>all their silver are old :1, have milk spots :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type  \\\n",
       "0  Mint Jewels - Al Karama  negative  keywords   \n",
       "1  Mint Jewels - Al Karama  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  unprofessional :2, dishonest :1, aggressive :1...   \n",
       "1  no proper testing system :1, incorrect rate co...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unorganized system :1, unprofessional manner :...   \n",
       "1  no testing machines :1, incorrect rate codes :...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0                          aggressive :1, yelling :1                  \n",
       "1  demeanour turned aggressive :1, Transparency a...                  \n",
       "\n",
       "               Product Variety         Discount Making Charge  \\\n",
       "0                                low discount:1                 \n",
       "1  add more for buying gold: 1  more discount:1                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  high price: 3, incorrect rates: 1, lowest pric...   \n",
       "1  extremely high: 1, price could be better: 1, p...   \n",
       "\n",
       "                                   Product Quality Jewellery Exchange  \n",
       "0                            old :1, milk spots :1                     \n",
       "1  all their silver are old :1, have milk spots :1                     "
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_min_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_min_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_min_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'min_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_min_ak = pd.concat([negative_keywords_min_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_min_ak = pd.concat([negative_keywords_min_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_min_ak = negative_keywords_min_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_min_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069902e-595f-4a18-b49a-072062d7cdc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "ddc56d86-373f-4f5c-af91-f88820cdf7e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:21:56.794890Z",
     "iopub.status.busy": "2025-06-12T00:21:56.794655Z",
     "iopub.status.idle": "2025-06-12T00:22:11.828515Z",
     "shell.execute_reply": "2025-06-12T00:22:11.827990Z",
     "shell.execute_reply.started": "2025-06-12T00:21:56.794874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  15.0\n",
      "Total Input Tokens -  7526\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  554\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_ak = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_ak=[0]\n",
    "keyword_input_token_joy_ak = 0\n",
    "keyword_output_token_joy_ak = 0\n",
    "keyword_start_time_loop_joy_ak = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_ak, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_ak[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_ak = keyword_dataframes['joy_ak_final_sen_df_jul'][keyword_dataframes['joy_ak_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_ak:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_ak,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_ak.append(keywords)\n",
    "        keyword_input_token_joy_ak += input_tokens_loop\n",
    "        keyword_output_token_joy_ak += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_ak = time.time()\n",
    "keyword_cost_input_token_joy_ak = round((0.01/1000)*keyword_input_token_joy_ak,2)\n",
    "keyword_cost_output_token_joy_ak = round((0.03/1000)*keyword_output_token_joy_ak,2)\n",
    "keyword_total_cost_joy_ak = keyword_cost_input_token_joy_ak + keyword_cost_output_token_joy_ak\n",
    "keyword_total_time_loop_joy_ak = keyword_end_time_loop_joy_ak - keyword_start_time_loop_joy_ak\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_ak[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_ak,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_ak)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_ak)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_ak)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_ak)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_ak,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "b986a1f5-f1dc-4173-a0c2-9e0719be0522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:11.829891Z",
     "iopub.status.busy": "2025-06-12T00:22:11.829253Z",
     "iopub.status.idle": "2025-06-12T00:22:11.874759Z",
     "shell.execute_reply": "2025-06-12T00:22:11.874288Z",
     "shell.execute_reply.started": "2025-06-12T00:22:11.829868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery - Al Karama</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>waiting :3, worst experience :1, bad experienc...</td>\n",
       "      <td>incompetent staffs:1, not supportive:1, ignori...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>limited :1, collection :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>making charges: 3, very high: 2</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>defective :1, fake :1, broken :1, bad quality ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery - Al Karama</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>Be prepared to wait for 40mins for them to com...</td>\n",
       "      <td>Salesman not supportive:1, took more than one ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>collections of long chain is limited :1, More ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>making charges r more: 1, charging making char...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>gold chain broken :1, bad gold quality :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery - Al Karama  negative  keywords   \n",
       "1  Joyalukkas Jewellery - Al Karama  negative   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  waiting :3, worst experience :1, bad experienc...   \n",
       "1  Be prepared to wait for 40mins for them to com...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  incompetent staffs:1, not supportive:1, ignori...   \n",
       "1  Salesman not supportive:1, took more than one ...   \n",
       "\n",
       "                           Product Design  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                          limited :1, collection :1   \n",
       "1  collections of long chain is limited :1, More ...   \n",
       "\n",
       "                                 Discount  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                    making charges: 3, very high: 2   \n",
       "1  making charges r more: 1, charging making char...   \n",
       "\n",
       "                                    Price  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  defective :1, fake :1, broken :1, bad quality ...                     \n",
       "1          gold chain broken :1, bad gold quality :1                     "
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_ak = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_ak[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_ak:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_ak'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_ak = pd.concat([negative_keywords_joy_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_ak = pd.concat([negative_keywords_joy_ak, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_ak = negative_keywords_joy_ak.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b336c6-9df5-4cd6-a43c-819b040690df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### kan_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "1b07937f-4f6a-4edb-8cbd-613d981412b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:11.875735Z",
     "iopub.status.busy": "2025-06-12T00:22:11.875520Z",
     "iopub.status.idle": "2025-06-12T00:22:15.391523Z",
     "shell.execute_reply": "2025-06-12T00:22:15.391029Z",
     "shell.execute_reply.started": "2025-06-12T00:22:11.875718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  3.5\n",
      "Total Input Tokens -  1519\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  68\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.02\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_kan_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_kan_mb=[0]\n",
    "keyword_input_token_kan_mb = 0\n",
    "keyword_output_token_kan_mb = 0\n",
    "keyword_start_time_loop_kan_mb = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_kan_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_kan_mb[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_kan_mb = keyword_dataframes['kan_mb_final_sen_df_jul'][keyword_dataframes['kan_mb_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_kan_mb:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_kan_mb,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_kan_mb.append(keywords)\n",
    "        keyword_input_token_kan_mb += input_tokens_loop\n",
    "        keyword_output_token_kan_mb += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_kan_mb = time.time()\n",
    "keyword_cost_input_token_kan_mb = round((0.01/1000)*keyword_input_token_kan_mb,2)\n",
    "keyword_cost_output_token_kan_mb = round((0.03/1000)*keyword_output_token_kan_mb,2)\n",
    "keyword_total_cost_kan_mb = keyword_cost_input_token_kan_mb + keyword_cost_output_token_kan_mb\n",
    "keyword_total_time_loop_kan_mb = keyword_end_time_loop_kan_mb - keyword_start_time_loop_kan_mb\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_kan_mb[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_kan_mb,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_kan_mb)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_kan_mb)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_kan_mb)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_kan_mb)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_kan_mb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "5e7d0218-f10e-4270-a684-5d2f3c5de2c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:15.392491Z",
     "iopub.status.busy": "2025-06-12T00:22:15.392240Z",
     "iopub.status.idle": "2025-06-12T00:22:15.420270Z",
     "shell.execute_reply": "2025-06-12T00:22:15.419725Z",
     "shell.execute_reply.started": "2025-06-12T00:22:15.392455Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kanz Jewellers</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kanz Jewellers</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store Name Sentiment      Type Customer Confidence Store Experience  \\\n",
       "0  Kanz Jewellers  negative  keywords                                        \n",
       "1  Kanz Jewellers  negative   phrases                                        \n",
       "\n",
       "                              Store Staff Product Design Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases                                  \n",
       "1  No relevant negative keywords/ phrases                                  \n",
       "\n",
       "  Discount Making Charge Price Product Quality Jewellery Exchange  \n",
       "0                                                                  \n",
       "1                                                                  "
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_kan_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_kan_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_kan_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'kan_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_kan_mb = pd.concat([negative_keywords_kan_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_kan_mb = pd.concat([negative_keywords_kan_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_kan_mb = negative_keywords_kan_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_kan_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821122a-a004-4a26-9958-072d7896801d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### agd_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "91ec58e1-41a2-433a-8ce6-36751423ddd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:15.421087Z",
     "iopub.status.busy": "2025-06-12T00:22:15.420899Z",
     "iopub.status.idle": "2025-06-12T00:22:17.434912Z",
     "shell.execute_reply": "2025-06-12T00:22:17.434373Z",
     "shell.execute_reply.started": "2025-06-12T00:22:15.421070Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  2.0\n",
      "Total Input Tokens -  1444\n",
      "Total Input Cost = USD  0.01\n",
      "Total Output Tokens -  81\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.01\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_agd_mb = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_agd_mb=[0]\n",
    "keyword_input_token_agd_mb = 0\n",
    "keyword_output_token_agd_mb = 0\n",
    "keyword_start_time_loop_agd_mb = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_agd_mb, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_agd_mb[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_agd_mb = keyword_dataframes['agd_mb_final_sen_df_jul'][keyword_dataframes['agd_mb_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_agd_mb:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_agd_mb,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_agd_mb.append(keywords)\n",
    "        keyword_input_token_agd_mb += input_tokens_loop\n",
    "        keyword_output_token_agd_mb += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_agd_mb = time.time()\n",
    "keyword_cost_input_token_agd_mb = round((0.01/1000)*keyword_input_token_agd_mb,2)\n",
    "keyword_cost_output_token_agd_mb = round((0.03/1000)*keyword_output_token_agd_mb,2)\n",
    "keyword_total_cost_agd_mb = keyword_cost_input_token_agd_mb + keyword_cost_output_token_agd_mb\n",
    "keyword_total_time_loop_agd_mb = keyword_end_time_loop_agd_mb - keyword_start_time_loop_agd_mb\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_agd_mb[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_agd_mb,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_agd_mb)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_agd_mb)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_agd_mb)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_agd_mb)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_agd_mb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "3616ab77-3d8c-49ed-9362-ae7da177e791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:17.435898Z",
     "iopub.status.busy": "2025-06-12T00:22:17.435599Z",
     "iopub.status.idle": "2025-06-12T00:22:17.462778Z",
     "shell.execute_reply": "2025-06-12T00:22:17.462315Z",
     "shell.execute_reply.started": "2025-06-12T00:22:17.435879Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arakkal Gold and Diamonds LLC - Meena Bazar - ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arakkal Gold and Diamonds LLC - Meena Bazar - ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Store Name Sentiment      Type  \\\n",
       "0  Arakkal Gold and Diamonds LLC - Meena Bazar - ...  negative  keywords   \n",
       "1  Arakkal Gold and Diamonds LLC - Meena Bazar - ...  negative   phrases   \n",
       "\n",
       "  Customer Confidence                        Store Experience Store Staff  \\\n",
       "0                      No relevant negative keywords/ phrases               \n",
       "1                      No relevant negative keywords/ phrases               \n",
       "\n",
       "  Product Design Product Variety Discount Making Charge  \\\n",
       "0                                                         \n",
       "1                                                         \n",
       "\n",
       "                                    Price Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                                     \n",
       "1  No relevant negative keywords/ phrases                                     "
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_agd_mb = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_agd_mb[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_agd_mb:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'agd_mb'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_agd_mb = pd.concat([negative_keywords_agd_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_agd_mb = pd.concat([negative_keywords_agd_mb, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_agd_mb = negative_keywords_agd_mb.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_agd_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cbcca-4459-4d6f-a93e-3d67d2cd8761",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### bhi_dec_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "32739818-bc5c-490f-8519-36c2bb7b25a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:17.463618Z",
     "iopub.status.busy": "2025-06-12T00:22:17.463386Z",
     "iopub.status.idle": "2025-06-12T00:22:27.988478Z",
     "shell.execute_reply": "2025-06-12T00:22:27.987956Z",
     "shell.execute_reply.started": "2025-06-12T00:22:17.463601Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.5\n",
      "Total Input Tokens -  4829\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  341\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_bhi_dec_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_bhi_dec_ga=[0]\n",
    "keyword_input_token_bhi_dec_ga = 0\n",
    "keyword_output_token_bhi_dec_ga = 0\n",
    "keyword_start_time_loop_bhi_dec_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_bhi_dec_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_bhi_dec_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_bhi_dec_ga = keyword_dataframes['bhi_dec_ga_final_sen_df_jul'][keyword_dataframes['bhi_dec_ga_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_bhi_dec_ga:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_bhi_dec_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_bhi_dec_ga.append(keywords)\n",
    "        keyword_input_token_bhi_dec_ga += input_tokens_loop\n",
    "        keyword_output_token_bhi_dec_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_bhi_dec_ga = time.time()\n",
    "keyword_cost_input_token_bhi_dec_ga = round((0.01/1000)*keyword_input_token_bhi_dec_ga,2)\n",
    "keyword_cost_output_token_bhi_dec_ga = round((0.03/1000)*keyword_output_token_bhi_dec_ga,2)\n",
    "keyword_total_cost_bhi_dec_ga = keyword_cost_input_token_bhi_dec_ga + keyword_cost_output_token_bhi_dec_ga\n",
    "keyword_total_time_loop_bhi_dec_ga = keyword_end_time_loop_bhi_dec_ga - keyword_start_time_loop_bhi_dec_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_bhi_dec_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_bhi_dec_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_bhi_dec_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_bhi_dec_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_bhi_dec_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_bhi_dec_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_bhi_dec_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "e69818f5-a22d-4b9f-882f-4a5bb7e3b8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:27.989436Z",
     "iopub.status.busy": "2025-06-12T00:22:27.989159Z",
     "iopub.status.idle": "2025-06-12T00:22:28.023805Z",
     "shell.execute_reply": "2025-06-12T00:22:28.023360Z",
     "shell.execute_reply.started": "2025-06-12T00:22:27.989419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bhindi Jewellers-Decatur, GA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>scam :1, fake gold :1, crooked :1, cheat :1, n...</td>\n",
       "      <td>locked door :1, appointment required :1, turne...</td>\n",
       "      <td>not responsible :1, not respond :1, turned awa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inflated :1, expensive :1, more :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bhindi Jewellers-Decatur, GA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Product not as ordered :1, sells Rolex’s direc...</td>\n",
       "      <td>store owner was not responsible :1, staff stoo...</td>\n",
       "      <td>staff stood by looking like I came to rob the ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inflated price :1, more than any other places ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Store Name Sentiment      Type  \\\n",
       "0  Bhindi Jewellers-Decatur, GA  negative  keywords   \n",
       "1  Bhindi Jewellers-Decatur, GA  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  scam :1, fake gold :1, crooked :1, cheat :1, n...   \n",
       "1  Product not as ordered :1, sells Rolex’s direc...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  locked door :1, appointment required :1, turne...   \n",
       "1  store owner was not responsible :1, staff stoo...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  not responsible :1, not respond :1, turned awa...                  \n",
       "1  staff stood by looking like I came to rob the ...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                               Price  \\\n",
       "0                 inflated :1, expensive :1, more :1   \n",
       "1  inflated price :1, more than any other places ...   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                     \n",
       "1  No relevant negative keywords/ phrases                     "
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_bhi_dec_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_bhi_dec_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_bhi_dec_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'bhi_dec_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_bhi_dec_ga = pd.concat([negative_keywords_bhi_dec_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_bhi_dec_ga = pd.concat([negative_keywords_bhi_dec_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_bhi_dec_ga = negative_keywords_bhi_dec_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_bhi_dec_ga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e78763-4c38-48bb-afe8-a2539b09b3ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### eve_joh_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "990d3da7-bfbb-4aa7-87be-c619528e6163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  0.0\n",
      "Total Input Tokens -  0\n",
      "Total Input Cost = USD  0.0\n",
      "Total Output Tokens -  0\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_eve_joh_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_eve_joh_ga=[0]\n",
    "keyword_input_token_eve_joh_ga = 0\n",
    "keyword_output_token_eve_joh_ga = 0\n",
    "keyword_start_time_loop_eve_joh_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_eve_joh_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_eve_joh_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_eve_joh_ga = keyword_dataframes['eve_joh_ga_final_sen_df_jul'][keyword_dataframes['eve_joh_ga_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_eve_joh_ga:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_eve_joh_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_eve_joh_ga.append(keywords)\n",
    "        keyword_input_token_eve_joh_ga += input_tokens_loop\n",
    "        keyword_output_token_eve_joh_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_eve_joh_ga = time.time()\n",
    "keyword_cost_input_token_eve_joh_ga = round((0.01/1000)*keyword_input_token_eve_joh_ga,2)\n",
    "keyword_cost_output_token_eve_joh_ga = round((0.03/1000)*keyword_output_token_eve_joh_ga,2)\n",
    "keyword_total_cost_eve_joh_ga = keyword_cost_input_token_eve_joh_ga + keyword_cost_output_token_eve_joh_ga\n",
    "keyword_total_time_loop_eve_joh_ga = keyword_end_time_loop_eve_joh_ga - keyword_start_time_loop_eve_joh_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_eve_joh_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_eve_joh_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_eve_joh_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_eve_joh_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_eve_joh_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_eve_joh_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_eve_joh_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "799cea81-3690-4a67-b638-dac8caa2abcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Type, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1264/2278586414.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mrow_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{ph.strip()}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnegative_keywords_eve_joh_ga\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnegative_keywords_eve_joh_ga\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mnegative_keywords_eve_joh_ga\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_keywords_eve_joh_ga\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mnegative_keywords_eve_joh_ga\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     )\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             )\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert Type, already exists"
     ]
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_eve_joh_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_eve_joh_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_eve_joh_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'eve_joh_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_eve_joh_ga = pd.concat([negative_keywords_eve_joh_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_eve_joh_ga = pd.concat([negative_keywords_eve_joh_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_eve_joh_ga = negative_keywords_eve_joh_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_eve_joh_ga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa2582-f231-43ad-86df-abb86d8dec64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### jar_bol_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "dbf9ddca-847a-4228-aca2-66648ecb3086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:28.024739Z",
     "iopub.status.busy": "2025-06-12T00:22:28.024479Z",
     "iopub.status.idle": "2025-06-12T00:22:38.051513Z",
     "shell.execute_reply": "2025-06-12T00:22:38.050916Z",
     "shell.execute_reply.started": "2025-06-12T00:22:28.024722Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.0\n",
      "Total Input Tokens -  5068\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  304\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_jar_bol_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_bol_il=[0]\n",
    "keyword_input_token_jar_bol_il = 0\n",
    "keyword_output_token_jar_bol_il = 0\n",
    "keyword_start_time_loop_jar_bol_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_bol_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_bol_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_bol_il = keyword_dataframes['jar_bol_il_final_sen_df_jul'][keyword_dataframes['jar_bol_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_jar_bol_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_jar_bol_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_jar_bol_il.append(keywords)\n",
    "        keyword_input_token_jar_bol_il += input_tokens_loop\n",
    "        keyword_output_token_jar_bol_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_bol_il = time.time()\n",
    "keyword_cost_input_token_jar_bol_il = round((0.01/1000)*keyword_input_token_jar_bol_il,2)\n",
    "keyword_cost_output_token_jar_bol_il = round((0.03/1000)*keyword_output_token_jar_bol_il,2)\n",
    "keyword_total_cost_jar_bol_il = keyword_cost_input_token_jar_bol_il + keyword_cost_output_token_jar_bol_il\n",
    "keyword_total_time_loop_jar_bol_il = keyword_end_time_loop_jar_bol_il - keyword_start_time_loop_jar_bol_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_bol_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_bol_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_bol_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_bol_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_bol_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_bol_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_bol_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "89682a80-750f-4af3-9d32-045e4d3dd24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:38.053074Z",
     "iopub.status.busy": "2025-06-12T00:22:38.052379Z",
     "iopub.status.idle": "2025-06-12T00:22:38.098421Z",
     "shell.execute_reply": "2025-06-12T00:22:38.097817Z",
     "shell.execute_reply.started": "2025-06-12T00:22:38.053041Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Bolingbrook, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>unprofessional :1, unknowledgeable :1, shady :...</td>\n",
       "      <td>rude :6, unprofessional :1, unwelcoming :1, mi...</td>\n",
       "      <td>rude :6, unprofessional :1, unknowledgeable :1...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Bolingbrook, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>low toned, sarcastic comments :1, not advanced...</td>\n",
       "      <td>waited 45min before helping :1, not welcoming ...</td>\n",
       "      <td>rude unnecessary questions :1, rude unnecessar...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store Name Sentiment      Type  \\\n",
       "0  Jared-Bolingbrook, IL  negative  keywords   \n",
       "1  Jared-Bolingbrook, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  unprofessional :1, unknowledgeable :1, shady :...   \n",
       "1  low toned, sarcastic comments :1, not advanced...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  rude :6, unprofessional :1, unwelcoming :1, mi...   \n",
       "1  waited 45min before helping :1, not welcoming ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :6, unprofessional :1, unknowledgeable :1...                  \n",
       "1  rude unnecessary questions :1, rude unnecessar...                  \n",
       "\n",
       "                          Product Variety Discount Making Charge Price  \\\n",
       "0  No relevant negative keywords/ phrases                                \n",
       "1  No relevant negative keywords/ phrases                                \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_jar_bol_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_jar_bol_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_jar_bol_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_bol_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_jar_bol_il = pd.concat([negative_keywords_jar_bol_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_jar_bol_il = pd.concat([negative_keywords_jar_bol_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_jar_bol_il = negative_keywords_jar_bol_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_jar_bol_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed2033-ef13-4a17-a81d-aa181050912a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### jar_ver_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "c1c134f9-ca57-43d9-8dde-5c3c8b54f1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:38.100222Z",
     "iopub.status.busy": "2025-06-12T00:22:38.100005Z",
     "iopub.status.idle": "2025-06-12T00:22:49.133147Z",
     "shell.execute_reply": "2025-06-12T00:22:49.132503Z",
     "shell.execute_reply.started": "2025-06-12T00:22:38.100204Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  11.0\n",
      "Total Input Tokens -  5726\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  410\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_jar_ver_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_ver_il=[0]\n",
    "keyword_input_token_jar_ver_il = 0\n",
    "keyword_output_token_jar_ver_il = 0\n",
    "keyword_start_time_loop_jar_ver_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_ver_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_ver_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_ver_il = keyword_dataframes['jar_ver_il_final_sen_df_jul'][keyword_dataframes['jar_ver_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_jar_ver_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_jar_ver_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_jar_ver_il.append(keywords)\n",
    "        keyword_input_token_jar_ver_il += input_tokens_loop\n",
    "        keyword_output_token_jar_ver_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_ver_il = time.time()\n",
    "keyword_cost_input_token_jar_ver_il = round((0.01/1000)*keyword_input_token_jar_ver_il,2)\n",
    "keyword_cost_output_token_jar_ver_il = round((0.03/1000)*keyword_output_token_jar_ver_il,2)\n",
    "keyword_total_cost_jar_ver_il = keyword_cost_input_token_jar_ver_il + keyword_cost_output_token_jar_ver_il\n",
    "keyword_total_time_loop_jar_ver_il = keyword_end_time_loop_jar_ver_il - keyword_start_time_loop_jar_ver_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_ver_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_ver_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_ver_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_ver_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_ver_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_ver_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_ver_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "75bd2522-8908-47ec-bcf2-6de5e44de48d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:49.134382Z",
     "iopub.status.busy": "2025-06-12T00:22:49.134023Z",
     "iopub.status.idle": "2025-06-12T00:22:49.171429Z",
     "shell.execute_reply": "2025-06-12T00:22:49.170837Z",
     "shell.execute_reply.started": "2025-06-12T00:22:49.134352Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Vernon Hills, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>don't trust :1, not happy :1, don't live :1, n...</td>\n",
       "      <td>rude :2, condescending :1, wrong ring :1, stin...</td>\n",
       "      <td>rude :3, condescending :1, dismissive :1, vola...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hefty amount:1, pay $1400:1</td>\n",
       "      <td>diamonds falling :1, quality product :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Vernon Hills, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>don't trust a store owner to update :1, diamon...</td>\n",
       "      <td>immediate attitude of the manager :1, incredib...</td>\n",
       "      <td>extremely rude and volatile :1, verbally abusi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>spent a hefty amount:1, pay $1400 to select a ...</td>\n",
       "      <td>diamonds keep falling out :1, not enough to bu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Store Name Sentiment      Type  \\\n",
       "0  Jared-Vernon Hills, IL  negative  keywords   \n",
       "1  Jared-Vernon Hills, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  don't trust :1, not happy :1, don't live :1, n...   \n",
       "1  don't trust a store owner to update :1, diamon...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  rude :2, condescending :1, wrong ring :1, stin...   \n",
       "1  immediate attitude of the manager :1, incredib...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :3, condescending :1, dismissive :1, vola...                  \n",
       "1  extremely rude and volatile :1, verbally abusi...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                               Price  \\\n",
       "0                        hefty amount:1, pay $1400:1   \n",
       "1  spent a hefty amount:1, pay $1400 to select a ...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0            diamonds falling :1, quality product :1                     \n",
       "1  diamonds keep falling out :1, not enough to bu...                     "
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_jar_ver_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_jar_ver_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_jar_ver_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_ver_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_jar_ver_il = pd.concat([negative_keywords_jar_ver_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_jar_ver_il = pd.concat([negative_keywords_jar_ver_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_jar_ver_il = negative_keywords_jar_ver_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_jar_ver_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716164d7-814d-46ea-be9a-5af19faa644c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### jar_lom_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "f6910f02-461e-4cf0-be13-e992997241e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:49.172741Z",
     "iopub.status.busy": "2025-06-12T00:22:49.172468Z",
     "iopub.status.idle": "2025-06-12T00:22:58.706982Z",
     "shell.execute_reply": "2025-06-12T00:22:58.706247Z",
     "shell.execute_reply.started": "2025-06-12T00:22:49.172715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  9.5\n",
      "Total Input Tokens -  6437\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  339\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_jar_lom_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_lom_il=[0]\n",
    "keyword_input_token_jar_lom_il = 0\n",
    "keyword_output_token_jar_lom_il = 0\n",
    "keyword_start_time_loop_jar_lom_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_lom_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_lom_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_lom_il = keyword_dataframes['jar_lom_il_final_sen_df_jul'][keyword_dataframes['jar_lom_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_jar_lom_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_jar_lom_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_jar_lom_il.append(keywords)\n",
    "        keyword_input_token_jar_lom_il += input_tokens_loop\n",
    "        keyword_output_token_jar_lom_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_lom_il = time.time()\n",
    "keyword_cost_input_token_jar_lom_il = round((0.01/1000)*keyword_input_token_jar_lom_il,2)\n",
    "keyword_cost_output_token_jar_lom_il = round((0.03/1000)*keyword_output_token_jar_lom_il,2)\n",
    "keyword_total_cost_jar_lom_il = keyword_cost_input_token_jar_lom_il + keyword_cost_output_token_jar_lom_il\n",
    "keyword_total_time_loop_jar_lom_il = keyword_end_time_loop_jar_lom_il - keyword_start_time_loop_jar_lom_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_lom_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_lom_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_lom_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_lom_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_lom_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_lom_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_lom_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "0cd48c80-8652-42f7-aaf6-9332db0b9e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:58.708477Z",
     "iopub.status.busy": "2025-06-12T00:22:58.708195Z",
     "iopub.status.idle": "2025-06-12T00:22:58.768567Z",
     "shell.execute_reply": "2025-06-12T00:22:58.767927Z",
     "shell.execute_reply.started": "2025-06-12T00:22:58.708451Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Lombard, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>no apology :1, not valued :1</td>\n",
       "      <td>waiting :3, delay :1, poor service :1, rude :1...</td>\n",
       "      <td>ignored :2, rude :2, attitude :1, audacity :1,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>not cheap:1</td>\n",
       "      <td></td>\n",
       "      <td>ignored :1, couldn't fix :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Lombard, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>waiting too long :1, no apology for the delay ...</td>\n",
       "      <td>waiting too long :1, terrible experience :1, n...</td>\n",
       "      <td>ignored me and said they couldn't fix it :1, n...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>JEWLERY is not cheap especially when it comes ...</td>\n",
       "      <td></td>\n",
       "      <td>refunded the money to the card :1, not what I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Store Name Sentiment      Type  \\\n",
       "0  Jared-Lombard, IL  negative  keywords   \n",
       "1  Jared-Lombard, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                       no apology :1, not valued :1   \n",
       "1  waiting too long :1, no apology for the delay ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  waiting :3, delay :1, poor service :1, rude :1...   \n",
       "1  waiting too long :1, terrible experience :1, n...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  ignored :2, rude :2, attitude :1, audacity :1,...                  \n",
       "1  ignored me and said they couldn't fix it :1, n...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                                        not cheap:1                   \n",
       "1  JEWLERY is not cheap especially when it comes ...                   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                        ignored :1, couldn't fix :1  \n",
       "1  refunded the money to the card :1, not what I ...  "
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_jar_lom_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_jar_lom_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_jar_lom_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_lom_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_jar_lom_il = pd.concat([negative_keywords_jar_lom_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_jar_lom_il = pd.concat([negative_keywords_jar_lom_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_jar_lom_il = negative_keywords_jar_lom_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_jar_lom_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d198ee-26a1-45f4-9554-da0433b98557",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### jar_orl_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "3c9473db-1236-48c1-af67-c2ead60392ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:22:58.769818Z",
     "iopub.status.busy": "2025-06-12T00:22:58.769541Z",
     "iopub.status.idle": "2025-06-12T00:23:07.796679Z",
     "shell.execute_reply": "2025-06-12T00:23:07.796175Z",
     "shell.execute_reply.started": "2025-06-12T00:22:58.769784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  9.0\n",
      "Total Input Tokens -  4623\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  306\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_jar_orl_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_orl_il=[0]\n",
    "keyword_input_token_jar_orl_il = 0\n",
    "keyword_output_token_jar_orl_il = 0\n",
    "keyword_start_time_loop_jar_orl_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_orl_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_orl_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_orl_il = keyword_dataframes['jar_orl_il_final_sen_df_jul'][keyword_dataframes['jar_orl_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_jar_orl_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_jar_orl_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_jar_orl_il.append(keywords)\n",
    "        keyword_input_token_jar_orl_il += input_tokens_loop\n",
    "        keyword_output_token_jar_orl_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_orl_il = time.time()\n",
    "keyword_cost_input_token_jar_orl_il = round((0.01/1000)*keyword_input_token_jar_orl_il,2)\n",
    "keyword_cost_output_token_jar_orl_il = round((0.03/1000)*keyword_output_token_jar_orl_il,2)\n",
    "keyword_total_cost_jar_orl_il = keyword_cost_input_token_jar_orl_il + keyword_cost_output_token_jar_orl_il\n",
    "keyword_total_time_loop_jar_orl_il = keyword_end_time_loop_jar_orl_il - keyword_start_time_loop_jar_orl_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_orl_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_orl_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_orl_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_orl_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_orl_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_orl_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_orl_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "10ef0086-fd5b-441d-976c-0055d50e84da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:07.797629Z",
     "iopub.status.busy": "2025-06-12T00:23:07.797350Z",
     "iopub.status.idle": "2025-06-12T00:23:07.829719Z",
     "shell.execute_reply": "2025-06-12T00:23:07.829269Z",
     "shell.execute_reply.started": "2025-06-12T00:23:07.797609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Orland Park, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>scamming :1, don't care :1</td>\n",
       "      <td>unwelcomed :2, short :2, stone :2, buzzed in :...</td>\n",
       "      <td>unwelcomed :2, stone :2, short :2, awkwardness...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>scamming:1, charged:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Orland Park, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>charged me 7, 500 for a ring that cost not eve...</td>\n",
       "      <td>felt unwelcomed :2, looked us up and down :2, ...</td>\n",
       "      <td>looked us up and down :2, no open ended conver...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>cost not even half:1, perfectly happy scamming...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store Name Sentiment      Type  \\\n",
       "0  Jared-Orland Park, IL  negative  keywords   \n",
       "1  Jared-Orland Park, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                         scamming :1, don't care :1   \n",
       "1  charged me 7, 500 for a ring that cost not eve...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unwelcomed :2, short :2, stone :2, buzzed in :...   \n",
       "1  felt unwelcomed :2, looked us up and down :2, ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  unwelcomed :2, stone :2, short :2, awkwardness...                  \n",
       "1  looked us up and down :2, no open ended conver...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                              scamming:1, charged:1                   \n",
       "1  cost not even half:1, perfectly happy scamming...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_jar_orl_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_jar_orl_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_jar_orl_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_orl_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_jar_orl_il = pd.concat([negative_keywords_jar_orl_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_jar_orl_il = pd.concat([negative_keywords_jar_orl_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_jar_orl_il = negative_keywords_jar_orl_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_jar_orl_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54b915-6e1a-4088-b8b0-ebf0e66a3746",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### jar_aur_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "b98e7451-62a1-4d03-9fbd-02c4b31ba194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:07.830665Z",
     "iopub.status.busy": "2025-06-12T00:23:07.830411Z",
     "iopub.status.idle": "2025-06-12T00:23:15.351067Z",
     "shell.execute_reply": "2025-06-12T00:23:15.350536Z",
     "shell.execute_reply.started": "2025-06-12T00:23:07.830648Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  7.5\n",
      "Total Input Tokens -  2728\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  234\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_jar_aur_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_aur_il=[0]\n",
    "keyword_input_token_jar_aur_il = 0\n",
    "keyword_output_token_jar_aur_il = 0\n",
    "keyword_start_time_loop_jar_aur_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_aur_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_aur_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_aur_il = keyword_dataframes['jar_aur_il_final_sen_df_jul'][keyword_dataframes['jar_aur_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_jar_aur_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_jar_aur_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_jar_aur_il.append(keywords)\n",
    "        keyword_input_token_jar_aur_il += input_tokens_loop\n",
    "        keyword_output_token_jar_aur_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_aur_il = time.time()\n",
    "keyword_cost_input_token_jar_aur_il = round((0.01/1000)*keyword_input_token_jar_aur_il,2)\n",
    "keyword_cost_output_token_jar_aur_il = round((0.03/1000)*keyword_output_token_jar_aur_il,2)\n",
    "keyword_total_cost_jar_aur_il = keyword_cost_input_token_jar_aur_il + keyword_cost_output_token_jar_aur_il\n",
    "keyword_total_time_loop_jar_aur_il = keyword_end_time_loop_jar_aur_il - keyword_start_time_loop_jar_aur_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_aur_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_aur_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_aur_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_aur_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_aur_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_aur_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_aur_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "f65440a1-7dfe-4ef0-bd07-38b7f33f00e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:15.352110Z",
     "iopub.status.busy": "2025-06-12T00:23:15.351880Z",
     "iopub.status.idle": "2025-06-12T00:23:15.381096Z",
     "shell.execute_reply": "2025-06-12T00:23:15.380608Z",
     "shell.execute_reply.started": "2025-06-12T00:23:15.352084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Aurora, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>disappointed :2, rude :1, unwelcome :1, condes...</td>\n",
       "      <td>rude :2, condescending :1, screamed :1, unwelc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>cheap:1, expensive:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Aurora, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>extremely disappointing experience :1, worse c...</td>\n",
       "      <td>screamed to me :1, incredibly rude :1, condesc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>not too expensive:1, if I want something cheap...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Jared-Aurora, IL  negative  keywords                       \n",
       "1  Jared-Aurora, IL  negative   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  disappointed :2, rude :1, unwelcome :1, condes...   \n",
       "1  extremely disappointing experience :1, worse c...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :2, condescending :1, screamed :1, unwelc...                  \n",
       "1  screamed to me :1, incredibly rude :1, condesc...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                               cheap:1, expensive:1                   \n",
       "1  not too expensive:1, if I want something cheap...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_jar_aur_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_jar_aur_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_jar_aur_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_aur_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_jar_aur_il = pd.concat([negative_keywords_jar_aur_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_jar_aur_il = pd.concat([negative_keywords_jar_aur_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_jar_aur_il = negative_keywords_jar_aur_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_jar_aur_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb613916-7344-4080-8ee3-7dacc9cdf937",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### jar_alg_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "b79fedc0-a07e-4b6f-b579-86e3aaa94d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:15.382114Z",
     "iopub.status.busy": "2025-06-12T00:23:15.381797Z",
     "iopub.status.idle": "2025-06-12T00:23:22.404758Z",
     "shell.execute_reply": "2025-06-12T00:23:22.404181Z",
     "shell.execute_reply.started": "2025-06-12T00:23:15.382085Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  7.0\n",
      "Total Input Tokens -  3132\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  248\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_jar_alg_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_alg_il=[0]\n",
    "keyword_input_token_jar_alg_il = 0\n",
    "keyword_output_token_jar_alg_il = 0\n",
    "keyword_start_time_loop_jar_alg_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_alg_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_alg_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_alg_il = keyword_dataframes['jar_alg_il_final_sen_df_jul'][keyword_dataframes['jar_alg_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_jar_alg_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_jar_alg_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_jar_alg_il.append(keywords)\n",
    "        keyword_input_token_jar_alg_il += input_tokens_loop\n",
    "        keyword_output_token_jar_alg_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_alg_il = time.time()\n",
    "keyword_cost_input_token_jar_alg_il = round((0.01/1000)*keyword_input_token_jar_alg_il,2)\n",
    "keyword_cost_output_token_jar_alg_il = round((0.03/1000)*keyword_output_token_jar_alg_il,2)\n",
    "keyword_total_cost_jar_alg_il = keyword_cost_input_token_jar_alg_il + keyword_cost_output_token_jar_alg_il\n",
    "keyword_total_time_loop_jar_alg_il = keyword_end_time_loop_jar_alg_il - keyword_start_time_loop_jar_alg_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_alg_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_alg_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_alg_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_alg_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_alg_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_alg_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_alg_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "9d619a45-a4e8-4c09-be81-86595517f555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:22.405881Z",
     "iopub.status.busy": "2025-06-12T00:23:22.405578Z",
     "iopub.status.idle": "2025-06-12T00:23:22.436379Z",
     "shell.execute_reply": "2025-06-12T00:23:22.435874Z",
     "shell.execute_reply.started": "2025-06-12T00:23:22.405861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Algonquin, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trust :1, tarnishing :1, pathetic :1</td>\n",
       "      <td>pathetic store :1, no response :1, locked down...</td>\n",
       "      <td>no response :1, pathetic store :1, not a word ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Algonquin, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Do not trust this store :1, What a pathetic st...</td>\n",
       "      <td>entire place was locked down :1, totally ruine...</td>\n",
       "      <td>didn't bother changing the band :1, should hav...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Jared-Algonquin, IL  negative  keywords   \n",
       "1  Jared-Algonquin, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0               trust :1, tarnishing :1, pathetic :1   \n",
       "1  Do not trust this store :1, What a pathetic st...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  pathetic store :1, no response :1, locked down...   \n",
       "1  entire place was locked down :1, totally ruine...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  no response :1, pathetic store :1, not a word ...                  \n",
       "1  didn't bother changing the band :1, should hav...                  \n",
       "\n",
       "  Product Variety Discount Making Charge Price Product Quality  \\\n",
       "0                                                                \n",
       "1                                                                \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_jar_alg_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_jar_alg_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_jar_alg_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_alg_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_jar_alg_il = pd.concat([negative_keywords_jar_alg_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_jar_alg_il = pd.concat([negative_keywords_jar_alg_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_jar_alg_il = negative_keywords_jar_alg_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_jar_alg_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deba797-b315-4aed-8d83-3f73ae6c0321",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### jar_sch_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "8470c233-fc07-4290-824a-c27ab65a0a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:22.437512Z",
     "iopub.status.busy": "2025-06-12T00:23:22.437220Z",
     "iopub.status.idle": "2025-06-12T00:23:35.470392Z",
     "shell.execute_reply": "2025-06-12T00:23:35.469893Z",
     "shell.execute_reply.started": "2025-06-12T00:23:22.437485Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  13.0\n",
      "Total Input Tokens -  8177\n",
      "Total Input Cost = USD  0.08\n",
      "Total Output Tokens -  437\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.09\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_jar_sch_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_jar_sch_il=[0]\n",
    "keyword_input_token_jar_sch_il = 0\n",
    "keyword_output_token_jar_sch_il = 0\n",
    "keyword_start_time_loop_jar_sch_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_jar_sch_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_jar_sch_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_jar_sch_il = keyword_dataframes['jar_sch_il_final_sen_df_jul'][keyword_dataframes['jar_sch_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_jar_sch_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_jar_sch_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_jar_sch_il.append(keywords)\n",
    "        keyword_input_token_jar_sch_il += input_tokens_loop\n",
    "        keyword_output_token_jar_sch_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_jar_sch_il = time.time()\n",
    "keyword_cost_input_token_jar_sch_il = round((0.01/1000)*keyword_input_token_jar_sch_il,2)\n",
    "keyword_cost_output_token_jar_sch_il = round((0.03/1000)*keyword_output_token_jar_sch_il,2)\n",
    "keyword_total_cost_jar_sch_il = keyword_cost_input_token_jar_sch_il + keyword_cost_output_token_jar_sch_il\n",
    "keyword_total_time_loop_jar_sch_il = keyword_end_time_loop_jar_sch_il - keyword_start_time_loop_jar_sch_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_jar_sch_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_jar_sch_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_jar_sch_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_jar_sch_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_jar_sch_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_jar_sch_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_jar_sch_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "6bab9598-353c-4c4c-8648-7fda7312d98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:35.471605Z",
     "iopub.status.busy": "2025-06-12T00:23:35.471264Z",
     "iopub.status.idle": "2025-06-12T00:23:35.512666Z",
     "shell.execute_reply": "2025-06-12T00:23:35.512128Z",
     "shell.execute_reply.started": "2025-06-12T00:23:35.471577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared-Schaumburg, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>no appraisal:1, excuses:1, unable to help:1, d...</td>\n",
       "      <td>rude :3, locked :1, disorganized :1, unprofess...</td>\n",
       "      <td>rude :3, condescending :1, demeaning :1, annoy...</td>\n",
       "      <td>No light :1, ring boxes :1</td>\n",
       "      <td>barely anything:1, settings only:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>broken :2, awful :1, not great :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jared-Schaumburg, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>be careful buying here as they don't honor the...</td>\n",
       "      <td>rudest salesperson :1, awful experience :1, aw...</td>\n",
       "      <td>rudest salesperson :1, made us feel stupid :1,...</td>\n",
       "      <td>No light up ring boxes :1</td>\n",
       "      <td>none of the 5:1, not in store:1, almost all th...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>broke in half :1, quality of product is not gr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Store Name Sentiment      Type  \\\n",
       "0  Jared-Schaumburg, IL  negative  keywords   \n",
       "1  Jared-Schaumburg, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  no appraisal:1, excuses:1, unable to help:1, d...   \n",
       "1  be careful buying here as they don't honor the...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  rude :3, locked :1, disorganized :1, unprofess...   \n",
       "1  rudest salesperson :1, awful experience :1, aw...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :3, condescending :1, demeaning :1, annoy...   \n",
       "1  rudest salesperson :1, made us feel stupid :1,...   \n",
       "\n",
       "               Product Design  \\\n",
       "0  No light :1, ring boxes :1   \n",
       "1   No light up ring boxes :1   \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0                 barely anything:1, settings only:1                          \n",
       "1  none of the 5:1, not in store:1, almost all th...                          \n",
       "\n",
       "  Price                                    Product Quality Jewellery Exchange  \n",
       "0                        broken :2, awful :1, not great :1                     \n",
       "1        broke in half :1, quality of product is not gr...                     "
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_jar_sch_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_jar_sch_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_jar_sch_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'jar_sch_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_jar_sch_il = pd.concat([negative_keywords_jar_sch_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_jar_sch_il = pd.concat([negative_keywords_jar_sch_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_jar_sch_il = negative_keywords_jar_sch_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_jar_sch_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be8c6c-bb41-4585-96ba-b8d00aea4543",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_suw_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "aa9326cc-74fd-40a9-aeef-ef479660a8c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:35.513555Z",
     "iopub.status.busy": "2025-06-12T00:23:35.513338Z",
     "iopub.status.idle": "2025-06-12T00:23:55.555972Z",
     "shell.execute_reply": "2025-06-12T00:23:55.555475Z",
     "shell.execute_reply.started": "2025-06-12T00:23:35.513536Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  20.0\n",
      "Total Input Tokens -  12990\n",
      "Total Input Cost = USD  0.13\n",
      "Total Output Tokens -  827\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.15\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_suw_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_suw_ga=[0]\n",
    "keyword_input_token_joy_suw_ga = 0\n",
    "keyword_output_token_joy_suw_ga = 0\n",
    "keyword_start_time_loop_joy_suw_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_suw_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_suw_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_suw_ga = keyword_dataframes['joy_suw_ga_final_sen_df_jul'][keyword_dataframes['joy_suw_ga_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_suw_ga:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_suw_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_suw_ga.append(keywords)\n",
    "        keyword_input_token_joy_suw_ga += input_tokens_loop\n",
    "        keyword_output_token_joy_suw_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_suw_ga = time.time()\n",
    "keyword_cost_input_token_joy_suw_ga = round((0.01/1000)*keyword_input_token_joy_suw_ga,2)\n",
    "keyword_cost_output_token_joy_suw_ga = round((0.03/1000)*keyword_output_token_joy_suw_ga,2)\n",
    "keyword_total_cost_joy_suw_ga = keyword_cost_input_token_joy_suw_ga + keyword_cost_output_token_joy_suw_ga\n",
    "keyword_total_time_loop_joy_suw_ga = keyword_end_time_loop_joy_suw_ga - keyword_start_time_loop_joy_suw_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_suw_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_suw_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_suw_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_suw_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_suw_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_suw_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_suw_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "51972f5b-e1d8-4858-99e3-e75941a827c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:55.556978Z",
     "iopub.status.busy": "2025-06-12T00:23:55.556717Z",
     "iopub.status.idle": "2025-06-12T00:23:55.603263Z",
     "shell.execute_reply": "2025-06-12T00:23:55.602762Z",
     "shell.execute_reply.started": "2025-06-12T00:23:55.556959Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Suwanee, GA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>unethical :1, disappointed :1, regret :1, bewa...</td>\n",
       "      <td>bad service :2, rude attitude :1, unprofession...</td>\n",
       "      <td>rude :3, unprofessional :2, disrespectful :2, ...</td>\n",
       "      <td>poor designs:1</td>\n",
       "      <td>limited options: 2, limited collection: 2, not...</td>\n",
       "      <td></td>\n",
       "      <td>expensive:1, high:1, hidden:1, rip:1, markup:1</td>\n",
       "      <td>pricey :1, price difference :1, high :1, low b...</td>\n",
       "      <td>poor quality :1, worst :1, faulty :1, weak :1</td>\n",
       "      <td>faulty item:2, refund:1, exchange:1, untagged:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Suwanee, GA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>don't feel like enrolling :1, worst experience...</td>\n",
       "      <td>least interested to even show the jewellery :1...</td>\n",
       "      <td>very rude in talking :1, doesn't care customer...</td>\n",
       "      <td>No relevant negative phrases</td>\n",
       "      <td>lack of variety in the jewelry offerings: 1, s...</td>\n",
       "      <td></td>\n",
       "      <td>making charges are 100% more than gold prices:...</td>\n",
       "      <td>Quite pricey I felt for such a small piece :1,...</td>\n",
       "      <td>very poor quality :1, quality of gold is worst...</td>\n",
       "      <td>faulty one:2, not the correct one:1, missing t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Suwanee, GA  negative  keywords   \n",
       "1  Joyalukkas Jewellery-Suwanee, GA  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  unethical :1, disappointed :1, regret :1, bewa...   \n",
       "1  don't feel like enrolling :1, worst experience...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  bad service :2, rude attitude :1, unprofession...   \n",
       "1  least interested to even show the jewellery :1...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :3, unprofessional :2, disrespectful :2, ...   \n",
       "1  very rude in talking :1, doesn't care customer...   \n",
       "\n",
       "                 Product Design  \\\n",
       "0                poor designs:1   \n",
       "1  No relevant negative phrases   \n",
       "\n",
       "                                     Product Variety Discount  \\\n",
       "0  limited options: 2, limited collection: 2, not...            \n",
       "1  lack of variety in the jewelry offerings: 1, s...            \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0     expensive:1, high:1, hidden:1, rip:1, markup:1   \n",
       "1  making charges are 100% more than gold prices:...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  pricey :1, price difference :1, high :1, low b...   \n",
       "1  Quite pricey I felt for such a small piece :1,...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0      poor quality :1, worst :1, faulty :1, weak :1   \n",
       "1  very poor quality :1, quality of gold is worst...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  faulty item:2, refund:1, exchange:1, untagged:...  \n",
       "1  faulty one:2, not the correct one:1, missing t...  "
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_suw_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_suw_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_suw_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_suw_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_suw_ga = pd.concat([negative_keywords_joy_suw_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_suw_ga = pd.concat([negative_keywords_joy_suw_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_suw_ga = negative_keywords_joy_suw_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_suw_ga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab91e90-0dfa-4880-bfbc-6c69d7edf8fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "09e56f1a-f8b9-4c1c-8bbc-81f7e0935784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:23:55.604126Z",
     "iopub.status.busy": "2025-06-12T00:23:55.603908Z",
     "iopub.status.idle": "2025-06-12T00:24:15.145731Z",
     "shell.execute_reply": "2025-06-12T00:24:15.145158Z",
     "shell.execute_reply.started": "2025-06-12T00:23:55.604109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  19.5\n",
      "Total Input Tokens -  11901\n",
      "Total Input Cost = USD  0.12\n",
      "Total Output Tokens -  700\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.14\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_chi_il=[0]\n",
    "keyword_input_token_joy_chi_il = 0\n",
    "keyword_output_token_joy_chi_il = 0\n",
    "keyword_start_time_loop_joy_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_chi_il = keyword_dataframes['joy_chi_il_final_sen_df_jul'][keyword_dataframes['joy_chi_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_chi_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_chi_il.append(keywords)\n",
    "        keyword_input_token_joy_chi_il += input_tokens_loop\n",
    "        keyword_output_token_joy_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_chi_il = time.time()\n",
    "keyword_cost_input_token_joy_chi_il = round((0.01/1000)*keyword_input_token_joy_chi_il,2)\n",
    "keyword_cost_output_token_joy_chi_il = round((0.03/1000)*keyword_output_token_joy_chi_il,2)\n",
    "keyword_total_cost_joy_chi_il = keyword_cost_input_token_joy_chi_il + keyword_cost_output_token_joy_chi_il\n",
    "keyword_total_time_loop_joy_chi_il = keyword_end_time_loop_joy_chi_il - keyword_start_time_loop_joy_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "6964f328-8995-4be1-b743-b9568d410e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:24:15.146746Z",
     "iopub.status.busy": "2025-06-12T00:24:15.146438Z",
     "iopub.status.idle": "2025-06-12T00:24:15.197979Z",
     "shell.execute_reply": "2025-06-12T00:24:15.197484Z",
     "shell.execute_reply.started": "2025-06-12T00:24:15.146719Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>not honest:1, scam:1, lack of integrity:1, lac...</td>\n",
       "      <td>unresponsive :1, rude :1, unprofessional :1, d...</td>\n",
       "      <td>rude :3, unresponsive :1, unprofessional :1, a...</td>\n",
       "      <td>Old designs:1</td>\n",
       "      <td>collections :3, choice :1, design :1</td>\n",
       "      <td>no discounts :1, better deal :1</td>\n",
       "      <td>daylight robbery:1</td>\n",
       "      <td>expensive: 1, pricey: 1, manipulated: 1, diffe...</td>\n",
       "      <td>manufacturing defect :3, faulty :1, flaw :1, b...</td>\n",
       "      <td>lost value:1, bring back:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>totally different before and after business:1,...</td>\n",
       "      <td>very disappointing experience :1, very bad exp...</td>\n",
       "      <td>very rude :2, absolutely zero patience :1, doe...</td>\n",
       "      <td>No relevant negative phrases</td>\n",
       "      <td>Not too many collections :1, need some more ch...</td>\n",
       "      <td>no real benefits or discounts :1, discounts ca...</td>\n",
       "      <td>day light robbery in name of making charges:1</td>\n",
       "      <td>negotiating the price: 2, manipulated prices: ...</td>\n",
       "      <td>clear manufacturing defect :2, started showing...</td>\n",
       "      <td>don't bring back the ring to exchange within 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Chicago, IL  negative  keywords   \n",
       "1  Joyalukkas Jewellery-Chicago, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  not honest:1, scam:1, lack of integrity:1, lac...   \n",
       "1  totally different before and after business:1,...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unresponsive :1, rude :1, unprofessional :1, d...   \n",
       "1  very disappointing experience :1, very bad exp...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :3, unresponsive :1, unprofessional :1, a...   \n",
       "1  very rude :2, absolutely zero patience :1, doe...   \n",
       "\n",
       "                 Product Design  \\\n",
       "0                 Old designs:1   \n",
       "1  No relevant negative phrases   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0               collections :3, choice :1, design :1   \n",
       "1  Not too many collections :1, need some more ch...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                    no discounts :1, better deal :1   \n",
       "1  no real benefits or discounts :1, discounts ca...   \n",
       "\n",
       "                                   Making Charge  \\\n",
       "0                             daylight robbery:1   \n",
       "1  day light robbery in name of making charges:1   \n",
       "\n",
       "                                               Price  \\\n",
       "0  expensive: 1, pricey: 1, manipulated: 1, diffe...   \n",
       "1  negotiating the price: 2, manipulated prices: ...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  manufacturing defect :3, faulty :1, flaw :1, b...   \n",
       "1  clear manufacturing defect :2, started showing...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                         lost value:1, bring back:1  \n",
       "1  don't bring back the ring to exchange within 1...  "
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_chi_il = pd.concat([negative_keywords_joy_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_chi_il = pd.concat([negative_keywords_joy_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_chi_il = negative_keywords_joy_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4b3d3-91ed-4f98-a511-c14e878acae7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_hou_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "7906f44b-d61b-443c-8f3b-5d6a1c227b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:24:15.198922Z",
     "iopub.status.busy": "2025-06-12T00:24:15.198688Z",
     "iopub.status.idle": "2025-06-12T00:24:37.747250Z",
     "shell.execute_reply": "2025-06-12T00:24:37.746677Z",
     "shell.execute_reply.started": "2025-06-12T00:24:15.198905Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  22.5\n",
      "Total Input Tokens -  16723\n",
      "Total Input Cost = USD  0.17\n",
      "Total Output Tokens -  779\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.19\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_hou_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_hou_tx=[0]\n",
    "keyword_input_token_joy_hou_tx = 0\n",
    "keyword_output_token_joy_hou_tx = 0\n",
    "keyword_start_time_loop_joy_hou_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_hou_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_hou_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_hou_tx = keyword_dataframes['joy_hou_tx_final_sen_df_jul'][keyword_dataframes['joy_hou_tx_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_hou_tx:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_hou_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_hou_tx.append(keywords)\n",
    "        keyword_input_token_joy_hou_tx += input_tokens_loop\n",
    "        keyword_output_token_joy_hou_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_hou_tx = time.time()\n",
    "keyword_cost_input_token_joy_hou_tx = round((0.01/1000)*keyword_input_token_joy_hou_tx,2)\n",
    "keyword_cost_output_token_joy_hou_tx = round((0.03/1000)*keyword_output_token_joy_hou_tx,2)\n",
    "keyword_total_cost_joy_hou_tx = keyword_cost_input_token_joy_hou_tx + keyword_cost_output_token_joy_hou_tx\n",
    "keyword_total_time_loop_joy_hou_tx = keyword_end_time_loop_joy_hou_tx - keyword_start_time_loop_joy_hou_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_hou_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_hou_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_hou_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_hou_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_hou_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_hou_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_hou_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "14865b04-68d4-4353-8403-b935820bb065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:24:37.748555Z",
     "iopub.status.busy": "2025-06-12T00:24:37.748261Z",
     "iopub.status.idle": "2025-06-12T00:24:37.797551Z",
     "shell.execute_reply": "2025-06-12T00:24:37.796964Z",
     "shell.execute_reply.started": "2025-06-12T00:24:37.748526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Houston, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>fraud :2, transparency :2, depreciate :1, trap...</td>\n",
       "      <td>rude :3, ignoring :2, unprofessional :2, disre...</td>\n",
       "      <td>rude :3, unhelpful :2, disrespectful :2, unpro...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>limited :2, lackluster :1, dated :1, uninspiri...</td>\n",
       "      <td>no discount:1, higher:1, caveats:1, bargain:1,...</td>\n",
       "      <td>higher:2, fraud:1, ridicules:1, sheer:1, trap:1</td>\n",
       "      <td>high :2, unclear :1, misleading :1, arbitrary ...</td>\n",
       "      <td>poor quality:1, mediocre quality:1</td>\n",
       "      <td>no transparency: 2, poor customer service: 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Houston, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>fraud business model :2, no transparency :1, s...</td>\n",
       "      <td>no immediate greeting :1, pretending to be bus...</td>\n",
       "      <td>show ZERO courtesy towards customers :1, greet...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>not a lot of selection :1, wish they had more ...</td>\n",
       "      <td>not willing to give any discount:1, don't get ...</td>\n",
       "      <td>charge me 22% Making:1, high in Making Charges...</td>\n",
       "      <td>no transparency :2, prices were disproportiona...</td>\n",
       "      <td>broke immediately:1, quality is poor:1, broke ...</td>\n",
       "      <td>lack of transparency: 1, feeling deceived: 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Houston, TX  negative  keywords   \n",
       "1  Joyalukkas Jewellery-Houston, TX  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  fraud :2, transparency :2, depreciate :1, trap...   \n",
       "1  fraud business model :2, no transparency :1, s...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  rude :3, ignoring :2, unprofessional :2, disre...   \n",
       "1  no immediate greeting :1, pretending to be bus...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :3, unhelpful :2, disrespectful :2, unpro...   \n",
       "1  show ZERO courtesy towards customers :1, greet...   \n",
       "\n",
       "                           Product Design  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  limited :2, lackluster :1, dated :1, uninspiri...   \n",
       "1  not a lot of selection :1, wish they had more ...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  no discount:1, higher:1, caveats:1, bargain:1,...   \n",
       "1  not willing to give any discount:1, don't get ...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0    higher:2, fraud:1, ridicules:1, sheer:1, trap:1   \n",
       "1  charge me 22% Making:1, high in Making Charges...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  high :2, unclear :1, misleading :1, arbitrary ...   \n",
       "1  no transparency :2, prices were disproportiona...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0                 poor quality:1, mediocre quality:1   \n",
       "1  broke immediately:1, quality is poor:1, broke ...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  no transparency: 2, poor customer service: 1, ...  \n",
       "1  lack of transparency: 1, feeling deceived: 1, ...  "
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_hou_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_hou_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_hou_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_hou_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_hou_tx = pd.concat([negative_keywords_joy_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_hou_tx = pd.concat([negative_keywords_joy_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_hou_tx = negative_keywords_joy_hou_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_hou_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd998f-6549-44f6-8239-891631657175",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### joy_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "eee46797-e984-49a6-a5c7-bbb08e7d10f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:24:37.798789Z",
     "iopub.status.busy": "2025-06-12T00:24:37.798417Z",
     "iopub.status.idle": "2025-06-12T00:24:59.850139Z",
     "shell.execute_reply": "2025-06-12T00:24:59.849593Z",
     "shell.execute_reply.started": "2025-06-12T00:24:37.798762Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  22.0\n",
      "Total Input Tokens -  9870\n",
      "Total Input Cost = USD  0.1\n",
      "Total Output Tokens -  731\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_joy_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_joy_fri_tx=[0]\n",
    "keyword_input_token_joy_fri_tx = 0\n",
    "keyword_output_token_joy_fri_tx = 0\n",
    "keyword_start_time_loop_joy_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_joy_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_joy_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_joy_fri_tx = keyword_dataframes['joy_fri_tx_final_sen_df_jul'][keyword_dataframes['joy_fri_tx_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_joy_fri_tx:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_joy_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_joy_fri_tx.append(keywords)\n",
    "        keyword_input_token_joy_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_joy_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_joy_fri_tx = time.time()\n",
    "keyword_cost_input_token_joy_fri_tx = round((0.01/1000)*keyword_input_token_joy_fri_tx,2)\n",
    "keyword_cost_output_token_joy_fri_tx = round((0.03/1000)*keyword_output_token_joy_fri_tx,2)\n",
    "keyword_total_cost_joy_fri_tx = keyword_cost_input_token_joy_fri_tx + keyword_cost_output_token_joy_fri_tx\n",
    "keyword_total_time_loop_joy_fri_tx = keyword_end_time_loop_joy_fri_tx - keyword_start_time_loop_joy_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_joy_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_joy_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_joy_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_joy_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_joy_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_joy_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_joy_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "08aa3af8-a2cf-48aa-9fcb-011a95179db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:24:59.851334Z",
     "iopub.status.busy": "2025-06-12T00:24:59.850969Z",
     "iopub.status.idle": "2025-06-12T00:24:59.898430Z",
     "shell.execute_reply": "2025-06-12T00:24:59.897530Z",
     "shell.execute_reply.started": "2025-06-12T00:24:59.851303Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyalukkas Jewellery-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>cheat :1, trust :1, respect :1, disappointed :...</td>\n",
       "      <td>bad experience:3, uninterested:1, unprofession...</td>\n",
       "      <td>bad attitude:2, rude:2, uninterested:1, unhelp...</td>\n",
       "      <td>distorted :1, not clean :1</td>\n",
       "      <td>limited collection:2, limited options:1, less ...</td>\n",
       "      <td></td>\n",
       "      <td>high :3, too much :1, highest :1, more :1, rel...</td>\n",
       "      <td>overpriced:2, extra:1, higher:1, wealthy:1, ne...</td>\n",
       "      <td>broke: 3, broken: 2, terrible: 1, distorted: 1...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyalukkas Jewellery-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>cheat with weight :1, impact your customer's t...</td>\n",
       "      <td>no transparency in weighing:1, mistakes in bil...</td>\n",
       "      <td>not even ready to take the box outside:1, not ...</td>\n",
       "      <td>item design was distorted :1, not a clean fix :1</td>\n",
       "      <td>Very limited collection compared to Malani:1, ...</td>\n",
       "      <td></td>\n",
       "      <td>making charges are very high :1, making charge...</td>\n",
       "      <td>price we have got is higher compared to the ot...</td>\n",
       "      <td>bad weld quality: 1, ring broke into 2 pieces:...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Joyalukkas Jewellery-Frisco, TX  negative  keywords   \n",
       "1  Joyalukkas Jewellery-Frisco, TX  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  cheat :1, trust :1, respect :1, disappointed :...   \n",
       "1  cheat with weight :1, impact your customer's t...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  bad experience:3, uninterested:1, unprofession...   \n",
       "1  no transparency in weighing:1, mistakes in bil...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  bad attitude:2, rude:2, uninterested:1, unhelp...   \n",
       "1  not even ready to take the box outside:1, not ...   \n",
       "\n",
       "                                     Product Design  \\\n",
       "0                        distorted :1, not clean :1   \n",
       "1  item design was distorted :1, not a clean fix :1   \n",
       "\n",
       "                                     Product Variety Discount  \\\n",
       "0  limited collection:2, limited options:1, less ...            \n",
       "1  Very limited collection compared to Malani:1, ...            \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  high :3, too much :1, highest :1, more :1, rel...   \n",
       "1  making charges are very high :1, making charge...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  overpriced:2, extra:1, higher:1, wealthy:1, ne...   \n",
       "1  price we have got is higher compared to the ot...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  broke: 3, broken: 2, terrible: 1, distorted: 1...                     \n",
       "1  bad weld quality: 1, ring broke into 2 pieces:...                     "
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_joy_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_joy_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_joy_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'joy_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_joy_fri_tx = pd.concat([negative_keywords_joy_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_joy_fri_tx = pd.concat([negative_keywords_joy_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_joy_fri_tx = negative_keywords_joy_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_joy_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80992bc7-74c2-4b8c-b865-44331c846172",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "c0f9860b-f4ab-40d1-8f81-7ee2dd50d0d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:24:59.899749Z",
     "iopub.status.busy": "2025-06-12T00:24:59.899326Z",
     "iopub.status.idle": "2025-06-12T00:25:09.925169Z",
     "shell.execute_reply": "2025-06-12T00:25:09.924677Z",
     "shell.execute_reply.started": "2025-06-12T00:24:59.899729Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.0\n",
      "Total Input Tokens -  5457\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  370\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_chi_il=[0]\n",
    "keyword_input_token_mal_chi_il = 0\n",
    "keyword_output_token_mal_chi_il = 0\n",
    "keyword_start_time_loop_mal_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_chi_il = keyword_dataframes['mal_chi_il_final_sen_df_jul'][keyword_dataframes['mal_chi_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_chi_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_chi_il.append(keywords)\n",
    "        keyword_input_token_mal_chi_il += input_tokens_loop\n",
    "        keyword_output_token_mal_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_chi_il = time.time()\n",
    "keyword_cost_input_token_mal_chi_il = round((0.01/1000)*keyword_input_token_mal_chi_il,2)\n",
    "keyword_cost_output_token_mal_chi_il = round((0.03/1000)*keyword_output_token_mal_chi_il,2)\n",
    "keyword_total_cost_mal_chi_il = keyword_cost_input_token_mal_chi_il + keyword_cost_output_token_mal_chi_il\n",
    "keyword_total_time_loop_mal_chi_il = keyword_end_time_loop_mal_chi_il - keyword_start_time_loop_mal_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "c88d6291-5504-47d4-b4e8-a7f778180106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:25:09.926343Z",
     "iopub.status.busy": "2025-06-12T00:25:09.925978Z",
     "iopub.status.idle": "2025-06-12T00:25:09.963965Z",
     "shell.execute_reply": "2025-06-12T00:25:09.963483Z",
     "shell.execute_reply.started": "2025-06-12T00:25:09.926322Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>bad experience:2, unacceptable:1, disappointin...</td>\n",
       "      <td>rude :1, unpleasant :1, idle :1, ignoring :1, ...</td>\n",
       "      <td></td>\n",
       "      <td>less designs:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>expensive: 2, overspending: 1, doubled: 1, sup...</td>\n",
       "      <td>broke:2, delicate:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>no interest in working:1, glued to their phone...</td>\n",
       "      <td>bad attitude :1, not helping :1, no interest i...</td>\n",
       "      <td></td>\n",
       "      <td>may be less no designs:1, hope they will add m...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>raise it price alot: 1, price was doubled befo...</td>\n",
       "      <td>broke the moment:1, broke off:1, did not hold ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Chicago, IL  negative  keywords   \n",
       "1  Malabar Gold & Diamonds-Chicago, IL  negative   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  bad experience:2, unacceptable:1, disappointin...   \n",
       "1  no interest in working:1, glued to their phone...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :1, unpleasant :1, idle :1, ignoring :1, ...                  \n",
       "1  bad attitude :1, not helping :1, no interest i...                  \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0                                     less designs:1                          \n",
       "1  may be less no designs:1, hope they will add m...                          \n",
       "\n",
       "                                               Price  \\\n",
       "0  expensive: 2, overspending: 1, doubled: 1, sup...   \n",
       "1  raise it price alot: 1, price was doubled befo...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0                                broke:2, delicate:1                     \n",
       "1  broke the moment:1, broke off:1, did not hold ...                     "
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_chi_il = pd.concat([negative_keywords_mal_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_chi_il = pd.concat([negative_keywords_mal_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_chi_il = negative_keywords_mal_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a6025-69e5-4fca-b3ce-9ea8491cc8d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_nap_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "e7921681-b6b0-4125-a9c4-b338d9680820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:25:09.964999Z",
     "iopub.status.busy": "2025-06-12T00:25:09.964774Z",
     "iopub.status.idle": "2025-06-12T00:25:32.007231Z",
     "shell.execute_reply": "2025-06-12T00:25:32.006732Z",
     "shell.execute_reply.started": "2025-06-12T00:25:09.964981Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  22.0\n",
      "Total Input Tokens -  11284\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  630\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_nap_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_nap_il=[0]\n",
    "keyword_input_token_mal_nap_il = 0\n",
    "keyword_output_token_mal_nap_il = 0\n",
    "keyword_start_time_loop_mal_nap_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_nap_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_nap_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_nap_il = keyword_dataframes['mal_nap_il_final_sen_df_jul'][keyword_dataframes['mal_nap_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_nap_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_nap_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_nap_il.append(keywords)\n",
    "        keyword_input_token_mal_nap_il += input_tokens_loop\n",
    "        keyword_output_token_mal_nap_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_nap_il = time.time()\n",
    "keyword_cost_input_token_mal_nap_il = round((0.01/1000)*keyword_input_token_mal_nap_il,2)\n",
    "keyword_cost_output_token_mal_nap_il = round((0.03/1000)*keyword_output_token_mal_nap_il,2)\n",
    "keyword_total_cost_mal_nap_il = keyword_cost_input_token_mal_nap_il + keyword_cost_output_token_mal_nap_il\n",
    "keyword_total_time_loop_mal_nap_il = keyword_end_time_loop_mal_nap_il - keyword_start_time_loop_mal_nap_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_nap_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_nap_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_nap_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_nap_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_nap_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_nap_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_nap_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "c2d9de86-e8de-4c34-8794-6d7e2f03de9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:25:32.008310Z",
     "iopub.status.busy": "2025-06-12T00:25:32.007992Z",
     "iopub.status.idle": "2025-06-12T00:25:32.058786Z",
     "shell.execute_reply": "2025-06-12T00:25:32.058276Z",
     "shell.execute_reply.started": "2025-06-12T00:25:32.008289Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Naperville, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>high price:1, huge margins:1</td>\n",
       "      <td>bad management :1, poor service :1, rude :1, d...</td>\n",
       "      <td>rude :2, arrogant :1, lazy :1, unprofessional ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>old fashioned :1</td>\n",
       "      <td>special offers:1</td>\n",
       "      <td>high price:1, huge margins:1</td>\n",
       "      <td>different price: 3, wrong price: 2, higher pri...</td>\n",
       "      <td>defective :1</td>\n",
       "      <td>deduct :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Naperville, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>charging 50% on the making charges:1, doesn’t ...</td>\n",
       "      <td>horribly managed crowd :1, waited for an hour ...</td>\n",
       "      <td>lack of communication between employees :2, di...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>Very old fashioned models :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>charging 50% on the making charges:1, surprise...</td>\n",
       "      <td>inconsistency in pricing: 1, confusing and com...</td>\n",
       "      <td>both pieces were defective :1, no one had even...</td>\n",
       "      <td>no deduction while you exchange :1, we will de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Naperville, IL  negative  keywords   \n",
       "1  Malabar Gold & Diamonds-Naperville, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                       high price:1, huge margins:1   \n",
       "1  charging 50% on the making charges:1, doesn’t ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  bad management :1, poor service :1, rude :1, d...   \n",
       "1  horribly managed crowd :1, waited for an hour ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :2, arrogant :1, lazy :1, unprofessional ...   \n",
       "1  lack of communication between employees :2, di...   \n",
       "\n",
       "                           Product Design               Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases              old fashioned :1   \n",
       "1  No relevant negative keywords/ phrases  Very old fashioned models :1   \n",
       "\n",
       "                                 Discount  \\\n",
       "0                        special offers:1   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                       high price:1, huge margins:1   \n",
       "1  charging 50% on the making charges:1, surprise...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  different price: 3, wrong price: 2, higher pri...   \n",
       "1  inconsistency in pricing: 1, confusing and com...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0                                       defective :1   \n",
       "1  both pieces were defective :1, no one had even...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                                          deduct :1  \n",
       "1  no deduction while you exchange :1, we will de...  "
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_nap_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_nap_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_nap_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_nap_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_nap_il = pd.concat([negative_keywords_mal_nap_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_nap_il = pd.concat([negative_keywords_mal_nap_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_nap_il = negative_keywords_mal_nap_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_nap_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf13576-077f-4459-a8a0-9439037df0f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_ise_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "d2e3b75a-cefd-45ed-9bb4-1229085aa4ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:25:32.059937Z",
     "iopub.status.busy": "2025-06-12T00:25:32.059569Z",
     "iopub.status.idle": "2025-06-12T00:25:47.593563Z",
     "shell.execute_reply": "2025-06-12T00:25:47.592920Z",
     "shell.execute_reply.started": "2025-06-12T00:25:32.059918Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  15.5\n",
      "Total Input Tokens -  10880\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  595\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_ise_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_ise_nj=[0]\n",
    "keyword_input_token_mal_ise_nj = 0\n",
    "keyword_output_token_mal_ise_nj = 0\n",
    "keyword_start_time_loop_mal_ise_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ise_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ise_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ise_nj = keyword_dataframes['mal_ise_nj_final_sen_df_jul'][keyword_dataframes['mal_ise_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_ise_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_ise_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_ise_nj.append(keywords)\n",
    "        keyword_input_token_mal_ise_nj += input_tokens_loop\n",
    "        keyword_output_token_mal_ise_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ise_nj = time.time()\n",
    "keyword_cost_input_token_mal_ise_nj = round((0.01/1000)*keyword_input_token_mal_ise_nj,2)\n",
    "keyword_cost_output_token_mal_ise_nj = round((0.03/1000)*keyword_output_token_mal_ise_nj,2)\n",
    "keyword_total_cost_mal_ise_nj = keyword_cost_input_token_mal_ise_nj + keyword_cost_output_token_mal_ise_nj\n",
    "keyword_total_time_loop_mal_ise_nj = keyword_end_time_loop_mal_ise_nj - keyword_start_time_loop_mal_ise_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_ise_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_ise_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_ise_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_ise_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_ise_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_ise_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_ise_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "0662757d-181b-4e45-971a-2cda4b17539b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:25:47.594834Z",
     "iopub.status.busy": "2025-06-12T00:25:47.594536Z",
     "iopub.status.idle": "2025-06-12T00:25:47.661802Z",
     "shell.execute_reply": "2025-06-12T00:25:47.661224Z",
     "shell.execute_reply.started": "2025-06-12T00:25:47.594805Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Iselin, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>refused to honor :1, unnecessary :1, concernin...</td>\n",
       "      <td>rude :2, pushy :1, unengaged :1, annoyed :1, h...</td>\n",
       "      <td>rude :2, unengaged :1, ignored :1, gossiping :...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>zero collection:1, limited options:1</td>\n",
       "      <td>No proper discounts :1, better discount :1</td>\n",
       "      <td>very high :2, expensive :1</td>\n",
       "      <td>expensive: 3, high: 3, costly: 1, overpriced: ...</td>\n",
       "      <td></td>\n",
       "      <td>no exchange :1, not too helpful :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Iselin, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>refused to honor their stated cash back policy...</td>\n",
       "      <td>sales woman started giving me lectures :1, rud...</td>\n",
       "      <td>not responding properly :1, giving me lectures...</td>\n",
       "      <td>design collection could be more up-to-date :1</td>\n",
       "      <td>no relevant negative phrases</td>\n",
       "      <td>No proper discounts or benefits for regular cu...</td>\n",
       "      <td>making charges and stone cost is also very hig...</td>\n",
       "      <td>very high: 2, making charges: 2, choose their ...</td>\n",
       "      <td></td>\n",
       "      <td>no exchange option for the items purchased out...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Iselin, NJ  negative  keywords   \n",
       "1  Malabar Gold & Diamonds-Iselin, NJ  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  refused to honor :1, unnecessary :1, concernin...   \n",
       "1  refused to honor their stated cash back policy...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  rude :2, pushy :1, unengaged :1, annoyed :1, h...   \n",
       "1  sales woman started giving me lectures :1, rud...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :2, unengaged :1, ignored :1, gossiping :...   \n",
       "1  not responding properly :1, giving me lectures...   \n",
       "\n",
       "                                  Product Design  \\\n",
       "0         No relevant negative keywords/ phrases   \n",
       "1  design collection could be more up-to-date :1   \n",
       "\n",
       "                        Product Variety  \\\n",
       "0  zero collection:1, limited options:1   \n",
       "1          no relevant negative phrases   \n",
       "\n",
       "                                            Discount  \\\n",
       "0         No proper discounts :1, better discount :1   \n",
       "1  No proper discounts or benefits for regular cu...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                         very high :2, expensive :1   \n",
       "1  making charges and stone cost is also very hig...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0  expensive: 3, high: 3, costly: 1, overpriced: ...                   \n",
       "1  very high: 2, making charges: 2, choose their ...                   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                 no exchange :1, not too helpful :1  \n",
       "1  no exchange option for the items purchased out...  "
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_ise_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_ise_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_ise_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ise_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_ise_nj = pd.concat([negative_keywords_mal_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_ise_nj = pd.concat([negative_keywords_mal_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_ise_nj = negative_keywords_mal_ise_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_ise_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977fcee-98d4-43fa-87e0-adcc50d95977",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "e3c59e7a-29f3-4574-8d5b-bc3d5f1c43d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:25:47.662983Z",
     "iopub.status.busy": "2025-06-12T00:25:47.662729Z",
     "iopub.status.idle": "2025-06-12T00:26:05.205406Z",
     "shell.execute_reply": "2025-06-12T00:26:05.204859Z",
     "shell.execute_reply.started": "2025-06-12T00:25:47.662958Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.5\n",
      "Total Input Tokens -  10687\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  650\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_fri_tx=[0]\n",
    "keyword_input_token_mal_fri_tx = 0\n",
    "keyword_output_token_mal_fri_tx = 0\n",
    "keyword_start_time_loop_mal_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_fri_tx = keyword_dataframes['mal_fri_tx_final_sen_df_jul'][keyword_dataframes['mal_fri_tx_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_fri_tx:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_fri_tx.append(keywords)\n",
    "        keyword_input_token_mal_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_mal_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_fri_tx = time.time()\n",
    "keyword_cost_input_token_mal_fri_tx = round((0.01/1000)*keyword_input_token_mal_fri_tx,2)\n",
    "keyword_cost_output_token_mal_fri_tx = round((0.03/1000)*keyword_output_token_mal_fri_tx,2)\n",
    "keyword_total_cost_mal_fri_tx = keyword_cost_input_token_mal_fri_tx + keyword_cost_output_token_mal_fri_tx\n",
    "keyword_total_time_loop_mal_fri_tx = keyword_end_time_loop_mal_fri_tx - keyword_start_time_loop_mal_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "e12493e6-6bb7-4457-90fb-f2dcfe88e056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:05.206399Z",
     "iopub.status.busy": "2025-06-12T00:26:05.206081Z",
     "iopub.status.idle": "2025-06-12T00:26:05.263622Z",
     "shell.execute_reply": "2025-06-12T00:26:05.263067Z",
     "shell.execute_reply.started": "2025-06-12T00:26:05.206379Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>disappointed :2, unprofessional :1, fake :1, s...</td>\n",
       "      <td>waiting :4, closed :2, unhelpful :1, ignored :...</td>\n",
       "      <td>rude :3, unhelpful :2, unprofessional :1, abru...</td>\n",
       "      <td></td>\n",
       "      <td>small collection:2, more inventory:1, more mod...</td>\n",
       "      <td>no discounts:1</td>\n",
       "      <td>expensive :1, scam :1, high :1</td>\n",
       "      <td>expensive:1, high:1, more:1</td>\n",
       "      <td>subpar :1, broke :1, low quality :1</td>\n",
       "      <td>exchange :2, NO FULL REFUND :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>none picked the phone :1, failed to listen :1,...</td>\n",
       "      <td>waited for 45+ minutes :2, waited for almost 4...</td>\n",
       "      <td>rude people along with Manager :1, took 2 hrs ...</td>\n",
       "      <td></td>\n",
       "      <td>collection was smaller than expected:2, need t...</td>\n",
       "      <td>gave good discount but now they are saying no ...</td>\n",
       "      <td>charged a little expensive on making charges :...</td>\n",
       "      <td>very high price:1, more expensive here:1, char...</td>\n",
       "      <td>not good quality :1, low quality product :1</td>\n",
       "      <td>only exchange, not explained to me :1, challen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Store Name Sentiment      Type  \\\n",
       "0  Malabar Gold & Diamonds-Frisco, TX  negative  keywords   \n",
       "1  Malabar Gold & Diamonds-Frisco, TX  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  disappointed :2, unprofessional :1, fake :1, s...   \n",
       "1  none picked the phone :1, failed to listen :1,...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  waiting :4, closed :2, unhelpful :1, ignored :...   \n",
       "1  waited for 45+ minutes :2, waited for almost 4...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :3, unhelpful :2, unprofessional :1, abru...                  \n",
       "1  rude people along with Manager :1, took 2 hrs ...                  \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  small collection:2, more inventory:1, more mod...   \n",
       "1  collection was smaller than expected:2, need t...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                                     no discounts:1   \n",
       "1  gave good discount but now they are saying no ...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                     expensive :1, scam :1, high :1   \n",
       "1  charged a little expensive on making charges :...   \n",
       "\n",
       "                                               Price  \\\n",
       "0                        expensive:1, high:1, more:1   \n",
       "1  very high price:1, more expensive here:1, char...   \n",
       "\n",
       "                               Product Quality  \\\n",
       "0          subpar :1, broke :1, low quality :1   \n",
       "1  not good quality :1, low quality product :1   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                     exchange :2, NO FULL REFUND :1  \n",
       "1  only exchange, not explained to me :1, challen...  "
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_fri_tx = pd.concat([negative_keywords_mal_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_fri_tx = pd.concat([negative_keywords_mal_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_fri_tx = negative_keywords_mal_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24497a08-2555-4757-95e0-147cac80c303",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mal_ric_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "c9db59f4-37f6-464d-a7e3-4cbe6cd10bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:05.264935Z",
     "iopub.status.busy": "2025-06-12T00:26:05.264487Z",
     "iopub.status.idle": "2025-06-12T00:26:17.297754Z",
     "shell.execute_reply": "2025-06-12T00:26:17.297234Z",
     "shell.execute_reply.started": "2025-06-12T00:26:05.264907Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  12.0\n",
      "Total Input Tokens -  6152\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  425\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mal_ric_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mal_ric_tx=[0]\n",
    "keyword_input_token_mal_ric_tx = 0\n",
    "keyword_output_token_mal_ric_tx = 0\n",
    "keyword_start_time_loop_mal_ric_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mal_ric_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mal_ric_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mal_ric_tx = keyword_dataframes['mal_ric_tx_final_sen_df_jul'][keyword_dataframes['mal_ric_tx_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mal_ric_tx:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mal_ric_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mal_ric_tx.append(keywords)\n",
    "        keyword_input_token_mal_ric_tx += input_tokens_loop\n",
    "        keyword_output_token_mal_ric_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mal_ric_tx = time.time()\n",
    "keyword_cost_input_token_mal_ric_tx = round((0.01/1000)*keyword_input_token_mal_ric_tx,2)\n",
    "keyword_cost_output_token_mal_ric_tx = round((0.03/1000)*keyword_output_token_mal_ric_tx,2)\n",
    "keyword_total_cost_mal_ric_tx = keyword_cost_input_token_mal_ric_tx + keyword_cost_output_token_mal_ric_tx\n",
    "keyword_total_time_loop_mal_ric_tx = keyword_end_time_loop_mal_ric_tx - keyword_start_time_loop_mal_ric_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mal_ric_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mal_ric_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mal_ric_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mal_ric_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mal_ric_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mal_ric_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mal_ric_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "65e8c05b-e360-4314-80c8-28b131c5ddf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:17.298895Z",
     "iopub.status.busy": "2025-06-12T00:26:17.298527Z",
     "iopub.status.idle": "2025-06-12T00:26:17.336393Z",
     "shell.execute_reply": "2025-06-12T00:26:17.335890Z",
     "shell.execute_reply.started": "2025-06-12T00:26:17.298866Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malani Jewellers-Richardson, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>lying :2, stupid :1</td>\n",
       "      <td>uncomfortable :1, rude :1, disappointed :1, un...</td>\n",
       "      <td>rude :3, unprofessional :1, hateful :1, disres...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>fake discounts:1</td>\n",
       "      <td></td>\n",
       "      <td>higher side:1, mark up:1, overcharged:1, fake ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malani Jewellers-Richardson, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>take all your information before you even deci...</td>\n",
       "      <td>eyes following my every move :1, experience wa...</td>\n",
       "      <td>not even giving the full details :1, not very ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mark up the price and give fake discounts:1</td>\n",
       "      <td></td>\n",
       "      <td>mark up the price:1, doesn't match with the li...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Malani Jewellers-Richardson, TX  negative  keywords   \n",
       "1  Malani Jewellers-Richardson, TX  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                                lying :2, stupid :1   \n",
       "1  take all your information before you even deci...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  uncomfortable :1, rude :1, disappointed :1, un...   \n",
       "1  eyes following my every move :1, experience wa...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :3, unprofessional :1, hateful :1, disres...                  \n",
       "1  not even giving the full details :1, not very ...                  \n",
       "\n",
       "  Product Variety                                     Discount Making Charge  \\\n",
       "0                                             fake discounts:1                 \n",
       "1                  mark up the price and give fake discounts:1                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  higher side:1, mark up:1, overcharged:1, fake ...   \n",
       "1  mark up the price:1, doesn't match with the li...   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                     \n",
       "1  No relevant negative keywords/ phrases                     "
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mal_ric_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mal_ric_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mal_ric_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mal_ric_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mal_ric_tx = pd.concat([negative_keywords_mal_ric_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mal_ric_tx = pd.concat([negative_keywords_mal_ric_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mal_ric_tx = negative_keywords_mal_ric_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mal_ric_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75194f-3c25-46a5-88cb-4846de851106",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### may_vie_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "f1f12b93-a4a3-4cf3-aeb3-39205c023f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:17.337285Z",
     "iopub.status.busy": "2025-06-12T00:26:17.337079Z",
     "iopub.status.idle": "2025-06-12T00:26:22.857033Z",
     "shell.execute_reply": "2025-06-12T00:26:22.856419Z",
     "shell.execute_reply.started": "2025-06-12T00:26:17.337269Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  5.5\n",
      "Total Input Tokens -  2629\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  210\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_may_vie_va = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_may_vie_va=[0]\n",
    "keyword_input_token_may_vie_va = 0\n",
    "keyword_output_token_may_vie_va = 0\n",
    "keyword_start_time_loop_may_vie_va = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_may_vie_va, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_may_vie_va[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_may_vie_va = keyword_dataframes['may_vie_va_final_sen_df_jul'][keyword_dataframes['may_vie_va_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_may_vie_va:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_may_vie_va,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_may_vie_va.append(keywords)\n",
    "        keyword_input_token_may_vie_va += input_tokens_loop\n",
    "        keyword_output_token_may_vie_va += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_may_vie_va = time.time()\n",
    "keyword_cost_input_token_may_vie_va = round((0.01/1000)*keyword_input_token_may_vie_va,2)\n",
    "keyword_cost_output_token_may_vie_va = round((0.03/1000)*keyword_output_token_may_vie_va,2)\n",
    "keyword_total_cost_may_vie_va = keyword_cost_input_token_may_vie_va + keyword_cost_output_token_may_vie_va\n",
    "keyword_total_time_loop_may_vie_va = keyword_end_time_loop_may_vie_va - keyword_start_time_loop_may_vie_va\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_may_vie_va[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_may_vie_va,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_may_vie_va)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_may_vie_va)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_may_vie_va)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_may_vie_va)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_may_vie_va,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "9b9b7b13-e377-41f2-bca2-29b5945c2529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:22.865964Z",
     "iopub.status.busy": "2025-06-12T00:26:22.865494Z",
     "iopub.status.idle": "2025-06-12T00:26:22.897051Z",
     "shell.execute_reply": "2025-06-12T00:26:22.896420Z",
     "shell.execute_reply.started": "2025-06-12T00:26:22.865932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May Jewelers-Vienna, VA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>horrible experience:1, scammed:1, terrible ser...</td>\n",
       "      <td>rude :1, annoying :1, scammers :1, horrible :1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high prices :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May Jewelers-Vienna, VA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>cut off gold:2, didn't adjust the size:1, scam...</td>\n",
       "      <td>guy with glasses started yelling :1, old lady ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>extremely high prices :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  May Jewelers-Vienna, VA  negative  keywords                       \n",
       "1  May Jewelers-Vienna, VA  negative   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  horrible experience:1, scammed:1, terrible ser...   \n",
       "1  cut off gold:2, didn't adjust the size:1, scam...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :1, annoying :1, scammers :1, horrible :1...                  \n",
       "1  guy with glasses started yelling :1, old lady ...                  \n",
       "\n",
       "  Product Variety Discount Making Charge                     Price  \\\n",
       "0                                                   high prices :1   \n",
       "1                                         extremely high prices :1   \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_may_vie_va = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_may_vie_va[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_may_vie_va:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'may_vie_va'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_may_vie_va = pd.concat([negative_keywords_may_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_may_vie_va = pd.concat([negative_keywords_may_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_may_vie_va = negative_keywords_may_vie_va.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_may_vie_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5e790-6ce8-4828-903e-1120da3ee9ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### son_ise_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "68f69a0c-fe6f-44a0-9935-3d03cdeba33d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:22.898210Z",
     "iopub.status.busy": "2025-06-12T00:26:22.897779Z",
     "iopub.status.idle": "2025-06-12T00:26:34.428841Z",
     "shell.execute_reply": "2025-06-12T00:26:34.428186Z",
     "shell.execute_reply.started": "2025-06-12T00:26:22.898190Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  11.5\n",
      "Total Input Tokens -  7420\n",
      "Total Input Cost = USD  0.07\n",
      "Total Output Tokens -  464\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_son_ise_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_son_ise_nj=[0]\n",
    "keyword_input_token_son_ise_nj = 0\n",
    "keyword_output_token_son_ise_nj = 0\n",
    "keyword_start_time_loop_son_ise_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_son_ise_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_son_ise_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_son_ise_nj = keyword_dataframes['son_ise_nj_final_sen_df_jul'][keyword_dataframes['son_ise_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_son_ise_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_son_ise_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_son_ise_nj.append(keywords)\n",
    "        keyword_input_token_son_ise_nj += input_tokens_loop\n",
    "        keyword_output_token_son_ise_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_son_ise_nj = time.time()\n",
    "keyword_cost_input_token_son_ise_nj = round((0.01/1000)*keyword_input_token_son_ise_nj,2)\n",
    "keyword_cost_output_token_son_ise_nj = round((0.03/1000)*keyword_output_token_son_ise_nj,2)\n",
    "keyword_total_cost_son_ise_nj = keyword_cost_input_token_son_ise_nj + keyword_cost_output_token_son_ise_nj\n",
    "keyword_total_time_loop_son_ise_nj = keyword_end_time_loop_son_ise_nj - keyword_start_time_loop_son_ise_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_son_ise_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_son_ise_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_son_ise_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_son_ise_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_son_ise_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_son_ise_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_son_ise_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "6b3b8909-9a35-494f-a887-eff461b4406f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:34.429988Z",
     "iopub.status.busy": "2025-06-12T00:26:34.429715Z",
     "iopub.status.idle": "2025-06-12T00:26:34.488163Z",
     "shell.execute_reply": "2025-06-12T00:26:34.487518Z",
     "shell.execute_reply.started": "2025-06-12T00:26:34.429962Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sona Jewelers-Iselin, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>overpriced:1</td>\n",
       "      <td>delayed order:1, unresponsive:1, overpriced:1,...</td>\n",
       "      <td>rude :2, uninterested :1, unappreciated :1, ru...</td>\n",
       "      <td>designs sucks:1, highly priced:1, looks fake:1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>overpriced: 3, pricey: 2, pricy: 2, high: 1, e...</td>\n",
       "      <td>poor quality:2, cheaply made:1, disintegrated:...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sona Jewelers-Iselin, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>prices are outrageously high for the quality:1</td>\n",
       "      <td>kept promising it would be ready the next day:...</td>\n",
       "      <td>staff seemed uninterested in helping :1, staff...</td>\n",
       "      <td>mix wax and metals:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>outrageously high for the quality: 1, way too ...</td>\n",
       "      <td>quality is really poor:1, completely disintegr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type  \\\n",
       "0  Sona Jewelers-Iselin, NJ  negative  keywords   \n",
       "1  Sona Jewelers-Iselin, NJ  negative   phrases   \n",
       "\n",
       "                              Customer Confidence  \\\n",
       "0                                    overpriced:1   \n",
       "1  prices are outrageously high for the quality:1   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  delayed order:1, unresponsive:1, overpriced:1,...   \n",
       "1  kept promising it would be ready the next day:...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :2, uninterested :1, unappreciated :1, ru...   \n",
       "1  staff seemed uninterested in helping :1, staff...   \n",
       "\n",
       "                                      Product Design Product Variety Discount  \\\n",
       "0  designs sucks:1, highly priced:1, looks fake:1...                            \n",
       "1                               mix wax and metals:1                            \n",
       "\n",
       "  Making Charge                                              Price  \\\n",
       "0                overpriced: 3, pricey: 2, pricy: 2, high: 1, e...   \n",
       "1                outrageously high for the quality: 1, way too ...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  poor quality:2, cheaply made:1, disintegrated:...                     \n",
       "1  quality is really poor:1, completely disintegr...                     "
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_son_ise_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_son_ise_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_son_ise_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'son_ise_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_son_ise_nj = pd.concat([negative_keywords_son_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_son_ise_nj = pd.concat([negative_keywords_son_ise_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_son_ise_nj = negative_keywords_son_ise_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_son_ise_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc86d82-8d5d-4cc2-91c2-ce59d60fed73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "06b783e4-4160-4c0f-bc19-541eebc1ed35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:34.489447Z",
     "iopub.status.busy": "2025-06-12T00:26:34.489049Z",
     "iopub.status.idle": "2025-06-12T00:26:48.022689Z",
     "shell.execute_reply": "2025-06-12T00:26:48.022104Z",
     "shell.execute_reply.started": "2025-06-12T00:26:34.489425Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  13.5\n",
      "Total Input Tokens -  4950\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  386\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_chi_il=[0]\n",
    "keyword_input_token_tif_chi_il = 0\n",
    "keyword_output_token_tif_chi_il = 0\n",
    "keyword_start_time_loop_tif_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_chi_il = keyword_dataframes['tif_chi_il_final_sen_df_jul'][keyword_dataframes['tif_chi_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_chi_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_chi_il.append(keywords)\n",
    "        keyword_input_token_tif_chi_il += input_tokens_loop\n",
    "        keyword_output_token_tif_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_chi_il = time.time()\n",
    "keyword_cost_input_token_tif_chi_il = round((0.01/1000)*keyword_input_token_tif_chi_il,2)\n",
    "keyword_cost_output_token_tif_chi_il = round((0.03/1000)*keyword_output_token_tif_chi_il,2)\n",
    "keyword_total_cost_tif_chi_il = keyword_cost_input_token_tif_chi_il + keyword_cost_output_token_tif_chi_il\n",
    "keyword_total_time_loop_tif_chi_il = keyword_end_time_loop_tif_chi_il - keyword_start_time_loop_tif_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "9dc9720c-adef-490b-926f-035dc0b4f742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:48.023908Z",
     "iopub.status.busy": "2025-06-12T00:26:48.023538Z",
     "iopub.status.idle": "2025-06-12T00:26:48.059867Z",
     "shell.execute_reply": "2025-06-12T00:26:48.059340Z",
     "shell.execute_reply.started": "2025-06-12T00:26:48.023878Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>sold their customer list:1, marketing company:...</td>\n",
       "      <td>unprofessional :1, unwelcome :1, uncomfortable...</td>\n",
       "      <td>unprofessional :1, rude :2, inappropriate :1, ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>expensive: 2, poor: 1</td>\n",
       "      <td>tarnishes :1, defective :1, broke :1, unwearab...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>DO NOT give any of your info:1, end-up on a “r...</td>\n",
       "      <td>inappropriate comment :1, deplorable state :1,...</td>\n",
       "      <td>made an inappropriate comment :1, salesman was...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>very expensive: 1, sells items at that price: ...</td>\n",
       "      <td>tarnishes so badly :1, defective one :1, broke...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Chicago, IL  negative  keywords   \n",
       "1  Tiffany & Co-Chicago, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  sold their customer list:1, marketing company:...   \n",
       "1  DO NOT give any of your info:1, end-up on a “r...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unprofessional :1, unwelcome :1, uncomfortable...   \n",
       "1  inappropriate comment :1, deplorable state :1,...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  unprofessional :1, rude :2, inappropriate :1, ...                  \n",
       "1  made an inappropriate comment :1, salesman was...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                               Price  \\\n",
       "0                              expensive: 2, poor: 1   \n",
       "1  very expensive: 1, sells items at that price: ...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  tarnishes :1, defective :1, broke :1, unwearab...                     \n",
       "1  tarnishes so badly :1, defective one :1, broke...                     "
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_chi_il = pd.concat([negative_keywords_tif_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_chi_il = pd.concat([negative_keywords_tif_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_chi_il = negative_keywords_tif_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b622ab-80a1-49a7-8d31-7970760199da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_nor_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "d4a96f7d-1c8c-4b3e-be07-d2dfbb292d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:48.060938Z",
     "iopub.status.busy": "2025-06-12T00:26:48.060700Z",
     "iopub.status.idle": "2025-06-12T00:26:57.090538Z",
     "shell.execute_reply": "2025-06-12T00:26:57.089986Z",
     "shell.execute_reply.started": "2025-06-12T00:26:48.060920Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  9.0\n",
      "Total Input Tokens -  5080\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  332\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_nor_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_nor_il=[0]\n",
    "keyword_input_token_tif_nor_il = 0\n",
    "keyword_output_token_tif_nor_il = 0\n",
    "keyword_start_time_loop_tif_nor_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_nor_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_nor_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_nor_il = keyword_dataframes['tif_nor_il_final_sen_df_jul'][keyword_dataframes['tif_nor_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_nor_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_nor_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_nor_il.append(keywords)\n",
    "        keyword_input_token_tif_nor_il += input_tokens_loop\n",
    "        keyword_output_token_tif_nor_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_nor_il = time.time()\n",
    "keyword_cost_input_token_tif_nor_il = round((0.01/1000)*keyword_input_token_tif_nor_il,2)\n",
    "keyword_cost_output_token_tif_nor_il = round((0.03/1000)*keyword_output_token_tif_nor_il,2)\n",
    "keyword_total_cost_tif_nor_il = keyword_cost_input_token_tif_nor_il + keyword_cost_output_token_tif_nor_il\n",
    "keyword_total_time_loop_tif_nor_il = keyword_end_time_loop_tif_nor_il - keyword_start_time_loop_tif_nor_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_nor_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_nor_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_nor_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_nor_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_nor_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_nor_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_nor_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "bbd66126-ac2f-4896-aa6b-8bb129a8099c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:57.091588Z",
     "iopub.status.busy": "2025-06-12T00:26:57.091365Z",
     "iopub.status.idle": "2025-06-12T00:26:57.131219Z",
     "shell.execute_reply": "2025-06-12T00:26:57.130718Z",
     "shell.execute_reply.started": "2025-06-12T00:26:57.091569Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Northbrook, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>RUDE :1, discriminatory :1</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>charge :1, cheap :1</td>\n",
       "      <td>tarnished :3, disappointed :1, appaling :1</td>\n",
       "      <td>nothing done:1, extremely disappointed:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Northbrook, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>Wouldn't let me touch product I requested :1</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>wanted to charge me 20$ :1, not a cheap store :1</td>\n",
       "      <td>worst combination of materials :1, needed extr...</td>\n",
       "      <td>wanted to exchange it and was told there was n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Northbrook, IL  negative  keywords                       \n",
       "1  Tiffany & Co-Northbrook, IL  negative   phrases                       \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                    Store Staff Product Design  \\\n",
       "0                    RUDE :1, discriminatory :1                  \n",
       "1  Wouldn't let me touch product I requested :1                  \n",
       "\n",
       "                          Product Variety Discount Making Charge  \\\n",
       "0  No relevant negative keywords/ phrases                          \n",
       "1  No relevant negative keywords/ phrases                          \n",
       "\n",
       "                                              Price  \\\n",
       "0                               charge :1, cheap :1   \n",
       "1  wanted to charge me 20$ :1, not a cheap store :1   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0         tarnished :3, disappointed :1, appaling :1   \n",
       "1  worst combination of materials :1, needed extr...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0           nothing done:1, extremely disappointed:1  \n",
       "1  wanted to exchange it and was told there was n...  "
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_nor_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_nor_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_nor_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_nor_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_nor_il = pd.concat([negative_keywords_tif_nor_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_nor_il = pd.concat([negative_keywords_tif_nor_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_nor_il = negative_keywords_tif_nor_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_nor_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b3f42-70e3-45bf-b787-3e56d7f1ac93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_sko_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "2627a8cf-5e44-408c-bdbb-8083e71a62ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:26:57.132112Z",
     "iopub.status.busy": "2025-06-12T00:26:57.131893Z",
     "iopub.status.idle": "2025-06-12T00:27:05.154963Z",
     "shell.execute_reply": "2025-06-12T00:27:05.154397Z",
     "shell.execute_reply.started": "2025-06-12T00:26:57.132095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  8.0\n",
      "Total Input Tokens -  5959\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  351\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_sko_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_sko_il=[0]\n",
    "keyword_input_token_tif_sko_il = 0\n",
    "keyword_output_token_tif_sko_il = 0\n",
    "keyword_start_time_loop_tif_sko_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_sko_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_sko_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_sko_il = keyword_dataframes['tif_sko_il_final_sen_df_jul'][keyword_dataframes['tif_sko_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_sko_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_sko_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_sko_il.append(keywords)\n",
    "        keyword_input_token_tif_sko_il += input_tokens_loop\n",
    "        keyword_output_token_tif_sko_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_sko_il = time.time()\n",
    "keyword_cost_input_token_tif_sko_il = round((0.01/1000)*keyword_input_token_tif_sko_il,2)\n",
    "keyword_cost_output_token_tif_sko_il = round((0.03/1000)*keyword_output_token_tif_sko_il,2)\n",
    "keyword_total_cost_tif_sko_il = keyword_cost_input_token_tif_sko_il + keyword_cost_output_token_tif_sko_il\n",
    "keyword_total_time_loop_tif_sko_il = keyword_end_time_loop_tif_sko_il - keyword_start_time_loop_tif_sko_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_sko_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_sko_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_sko_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_sko_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_sko_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_sko_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_sko_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "9f13bfcd-4e8b-487d-8739-fcf95d00f85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:05.155888Z",
     "iopub.status.busy": "2025-06-12T00:27:05.155623Z",
     "iopub.status.idle": "2025-06-12T00:27:05.191854Z",
     "shell.execute_reply": "2025-06-12T00:27:05.191386Z",
     "shell.execute_reply.started": "2025-06-12T00:27:05.155869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Skokie, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>dishonest :1, refused :1, lost :1, discrepancy...</td>\n",
       "      <td>disappointing :2, lost :2, irreplaceable :1, s...</td>\n",
       "      <td>rude :1, dismissive :1, dishonest :1, attitude...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Skokie, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>did not honor the Tiffany promise :1, refused ...</td>\n",
       "      <td>deeply disappointing :1, policy should change ...</td>\n",
       "      <td>did not honor the Tiffany promise :1, refused ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Skokie, IL  negative  keywords   \n",
       "1  Tiffany & Co-Skokie, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  dishonest :1, refused :1, lost :1, discrepancy...   \n",
       "1  did not honor the Tiffany promise :1, refused ...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  disappointing :2, lost :2, irreplaceable :1, s...   \n",
       "1  deeply disappointing :1, policy should change ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :1, dismissive :1, dishonest :1, attitude...                  \n",
       "1  did not honor the Tiffany promise :1, refused ...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                    Price  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                          Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                     \n",
       "1  No relevant negative keywords/ phrases                     "
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_sko_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_sko_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_sko_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_sko_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_sko_il = pd.concat([negative_keywords_tif_sko_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_sko_il = pd.concat([negative_keywords_tif_sko_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_sko_il = negative_keywords_tif_sko_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_sko_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df223d04-e597-4ce5-b582-d274d4848879",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_eas_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "f2f41a00-f393-4959-ab40-26799977e7cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:05.193170Z",
     "iopub.status.busy": "2025-06-12T00:27:05.192696Z",
     "iopub.status.idle": "2025-06-12T00:27:11.212719Z",
     "shell.execute_reply": "2025-06-12T00:27:11.212215Z",
     "shell.execute_reply.started": "2025-06-12T00:27:05.193149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  6.0\n",
      "Total Input Tokens -  2758\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  215\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_eas_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_eas_nj=[0]\n",
    "keyword_input_token_tif_eas_nj = 0\n",
    "keyword_output_token_tif_eas_nj = 0\n",
    "keyword_start_time_loop_tif_eas_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_eas_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_eas_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_eas_nj = keyword_dataframes['tif_eas_nj_final_sen_df_jul'][keyword_dataframes['tif_eas_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_eas_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_eas_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_eas_nj.append(keywords)\n",
    "        keyword_input_token_tif_eas_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_eas_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_eas_nj = time.time()\n",
    "keyword_cost_input_token_tif_eas_nj = round((0.01/1000)*keyword_input_token_tif_eas_nj,2)\n",
    "keyword_cost_output_token_tif_eas_nj = round((0.03/1000)*keyword_output_token_tif_eas_nj,2)\n",
    "keyword_total_cost_tif_eas_nj = keyword_cost_input_token_tif_eas_nj + keyword_cost_output_token_tif_eas_nj\n",
    "keyword_total_time_loop_tif_eas_nj = keyword_end_time_loop_tif_eas_nj - keyword_start_time_loop_tif_eas_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_eas_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_eas_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_eas_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_eas_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_eas_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_eas_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_eas_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "e2d84cea-d912-4394-b345-2faf6cb0f1af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:11.213696Z",
     "iopub.status.busy": "2025-06-12T00:27:11.213401Z",
     "iopub.status.idle": "2025-06-12T00:27:11.245504Z",
     "shell.execute_reply": "2025-06-12T00:27:11.245030Z",
     "shell.execute_reply.started": "2025-06-12T00:27:11.213675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-East Rutherford, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>ignored :1, unhelpful :1, dismissive :1, conde...</td>\n",
       "      <td>rude :1, unhelpful :1, dismissive :1, condesce...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-East Rutherford, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>completely ignored when entering a store :1, d...</td>\n",
       "      <td>verbally abusing :1, bothered by my presence :...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-East Rutherford, NJ  negative  keywords                       \n",
       "1  Tiffany & Co-East Rutherford, NJ  negative   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  ignored :1, unhelpful :1, dismissive :1, conde...   \n",
       "1  completely ignored when entering a store :1, d...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :1, unhelpful :1, dismissive :1, condesce...                  \n",
       "1  verbally abusing :1, bothered by my presence :...                  \n",
       "\n",
       "                          Product Variety Discount Making Charge Price  \\\n",
       "0  No relevant negative keywords/ phrases                                \n",
       "1  No relevant negative keywords/ phrases                                \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_eas_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_eas_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_eas_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_eas_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_eas_nj = pd.concat([negative_keywords_tif_eas_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_eas_nj = pd.concat([negative_keywords_tif_eas_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_eas_nj = negative_keywords_tif_eas_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_eas_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd3232-b711-4ee5-afe7-247271ee2243",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_red_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "55763d4f-80f4-47aa-b6e3-f2c2a0570fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:11.246433Z",
     "iopub.status.busy": "2025-06-12T00:27:11.246163Z",
     "iopub.status.idle": "2025-06-12T00:27:21.272448Z",
     "shell.execute_reply": "2025-06-12T00:27:21.271904Z",
     "shell.execute_reply.started": "2025-06-12T00:27:11.246408Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.0\n",
      "Total Input Tokens -  5811\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  371\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_red_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_red_nj=[0]\n",
    "keyword_input_token_tif_red_nj = 0\n",
    "keyword_output_token_tif_red_nj = 0\n",
    "keyword_start_time_loop_tif_red_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_red_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_red_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_red_nj = keyword_dataframes['tif_red_nj_final_sen_df_jul'][keyword_dataframes['tif_red_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_red_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_red_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_red_nj.append(keywords)\n",
    "        keyword_input_token_tif_red_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_red_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_red_nj = time.time()\n",
    "keyword_cost_input_token_tif_red_nj = round((0.01/1000)*keyword_input_token_tif_red_nj,2)\n",
    "keyword_cost_output_token_tif_red_nj = round((0.03/1000)*keyword_output_token_tif_red_nj,2)\n",
    "keyword_total_cost_tif_red_nj = keyword_cost_input_token_tif_red_nj + keyword_cost_output_token_tif_red_nj\n",
    "keyword_total_time_loop_tif_red_nj = keyword_end_time_loop_tif_red_nj - keyword_start_time_loop_tif_red_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_red_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_red_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_red_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_red_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_red_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_red_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_red_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "2359e6e8-bae2-47e8-8914-df756e5f17b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:21.273416Z",
     "iopub.status.busy": "2025-06-12T00:27:21.273132Z",
     "iopub.status.idle": "2025-06-12T00:27:21.308408Z",
     "shell.execute_reply": "2025-06-12T00:27:21.307884Z",
     "shell.execute_reply.started": "2025-06-12T00:27:21.273394Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Red Bank, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>rude treatment:1, misled:1, disrespected:1, fr...</td>\n",
       "      <td>rude treatment:1, unwilling:1, misled:1, disre...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>overpriced:1, expensive:1</td>\n",
       "      <td>Garbage :1, overpriced :1</td>\n",
       "      <td>store policy :2, original purchaser :2, remain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Red Bank, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>staff clearly profiles patrons:1, unwilling to...</td>\n",
       "      <td>staff clearly profiles patrons:1, unwilling to...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>way overpriced:1, expensive place:1, high end,...</td>\n",
       "      <td>Garbage jewelry :1</td>\n",
       "      <td>could only be paid by check to the original pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Red Bank, NJ  negative  keywords                       \n",
       "1  Tiffany & Co-Red Bank, NJ  negative   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  rude treatment:1, misled:1, disrespected:1, fr...   \n",
       "1  staff clearly profiles patrons:1, unwilling to...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude treatment:1, unwilling:1, misled:1, disre...                  \n",
       "1  staff clearly profiles patrons:1, unwilling to...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                               Price  \\\n",
       "0                          overpriced:1, expensive:1   \n",
       "1  way overpriced:1, expensive place:1, high end,...   \n",
       "\n",
       "             Product Quality  \\\n",
       "0  Garbage :1, overpriced :1   \n",
       "1         Garbage jewelry :1   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  store policy :2, original purchaser :2, remain...  \n",
       "1  could only be paid by check to the original pu...  "
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_red_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_red_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_red_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_red_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_red_nj = pd.concat([negative_keywords_tif_red_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_red_nj = pd.concat([negative_keywords_tif_red_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_red_nj = negative_keywords_tif_red_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_red_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125296e7-5346-4eaf-8fbe-16e33be84b50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_hac_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "355c5640-8f35-44d8-a9f4-eecad1e62c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:21.309515Z",
     "iopub.status.busy": "2025-06-12T00:27:21.309219Z",
     "iopub.status.idle": "2025-06-12T00:27:30.334977Z",
     "shell.execute_reply": "2025-06-12T00:27:30.334327Z",
     "shell.execute_reply.started": "2025-06-12T00:27:21.309495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  9.0\n",
      "Total Input Tokens -  4474\n",
      "Total Input Cost = USD  0.04\n",
      "Total Output Tokens -  399\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_hac_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_hac_nj=[0]\n",
    "keyword_input_token_tif_hac_nj = 0\n",
    "keyword_output_token_tif_hac_nj = 0\n",
    "keyword_start_time_loop_tif_hac_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_hac_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_hac_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_hac_nj = keyword_dataframes['tif_hac_nj_final_sen_df_jul'][keyword_dataframes['tif_hac_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_hac_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_hac_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_hac_nj.append(keywords)\n",
    "        keyword_input_token_tif_hac_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_hac_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_hac_nj = time.time()\n",
    "keyword_cost_input_token_tif_hac_nj = round((0.01/1000)*keyword_input_token_tif_hac_nj,2)\n",
    "keyword_cost_output_token_tif_hac_nj = round((0.03/1000)*keyword_output_token_tif_hac_nj,2)\n",
    "keyword_total_cost_tif_hac_nj = keyword_cost_input_token_tif_hac_nj + keyword_cost_output_token_tif_hac_nj\n",
    "keyword_total_time_loop_tif_hac_nj = keyword_end_time_loop_tif_hac_nj - keyword_start_time_loop_tif_hac_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_hac_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_hac_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_hac_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_hac_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_hac_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_hac_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_hac_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "2a154da3-0d36-44d5-9292-db178c375450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:30.336951Z",
     "iopub.status.busy": "2025-06-12T00:27:30.336691Z",
     "iopub.status.idle": "2025-06-12T00:27:30.372464Z",
     "shell.execute_reply": "2025-06-12T00:27:30.371826Z",
     "shell.execute_reply.started": "2025-06-12T00:27:30.336933Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Hackensack, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>reputation :1, stand by :1, reputable :1</td>\n",
       "      <td>unprofessional :2, rude :2, negative impressio...</td>\n",
       "      <td>rude :3, unprofessional :2, not knowledgeable ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>normal wear :1, fell out :1, repair :1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Hackensack, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>do not stand by their products or customers :1...</td>\n",
       "      <td>very unprofessional and really turned me away ...</td>\n",
       "      <td>staff are rude and not knowledgeable :1, very ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>small diamonds fell out :1, do not stand by th...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Hackensack, NJ  negative  keywords   \n",
       "1  Tiffany & Co-Hackensack, NJ  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0           reputation :1, stand by :1, reputable :1   \n",
       "1  do not stand by their products or customers :1...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unprofessional :2, rude :2, negative impressio...   \n",
       "1  very unprofessional and really turned me away ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :3, unprofessional :2, not knowledgeable ...                  \n",
       "1  staff are rude and not knowledgeable :1, very ...                  \n",
       "\n",
       "  Product Variety Discount Making Charge  \\\n",
       "0                                          \n",
       "1                                          \n",
       "\n",
       "                                    Price  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0             normal wear :1, fell out :1, repair :1                     \n",
       "1  small diamonds fell out :1, do not stand by th...                     "
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_hac_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_hac_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_hac_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_hac_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_hac_nj = pd.concat([negative_keywords_tif_hac_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_hac_nj = pd.concat([negative_keywords_tif_hac_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_hac_nj = negative_keywords_tif_hac_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_hac_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd184db-10f1-42cf-957a-4b8c9c8638ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_sho_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "3431f97a-70ec-4cd7-8dfb-74ab37f8f175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:30.373617Z",
     "iopub.status.busy": "2025-06-12T00:27:30.373360Z",
     "iopub.status.idle": "2025-06-12T00:27:41.903010Z",
     "shell.execute_reply": "2025-06-12T00:27:41.902455Z",
     "shell.execute_reply.started": "2025-06-12T00:27:30.373593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  11.5\n",
      "Total Input Tokens -  6545\n",
      "Total Input Cost = USD  0.07\n",
      "Total Output Tokens -  433\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_sho_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_sho_nj=[0]\n",
    "keyword_input_token_tif_sho_nj = 0\n",
    "keyword_output_token_tif_sho_nj = 0\n",
    "keyword_start_time_loop_tif_sho_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_sho_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_sho_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_sho_nj = keyword_dataframes['tif_sho_nj_final_sen_df_jul'][keyword_dataframes['tif_sho_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_sho_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_sho_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_sho_nj.append(keywords)\n",
    "        keyword_input_token_tif_sho_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_sho_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_sho_nj = time.time()\n",
    "keyword_cost_input_token_tif_sho_nj = round((0.01/1000)*keyword_input_token_tif_sho_nj,2)\n",
    "keyword_cost_output_token_tif_sho_nj = round((0.03/1000)*keyword_output_token_tif_sho_nj,2)\n",
    "keyword_total_cost_tif_sho_nj = keyword_cost_input_token_tif_sho_nj + keyword_cost_output_token_tif_sho_nj\n",
    "keyword_total_time_loop_tif_sho_nj = keyword_end_time_loop_tif_sho_nj - keyword_start_time_loop_tif_sho_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_sho_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_sho_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_sho_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_sho_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_sho_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_sho_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_sho_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "86de7cbb-12c5-4af3-be7a-f43d6e0f3e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:41.903869Z",
     "iopub.status.busy": "2025-06-12T00:27:41.903675Z",
     "iopub.status.idle": "2025-06-12T00:27:41.942767Z",
     "shell.execute_reply": "2025-06-12T00:27:41.942147Z",
     "shell.execute_reply.started": "2025-06-12T00:27:41.903851Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Short Hills, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>out of luck:1, outrageous:1, waste:1</td>\n",
       "      <td>scratches :1, looser :1, incorrect :1, defensi...</td>\n",
       "      <td>unprofessional :1, defensive :1, rude :1, mise...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>over priced:1, premium:1, five figures:1</td>\n",
       "      <td>scratches :1, low quality :1, marked up :1, fa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Short Hills, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>claims it has all the quality guarantees and w...</td>\n",
       "      <td>noticeable large scratches :1, took them 15-20...</td>\n",
       "      <td>asked too many personal questions :1, very sho...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>not worth the premium:1, over priced low quali...</td>\n",
       "      <td>noticeable large scratches :1, low quality jew...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Short Hills, NJ  negative  keywords   \n",
       "1  Tiffany & Co-Short Hills, NJ  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0               out of luck:1, outrageous:1, waste:1   \n",
       "1  claims it has all the quality guarantees and w...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  scratches :1, looser :1, incorrect :1, defensi...   \n",
       "1  noticeable large scratches :1, took them 15-20...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  unprofessional :1, defensive :1, rude :1, mise...                  \n",
       "1  asked too many personal questions :1, very sho...                  \n",
       "\n",
       "                          Product Variety Discount Making Charge  \\\n",
       "0  No relevant negative keywords/ phrases                          \n",
       "1  No relevant negative keywords/ phrases                          \n",
       "\n",
       "                                               Price  \\\n",
       "0           over priced:1, premium:1, five figures:1   \n",
       "1  not worth the premium:1, over priced low quali...   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0  scratches :1, low quality :1, marked up :1, fa...                     \n",
       "1  noticeable large scratches :1, low quality jew...                     "
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_sho_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_sho_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_sho_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_sho_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_sho_nj = pd.concat([negative_keywords_tif_sho_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_sho_nj = pd.concat([negative_keywords_tif_sho_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_sho_nj = negative_keywords_tif_sho_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_sho_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44fbe7-08fc-4f64-9466-8a367197ee8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_par_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "0aeff56e-65b0-4079-8918-589e42432d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:41.944079Z",
     "iopub.status.busy": "2025-06-12T00:27:41.943654Z",
     "iopub.status.idle": "2025-06-12T00:27:46.964594Z",
     "shell.execute_reply": "2025-06-12T00:27:46.964098Z",
     "shell.execute_reply.started": "2025-06-12T00:27:41.944051Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  5.0\n",
      "Total Input Tokens -  2947\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  191\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_par_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_par_nj=[0]\n",
    "keyword_input_token_tif_par_nj = 0\n",
    "keyword_output_token_tif_par_nj = 0\n",
    "keyword_start_time_loop_tif_par_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_par_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_par_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_par_nj = keyword_dataframes['tif_par_nj_final_sen_df_jul'][keyword_dataframes['tif_par_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_par_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_par_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_par_nj.append(keywords)\n",
    "        keyword_input_token_tif_par_nj += input_tokens_loop\n",
    "        keyword_output_token_tif_par_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_par_nj = time.time()\n",
    "keyword_cost_input_token_tif_par_nj = round((0.01/1000)*keyword_input_token_tif_par_nj,2)\n",
    "keyword_cost_output_token_tif_par_nj = round((0.03/1000)*keyword_output_token_tif_par_nj,2)\n",
    "keyword_total_cost_tif_par_nj = keyword_cost_input_token_tif_par_nj + keyword_cost_output_token_tif_par_nj\n",
    "keyword_total_time_loop_tif_par_nj = keyword_end_time_loop_tif_par_nj - keyword_start_time_loop_tif_par_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_par_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_par_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_par_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_par_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_par_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_par_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_par_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "91c9317b-ccf5-4b7d-8899-34d6c246efab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:46.965586Z",
     "iopub.status.busy": "2025-06-12T00:27:46.965292Z",
     "iopub.status.idle": "2025-06-12T00:27:46.998250Z",
     "shell.execute_reply": "2025-06-12T00:27:46.997735Z",
     "shell.execute_reply.started": "2025-06-12T00:27:46.965566Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Paramus, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>unprofessional :1, unacceptable :1, dismissive...</td>\n",
       "      <td>unhelpful :1, dismissive :1, rude :1, unprofes...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Paramus, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>treated poorly :1, no communication whatsoever...</td>\n",
       "      <td>no empathy whatsoever :1, treated poorly :1, b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tiffany & Co-Paramus, NJ  negative  keywords                       \n",
       "1  Tiffany & Co-Paramus, NJ  negative   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  unprofessional :1, unacceptable :1, dismissive...   \n",
       "1  treated poorly :1, no communication whatsoever...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  unhelpful :1, dismissive :1, rude :1, unprofes...                  \n",
       "1  no empathy whatsoever :1, treated poorly :1, b...                  \n",
       "\n",
       "  Product Variety Discount Making Charge Price Product Quality  \\\n",
       "0                                                                \n",
       "1                                                                \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_par_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_par_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_par_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_par_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_par_nj = pd.concat([negative_keywords_tif_par_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_par_nj = pd.concat([negative_keywords_tif_par_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_par_nj = negative_keywords_tif_par_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_par_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062baea1-9f28-4c8a-86d0-8ad6175f2f1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_vie_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "3c8efaf8-646c-4540-9e1d-2abd6ad3c6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:46.999292Z",
     "iopub.status.busy": "2025-06-12T00:27:46.999006Z",
     "iopub.status.idle": "2025-06-12T00:27:51.014794Z",
     "shell.execute_reply": "2025-06-12T00:27:51.014213Z",
     "shell.execute_reply.started": "2025-06-12T00:27:46.999273Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  4.0\n",
      "Total Input Tokens -  2508\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  140\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.03\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_vie_va = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_vie_va=[0]\n",
    "keyword_input_token_tif_vie_va = 0\n",
    "keyword_output_token_tif_vie_va = 0\n",
    "keyword_start_time_loop_tif_vie_va = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_vie_va, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_vie_va[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_vie_va = keyword_dataframes['tif_vie_va_final_sen_df_jul'][keyword_dataframes['tif_vie_va_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_vie_va:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_vie_va,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_vie_va.append(keywords)\n",
    "        keyword_input_token_tif_vie_va += input_tokens_loop\n",
    "        keyword_output_token_tif_vie_va += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_vie_va = time.time()\n",
    "keyword_cost_input_token_tif_vie_va = round((0.01/1000)*keyword_input_token_tif_vie_va,2)\n",
    "keyword_cost_output_token_tif_vie_va = round((0.03/1000)*keyword_output_token_tif_vie_va,2)\n",
    "keyword_total_cost_tif_vie_va = keyword_cost_input_token_tif_vie_va + keyword_cost_output_token_tif_vie_va\n",
    "keyword_total_time_loop_tif_vie_va = keyword_end_time_loop_tif_vie_va - keyword_start_time_loop_tif_vie_va\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_vie_va[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_vie_va,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_vie_va)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_vie_va)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_vie_va)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_vie_va)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_vie_va,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "d09fdb34-af04-4f50-9530-0ded4ab76251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:51.015730Z",
     "iopub.status.busy": "2025-06-12T00:27:51.015456Z",
     "iopub.status.idle": "2025-06-12T00:27:51.046845Z",
     "shell.execute_reply": "2025-06-12T00:27:51.046406Z",
     "shell.execute_reply.started": "2025-06-12T00:27:51.015710Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany &amp; Co-Vienna, VA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>empty store :1, no warmth :1, no verification :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiffany &amp; Co-Vienna, VA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>treats customers like transactions :1, no warm...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type  \\\n",
       "0  Tiffany & Co-Vienna, VA  negative  keywords   \n",
       "1  Tiffany & Co-Vienna, VA  negative   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0   empty store :1, no warmth :1, no verification :1   \n",
       "1  treats customers like transactions :1, no warm...   \n",
       "\n",
       "                              Store Staff Product Design Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases                                  \n",
       "1  No relevant negative keywords/ phrases                                  \n",
       "\n",
       "  Discount Making Charge Price Product Quality Jewellery Exchange  \n",
       "0                                                                  \n",
       "1                                                                  "
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_vie_va = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_vie_va[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_vie_va:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_vie_va'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_vie_va = pd.concat([negative_keywords_tif_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_vie_va = pd.concat([negative_keywords_tif_vie_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_vie_va = negative_keywords_tif_vie_va.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_vie_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c879663-4049-42e2-822e-13e37b097874",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tif_ric_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "3948a5ad-782b-419c-8cf6-e116f7fe5793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:51.047759Z",
     "iopub.status.busy": "2025-06-12T00:27:51.047553Z",
     "iopub.status.idle": "2025-06-12T00:27:51.060501Z",
     "shell.execute_reply": "2025-06-12T00:27:51.059999Z",
     "shell.execute_reply.started": "2025-06-12T00:27:51.047742Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  0.0\n",
      "Total Input Tokens -  0\n",
      "Total Input Cost = USD  0.0\n",
      "Total Output Tokens -  0\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tif_ric_va = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tif_ric_va=[0]\n",
    "keyword_input_token_tif_ric_va = 0\n",
    "keyword_output_token_tif_ric_va = 0\n",
    "keyword_start_time_loop_tif_ric_va = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tif_ric_va, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tif_ric_va[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tif_ric_va = keyword_dataframes['tif_ric_va_final_sen_df_jul'][keyword_dataframes['tif_ric_va_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tif_ric_va:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tif_ric_va,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tif_ric_va.append(keywords)\n",
    "        keyword_input_token_tif_ric_va += input_tokens_loop\n",
    "        keyword_output_token_tif_ric_va += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tif_ric_va = time.time()\n",
    "keyword_cost_input_token_tif_ric_va = round((0.01/1000)*keyword_input_token_tif_ric_va,2)\n",
    "keyword_cost_output_token_tif_ric_va = round((0.03/1000)*keyword_output_token_tif_ric_va,2)\n",
    "keyword_total_cost_tif_ric_va = keyword_cost_input_token_tif_ric_va + keyword_cost_output_token_tif_ric_va\n",
    "keyword_total_time_loop_tif_ric_va = keyword_end_time_loop_tif_ric_va - keyword_start_time_loop_tif_ric_va\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tif_ric_va[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tif_ric_va,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tif_ric_va)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tif_ric_va)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tif_ric_va)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tif_ric_va)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tif_ric_va,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "c1186df9-42e4-4315-b99c-8f2758c75cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:27:51.061882Z",
     "iopub.status.busy": "2025-06-12T00:27:51.061335Z",
     "iopub.status.idle": "2025-06-12T00:27:51.083580Z",
     "shell.execute_reply": "2025-06-12T00:27:51.082659Z",
     "shell.execute_reply.started": "2025-06-12T00:27:51.061856Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Type, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16051/906793812.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mrow_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnegative_keywords_tif_ric_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnegative_keywords_tif_ric_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mnegative_keywords_tif_ric_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_keywords_tif_ric_va\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mnegative_keywords_tif_ric_va\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot insert \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert Type, already exists"
     ]
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tif_ric_va = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tif_ric_va[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tif_ric_va:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tif_ric_va'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tif_ric_va = pd.concat([negative_keywords_tif_ric_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tif_ric_va = pd.concat([negative_keywords_tif_ric_va, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tif_ric_va = negative_keywords_tif_ric_va.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tif_ric_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f031acb-93ae-4788-bbec-c2ed69d34b1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### vbj_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "a48663ec-2b7f-4b8f-bd8d-6b537e0b2c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:28:49.291152Z",
     "iopub.status.busy": "2025-06-12T00:28:49.290862Z",
     "iopub.status.idle": "2025-06-12T00:29:06.324701Z",
     "shell.execute_reply": "2025-06-12T00:29:06.324145Z",
     "shell.execute_reply.started": "2025-06-12T00:28:49.291132Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  17.0\n",
      "Total Input Tokens -  11789\n",
      "Total Input Cost = USD  0.12\n",
      "Total Output Tokens -  746\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.14\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_vbj_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_vbj_fri_tx=[0]\n",
    "keyword_input_token_vbj_fri_tx = 0\n",
    "keyword_output_token_vbj_fri_tx = 0\n",
    "keyword_start_time_loop_vbj_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_vbj_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_vbj_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_vbj_fri_tx = keyword_dataframes['vbj_fri_tx_final_sen_df_jul'][keyword_dataframes['vbj_fri_tx_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_vbj_fri_tx:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_vbj_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_vbj_fri_tx.append(keywords)\n",
    "        keyword_input_token_vbj_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_vbj_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_vbj_fri_tx = time.time()\n",
    "keyword_cost_input_token_vbj_fri_tx = round((0.01/1000)*keyword_input_token_vbj_fri_tx,2)\n",
    "keyword_cost_output_token_vbj_fri_tx = round((0.03/1000)*keyword_output_token_vbj_fri_tx,2)\n",
    "keyword_total_cost_vbj_fri_tx = keyword_cost_input_token_vbj_fri_tx + keyword_cost_output_token_vbj_fri_tx\n",
    "keyword_total_time_loop_vbj_fri_tx = keyword_end_time_loop_vbj_fri_tx - keyword_start_time_loop_vbj_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_vbj_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_vbj_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_vbj_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_vbj_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_vbj_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_vbj_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_vbj_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "5792fb2b-349f-4586-9bb3-04e88b3cd630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:06.326120Z",
     "iopub.status.busy": "2025-06-12T00:29:06.325821Z",
     "iopub.status.idle": "2025-06-12T00:29:06.377996Z",
     "shell.execute_reply": "2025-06-12T00:29:06.377402Z",
     "shell.execute_reply.started": "2025-06-12T00:29:06.326100Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VBJ Jewellers-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>poor :1, unfair :1, rip off :1, not trust :1, ...</td>\n",
       "      <td>un-inviting :1, crowded :1, hesitant :1, ignor...</td>\n",
       "      <td>un-inviting :1, un-inviting :1, disappointing ...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>no discounts:2, better rates:1</td>\n",
       "      <td>unfair :1, rip off :1</td>\n",
       "      <td>expensive: 1, high: 1, rigid: 1, competative: ...</td>\n",
       "      <td>damage :2, fake :1, damaged :1, yellow stones ...</td>\n",
       "      <td>return process:1, restocking fee:1, making cos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBJ Jewellers-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>no report available :1, not there in the GIA d...</td>\n",
       "      <td>treatment we got there :1, billing section nee...</td>\n",
       "      <td>very hesitant to show us other stuff :1, not a...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>no proper treatment and no discounts:1, told t...</td>\n",
       "      <td>charging all the making cost on customer who r...</td>\n",
       "      <td>charged me almost 10% of the cost: 1, pricing ...</td>\n",
       "      <td>one of the pieces that I like the most had dam...</td>\n",
       "      <td>return process is tiresome:1, not straightaway...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store Name Sentiment      Type  \\\n",
       "0  VBJ Jewellers-Frisco, TX  negative  keywords   \n",
       "1  VBJ Jewellers-Frisco, TX  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  poor :1, unfair :1, rip off :1, not trust :1, ...   \n",
       "1  no report available :1, not there in the GIA d...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  un-inviting :1, crowded :1, hesitant :1, ignor...   \n",
       "1  treatment we got there :1, billing section nee...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  un-inviting :1, un-inviting :1, disappointing ...                  \n",
       "1  very hesitant to show us other stuff :1, not a...                  \n",
       "\n",
       "                          Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                            Discount  \\\n",
       "0                     no discounts:2, better rates:1   \n",
       "1  no proper treatment and no discounts:1, told t...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                              unfair :1, rip off :1   \n",
       "1  charging all the making cost on customer who r...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  expensive: 1, high: 1, rigid: 1, competative: ...   \n",
       "1  charged me almost 10% of the cost: 1, pricing ...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  damage :2, fake :1, damaged :1, yellow stones ...   \n",
       "1  one of the pieces that I like the most had dam...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  return process:1, restocking fee:1, making cos...  \n",
       "1  return process is tiresome:1, not straightaway...  "
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_vbj_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_vbj_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_vbj_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'vbj_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_vbj_fri_tx = pd.concat([negative_keywords_vbj_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_vbj_fri_tx = pd.concat([negative_keywords_vbj_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_vbj_fri_tx = negative_keywords_vbj_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_vbj_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c78f0-650b-45c7-91eb-d1b4886e205f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_chi_il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "2111d838-ba3e-47fa-95a2-3df1d1537f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:06.378904Z",
     "iopub.status.busy": "2025-06-12T00:29:06.378717Z",
     "iopub.status.idle": "2025-06-12T00:29:21.411897Z",
     "shell.execute_reply": "2025-06-12T00:29:21.411368Z",
     "shell.execute_reply.started": "2025-06-12T00:29:06.378887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  15.0\n",
      "Total Input Tokens -  11177\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  594\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_chi_il = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_chi_il=[0]\n",
    "keyword_input_token_tan_chi_il = 0\n",
    "keyword_output_token_tan_chi_il = 0\n",
    "keyword_start_time_loop_tan_chi_il = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_chi_il, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_chi_il[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_chi_il = keyword_dataframes['tan_chi_il_final_sen_df_jul'][keyword_dataframes['tan_chi_il_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_chi_il:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_chi_il,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_chi_il.append(keywords)\n",
    "        keyword_input_token_tan_chi_il += input_tokens_loop\n",
    "        keyword_output_token_tan_chi_il += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_chi_il = time.time()\n",
    "keyword_cost_input_token_tan_chi_il = round((0.01/1000)*keyword_input_token_tan_chi_il,2)\n",
    "keyword_cost_output_token_tan_chi_il = round((0.03/1000)*keyword_output_token_tan_chi_il,2)\n",
    "keyword_total_cost_tan_chi_il = keyword_cost_input_token_tan_chi_il + keyword_cost_output_token_tan_chi_il\n",
    "keyword_total_time_loop_tan_chi_il = keyword_end_time_loop_tan_chi_il - keyword_start_time_loop_tan_chi_il\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_chi_il[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_chi_il,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_chi_il)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_chi_il)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_chi_il)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_chi_il)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_chi_il,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "b3296d3e-5a10-4dcf-a1ac-695b27c38fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:21.413365Z",
     "iopub.status.busy": "2025-06-12T00:29:21.413092Z",
     "iopub.status.idle": "2025-06-12T00:29:21.453496Z",
     "shell.execute_reply": "2025-06-12T00:29:21.452996Z",
     "shell.execute_reply.started": "2025-06-12T00:29:21.413345Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>disregard :1, erode trust :1, compromise :1, m...</td>\n",
       "      <td>poor experience: 2, poor service: 2, human err...</td>\n",
       "      <td>rude :2, poor service :2, neglect :1, untraine...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>misguide :2, human error :2, freeze :1, lock :...</td>\n",
       "      <td>defective :2, unsatisfactory :2</td>\n",
       "      <td>store credit:2, defective product:2, exchange ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Chicago, IL</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>removing critical feedback :1, blatant disrega...</td>\n",
       "      <td>no idea as how and who will help: 1, not easy ...</td>\n",
       "      <td>none of them bothered to assist me :2, not all...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>cannot fix the gold price :1, cannot freeze th...</td>\n",
       "      <td>product was defective :2, repair was not satis...</td>\n",
       "      <td>can't exchange another store product:2, argued...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Chicago, IL  negative  keywords   \n",
       "1  Tanishq-Chicago, IL  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  disregard :1, erode trust :1, compromise :1, m...   \n",
       "1  removing critical feedback :1, blatant disrega...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  poor experience: 2, poor service: 2, human err...   \n",
       "1  no idea as how and who will help: 1, not easy ...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :2, poor service :2, neglect :1, untraine...                  \n",
       "1  none of them bothered to assist me :2, not all...                  \n",
       "\n",
       "  Product Variety                                Discount Making Charge  \\\n",
       "0                  No relevant negative keywords/ phrases                 \n",
       "1                  No relevant negative keywords/ phrases                 \n",
       "\n",
       "                                               Price  \\\n",
       "0  misguide :2, human error :2, freeze :1, lock :...   \n",
       "1  cannot fix the gold price :1, cannot freeze th...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0                    defective :2, unsatisfactory :2   \n",
       "1  product was defective :2, repair was not satis...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  store credit:2, defective product:2, exchange ...  \n",
       "1  can't exchange another store product:2, argued...  "
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_chi_il = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_chi_il[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_chi_il:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_chi_il'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_chi_il = pd.concat([negative_keywords_tan_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_chi_il = pd.concat([negative_keywords_tan_chi_il, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_chi_il = negative_keywords_tan_chi_il.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_chi_il"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c1cd0-85d4-4bb8-8346-a7f8de0fbdbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_fri_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "5a5d012d-60ae-4838-9b53-c1558c50a30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:21.454363Z",
     "iopub.status.busy": "2025-06-12T00:29:21.454162Z",
     "iopub.status.idle": "2025-06-12T00:29:41.495138Z",
     "shell.execute_reply": "2025-06-12T00:29:41.494544Z",
     "shell.execute_reply.started": "2025-06-12T00:29:21.454343Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  20.0\n",
      "Total Input Tokens -  11380\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  756\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_fri_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_fri_tx=[0]\n",
    "keyword_input_token_tan_fri_tx = 0\n",
    "keyword_output_token_tan_fri_tx = 0\n",
    "keyword_start_time_loop_tan_fri_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_fri_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_fri_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_fri_tx = keyword_dataframes['tan_fri_tx_final_sen_df_jul'][keyword_dataframes['tan_fri_tx_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_fri_tx:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_fri_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_fri_tx.append(keywords)\n",
    "        keyword_input_token_tan_fri_tx += input_tokens_loop\n",
    "        keyword_output_token_tan_fri_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_fri_tx = time.time()\n",
    "keyword_cost_input_token_tan_fri_tx = round((0.01/1000)*keyword_input_token_tan_fri_tx,2)\n",
    "keyword_cost_output_token_tan_fri_tx = round((0.03/1000)*keyword_output_token_tan_fri_tx,2)\n",
    "keyword_total_cost_tan_fri_tx = keyword_cost_input_token_tan_fri_tx + keyword_cost_output_token_tan_fri_tx\n",
    "keyword_total_time_loop_tan_fri_tx = keyword_end_time_loop_tan_fri_tx - keyword_start_time_loop_tan_fri_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_fri_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_fri_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_fri_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_fri_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_fri_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_fri_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_fri_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "e9a54490-da47-458a-ae28-831b406199d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:41.496316Z",
     "iopub.status.busy": "2025-06-12T00:29:41.496103Z",
     "iopub.status.idle": "2025-06-12T00:29:41.542955Z",
     "shell.execute_reply": "2025-06-12T00:29:41.542414Z",
     "shell.execute_reply.started": "2025-06-12T00:29:41.496298Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>faulty machines:1, limited knowledge:1, faulty...</td>\n",
       "      <td>poor experience:2, denied entry:2, limited cho...</td>\n",
       "      <td>unhelpful :2, arrogant :1, amateur :1, unfrien...</td>\n",
       "      <td></td>\n",
       "      <td>limited collection: 3, less collection: 1, not...</td>\n",
       "      <td>no clarity :2, little more :2, not giving :2, ...</td>\n",
       "      <td>high :4</td>\n",
       "      <td>overpriced:2, budget:2</td>\n",
       "      <td>broken :2, faulty :2, breakages :1</td>\n",
       "      <td>faulty machines: 2, no cash: 1, store credits:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Frisco, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>multiple breakages within the chain:1, weighin...</td>\n",
       "      <td>locked doors at 6:30:2, no clarity in communic...</td>\n",
       "      <td>didn't help much :2, didn't understand English...</td>\n",
       "      <td></td>\n",
       "      <td>choices were very limited: 2, didn't meet our ...</td>\n",
       "      <td>didn't get much of a discount :2, not giving m...</td>\n",
       "      <td>Making charge is very high :3, making charges ...</td>\n",
       "      <td>spending more than budget:2, pricing of the pr...</td>\n",
       "      <td>broke immediately :1, multiple breakages :1, f...</td>\n",
       "      <td>weighing machines at this branch are faulty: 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Frisco, TX  negative  keywords   \n",
       "1  Tanishq-Frisco, TX  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  faulty machines:1, limited knowledge:1, faulty...   \n",
       "1  multiple breakages within the chain:1, weighin...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  poor experience:2, denied entry:2, limited cho...   \n",
       "1  locked doors at 6:30:2, no clarity in communic...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  unhelpful :2, arrogant :1, amateur :1, unfrien...                  \n",
       "1  didn't help much :2, didn't understand English...                  \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  limited collection: 3, less collection: 1, not...   \n",
       "1  choices were very limited: 2, didn't meet our ...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0  no clarity :2, little more :2, not giving :2, ...   \n",
       "1  didn't get much of a discount :2, not giving m...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                                            high :4   \n",
       "1  Making charge is very high :3, making charges ...   \n",
       "\n",
       "                                               Price  \\\n",
       "0                             overpriced:2, budget:2   \n",
       "1  spending more than budget:2, pricing of the pr...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0                 broken :2, faulty :2, breakages :1   \n",
       "1  broke immediately :1, multiple breakages :1, f...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  faulty machines: 2, no cash: 1, store credits:...  \n",
       "1  weighing machines at this branch are faulty: 1...  "
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_fri_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_fri_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_fri_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_fri_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_fri_tx = pd.concat([negative_keywords_tan_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_fri_tx = pd.concat([negative_keywords_tan_fri_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_fri_tx = negative_keywords_tan_fri_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_fri_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c715b5-9676-49ac-8b78-101aa4bbdca5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_hou_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "cdaddb36-da26-455d-b40f-faf6966697b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:41.543855Z",
     "iopub.status.busy": "2025-06-12T00:29:41.543617Z",
     "iopub.status.idle": "2025-06-12T00:29:55.073877Z",
     "shell.execute_reply": "2025-06-12T00:29:55.073360Z",
     "shell.execute_reply.started": "2025-06-12T00:29:41.543839Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  13.5\n",
      "Total Input Tokens -  10618\n",
      "Total Input Cost = USD  0.11\n",
      "Total Output Tokens -  503\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_hou_tx = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_hou_tx=[0]\n",
    "keyword_input_token_tan_hou_tx = 0\n",
    "keyword_output_token_tan_hou_tx = 0\n",
    "keyword_start_time_loop_tan_hou_tx = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_hou_tx, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_hou_tx[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_hou_tx = keyword_dataframes['tan_hou_tx_final_sen_df_jul'][keyword_dataframes['tan_hou_tx_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_hou_tx:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_hou_tx,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_hou_tx.append(keywords)\n",
    "        keyword_input_token_tan_hou_tx += input_tokens_loop\n",
    "        keyword_output_token_tan_hou_tx += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_hou_tx = time.time()\n",
    "keyword_cost_input_token_tan_hou_tx = round((0.01/1000)*keyword_input_token_tan_hou_tx,2)\n",
    "keyword_cost_output_token_tan_hou_tx = round((0.03/1000)*keyword_output_token_tan_hou_tx,2)\n",
    "keyword_total_cost_tan_hou_tx = keyword_cost_input_token_tan_hou_tx + keyword_cost_output_token_tan_hou_tx\n",
    "keyword_total_time_loop_tan_hou_tx = keyword_end_time_loop_tan_hou_tx - keyword_start_time_loop_tan_hou_tx\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_hou_tx[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_hou_tx,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_hou_tx)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_hou_tx)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_hou_tx)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_hou_tx)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_hou_tx,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "999d719c-1f29-47f6-b2e2-42ac0e3b07d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:55.074860Z",
     "iopub.status.busy": "2025-06-12T00:29:55.074592Z",
     "iopub.status.idle": "2025-06-12T00:29:55.115510Z",
     "shell.execute_reply": "2025-06-12T00:29:55.115011Z",
     "shell.execute_reply.started": "2025-06-12T00:29:55.074841Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Houston, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>cheated :2, hidden fee :2, damaged product :2,...</td>\n",
       "      <td>bad customer :4, horrible experience :3, rude ...</td>\n",
       "      <td>attitude problem:2, rude:2, unhelpful:1, uneth...</td>\n",
       "      <td></td>\n",
       "      <td>few varieties:2, better collection:1, similar:1</td>\n",
       "      <td></td>\n",
       "      <td>hidden fee: 2, high: 2</td>\n",
       "      <td>expensive :1</td>\n",
       "      <td>damaged product:2, deformed:2, suspect:1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Houston, TX</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>rethink our loyalty :2, should we be able to t...</td>\n",
       "      <td>attitude problem :2, never coming back again :...</td>\n",
       "      <td>staff not treating my friend very well:1, secu...</td>\n",
       "      <td></td>\n",
       "      <td>expected better collection:1, few varieties in...</td>\n",
       "      <td></td>\n",
       "      <td>making charges are very high: 2, hidden fee of...</td>\n",
       "      <td>over 25% more expensive :1</td>\n",
       "      <td>got deformed in one usage:1, damaged product:1...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Houston, TX  negative  keywords   \n",
       "1  Tanishq-Houston, TX  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  cheated :2, hidden fee :2, damaged product :2,...   \n",
       "1  rethink our loyalty :2, should we be able to t...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  bad customer :4, horrible experience :3, rude ...   \n",
       "1  attitude problem :2, never coming back again :...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  attitude problem:2, rude:2, unhelpful:1, uneth...                  \n",
       "1  staff not treating my friend very well:1, secu...                  \n",
       "\n",
       "                                     Product Variety Discount  \\\n",
       "0    few varieties:2, better collection:1, similar:1            \n",
       "1  expected better collection:1, few varieties in...            \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                             hidden fee: 2, high: 2   \n",
       "1  making charges are very high: 2, hidden fee of...   \n",
       "\n",
       "                        Price  \\\n",
       "0                expensive :1   \n",
       "1  over 25% more expensive :1   \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0           damaged product:2, deformed:2, suspect:1                     \n",
       "1  got deformed in one usage:1, damaged product:1...                     "
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_hou_tx = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_hou_tx[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_hou_tx:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_hou_tx'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_hou_tx = pd.concat([negative_keywords_tan_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_hou_tx = pd.concat([negative_keywords_tan_hou_tx, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_hou_tx = negative_keywords_tan_hou_tx.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_hou_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8c99d-0492-4f22-a4ce-38ee6ffdd4a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_new_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "8a3dfec6-f754-4d63-af10-a18a842613c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:29:55.116842Z",
     "iopub.status.busy": "2025-06-12T00:29:55.116326Z",
     "iopub.status.idle": "2025-06-12T00:30:17.659778Z",
     "shell.execute_reply": "2025-06-12T00:30:17.659262Z",
     "shell.execute_reply.started": "2025-06-12T00:29:55.116822Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  22.5\n",
      "Total Input Tokens -  27451\n",
      "Total Input Cost = USD  0.27\n",
      "Total Output Tokens -  813\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.29\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_new_nj = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_new_nj=[0]\n",
    "keyword_input_token_tan_new_nj = 0\n",
    "keyword_output_token_tan_new_nj = 0\n",
    "keyword_start_time_loop_tan_new_nj = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_new_nj, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_new_nj[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_new_nj = keyword_dataframes['tan_new_nj_final_sen_df_jul'][keyword_dataframes['tan_new_nj_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_new_nj:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_new_nj,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_new_nj.append(keywords)\n",
    "        keyword_input_token_tan_new_nj += input_tokens_loop\n",
    "        keyword_output_token_tan_new_nj += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_new_nj = time.time()\n",
    "keyword_cost_input_token_tan_new_nj = round((0.01/1000)*keyword_input_token_tan_new_nj,2)\n",
    "keyword_cost_output_token_tan_new_nj = round((0.03/1000)*keyword_output_token_tan_new_nj,2)\n",
    "keyword_total_cost_tan_new_nj = keyword_cost_input_token_tan_new_nj + keyword_cost_output_token_tan_new_nj\n",
    "keyword_total_time_loop_tan_new_nj = keyword_end_time_loop_tan_new_nj - keyword_start_time_loop_tan_new_nj\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_new_nj[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_new_nj,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_new_nj)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_new_nj)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_new_nj)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_new_nj)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_new_nj,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "aa22b56d-356d-42ea-b1fa-528455cd886b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:17.662120Z",
     "iopub.status.busy": "2025-06-12T00:30:17.661669Z",
     "iopub.status.idle": "2025-06-12T00:30:17.707693Z",
     "shell.execute_reply": "2025-06-12T00:30:17.707206Z",
     "shell.execute_reply.started": "2025-06-12T00:30:17.662092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-New Jersey, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>uncomfortable :2, insecure :1, discriminative ...</td>\n",
       "      <td>long wait :3, rude staff :2, bad management :2...</td>\n",
       "      <td>rude :4, dismissive :3, unprofessional :2, ind...</td>\n",
       "      <td></td>\n",
       "      <td>limited inventory: 2, lack of variety: 1, limi...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>high :2, expensive :2, overpriced :1, unreason...</td>\n",
       "      <td>poorly finished:2, faulty:2, damaged:1, broke:...</td>\n",
       "      <td>no returns :2, poor exchange :1, painful excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-New Jersey, NJ</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>no longer feel comfortable spending my money :...</td>\n",
       "      <td>waited for two hours :2, no one attended :2, n...</td>\n",
       "      <td>treated very rudely :2, rude and dismissive :1...</td>\n",
       "      <td></td>\n",
       "      <td>extremely limited inventory: 1, not a lot of v...</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>prices are so high here compared to stores on ...</td>\n",
       "      <td>diamonds from a bracelet just fell off:1, clas...</td>\n",
       "      <td>exchanges are not accepted after 6 PM :2, very...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Store Name Sentiment      Type  \\\n",
       "0  Tanishq-New Jersey, NJ  negative  keywords   \n",
       "1  Tanishq-New Jersey, NJ  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  uncomfortable :2, insecure :1, discriminative ...   \n",
       "1  no longer feel comfortable spending my money :...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  long wait :3, rude staff :2, bad management :2...   \n",
       "1  waited for two hours :2, no one attended :2, n...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  rude :4, dismissive :3, unprofessional :2, ind...                  \n",
       "1  treated very rudely :2, rude and dismissive :1...                  \n",
       "\n",
       "                                     Product Variety Discount  \\\n",
       "0  limited inventory: 2, lack of variety: 1, limi...            \n",
       "1  extremely limited inventory: 1, not a lot of v...            \n",
       "\n",
       "                            Making Charge  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                               Price  \\\n",
       "0  high :2, expensive :2, overpriced :1, unreason...   \n",
       "1  prices are so high here compared to stores on ...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0  poorly finished:2, faulty:2, damaged:1, broke:...   \n",
       "1  diamonds from a bracelet just fell off:1, clas...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  no returns :2, poor exchange :1, painful excha...  \n",
       "1  exchanges are not accepted after 6 PM :2, very...  "
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_new_nj = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_new_nj[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_new_nj:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_new_nj'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_new_nj = pd.concat([negative_keywords_tan_new_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_new_nj = pd.concat([negative_keywords_tan_new_nj, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_new_nj = negative_keywords_tan_new_nj.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_new_nj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f1cba-9af0-4a35-9cd7-8caca64bb4a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_bar_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "6e9a10d9-d1e2-451a-adf6-bedea9ba9dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:17.708649Z",
     "iopub.status.busy": "2025-06-12T00:30:17.708390Z",
     "iopub.status.idle": "2025-06-12T00:30:36.748854Z",
     "shell.execute_reply": "2025-06-12T00:30:36.748368Z",
     "shell.execute_reply.started": "2025-06-12T00:30:17.708631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  19.0\n",
      "Total Input Tokens -  9587\n",
      "Total Input Cost = USD  0.1\n",
      "Total Output Tokens -  592\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_bar_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_bar_db=[0]\n",
    "keyword_input_token_tan_bar_db = 0\n",
    "keyword_output_token_tan_bar_db = 0\n",
    "keyword_start_time_loop_tan_bar_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_bar_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_bar_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_bar_db = keyword_dataframes['tan_bar_db_final_sen_df_jul'][keyword_dataframes['tan_bar_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_bar_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_bar_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_bar_db.append(keywords)\n",
    "        keyword_input_token_tan_bar_db += input_tokens_loop\n",
    "        keyword_output_token_tan_bar_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_bar_db = time.time()\n",
    "keyword_cost_input_token_tan_bar_db = round((0.01/1000)*keyword_input_token_tan_bar_db,2)\n",
    "keyword_cost_output_token_tan_bar_db = round((0.03/1000)*keyword_output_token_tan_bar_db,2)\n",
    "keyword_total_cost_tan_bar_db = keyword_cost_input_token_tan_bar_db + keyword_cost_output_token_tan_bar_db\n",
    "keyword_total_time_loop_tan_bar_db = keyword_end_time_loop_tan_bar_db - keyword_start_time_loop_tan_bar_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_bar_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_bar_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_bar_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_bar_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_bar_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_bar_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_bar_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "85a12127-f197-40a5-b59f-12863588a334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:36.749849Z",
     "iopub.status.busy": "2025-06-12T00:30:36.749589Z",
     "iopub.status.idle": "2025-06-12T00:30:36.792809Z",
     "shell.execute_reply": "2025-06-12T00:30:36.792296Z",
     "shell.execute_reply.started": "2025-06-12T00:30:36.749829Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Al Barsha, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>lied :4, false information :2, careful :2</td>\n",
       "      <td>worst experience:1, poor way:1, bad experience...</td>\n",
       "      <td>lied :2, unfriendly :1, humiliated :1, rude :1...</td>\n",
       "      <td></td>\n",
       "      <td>limited :1</td>\n",
       "      <td>marketing gimmick: 2, discount scams: 1</td>\n",
       "      <td>high making :5, making charges :4, making char...</td>\n",
       "      <td>expensive: 2</td>\n",
       "      <td></td>\n",
       "      <td>making charges:2, less gold:2, additional:2, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Al Barsha, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>information provided to us was false :2, repre...</td>\n",
       "      <td>not at all friendly:1, no any respect:1, treat...</td>\n",
       "      <td>not at all friendly :1, asked not to try &amp; mak...</td>\n",
       "      <td></td>\n",
       "      <td>needed more office wear :1, needs to add more ...</td>\n",
       "      <td>all these other brands giving you 50-70% off i...</td>\n",
       "      <td>making charged quite high around 15% :2, makin...</td>\n",
       "      <td>Price bit expensive: 2</td>\n",
       "      <td></td>\n",
       "      <td>losing 3 grams of our gold:2, charged a making...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Al Barsha, DB  negative  keywords   \n",
       "1  Tanishq Jewellers-Al Barsha, DB  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0          lied :4, false information :2, careful :2   \n",
       "1  information provided to us was false :2, repre...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  worst experience:1, poor way:1, bad experience...   \n",
       "1  not at all friendly:1, no any respect:1, treat...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  lied :2, unfriendly :1, humiliated :1, rude :1...                  \n",
       "1  not at all friendly :1, asked not to try & mak...                  \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0                                         limited :1   \n",
       "1  needed more office wear :1, needs to add more ...   \n",
       "\n",
       "                                            Discount  \\\n",
       "0            marketing gimmick: 2, discount scams: 1   \n",
       "1  all these other brands giving you 50-70% off i...   \n",
       "\n",
       "                                       Making Charge                   Price  \\\n",
       "0  high making :5, making charges :4, making char...            expensive: 2   \n",
       "1  making charged quite high around 15% :2, makin...  Price bit expensive: 2   \n",
       "\n",
       "  Product Quality                                 Jewellery Exchange  \n",
       "0                  making charges:2, less gold:2, additional:2, h...  \n",
       "1                  losing 3 grams of our gold:2, charged a making...  "
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_bar_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_bar_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_bar_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_bar_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_bar_db = pd.concat([negative_keywords_tan_bar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_bar_db = pd.concat([negative_keywords_tan_bar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_bar_db = negative_keywords_tan_bar_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_bar_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6a3dd-e6ef-4aa1-bc16-24e96fd1a40b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_fah_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "f0531716-cd8e-45d3-a60e-5169e8c2a5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:36.793852Z",
     "iopub.status.busy": "2025-06-12T00:30:36.793566Z",
     "iopub.status.idle": "2025-06-12T00:30:46.819715Z",
     "shell.execute_reply": "2025-06-12T00:30:46.819221Z",
     "shell.execute_reply.started": "2025-06-12T00:30:36.793826Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.0\n",
      "Total Input Tokens -  6420\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  392\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_fah_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_fah_db=[0]\n",
    "keyword_input_token_tan_fah_db = 0\n",
    "keyword_output_token_tan_fah_db = 0\n",
    "keyword_start_time_loop_tan_fah_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_fah_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_fah_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_fah_db = keyword_dataframes['tan_fah_db_final_sen_df_jul'][keyword_dataframes['tan_fah_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_fah_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_fah_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_fah_db.append(keywords)\n",
    "        keyword_input_token_tan_fah_db += input_tokens_loop\n",
    "        keyword_output_token_tan_fah_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_fah_db = time.time()\n",
    "keyword_cost_input_token_tan_fah_db = round((0.01/1000)*keyword_input_token_tan_fah_db,2)\n",
    "keyword_cost_output_token_tan_fah_db = round((0.03/1000)*keyword_output_token_tan_fah_db,2)\n",
    "keyword_total_cost_tan_fah_db = keyword_cost_input_token_tan_fah_db + keyword_cost_output_token_tan_fah_db\n",
    "keyword_total_time_loop_tan_fah_db = keyword_end_time_loop_tan_fah_db - keyword_start_time_loop_tan_fah_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_fah_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_fah_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_fah_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_fah_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_fah_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_fah_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_fah_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "56bf3eb1-fa10-4268-94c6-ca94bdc36d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:46.820906Z",
     "iopub.status.busy": "2025-06-12T00:30:46.820532Z",
     "iopub.status.idle": "2025-06-12T00:30:46.861659Z",
     "shell.execute_reply": "2025-06-12T00:30:46.861218Z",
     "shell.execute_reply.started": "2025-06-12T00:30:46.820875Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Al Fahidi, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>false details:1, wrong info:1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>false details: 2, wrong info: 2</td>\n",
       "      <td></td>\n",
       "      <td>more design:3, lack:1, disappointed:1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>high :2, higher :1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Al Fahidi, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>telling false details:1, salesman told us we c...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>telling false details: 2, salesman told us we ...</td>\n",
       "      <td></td>\n",
       "      <td>Need to keep more chain design:2, looking for ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>making charges are too high :2, making charge ...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Al Fahidi, DB  negative  keywords   \n",
       "1  Tanishq Jewellers-Al Fahidi, DB  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                      false details:1, wrong info:1   \n",
       "1  telling false details:1, salesman told us we c...   \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0                    false details: 2, wrong info: 2                  \n",
       "1  telling false details: 2, salesman told us we ...                  \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0              more design:3, lack:1, disappointed:1   \n",
       "1  Need to keep more chain design:2, looking for ...   \n",
       "\n",
       "                                 Discount  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                                 high :2, higher :1   \n",
       "1  making charges are too high :2, making charge ...   \n",
       "\n",
       "                                    Price Product Quality Jewellery Exchange  \n",
       "0  No relevant negative keywords/ phrases                                     \n",
       "1  No relevant negative keywords/ phrases                                     "
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_fah_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_fah_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_fah_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_fah_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_fah_db = pd.concat([negative_keywords_tan_fah_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_fah_db = pd.concat([negative_keywords_tan_fah_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_fah_db = negative_keywords_tan_fah_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_fah_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650faed-29ea-4d55-9fd0-c66916d5ed98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_kar_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "56cc1608-7960-4afb-85c8-3c638b9fe7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:46.862668Z",
     "iopub.status.busy": "2025-06-12T00:30:46.862461Z",
     "iopub.status.idle": "2025-06-12T00:30:59.395944Z",
     "shell.execute_reply": "2025-06-12T00:30:59.395290Z",
     "shell.execute_reply.started": "2025-06-12T00:30:46.862651Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  12.5\n",
      "Total Input Tokens -  6439\n",
      "Total Input Cost = USD  0.06\n",
      "Total Output Tokens -  349\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_kar_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_kar_db=[0]\n",
    "keyword_input_token_tan_kar_db = 0\n",
    "keyword_output_token_tan_kar_db = 0\n",
    "keyword_start_time_loop_tan_kar_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_kar_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_kar_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_kar_db = keyword_dataframes['tan_kar_db_final_sen_df_jul'][keyword_dataframes['tan_kar_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_kar_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_kar_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_kar_db.append(keywords)\n",
    "        keyword_input_token_tan_kar_db += input_tokens_loop\n",
    "        keyword_output_token_tan_kar_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_kar_db = time.time()\n",
    "keyword_cost_input_token_tan_kar_db = round((0.01/1000)*keyword_input_token_tan_kar_db,2)\n",
    "keyword_cost_output_token_tan_kar_db = round((0.03/1000)*keyword_output_token_tan_kar_db,2)\n",
    "keyword_total_cost_tan_kar_db = keyword_cost_input_token_tan_kar_db + keyword_cost_output_token_tan_kar_db\n",
    "keyword_total_time_loop_tan_kar_db = keyword_end_time_loop_tan_kar_db - keyword_start_time_loop_tan_kar_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_kar_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_kar_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_kar_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_kar_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_kar_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_kar_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_kar_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "161571ad-5d28-4e3b-b3f4-882e42668d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:59.397146Z",
     "iopub.status.busy": "2025-06-12T00:30:59.396860Z",
     "iopub.status.idle": "2025-06-12T00:30:59.446865Z",
     "shell.execute_reply": "2025-06-12T00:30:59.446241Z",
     "shell.execute_reply.started": "2025-06-12T00:30:59.397113Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Al Karama, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>lying :2</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>disgusted :2, disinterested :2, laying :1, sto...</td>\n",
       "      <td></td>\n",
       "      <td>collection :2</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>very high:2, different:2, mess:2</td>\n",
       "      <td></td>\n",
       "      <td>broke :2, nightmare :2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Al Karama, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Manager is telling a lot of stories :2</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td>looked visibly disgusted/disinterested :2, Man...</td>\n",
       "      <td></td>\n",
       "      <td>Collection can be a bit more :2</td>\n",
       "      <td>no alternative way to purchase the jewels .......</td>\n",
       "      <td>making charges and all was different and was a...</td>\n",
       "      <td></td>\n",
       "      <td>broke in 2 weeks :2, without any undue pressur...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Al Karama, DB  negative  keywords   \n",
       "1  Tanishq Jewellers-Al Karama, DB  negative   phrases   \n",
       "\n",
       "                      Customer Confidence  \\\n",
       "0                                lying :2   \n",
       "1  Manager is telling a lot of stories :2   \n",
       "\n",
       "                         Store Experience  \\\n",
       "0  No relevant negative keywords/ phrases   \n",
       "1  No relevant negative keywords/ phrases   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  disgusted :2, disinterested :2, laying :1, sto...                  \n",
       "1  looked visibly disgusted/disinterested :2, Man...                  \n",
       "\n",
       "                   Product Variety  \\\n",
       "0                    collection :2   \n",
       "1  Collection can be a bit more :2   \n",
       "\n",
       "                                            Discount  \\\n",
       "0             No relevant negative keywords/ phrases   \n",
       "1  no alternative way to purchase the jewels .......   \n",
       "\n",
       "                                       Making Charge Price  \\\n",
       "0                   very high:2, different:2, mess:2         \n",
       "1  making charges and all was different and was a...         \n",
       "\n",
       "                                     Product Quality Jewellery Exchange  \n",
       "0                             broke :2, nightmare :2                     \n",
       "1  broke in 2 weeks :2, without any undue pressur...                     "
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_kar_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_kar_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_kar_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_kar_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_kar_db = pd.concat([negative_keywords_tan_kar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_kar_db = pd.concat([negative_keywords_tan_kar_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_kar_db = negative_keywords_tan_kar_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_kar_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0f38c-c34d-4106-8f08-910e61de974a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_ham_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "1aa441f4-be8b-4cd9-ac12-8fc5e82843c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:59.448264Z",
     "iopub.status.busy": "2025-06-12T00:30:59.447743Z",
     "iopub.status.idle": "2025-06-12T00:31:09.981186Z",
     "shell.execute_reply": "2025-06-12T00:31:09.980542Z",
     "shell.execute_reply.started": "2025-06-12T00:30:59.448245Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  10.5\n",
      "Total Input Tokens -  4834\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  363\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_ham_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_ham_ad=[0]\n",
    "keyword_input_token_tan_ham_ad = 0\n",
    "keyword_output_token_tan_ham_ad = 0\n",
    "keyword_start_time_loop_tan_ham_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_ham_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_ham_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_ham_ad = keyword_dataframes['tan_ham_ad_final_sen_df_jul'][keyword_dataframes['tan_ham_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_ham_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_ham_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_ham_ad.append(keywords)\n",
    "        keyword_input_token_tan_ham_ad += input_tokens_loop\n",
    "        keyword_output_token_tan_ham_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_ham_ad = time.time()\n",
    "keyword_cost_input_token_tan_ham_ad = round((0.01/1000)*keyword_input_token_tan_ham_ad,2)\n",
    "keyword_cost_output_token_tan_ham_ad = round((0.03/1000)*keyword_output_token_tan_ham_ad,2)\n",
    "keyword_total_cost_tan_ham_ad = keyword_cost_input_token_tan_ham_ad + keyword_cost_output_token_tan_ham_ad\n",
    "keyword_total_time_loop_tan_ham_ad = keyword_end_time_loop_tan_ham_ad - keyword_start_time_loop_tan_ham_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_ham_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_ham_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_ham_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_ham_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_ham_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_ham_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_ham_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "173ace65-86cc-4f68-8832-0dd66a90e4ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:31:09.982320Z",
     "iopub.status.busy": "2025-06-12T00:31:09.981991Z",
     "iopub.status.idle": "2025-06-12T00:31:10.030336Z",
     "shell.execute_reply": "2025-06-12T00:31:10.029755Z",
     "shell.execute_reply.started": "2025-06-12T00:31:09.982295Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Hamdan Bin Mohammed Street, AD</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>disappointing experience:1, ignored:1, disrega...</td>\n",
       "      <td>unprofessional :1, selective :1, ignored :1, d...</td>\n",
       "      <td></td>\n",
       "      <td>Limited choice :3, Not much choice :2, low sto...</td>\n",
       "      <td>loss: 2</td>\n",
       "      <td>increase :2, discount :2</td>\n",
       "      <td>loss: 2, budget: 2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Hamdan Bin Mohammed Street, AD</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>completely ignored us:1, noticeably selective:...</td>\n",
       "      <td>completely ignored us :1, without acknowledgin...</td>\n",
       "      <td></td>\n",
       "      <td>they have little to offer here :2</td>\n",
       "      <td>did not even give a discount: 2</td>\n",
       "      <td>increase the making charge :2, did not even gi...</td>\n",
       "      <td>increase the making charge: 2, did not even gi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Hamdan Bin Mohammed Street, AD  negative  keywords   \n",
       "1  Tanishq Jewellers-Hamdan Bin Mohammed Street, AD  negative   phrases   \n",
       "\n",
       "  Customer Confidence                                   Store Experience  \\\n",
       "0                      disappointing experience:1, ignored:1, disrega...   \n",
       "1                      completely ignored us:1, noticeably selective:...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0  unprofessional :1, selective :1, ignored :1, d...                  \n",
       "1  completely ignored us :1, without acknowledgin...                  \n",
       "\n",
       "                                     Product Variety  \\\n",
       "0  Limited choice :3, Not much choice :2, low sto...   \n",
       "1                  they have little to offer here :2   \n",
       "\n",
       "                          Discount  \\\n",
       "0                          loss: 2   \n",
       "1  did not even give a discount: 2   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                           increase :2, discount :2   \n",
       "1  increase the making charge :2, did not even gi...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                                 loss: 2, budget: 2                   \n",
       "1  increase the making charge: 2, did not even gi...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_ham_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_ham_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_ham_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_ham_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_ham_ad = pd.concat([negative_keywords_tan_ham_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_ham_ad = pd.concat([negative_keywords_tan_ham_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_ham_ad = negative_keywords_tan_ham_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_ham_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95eb1c2-54e8-4bd1-84c4-e5258f29864a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_mee_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "d852254a-7c1f-45a2-8e3e-c668bd3a9854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:31:10.031657Z",
     "iopub.status.busy": "2025-06-12T00:31:10.031376Z",
     "iopub.status.idle": "2025-06-12T00:31:17.555743Z",
     "shell.execute_reply": "2025-06-12T00:31:17.555215Z",
     "shell.execute_reply.started": "2025-06-12T00:31:10.031631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  7.5\n",
      "Total Input Tokens -  4077\n",
      "Total Input Cost = USD  0.04\n",
      "Total Output Tokens -  249\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_mee_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_mee_db=[0]\n",
    "keyword_input_token_tan_mee_db = 0\n",
    "keyword_output_token_tan_mee_db = 0\n",
    "keyword_start_time_loop_tan_mee_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_mee_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_mee_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_mee_db = keyword_dataframes['tan_mee_db_final_sen_df_jul'][keyword_dataframes['tan_mee_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_mee_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_mee_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_mee_db.append(keywords)\n",
    "        keyword_input_token_tan_mee_db += input_tokens_loop\n",
    "        keyword_output_token_tan_mee_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_mee_db = time.time()\n",
    "keyword_cost_input_token_tan_mee_db = round((0.01/1000)*keyword_input_token_tan_mee_db,2)\n",
    "keyword_cost_output_token_tan_mee_db = round((0.03/1000)*keyword_output_token_tan_mee_db,2)\n",
    "keyword_total_cost_tan_mee_db = keyword_cost_input_token_tan_mee_db + keyword_cost_output_token_tan_mee_db\n",
    "keyword_total_time_loop_tan_mee_db = keyword_end_time_loop_tan_mee_db - keyword_start_time_loop_tan_mee_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_mee_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_mee_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_mee_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_mee_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_mee_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_mee_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_mee_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "65d8e2f8-2e3d-445c-a881-61b5ad23611e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:31:17.556895Z",
     "iopub.status.busy": "2025-06-12T00:31:17.556542Z",
     "iopub.status.idle": "2025-06-12T00:31:17.595258Z",
     "shell.execute_reply": "2025-06-12T00:31:17.594682Z",
     "shell.execute_reply.started": "2025-06-12T00:31:17.556862Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Meena Bazar, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>over confident:2</td>\n",
       "      <td>nobody answer:2, useless:1, horrible:1, mistake:1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Meena Bazar, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>ask for your number and name:2, data collectio...</td>\n",
       "      <td>didn't receive the card:2, no one showed up:1,...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Meena Bazar, DB  negative  keywords   \n",
       "1  Tanishq Jewellers-Meena Bazar, DB  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0                                   over confident:2   \n",
       "1  ask for your number and name:2, data collectio...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  nobody answer:2, useless:1, horrible:1, mistake:1   \n",
       "1  didn't receive the card:2, no one showed up:1,...   \n",
       "\n",
       "                              Store Staff Product Design  \\\n",
       "0  No relevant negative keywords/ phrases                  \n",
       "1  No relevant negative keywords/ phrases                  \n",
       "\n",
       "                          Product Variety Discount Making Charge Price  \\\n",
       "0  No relevant negative keywords/ phrases                                \n",
       "1  No relevant negative keywords/ phrases                                \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_mee_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_mee_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_mee_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_mee_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_mee_db = pd.concat([negative_keywords_tan_mee_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_mee_db = pd.concat([negative_keywords_tan_mee_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_mee_db = negative_keywords_tan_mee_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_mee_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4aa69-5109-4c72-8019-0365e717da74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_sil_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "88d2edd0-6d92-48a4-a559-9f49937330ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:31:17.596488Z",
     "iopub.status.busy": "2025-06-12T00:31:17.596074Z",
     "iopub.status.idle": "2025-06-12T00:31:26.621311Z",
     "shell.execute_reply": "2025-06-12T00:31:26.620795Z",
     "shell.execute_reply.started": "2025-06-12T00:31:17.596468Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  9.0\n",
      "Total Input Tokens -  4301\n",
      "Total Input Cost = USD  0.04\n",
      "Total Output Tokens -  256\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_sil_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_sil_db=[0]\n",
    "keyword_input_token_tan_sil_db = 0\n",
    "keyword_output_token_tan_sil_db = 0\n",
    "keyword_start_time_loop_tan_sil_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_sil_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_sil_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_sil_db = keyword_dataframes['tan_sil_db_final_sen_df_jul'][keyword_dataframes['tan_sil_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_sil_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_sil_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_sil_db.append(keywords)\n",
    "        keyword_input_token_tan_sil_db += input_tokens_loop\n",
    "        keyword_output_token_tan_sil_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_sil_db = time.time()\n",
    "keyword_cost_input_token_tan_sil_db = round((0.01/1000)*keyword_input_token_tan_sil_db,2)\n",
    "keyword_cost_output_token_tan_sil_db = round((0.03/1000)*keyword_output_token_tan_sil_db,2)\n",
    "keyword_total_cost_tan_sil_db = keyword_cost_input_token_tan_sil_db + keyword_cost_output_token_tan_sil_db\n",
    "keyword_total_time_loop_tan_sil_db = keyword_end_time_loop_tan_sil_db - keyword_start_time_loop_tan_sil_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_sil_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_sil_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_sil_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_sil_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_sil_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_sil_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_sil_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "96c6e146-fc79-48ed-a9f3-e1671d04bcb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:31:26.622293Z",
     "iopub.status.busy": "2025-06-12T00:31:26.622072Z",
     "iopub.status.idle": "2025-06-12T00:31:26.658276Z",
     "shell.execute_reply": "2025-06-12T00:31:26.657828Z",
     "shell.execute_reply.started": "2025-06-12T00:31:26.622274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Silicon Central, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>time consuming:2, slow:1</td>\n",
       "      <td>unhelpful :1, show off :1</td>\n",
       "      <td></td>\n",
       "      <td>not available :2, not much :2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>expensive:2, costier:2, extra:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Silicon Central, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>very time consuming:2, very very slow:1, too m...</td>\n",
       "      <td>STOP SHOWING OFF IN FRONT OF YOUR CUSTOMERS AN...</td>\n",
       "      <td></td>\n",
       "      <td>mostly not available :2, not much options :2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>More than expensive:2, pay something extra:1, ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Silicon Central, DB  negative  keywords   \n",
       "1  Tanishq Jewellers-Silicon Central, DB  negative   phrases   \n",
       "\n",
       "  Customer Confidence                                   Store Experience  \\\n",
       "0                                               time consuming:2, slow:1   \n",
       "1                      very time consuming:2, very very slow:1, too m...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0                          unhelpful :1, show off :1                  \n",
       "1  STOP SHOWING OFF IN FRONT OF YOUR CUSTOMERS AN...                  \n",
       "\n",
       "                                Product Variety Discount Making Charge  \\\n",
       "0                 not available :2, not much :2                          \n",
       "1  mostly not available :2, not much options :2                          \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                    expensive:2, costier:2, extra:1                   \n",
       "1  More than expensive:2, pay something extra:1, ...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_sil_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_sil_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_sil_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_sil_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_sil_db = pd.concat([negative_keywords_tan_sil_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_sil_db = pd.concat([negative_keywords_tan_sil_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_sil_db = negative_keywords_tan_sil_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_sil_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202ee1b-7251-4e3a-b90a-2f742b93f8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46f6d193-780c-4936-8623-831b5e461114",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mia_awm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "905ce752-0483-44ff-a86c-aa2f2ae42719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:31:26.659239Z",
     "iopub.status.busy": "2025-06-12T00:31:26.658985Z",
     "iopub.status.idle": "2025-06-12T00:31:26.671864Z",
     "shell.execute_reply": "2025-06-12T00:31:26.671314Z",
     "shell.execute_reply.started": "2025-06-12T00:31:26.659215Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  0.0\n",
      "Total Input Tokens -  0\n",
      "Total Input Cost = USD  0.0\n",
      "Total Output Tokens -  0\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mia_awm_ad = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mia_awm_ad=[0]\n",
    "keyword_input_token_mia_awm_ad = 0\n",
    "keyword_output_token_mia_awm_ad = 0\n",
    "keyword_start_time_loop_mia_awm_ad = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mia_awm_ad, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mia_awm_ad[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mia_awm_ad = keyword_dataframes['mia_awm_ad_final_sen_df_jul'][keyword_dataframes['mia_awm_ad_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mia_awm_ad:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mia_awm_ad,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mia_awm_ad.append(keywords)\n",
    "        keyword_input_token_mia_awm_ad += input_tokens_loop\n",
    "        keyword_output_token_mia_awm_ad += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mia_awm_ad = time.time()\n",
    "keyword_cost_input_token_mia_awm_ad = round((0.01/1000)*keyword_input_token_mia_awm_ad,2)\n",
    "keyword_cost_output_token_mia_awm_ad = round((0.03/1000)*keyword_output_token_mia_awm_ad,2)\n",
    "keyword_total_cost_mia_awm_ad = keyword_cost_input_token_mia_awm_ad + keyword_cost_output_token_mia_awm_ad\n",
    "keyword_total_time_loop_mia_awm_ad = keyword_end_time_loop_mia_awm_ad - keyword_start_time_loop_mia_awm_ad\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mia_awm_ad[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mia_awm_ad,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mia_awm_ad)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mia_awm_ad)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mia_awm_ad)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mia_awm_ad)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mia_awm_ad,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "379cc35f-6374-4411-b26e-bf2d602e88ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:31:26.672995Z",
     "iopub.status.busy": "2025-06-12T00:31:26.672510Z",
     "iopub.status.idle": "2025-06-12T00:31:26.695046Z",
     "shell.execute_reply": "2025-06-12T00:31:26.693661Z",
     "shell.execute_reply.started": "2025-06-12T00:31:26.672976Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Type, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16051/2009688186.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mrow_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnegative_keywords_mia_awm_ad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnegative_keywords_mia_awm_ad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mnegative_keywords_mia_awm_ad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_keywords_mia_awm_ad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mnegative_keywords_mia_awm_ad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot insert \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert Type, already exists"
     ]
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mia_awm_ad = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mia_awm_ad[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mia_awm_ad:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mia_awm_ad'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mia_awm_ad = pd.concat([negative_keywords_mia_awm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mia_awm_ad = pd.concat([negative_keywords_mia_awm_ad, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mia_awm_ad = negative_keywords_mia_awm_ad.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mia_awm_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c6c82-6fab-4494-9f92-7274d2d10af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea104d9d-9bb1-41ce-847b-bd7227b95cb8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### mia_bur_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "3f600af6-f55b-469b-9878-33828371c599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:27.227848Z",
     "iopub.status.busy": "2025-06-12T00:32:27.227566Z",
     "iopub.status.idle": "2025-06-12T00:32:30.243933Z",
     "shell.execute_reply": "2025-06-12T00:32:30.243444Z",
     "shell.execute_reply.started": "2025-06-12T00:32:27.227827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  3.0\n",
      "Total Input Tokens -  1496\n",
      "Total Input Cost = USD  0.01\n",
      "Total Output Tokens -  88\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.01\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_mia_bur_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_mia_bur_db=[0]\n",
    "keyword_input_token_mia_bur_db = 0\n",
    "keyword_output_token_mia_bur_db = 0\n",
    "keyword_start_time_loop_mia_bur_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_mia_bur_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_mia_bur_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_mia_bur_db = keyword_dataframes['mia_bur_db_final_sen_df_jul'][keyword_dataframes['mia_bur_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_mia_bur_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_mia_bur_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_mia_bur_db.append(keywords)\n",
    "        keyword_input_token_mia_bur_db += input_tokens_loop\n",
    "        keyword_output_token_mia_bur_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_mia_bur_db = time.time()\n",
    "keyword_cost_input_token_mia_bur_db = round((0.01/1000)*keyword_input_token_mia_bur_db,2)\n",
    "keyword_cost_output_token_mia_bur_db = round((0.03/1000)*keyword_output_token_mia_bur_db,2)\n",
    "keyword_total_cost_mia_bur_db = keyword_cost_input_token_mia_bur_db + keyword_cost_output_token_mia_bur_db\n",
    "keyword_total_time_loop_mia_bur_db = keyword_end_time_loop_mia_bur_db - keyword_start_time_loop_mia_bur_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_mia_bur_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_mia_bur_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_mia_bur_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_mia_bur_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_mia_bur_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_mia_bur_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_mia_bur_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "86c2e94b-94d0-4c69-8606-8fbea6c1ff89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:30.245067Z",
     "iopub.status.busy": "2025-06-12T00:32:30.244841Z",
     "iopub.status.idle": "2025-06-12T00:32:30.272992Z",
     "shell.execute_reply": "2025-06-12T00:32:30.272512Z",
     "shell.execute_reply.started": "2025-06-12T00:32:30.245047Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mia-Burjuman, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mia-Burjuman, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td>Not very transparent with the pricing of makin...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store Name Sentiment      Type Customer Confidence Store Experience  \\\n",
       "0  Mia-Burjuman, DB  negative  keywords                                        \n",
       "1  Mia-Burjuman, DB  negative   phrases                                        \n",
       "\n",
       "  Store Staff Product Design                         Product Variety Discount  \\\n",
       "0                             No relevant negative keywords/ phrases            \n",
       "1                             No relevant negative keywords/ phrases            \n",
       "\n",
       "                                       Making Charge Price Product Quality  \\\n",
       "0             No relevant negative keywords/ phrases                         \n",
       "1  Not very transparent with the pricing of makin...                         \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_mia_bur_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_mia_bur_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_mia_bur_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'mia_bur_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_mia_bur_db = pd.concat([negative_keywords_mia_bur_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_mia_bur_db = pd.concat([negative_keywords_mia_bur_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_mia_bur_db = negative_keywords_mia_bur_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_mia_bur_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9989a5-b2dd-4a22-8207-3e622162c76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75ca133a-b604-4cf8-b3aa-563f9f0c408a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_am_om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "65833a7a-4b76-4ae6-87a7-c6b20b4c6200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:30.274001Z",
     "iopub.status.busy": "2025-06-12T00:32:30.273804Z",
     "iopub.status.idle": "2025-06-12T00:32:31.787369Z",
     "shell.execute_reply": "2025-06-12T00:32:31.786877Z",
     "shell.execute_reply.started": "2025-06-12T00:32:30.273983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  1.5\n",
      "Total Input Tokens -  780\n",
      "Total Input Cost = USD  0.01\n",
      "Total Output Tokens -  47\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.01\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_am_om = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_am_om=[0]\n",
    "keyword_input_token_tan_am_om = 0\n",
    "keyword_output_token_tan_am_om = 0\n",
    "keyword_start_time_loop_tan_am_om = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_am_om, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_am_om[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_am_om = keyword_dataframes['tan_am_om_final_sen_df_jul'][keyword_dataframes['tan_am_om_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_am_om:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_am_om,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_am_om.append(keywords)\n",
    "        keyword_input_token_tan_am_om += input_tokens_loop\n",
    "        keyword_output_token_tan_am_om += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_am_om = time.time()\n",
    "keyword_cost_input_token_tan_am_om = round((0.01/1000)*keyword_input_token_tan_am_om,2)\n",
    "keyword_cost_output_token_tan_am_om = round((0.03/1000)*keyword_output_token_tan_am_om,2)\n",
    "keyword_total_cost_tan_am_om = keyword_cost_input_token_tan_am_om + keyword_cost_output_token_tan_am_om\n",
    "keyword_total_time_loop_tan_am_om = keyword_end_time_loop_tan_am_om - keyword_start_time_loop_tan_am_om\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_am_om[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_am_om,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_am_om)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_am_om)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_am_om)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_am_om)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_am_om,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "aa64933d-161a-49e0-8b3b-b0bed3042e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:31.789153Z",
     "iopub.status.busy": "2025-06-12T00:32:31.788700Z",
     "iopub.status.idle": "2025-06-12T00:32:31.814177Z",
     "shell.execute_reply": "2025-06-12T00:32:31.813684Z",
     "shell.execute_reply.started": "2025-06-12T00:32:31.789135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Avenues Mall, OM</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>limited :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Avenues Mall, OM</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>options are limited :1, inventory is not match...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tanishq Jewellers-Avenues Mall, OM  negative  keywords                       \n",
       "1  Tanishq Jewellers-Avenues Mall, OM  negative   phrases                       \n",
       "\n",
       "  Store Experience Store Staff Product Design  \\\n",
       "0                                               \n",
       "1                                               \n",
       "\n",
       "                                     Product Variety Discount Making Charge  \\\n",
       "0                                         limited :1                          \n",
       "1  options are limited :1, inventory is not match...                          \n",
       "\n",
       "  Price Product Quality Jewellery Exchange  \n",
       "0                                           \n",
       "1                                           "
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_am_om = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_am_om[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_am_om:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_am_om'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_am_om = pd.concat([negative_keywords_tan_am_om, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_am_om = pd.concat([negative_keywords_tan_am_om, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_am_om = negative_keywords_tan_am_om.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_am_om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdfb47-eb36-4bec-b69d-b4e329180b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a2f942-3470-483b-8ac5-d9aff2b8d9a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_atl_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "9b7baf09-1797-45ad-9ec2-8743c0795474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:32.212108Z",
     "iopub.status.busy": "2025-06-12T00:32:32.211797Z",
     "iopub.status.idle": "2025-06-12T00:32:47.244043Z",
     "shell.execute_reply": "2025-06-12T00:32:47.243528Z",
     "shell.execute_reply.started": "2025-06-12T00:32:32.212087Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  15.0\n",
      "Total Input Tokens -  6951\n",
      "Total Input Cost = USD  0.07\n",
      "Total Output Tokens -  684\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.09\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_atl_ga = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_atl_ga=[0]\n",
    "keyword_input_token_tan_atl_ga = 0\n",
    "keyword_output_token_tan_atl_ga = 0\n",
    "keyword_start_time_loop_tan_atl_ga = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_atl_ga, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_atl_ga[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_atl_ga = keyword_dataframes['tan_atl_ga_final_sen_df_jul'][keyword_dataframes['tan_atl_ga_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_atl_ga:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_atl_ga,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_atl_ga.append(keywords)\n",
    "        keyword_input_token_tan_atl_ga += input_tokens_loop\n",
    "        keyword_output_token_tan_atl_ga += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_atl_ga = time.time()\n",
    "keyword_cost_input_token_tan_atl_ga = round((0.01/1000)*keyword_input_token_tan_atl_ga,2)\n",
    "keyword_cost_output_token_tan_atl_ga = round((0.03/1000)*keyword_output_token_tan_atl_ga,2)\n",
    "keyword_total_cost_tan_atl_ga = keyword_cost_input_token_tan_atl_ga + keyword_cost_output_token_tan_atl_ga\n",
    "keyword_total_time_loop_tan_atl_ga = keyword_end_time_loop_tan_atl_ga - keyword_start_time_loop_tan_atl_ga\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_atl_ga[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_atl_ga,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_atl_ga)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_atl_ga)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_atl_ga)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_atl_ga)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_atl_ga,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "f03ba972-cd8e-4b72-8fee-9413b5845902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:47.245258Z",
     "iopub.status.busy": "2025-06-12T00:32:47.244964Z",
     "iopub.status.idle": "2025-06-12T00:32:47.288411Z",
     "shell.execute_reply": "2025-06-12T00:32:47.287922Z",
     "shell.execute_reply.started": "2025-06-12T00:32:47.245239Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Atlanta, GA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>fake information:1, false promises:1, clueless...</td>\n",
       "      <td>clueless :2, contradictory :2, worst :1, terri...</td>\n",
       "      <td>clueless :2, dismissively :1</td>\n",
       "      <td></td>\n",
       "      <td>limited :1, not so great :1</td>\n",
       "      <td></td>\n",
       "      <td>higher :2, expensive :1, high :1, waste :1, co...</td>\n",
       "      <td>making charges: 3, competitive prices: 1, pric...</td>\n",
       "      <td></td>\n",
       "      <td>no returns:2, contradictory:1, clueless:1, res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Atlanta, GA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>cheating people with false promises:1, staff i...</td>\n",
       "      <td>return policies(NO RETURNS) :1, WORST STORE EX...</td>\n",
       "      <td>staff is clueless about their own policies :1,...</td>\n",
       "      <td></td>\n",
       "      <td>product selection felt quite limited :1, not s...</td>\n",
       "      <td></td>\n",
       "      <td>making charges to be significantly higher :1, ...</td>\n",
       "      <td>making charges to be significantly higher comp...</td>\n",
       "      <td></td>\n",
       "      <td>return literally only means exchange:1, terms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Atlanta, GA  negative  keywords   \n",
       "1  Tanishq-Atlanta, GA  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  fake information:1, false promises:1, clueless...   \n",
       "1  cheating people with false promises:1, staff i...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  clueless :2, contradictory :2, worst :1, terri...   \n",
       "1  return policies(NO RETURNS) :1, WORST STORE EX...   \n",
       "\n",
       "                                         Store Staff Product Design  \\\n",
       "0                       clueless :2, dismissively :1                  \n",
       "1  staff is clueless about their own policies :1,...                  \n",
       "\n",
       "                                     Product Variety Discount  \\\n",
       "0                        limited :1, not so great :1            \n",
       "1  product selection felt quite limited :1, not s...            \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  higher :2, expensive :1, high :1, waste :1, co...   \n",
       "1  making charges to be significantly higher :1, ...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0  making charges: 3, competitive prices: 1, pric...                   \n",
       "1  making charges to be significantly higher comp...                   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0  no returns:2, contradictory:1, clueless:1, res...  \n",
       "1  return literally only means exchange:1, terms ...  "
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_atl_ga = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_atl_ga[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_atl_ga:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_atl_ga'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_atl_ga = pd.concat([negative_keywords_tan_atl_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_atl_ga = pd.concat([negative_keywords_tan_atl_ga, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_atl_ga = negative_keywords_tan_atl_ga.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_atl_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384bda9b-ff13-4b63-bed8-9e36df931d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc501bd0-0e9a-449e-85c4-7e5204e2e96a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_fc_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "f19a2456-c257-4a5d-b9e3-399330e54b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:47.289377Z",
     "iopub.status.busy": "2025-06-12T00:32:47.289097Z",
     "iopub.status.idle": "2025-06-12T00:32:47.301513Z",
     "shell.execute_reply": "2025-06-12T00:32:47.301048Z",
     "shell.execute_reply.started": "2025-06-12T00:32:47.289359Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  0.0\n",
      "Total Input Tokens -  0\n",
      "Total Input Cost = USD  0.0\n",
      "Total Output Tokens -  0\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_fc_qa = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_fc_qa=[0]\n",
    "keyword_input_token_tan_fc_qa = 0\n",
    "keyword_output_token_tan_fc_qa = 0\n",
    "keyword_start_time_loop_tan_fc_qa = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_fc_qa, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_fc_qa[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_fc_qa = keyword_dataframes['tan_fc_qa_final_sen_df_jul'][keyword_dataframes['tan_fc_qa_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_fc_qa:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_fc_qa,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_fc_qa.append(keywords)\n",
    "        keyword_input_token_tan_fc_qa += input_tokens_loop\n",
    "        keyword_output_token_tan_fc_qa += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_fc_qa = time.time()\n",
    "keyword_cost_input_token_tan_fc_qa = round((0.01/1000)*keyword_input_token_tan_fc_qa,2)\n",
    "keyword_cost_output_token_tan_fc_qa = round((0.03/1000)*keyword_output_token_tan_fc_qa,2)\n",
    "keyword_total_cost_tan_fc_qa = keyword_cost_input_token_tan_fc_qa + keyword_cost_output_token_tan_fc_qa\n",
    "keyword_total_time_loop_tan_fc_qa = keyword_end_time_loop_tan_fc_qa - keyword_start_time_loop_tan_fc_qa\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_fc_qa[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_fc_qa,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_fc_qa)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_fc_qa)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_fc_qa)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_fc_qa)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_fc_qa,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "aa59f389-d351-4f80-b827-276dd7ec0ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:32:47.302874Z",
     "iopub.status.busy": "2025-06-12T00:32:47.302636Z",
     "iopub.status.idle": "2025-06-12T00:32:47.324239Z",
     "shell.execute_reply": "2025-06-12T00:32:47.323395Z",
     "shell.execute_reply.started": "2025-06-12T00:32:47.302856Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Type, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16051/3530082960.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mrow_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnegative_keywords_tan_fc_qa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnegative_keywords_tan_fc_qa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mnegative_keywords_tan_fc_qa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_keywords_tan_fc_qa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mnegative_keywords_tan_fc_qa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot insert \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert Type, already exists"
     ]
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_fc_qa = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_fc_qa[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_fc_qa:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_fc_qa'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_fc_qa = pd.concat([negative_keywords_tan_fc_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_fc_qa = pd.concat([negative_keywords_tan_fc_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_fc_qa = negative_keywords_tan_fc_qa.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_fc_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa92bb7-5caf-4eee-bad8-b8e6487985bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "248f37c3-5c6c-4e55-b053-85b21be002bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_gs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "7a77c289-0460-4792-abcf-d42fa0b4bfc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:30.119911Z",
     "iopub.status.busy": "2025-06-12T00:33:30.119443Z",
     "iopub.status.idle": "2025-06-12T00:33:36.640987Z",
     "shell.execute_reply": "2025-06-12T00:33:36.640493Z",
     "shell.execute_reply.started": "2025-06-12T00:33:30.119892Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  6.5\n",
      "Total Input Tokens -  3344\n",
      "Total Input Cost = USD  0.03\n",
      "Total Output Tokens -  229\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.04\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_gs_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_gs_db=[0]\n",
    "keyword_input_token_tan_gs_db = 0\n",
    "keyword_output_token_tan_gs_db = 0\n",
    "keyword_start_time_loop_tan_gs_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_gs_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_gs_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_gs_db = keyword_dataframes['tan_gs_db_final_sen_df_jul'][keyword_dataframes['tan_gs_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_gs_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_gs_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_gs_db.append(keywords)\n",
    "        keyword_input_token_tan_gs_db += input_tokens_loop\n",
    "        keyword_output_token_tan_gs_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_gs_db = time.time()\n",
    "keyword_cost_input_token_tan_gs_db = round((0.01/1000)*keyword_input_token_tan_gs_db,2)\n",
    "keyword_cost_output_token_tan_gs_db = round((0.03/1000)*keyword_output_token_tan_gs_db,2)\n",
    "keyword_total_cost_tan_gs_db = keyword_cost_input_token_tan_gs_db + keyword_cost_output_token_tan_gs_db\n",
    "keyword_total_time_loop_tan_gs_db = keyword_end_time_loop_tan_gs_db - keyword_start_time_loop_tan_gs_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_gs_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_gs_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_gs_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_gs_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_gs_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_gs_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_gs_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "48428422-2139-4369-a5f4-9813cf870e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:36.642163Z",
     "iopub.status.busy": "2025-06-12T00:33:36.641885Z",
     "iopub.status.idle": "2025-06-12T00:33:36.674463Z",
     "shell.execute_reply": "2025-06-12T00:33:36.673973Z",
     "shell.execute_reply.started": "2025-06-12T00:33:36.642146Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Gold Souk, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>crowded place :1, no clear signs :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>cheating :1</td>\n",
       "      <td>high :2, higher :2</td>\n",
       "      <td>cheating :1, disclosed :1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Gold Souk, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>payment process took lot of time :1, hard to c...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>discount was applied only on a single item :1,...</td>\n",
       "      <td>making charge bit high :1, making charge is in...</td>\n",
       "      <td>price for each item was not disclosed :1, disc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tanishq Jewellers-Gold Souk, DB  negative  keywords                       \n",
       "1  Tanishq Jewellers-Gold Souk, DB  negative   phrases                       \n",
       "\n",
       "                                    Store Experience Store Staff  \\\n",
       "0                crowded place :1, no clear signs :1               \n",
       "1  payment process took lot of time :1, hard to c...               \n",
       "\n",
       "  Product Design Product Variety  \\\n",
       "0                                  \n",
       "1                                  \n",
       "\n",
       "                                            Discount  \\\n",
       "0                                        cheating :1   \n",
       "1  discount was applied only on a single item :1,...   \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0                                 high :2, higher :2   \n",
       "1  making charge bit high :1, making charge is in...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                          cheating :1, disclosed :1                   \n",
       "1  price for each item was not disclosed :1, disc...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_gs_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_gs_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_gs_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_gs_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_gs_db = pd.concat([negative_keywords_tan_gs_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_gs_db = pd.concat([negative_keywords_tan_gs_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_gs_db = negative_keywords_tan_gs_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_gs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d53bb1-e3a7-45ea-a63e-18375af88d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5de16b0e-ffa5-423f-b64e-f1635b7acdd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_lul_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "cc644181-1511-4e54-84bf-1915cdfe4a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:36.675378Z",
     "iopub.status.busy": "2025-06-12T00:33:36.675134Z",
     "iopub.status.idle": "2025-06-12T00:33:40.192219Z",
     "shell.execute_reply": "2025-06-12T00:33:40.191682Z",
     "shell.execute_reply.started": "2025-06-12T00:33:36.675360Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  3.5\n",
      "Total Input Tokens -  733\n",
      "Total Input Cost = USD  0.01\n",
      "Total Output Tokens -  41\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.01\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_lul_qa = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_lul_qa=[0]\n",
    "keyword_input_token_tan_lul_qa = 0\n",
    "keyword_output_token_tan_lul_qa = 0\n",
    "keyword_start_time_loop_tan_lul_qa = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_lul_qa, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_lul_qa[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_lul_qa = keyword_dataframes['tan_lul_qa_final_sen_df_jul'][keyword_dataframes['tan_lul_qa_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_lul_qa:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_lul_qa,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_lul_qa.append(keywords)\n",
    "        keyword_input_token_tan_lul_qa += input_tokens_loop\n",
    "        keyword_output_token_tan_lul_qa += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_lul_qa = time.time()\n",
    "keyword_cost_input_token_tan_lul_qa = round((0.01/1000)*keyword_input_token_tan_lul_qa,2)\n",
    "keyword_cost_output_token_tan_lul_qa = round((0.03/1000)*keyword_output_token_tan_lul_qa,2)\n",
    "keyword_total_cost_tan_lul_qa = keyword_cost_input_token_tan_lul_qa + keyword_cost_output_token_tan_lul_qa\n",
    "keyword_total_time_loop_tan_lul_qa = keyword_end_time_loop_tan_lul_qa - keyword_start_time_loop_tan_lul_qa\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_lul_qa[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_lul_qa,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_lul_qa)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_lul_qa)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_lul_qa)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_lul_qa)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_lul_qa,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "1529b123-442d-4cb7-bda0-2793628e2dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:40.193508Z",
     "iopub.status.busy": "2025-06-12T00:33:40.193226Z",
     "iopub.status.idle": "2025-06-12T00:33:40.219044Z",
     "shell.execute_reply": "2025-06-12T00:33:40.218533Z",
     "shell.execute_reply.started": "2025-06-12T00:33:40.193490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Lulu Hypermarket, QA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Lulu Hypermarket, QA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Lulu Hypermarket, QA  negative  keywords   \n",
       "1  Tanishq Jewellers-Lulu Hypermarket, QA  negative   phrases   \n",
       "\n",
       "  Customer Confidence Store Experience Store Staff Product Design  \\\n",
       "0                                                                   \n",
       "1                                                                   \n",
       "\n",
       "                          Product Variety Discount Making Charge Price  \\\n",
       "0  No relevant negative keywords/ phrases                                \n",
       "1  No relevant negative keywords/ phrases                                \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_lul_qa = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_lul_qa[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_lul_qa:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_lul_qa'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_lul_qa = pd.concat([negative_keywords_tan_lul_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_lul_qa = pd.concat([negative_keywords_tan_lul_qa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_lul_qa = negative_keywords_tan_lul_qa.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_lul_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931f73b-12e7-4163-96e0-a4380253c890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21d4fa3c-09f8-4063-84bc-0e5212db5847",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_mank_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "643e73fb-b1a5-43e3-88ed-cb2a359c0491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:42.485793Z",
     "iopub.status.busy": "2025-06-12T00:33:42.485303Z",
     "iopub.status.idle": "2025-06-12T00:33:42.499475Z",
     "shell.execute_reply": "2025-06-12T00:33:42.498931Z",
     "shell.execute_reply.started": "2025-06-12T00:33:42.485769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  0.0\n",
      "Total Input Tokens -  0\n",
      "Total Input Cost = USD  0.0\n",
      "Total Output Tokens -  0\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_mank_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_mank_db=[0]\n",
    "keyword_input_token_tan_mank_db = 0\n",
    "keyword_output_token_tan_mank_db = 0\n",
    "keyword_start_time_loop_tan_mank_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_mank_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_mank_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_mank_db = keyword_dataframes['tan_mank_db_final_sen_df_jul'][keyword_dataframes['tan_mank_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_mank_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_mank_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_mank_db.append(keywords)\n",
    "        keyword_input_token_tan_mank_db += input_tokens_loop\n",
    "        keyword_output_token_tan_mank_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_mank_db = time.time()\n",
    "keyword_cost_input_token_tan_mank_db = round((0.01/1000)*keyword_input_token_tan_mank_db,2)\n",
    "keyword_cost_output_token_tan_mank_db = round((0.03/1000)*keyword_output_token_tan_mank_db,2)\n",
    "keyword_total_cost_tan_mank_db = keyword_cost_input_token_tan_mank_db + keyword_cost_output_token_tan_mank_db\n",
    "keyword_total_time_loop_tan_mank_db = keyword_end_time_loop_tan_mank_db - keyword_start_time_loop_tan_mank_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_mank_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_mank_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_mank_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_mank_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_mank_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_mank_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_mank_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "1c02c440-a4e7-40e5-bfd9-0f47753b28bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:43.311704Z",
     "iopub.status.busy": "2025-06-12T00:33:43.311440Z",
     "iopub.status.idle": "2025-06-12T00:33:43.335176Z",
     "shell.execute_reply": "2025-06-12T00:33:43.334465Z",
     "shell.execute_reply.started": "2025-06-12T00:33:43.311685Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Type, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16051/502080660.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mrow_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnegative_keywords_tan_mank_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnegative_keywords_tan_mank_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mnegative_keywords_tan_mank_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_keywords_tan_mank_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mnegative_keywords_tan_mank_db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot insert \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert Type, already exists"
     ]
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_mank_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_mank_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_mank_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_mank_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_mank_db = pd.concat([negative_keywords_tan_mank_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_mank_db = pd.concat([negative_keywords_tan_mank_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_mank_db = negative_keywords_tan_mank_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_mank_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4fc227-a8fe-4f9b-b046-cc23fef3d3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34fb0d02-3158-478a-b04c-d2663d0a3b89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_rol_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "75804089-2ac1-41c5-9b87-122309a924d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:46.214901Z",
     "iopub.status.busy": "2025-06-12T00:33:46.214360Z",
     "iopub.status.idle": "2025-06-12T00:33:47.730803Z",
     "shell.execute_reply": "2025-06-12T00:33:47.730211Z",
     "shell.execute_reply.started": "2025-06-12T00:33:46.214876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  1.5\n",
      "Total Input Tokens -  727\n",
      "Total Input Cost = USD  0.01\n",
      "Total Output Tokens -  40\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.01\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_rol_sh = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_rol_sh=[0]\n",
    "keyword_input_token_tan_rol_sh = 0\n",
    "keyword_output_token_tan_rol_sh = 0\n",
    "keyword_start_time_loop_tan_rol_sh = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_rol_sh, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_rol_sh[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_rol_sh = keyword_dataframes['tan_rol_sh_final_sen_df_jul'][keyword_dataframes['tan_rol_sh_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_rol_sh:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_rol_sh,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_rol_sh.append(keywords)\n",
    "        keyword_input_token_tan_rol_sh += input_tokens_loop\n",
    "        keyword_output_token_tan_rol_sh += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_rol_sh = time.time()\n",
    "keyword_cost_input_token_tan_rol_sh = round((0.01/1000)*keyword_input_token_tan_rol_sh,2)\n",
    "keyword_cost_output_token_tan_rol_sh = round((0.03/1000)*keyword_output_token_tan_rol_sh,2)\n",
    "keyword_total_cost_tan_rol_sh = keyword_cost_input_token_tan_rol_sh + keyword_cost_output_token_tan_rol_sh\n",
    "keyword_total_time_loop_tan_rol_sh = keyword_end_time_loop_tan_rol_sh - keyword_start_time_loop_tan_rol_sh\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_rol_sh[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_rol_sh,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_rol_sh)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_rol_sh)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_rol_sh)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_rol_sh)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_rol_sh,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "4bd69a2b-6fa9-48c9-bef3-2337652435c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:47.732115Z",
     "iopub.status.busy": "2025-06-12T00:33:47.731684Z",
     "iopub.status.idle": "2025-06-12T00:33:47.757175Z",
     "shell.execute_reply": "2025-06-12T00:33:47.756681Z",
     "shell.execute_reply.started": "2025-06-12T00:33:47.732093Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Rolla, SH</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Rolla, SH</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tanishq Jewellers-Rolla, SH  negative  keywords                       \n",
       "1  Tanishq Jewellers-Rolla, SH  negative   phrases                       \n",
       "\n",
       "  Store Experience Store Staff Product Design Product Variety Discount  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "\n",
       "  Making Charge                                   Price Product Quality  \\\n",
       "0                No relevant negative keywords/ phrases                   \n",
       "1                No relevant negative keywords/ phrases                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_rol_sh = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_rol_sh[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_rol_sh:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_rol_sh'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_rol_sh = pd.concat([negative_keywords_tan_rol_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_rol_sh = pd.concat([negative_keywords_tan_rol_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_rol_sh = negative_keywords_tan_rol_sh.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_rol_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb40ec6-6e8d-465a-89de-a622a50245e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20644aac-51d2-4d34-ab51-9ce989ae035f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_rse_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "de99fe8c-8a6c-4c2f-9966-b73da3c232a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:33:48.841699Z",
     "iopub.status.busy": "2025-06-12T00:33:48.841184Z",
     "iopub.status.idle": "2025-06-12T00:34:06.881268Z",
     "shell.execute_reply": "2025-06-12T00:34:06.880701Z",
     "shell.execute_reply.started": "2025-06-12T00:33:48.841675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  18.0\n",
      "Total Input Tokens -  8622\n",
      "Total Input Cost = USD  0.09\n",
      "Total Output Tokens -  707\n",
      "Total Output Cost = USD  0.02\n",
      "Total Cost = USD  0.11\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_rse_wa = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_rse_wa=[0]\n",
    "keyword_input_token_tan_rse_wa = 0\n",
    "keyword_output_token_tan_rse_wa = 0\n",
    "keyword_start_time_loop_tan_rse_wa = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_rse_wa, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_rse_wa[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_rse_wa = keyword_dataframes['tan_rse_wa_final_sen_df_jul'][keyword_dataframes['tan_rse_wa_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_rse_wa:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_rse_wa,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_rse_wa.append(keywords)\n",
    "        keyword_input_token_tan_rse_wa += input_tokens_loop\n",
    "        keyword_output_token_tan_rse_wa += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_rse_wa = time.time()\n",
    "keyword_cost_input_token_tan_rse_wa = round((0.01/1000)*keyword_input_token_tan_rse_wa,2)\n",
    "keyword_cost_output_token_tan_rse_wa = round((0.03/1000)*keyword_output_token_tan_rse_wa,2)\n",
    "keyword_total_cost_tan_rse_wa = keyword_cost_input_token_tan_rse_wa + keyword_cost_output_token_tan_rse_wa\n",
    "keyword_total_time_loop_tan_rse_wa = keyword_end_time_loop_tan_rse_wa - keyword_start_time_loop_tan_rse_wa\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_rse_wa[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_rse_wa,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_rse_wa)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_rse_wa)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_rse_wa)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_rse_wa)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_rse_wa,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "81c25ff1-7cab-4b51-af8b-cacbc57cad87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:06.882632Z",
     "iopub.status.busy": "2025-06-12T00:34:06.882166Z",
     "iopub.status.idle": "2025-06-12T00:34:06.928150Z",
     "shell.execute_reply": "2025-06-12T00:34:06.927661Z",
     "shell.execute_reply.started": "2025-06-12T00:34:06.882611Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Redmond Seattle, WA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>unfair pricing:2, unclear:1, overpaid:1, lack ...</td>\n",
       "      <td>uninterested staff :1, unclear bill :1, denied...</td>\n",
       "      <td>terrible employees:2, scammed:1, uninterested:...</td>\n",
       "      <td>breakdown:1, hard:1</td>\n",
       "      <td>traditional :2, contemporary :1, stylish :1, l...</td>\n",
       "      <td></td>\n",
       "      <td>unfair pricing:2, unclear:1, overpaid:1, addit...</td>\n",
       "      <td>overpriced:1, unreasonable:1, unclear:1, highe...</td>\n",
       "      <td>unreasonable :1, disappointed :1</td>\n",
       "      <td>refused :1, less gold :1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Redmond Seattle, WA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>weren’t transparent about the making charges:1...</td>\n",
       "      <td>no one came or asked what we were looking for ...</td>\n",
       "      <td>No one came or asked what we were looking for:...</td>\n",
       "      <td>earrings might be hard to wear:1, can breakdow...</td>\n",
       "      <td>Most of their collection is very traditional :...</td>\n",
       "      <td></td>\n",
       "      <td>weren’t transparent about the making charges:1...</td>\n",
       "      <td>overpaid for my purchase:1, much higher:1, com...</td>\n",
       "      <td>back hoop kept falling off :2, product quality...</td>\n",
       "      <td>couldn’t go back on the exchange :1, refused t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name Sentiment      Type  \\\n",
       "0  Tanishq-Redmond Seattle, WA  negative  keywords   \n",
       "1  Tanishq-Redmond Seattle, WA  negative   phrases   \n",
       "\n",
       "                                 Customer Confidence  \\\n",
       "0  unfair pricing:2, unclear:1, overpaid:1, lack ...   \n",
       "1  weren’t transparent about the making charges:1...   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  uninterested staff :1, unclear bill :1, denied...   \n",
       "1  no one came or asked what we were looking for ...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  terrible employees:2, scammed:1, uninterested:...   \n",
       "1  No one came or asked what we were looking for:...   \n",
       "\n",
       "                                      Product Design  \\\n",
       "0                                breakdown:1, hard:1   \n",
       "1  earrings might be hard to wear:1, can breakdow...   \n",
       "\n",
       "                                     Product Variety Discount  \\\n",
       "0  traditional :2, contemporary :1, stylish :1, l...            \n",
       "1  Most of their collection is very traditional :...            \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  unfair pricing:2, unclear:1, overpaid:1, addit...   \n",
       "1  weren’t transparent about the making charges:1...   \n",
       "\n",
       "                                               Price  \\\n",
       "0  overpriced:1, unreasonable:1, unclear:1, highe...   \n",
       "1  overpaid for my purchase:1, much higher:1, com...   \n",
       "\n",
       "                                     Product Quality  \\\n",
       "0                   unreasonable :1, disappointed :1   \n",
       "1  back hoop kept falling off :2, product quality...   \n",
       "\n",
       "                                  Jewellery Exchange  \n",
       "0                           refused :1, less gold :1  \n",
       "1  couldn’t go back on the exchange :1, refused t...  "
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_rse_wa = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_rse_wa[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_rse_wa:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_rse_wa'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_rse_wa = pd.concat([negative_keywords_tan_rse_wa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_rse_wa = pd.concat([negative_keywords_tan_rse_wa, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_rse_wa = negative_keywords_tan_rse_wa.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_rse_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c77617-656b-43e0-a15c-d68f5a2a7e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "982415ce-2fd3-44cd-ba44-91e274427c55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_sc_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "df1c36d0-e05f-43ce-bdf7-8e8ecba52bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:06.929176Z",
     "iopub.status.busy": "2025-06-12T00:34:06.928889Z",
     "iopub.status.idle": "2025-06-12T00:34:15.452197Z",
     "shell.execute_reply": "2025-06-12T00:34:15.451680Z",
     "shell.execute_reply.started": "2025-06-12T00:34:06.929156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  8.5\n",
      "Total Input Tokens -  4760\n",
      "Total Input Cost = USD  0.05\n",
      "Total Output Tokens -  347\n",
      "Total Output Cost = USD  0.01\n",
      "Total Cost = USD  0.06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_sc_ca = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_sc_ca=[0]\n",
    "keyword_input_token_tan_sc_ca = 0\n",
    "keyword_output_token_tan_sc_ca = 0\n",
    "keyword_start_time_loop_tan_sc_ca = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_sc_ca, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_sc_ca[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_sc_ca = keyword_dataframes['tan_sc_ca_final_sen_df_jul'][keyword_dataframes['tan_sc_ca_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_sc_ca:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_sc_ca,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_sc_ca.append(keywords)\n",
    "        keyword_input_token_tan_sc_ca += input_tokens_loop\n",
    "        keyword_output_token_tan_sc_ca += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_sc_ca = time.time()\n",
    "keyword_cost_input_token_tan_sc_ca = round((0.01/1000)*keyword_input_token_tan_sc_ca,2)\n",
    "keyword_cost_output_token_tan_sc_ca = round((0.03/1000)*keyword_output_token_tan_sc_ca,2)\n",
    "keyword_total_cost_tan_sc_ca = keyword_cost_input_token_tan_sc_ca + keyword_cost_output_token_tan_sc_ca\n",
    "keyword_total_time_loop_tan_sc_ca = keyword_end_time_loop_tan_sc_ca - keyword_start_time_loop_tan_sc_ca\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_sc_ca[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_sc_ca,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_sc_ca)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_sc_ca)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_sc_ca)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_sc_ca)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_sc_ca,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "a994b032-7fa7-403d-b34e-22f835e500bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:15.454023Z",
     "iopub.status.busy": "2025-06-12T00:34:15.453683Z",
     "iopub.status.idle": "2025-06-12T00:34:15.489299Z",
     "shell.execute_reply": "2025-06-12T00:34:15.488839Z",
     "shell.execute_reply.started": "2025-06-12T00:34:15.454005Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq-Santa Clara, CA</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td>rude :3, unprofessional :2, worst :2, impatien...</td>\n",
       "      <td>rude :3, unprofessional :2, impatient :1, unin...</td>\n",
       "      <td>design element:1, finishing:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high making charges:2, overpriced:1, unreasona...</td>\n",
       "      <td>over priced:1, expensive:1, high:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq-Santa Clara, CA</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td>worst experience ever :2, extremely rude :1, w...</td>\n",
       "      <td>worst customer service :2, spoke in a condesce...</td>\n",
       "      <td>broke a design element:1, finishing on this re...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unreasonable high making charges:1, making hol...</td>\n",
       "      <td>prices over online and in store varies:1, maki...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store Name Sentiment      Type Customer Confidence  \\\n",
       "0  Tanishq-Santa Clara, CA  negative  keywords                       \n",
       "1  Tanishq-Santa Clara, CA  negative   phrases                       \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0  rude :3, unprofessional :2, worst :2, impatien...   \n",
       "1  worst experience ever :2, extremely rude :1, w...   \n",
       "\n",
       "                                         Store Staff  \\\n",
       "0  rude :3, unprofessional :2, impatient :1, unin...   \n",
       "1  worst customer service :2, spoke in a condesce...   \n",
       "\n",
       "                                      Product Design Product Variety Discount  \\\n",
       "0                      design element:1, finishing:1                            \n",
       "1  broke a design element:1, finishing on this re...                            \n",
       "\n",
       "                                       Making Charge  \\\n",
       "0  high making charges:2, overpriced:1, unreasona...   \n",
       "1  unreasonable high making charges:1, making hol...   \n",
       "\n",
       "                                               Price Product Quality  \\\n",
       "0                 over priced:1, expensive:1, high:1                   \n",
       "1  prices over online and in store varies:1, maki...                   \n",
       "\n",
       "  Jewellery Exchange  \n",
       "0                     \n",
       "1                     "
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_sc_ca = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_sc_ca[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_sc_ca:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_sc_ca'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_sc_ca = pd.concat([negative_keywords_tan_sc_ca, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_sc_ca = pd.concat([negative_keywords_tan_sc_ca, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_sc_ca = negative_keywords_tan_sc_ca.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_sc_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4352c7e-ee4e-48ff-bb23-c662b6c51890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8384d6c3-4886-40c4-8aa1-c2e950c4aec8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_sc_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "4bd8aa21-650b-458c-ba76-6e82bd5f392f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:15.490215Z",
     "iopub.status.busy": "2025-06-12T00:34:15.490022Z",
     "iopub.status.idle": "2025-06-12T00:34:20.008102Z",
     "shell.execute_reply": "2025-06-12T00:34:20.007401Z",
     "shell.execute_reply.started": "2025-06-12T00:34:15.490192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  4.5\n",
      "Total Input Tokens -  2289\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  113\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.02\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_sc_sh = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_sc_sh=[0]\n",
    "keyword_input_token_tan_sc_sh = 0\n",
    "keyword_output_token_tan_sc_sh = 0\n",
    "keyword_start_time_loop_tan_sc_sh = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_sc_sh, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_sc_sh[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_sc_sh = keyword_dataframes['tan_sc_sh_final_sen_df_jul'][keyword_dataframes['tan_sc_sh_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_sc_sh:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_sc_sh,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_sc_sh.append(keywords)\n",
    "        keyword_input_token_tan_sc_sh += input_tokens_loop\n",
    "        keyword_output_token_tan_sc_sh += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_sc_sh = time.time()\n",
    "keyword_cost_input_token_tan_sc_sh = round((0.01/1000)*keyword_input_token_tan_sc_sh,2)\n",
    "keyword_cost_output_token_tan_sc_sh = round((0.03/1000)*keyword_output_token_tan_sc_sh,2)\n",
    "keyword_total_cost_tan_sc_sh = keyword_cost_input_token_tan_sc_sh + keyword_cost_output_token_tan_sc_sh\n",
    "keyword_total_time_loop_tan_sc_sh = keyword_end_time_loop_tan_sc_sh - keyword_start_time_loop_tan_sc_sh\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_sc_sh[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_sc_sh,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_sc_sh)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_sc_sh)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_sc_sh)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_sc_sh)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_sc_sh,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "36200d3f-e9c6-4282-bd96-cd65ac496692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:20.009178Z",
     "iopub.status.busy": "2025-06-12T00:34:20.008957Z",
     "iopub.status.idle": "2025-06-12T00:34:20.040539Z",
     "shell.execute_reply": "2025-06-12T00:34:20.040062Z",
     "shell.execute_reply.started": "2025-06-12T00:34:20.009160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Sharjah Central, SH</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>customer service :1</td>\n",
       "      <td></td>\n",
       "      <td>Limited options:1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Sharjah Central, SH</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Worst customer service :1</td>\n",
       "      <td></td>\n",
       "      <td>pay attention to diversity:1</td>\n",
       "      <td>make offers suitable for all occasions: 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Sharjah Central, SH  negative  keywords   \n",
       "1  Tanishq Jewellers-Sharjah Central, SH  negative   phrases   \n",
       "\n",
       "  Customer Confidence Store Experience                Store Staff  \\\n",
       "0                                             customer service :1   \n",
       "1                                       Worst customer service :1   \n",
       "\n",
       "  Product Design               Product Variety  \\\n",
       "0                            Limited options:1   \n",
       "1                 pay attention to diversity:1   \n",
       "\n",
       "                                    Discount Making Charge Price  \\\n",
       "0                                                                  \n",
       "1  make offers suitable for all occasions: 1                       \n",
       "\n",
       "  Product Quality Jewellery Exchange  \n",
       "0                                     \n",
       "1                                     "
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_sc_sh = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_sc_sh[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_sc_sh:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_sc_sh'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_sc_sh = pd.concat([negative_keywords_tan_sc_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_sc_sh = pd.concat([negative_keywords_tan_sc_sh, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_sc_sh = negative_keywords_tan_sc_sh.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_sc_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faef4f3-fb28-49b2-ba24-1edf509348c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "554e972f-6495-43c4-ac43-97e071c18769",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tan_taj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "a0293310-042c-4a3d-b630-f9964f222bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:20.041446Z",
     "iopub.status.busy": "2025-06-12T00:34:20.041182Z",
     "iopub.status.idle": "2025-06-12T00:34:24.057789Z",
     "shell.execute_reply": "2025-06-12T00:34:24.057183Z",
     "shell.execute_reply.started": "2025-06-12T00:34:20.041430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed  10  Iterations\n",
      "Total Execution time (in secs) -  4.0\n",
      "Total Input Tokens -  2485\n",
      "Total Input Cost = USD  0.02\n",
      "Total Output Tokens -  154\n",
      "Total Output Cost = USD  0.0\n",
      "Total Cost = USD  0.02\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dictionary\n",
    "keyword_negative_output_tan_taj_db = []\n",
    "# List of topic columns to iterate over, excluding the 'review_text' column\n",
    "keyword_topics = ['Customer Confidence',\n",
    "                  'Store Experience', \n",
    "                  'Store Staff', \n",
    "                  'Product Design', \n",
    "                  'Product Variety',\n",
    "                  'Discount', \n",
    "                  'Making Charge', \n",
    "                  'Price', \n",
    "                  'Product Quality',\n",
    "                  'Jewellery Exchange']\n",
    "\n",
    "keyword_counter_tan_taj_db=[0]\n",
    "keyword_input_token_tan_taj_db = 0\n",
    "keyword_output_token_tan_taj_db = 0\n",
    "keyword_start_time_loop_tan_taj_db = time.time()\n",
    "\n",
    "#Threading setup\n",
    "keyword_total_iterations = len(keyword_topics) \n",
    "stop_event = threading.Event()\n",
    "message_thread = threading.Thread(target=print_dynamic_message_keyword, args=(keyword_counter_tan_taj_db, keyword_total_iterations, stop_event))\n",
    "message_thread.start()\n",
    "\n",
    "# Loop through each topic\n",
    "for topic in keyword_topics:\n",
    "    keyword_counter_tan_taj_db[0]+=1\n",
    "    # Filter the DataFrame for rows where the topic has a value of 1\n",
    "    filtered_comments_tan_taj_db = keyword_dataframes['tan_taj_db_final_sen_df_jul'][keyword_dataframes['tan_taj_db_final_sen_df_jul'][topic]==-1]['review_text'].tolist()\n",
    "    #print(topic, \"-\", len(filtered_comments))\n",
    "    # If there are negative comments, call the negative_keywords function\n",
    "    if filtered_comments_tan_taj_db:\n",
    "        # Call the negative_keywords function and store the result\n",
    "        keywords, input_tokens_loop, output_token_loop = negative_keywords(filtered_comments_tan_taj_db,topic)        \n",
    "        # Add the result to the output dictionary\n",
    "        keyword_negative_output_tan_taj_db.append(keywords)\n",
    "        keyword_input_token_tan_taj_db += input_tokens_loop\n",
    "        keyword_output_token_tan_taj_db += output_token_loop\n",
    "\n",
    "#Stopping the dynamic message thread\n",
    "stop_event.set()\n",
    "message_thread.join()\n",
    "\n",
    "keyword_end_time_loop_tan_taj_db = time.time()\n",
    "keyword_cost_input_token_tan_taj_db = round((0.01/1000)*keyword_input_token_tan_taj_db,2)\n",
    "keyword_cost_output_token_tan_taj_db = round((0.03/1000)*keyword_output_token_tan_taj_db,2)\n",
    "keyword_total_cost_tan_taj_db = keyword_cost_input_token_tan_taj_db + keyword_cost_output_token_tan_taj_db\n",
    "keyword_total_time_loop_tan_taj_db = keyword_end_time_loop_tan_taj_db - keyword_start_time_loop_tan_taj_db\n",
    "\n",
    "#display loop performance parameters & cost\n",
    "clear_output(wait=True)\n",
    "print(\"Executed \",keyword_counter_tan_taj_db[0], \" Iterations\")\n",
    "print(\"Total Execution time (in secs) - \", round(keyword_total_time_loop_tan_taj_db,1))\n",
    "print(\"Total Input Tokens - \", keyword_input_token_tan_taj_db)\n",
    "print(\"Total Input Cost = USD \",keyword_cost_input_token_tan_taj_db)\n",
    "print(\"Total Output Tokens - \", keyword_output_token_tan_taj_db)\n",
    "print(\"Total Output Cost = USD \",keyword_cost_output_token_tan_taj_db)\n",
    "print(\"Total Cost = USD \",round(keyword_total_cost_tan_taj_db,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "0edad778-01c1-4d46-b50b-c8f6f091ba35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:24.058801Z",
     "iopub.status.busy": "2025-06-12T00:34:24.058497Z",
     "iopub.status.idle": "2025-06-12T00:34:24.088891Z",
     "shell.execute_reply": "2025-06-12T00:34:24.088428Z",
     "shell.execute_reply.started": "2025-06-12T00:34:24.058779Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanishq Jewellers-Taj, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>layer :1, trust :1</td>\n",
       "      <td>slow service:1, small shop:1, stand in que:1</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanishq Jewellers-Taj, DB</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Bad experience :1, Don't trust :1, be careful :1</td>\n",
       "      <td>extremely small shop:1, had to stand in que fo...</td>\n",
       "      <td>No relevant negative keywords/ phrases</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Store Name Sentiment      Type  \\\n",
       "0  Tanishq Jewellers-Taj, DB  negative  keywords   \n",
       "1  Tanishq Jewellers-Taj, DB  negative   phrases   \n",
       "\n",
       "                                Customer Confidence  \\\n",
       "0                                layer :1, trust :1   \n",
       "1  Bad experience :1, Don't trust :1, be careful :1   \n",
       "\n",
       "                                    Store Experience  \\\n",
       "0       slow service:1, small shop:1, stand in que:1   \n",
       "1  extremely small shop:1, had to stand in que fo...   \n",
       "\n",
       "                              Store Staff Product Design Product Variety  \\\n",
       "0  No relevant negative keywords/ phrases                                  \n",
       "1  No relevant negative keywords/ phrases                                  \n",
       "\n",
       "  Discount Making Charge Price Product Quality Jewellery Exchange  \n",
       "0                                                                  \n",
       "1                                                                  "
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an empty DataFrame\n",
    "negative_keywords_tan_taj_db = pd.DataFrame()\n",
    "\n",
    "# Define the columns based on the provided image\n",
    "columns = ['Store Name', \n",
    "           'Sentiment', \n",
    "           'Type', \n",
    "           'Customer Confidence',\n",
    "           'Store Experience', \n",
    "           'Store Staff', \n",
    "           'Product Design', \n",
    "           'Product Variety',\n",
    "           'Discount', \n",
    "           'Making Charge', \n",
    "           'Price', \n",
    "           'Product Quality',\n",
    "           'Jewellery Exchange']\n",
    "# Add these columns to the DataFrame\n",
    "for column in columns:\n",
    "    negative_keywords_tan_taj_db[column] = None\n",
    "\n",
    "# Process each JSON string\n",
    "for json_str in keyword_negative_output_tan_taj_db:\n",
    "    # Load the JSON string into a dictionary\n",
    "    data = json.loads(json_str)\n",
    "    # Get the key (category) from the dictionary\n",
    "    for category, content_list in data.items():\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {column: None for column in columns}\n",
    "        # Fill in the store name and sentiment\n",
    "        input_store_identifier = 'tan_taj_db'  \n",
    "        # Check if the input store identifier is in the keyword_mappings\n",
    "        row_data['Store Name'] = \"Store Name Not Found\"\n",
    "        for key, value in keyword_mappings.items():\n",
    "            if input_store_identifier in key:\n",
    "                row_data['Store Name'] = value\n",
    "                break\n",
    "        row_data['Sentiment'] = 'negative'\n",
    "        # Now extract keywords and phrases for each category\n",
    "        for content in content_list:\n",
    "            # Keywords are handled first\n",
    "            row_data['Type'] = 'keywords'\n",
    "            row_data[category] = ', '.join([f\"{kw.strip()}\" for kw in content['keywords'].split(',')])\n",
    "            negative_keywords_tan_taj_db = pd.concat([negative_keywords_tan_taj_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "            # Phrases are handled next\n",
    "            row_data['Type'] = 'phrases'\n",
    "            row_data[category] = ', '.join([f\"{ph.strip()}\" for ph in content['phrases'].split(',')])\n",
    "            negative_keywords_tan_taj_db = pd.concat([negative_keywords_tan_taj_db, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Now we will consolidate rows that have the same 'Type' into a single row for each 'Store Name' and 'Sentiment'\n",
    "negative_keywords_tan_taj_db = negative_keywords_tan_taj_db.groupby(['Store Name', 'Sentiment', 'Type']).agg(lambda x: ' '.join(x.dropna())).reset_index()\n",
    "\n",
    "negative_keywords_tan_taj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9318c-2127-413f-a067-eb541463e6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0d6fe-df8c-4f81-80f3-c8fc2cab4067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ed779cfb-b24c-4e26-9331-a5f7c2582019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword_negative_total_cost = keyword_total_cost_bhi_ak+keyword_total_cost_joy_ab+keyword_total_cost_joy_st_af+keyword_total_cost_joy_dm_ad+keyword_total_cost_joy_mz_ad+keyword_total_cost_joy_sh_ad+keyword_total_cost_mal_sc+keyword_total_cost_mal_ab+keyword_total_cost_mal_b1_af+keyword_total_cost_mal_ak+keyword_total_cost_mal_aw_ad+keyword_total_cost_mal_b1_ad+keyword_total_cost_mal_b2_ad+keyword_total_cost_mal_lu_ad+keyword_total_cost_mal_mb+keyword_total_cost_mal_sh_ad+keyword_total_cost_mna_mb+keyword_total_cost_joy_ak+keyword_total_cost_bhi_dec_ga+keyword_total_cost_jar_bol_il+keyword_total_cost_jar_ver_il+keyword_total_cost_jar_aur_il+keyword_total_cost_jar_alg_il+keyword_total_cost_jar_sch_il+keyword_total_cost_joy_suw_ga+keyword_total_cost_joy_chi_il+keyword_total_cost_joy_hou_tx+keyword_total_cost_joy_fri_tx+keyword_total_cost_mal_chi_il+keyword_total_cost_mal_nap_il+keyword_total_cost_mal_ise_nj+keyword_total_cost_mal_fri_tx+keyword_total_cost_mal_ric_tx+keyword_total_cost_son_ise_nj+keyword_total_cost_tif_chi_il+keyword_total_cost_tif_nor_il+keyword_total_cost_tif_sko_il+keyword_total_cost_tif_eas_nj+keyword_total_cost_tif_red_nj+keyword_total_cost_tif_sho_nj+keyword_total_cost_tif_par_nj+keyword_total_cost_vbj_fri_tx+keyword_total_cost_tan_chi_il+keyword_total_cost_tan_fri_tx+keyword_total_cost_tan_hou_tx+keyword_total_cost_tan_new_nj+keyword_total_cost_tan_bar_db+keyword_total_cost_tan_fah_db+keyword_total_cost_tan_kar_db+keyword_total_cost_tan_ham_ad+keyword_total_cost_tan_sil_db\n",
    "#+keyword_total_cost_eve_joh_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "bcbde9b5-65cc-4f69-af0c-e4e02625ea31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.57"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_negative_total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb7673-6edf-419c-ba3b-dc865b54a894",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Combined_df_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "e8a1123d-023e-4290-9139-f2426c6a8c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:37:11.261718Z",
     "iopub.status.busy": "2025-06-12T00:37:11.261394Z",
     "iopub.status.idle": "2025-06-12T00:37:11.290966Z",
     "shell.execute_reply": "2025-06-12T00:37:11.290491Z",
     "shell.execute_reply.started": "2025-06-12T00:37:11.261696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_negative_keywords = pd.DataFrame()\n",
    "\n",
    "negative_keyword_df_list = [\"negative_keywords_agd_mb\",\n",
    "                            \"negative_keywords_bhi_ak\",\n",
    "                            \"negative_keywords_bhi_dec_ga\",\n",
    "                            \"negative_keywords_eve_joh_ga\",\n",
    "                            \"negative_keywords_jar_alg_il\",\n",
    "                            \"negative_keywords_jar_aur_il\",\n",
    "                            \"negative_keywords_jar_bol_il\",\n",
    "                            \"negative_keywords_jar_lom_il\",\n",
    "                            \"negative_keywords_jar_orl_il\",\n",
    "                            \"negative_keywords_jar_sch_il\",\n",
    "                            \"negative_keywords_jar_ver_il\",\n",
    "                            \"negative_keywords_joy_ab\",\n",
    "                            \"negative_keywords_joy_ak\",\n",
    "                            \"negative_keywords_joy_chi_il\",\n",
    "                            \"negative_keywords_joy_dm_ad\",\n",
    "                            \"negative_keywords_joy_fri_tx\",\n",
    "                            \"negative_keywords_joy_hou_tx\",\n",
    "                            \"negative_keywords_joy_mz_ad\",\n",
    "                            \"negative_keywords_joy_sh_ad\",\n",
    "                            \"negative_keywords_joy_st_af\",\n",
    "                            \"negative_keywords_joy_suw_ga\",\n",
    "                            \"negative_keywords_kan_mb\",\n",
    "                            \"negative_keywords_mal_ab\",\n",
    "                            \"negative_keywords_mal_ak\",\n",
    "                            \"negative_keywords_mal_aw_ad\",\n",
    "                            \"negative_keywords_mal_b1_ad\",\n",
    "                            \"negative_keywords_mal_b1_af\",\n",
    "                            \"negative_keywords_mal_b2_ad\",\n",
    "                            \"negative_keywords_mal_b2_af\",\n",
    "                            \"negative_keywords_mal_chi_il\",\n",
    "                            \"negative_keywords_mal_dm_ad\",\n",
    "                            \"negative_keywords_mal_fri_tx\",\n",
    "                            \"negative_keywords_mal_ise_nj\",\n",
    "                            \"negative_keywords_mal_lu_ad\",\n",
    "                            \"negative_keywords_mal_mb\",\n",
    "                            \"negative_keywords_mal_nap_il\",\n",
    "                            \"negative_keywords_mal_ric_tx\",\n",
    "                            \"negative_keywords_mal_sc\",\n",
    "                            \"negative_keywords_mal_sh_ad\",\n",
    "                            \"negative_keywords_may_vie_va\",\n",
    "                            \"negative_keywords_mia_awm_ad\",\n",
    "                            \"negative_keywords_mia_bur_db\",\n",
    "                            \"negative_keywords_min_ak\",\n",
    "                            \"negative_keywords_mna_mb\",\n",
    "                            \"negative_keywords_son_ise_nj\",\n",
    "                            \"negative_keywords_tan_am_om\",\n",
    "                            \"negative_keywords_tan_atl_ga\",\n",
    "                            \"negative_keywords_tan_bar_db\",\n",
    "                            \"negative_keywords_tan_chi_il\",\n",
    "                            \"negative_keywords_tan_fah_db\",\n",
    "                            \"negative_keywords_tan_fc_qa\",\n",
    "                            \"negative_keywords_tan_fri_tx\",\n",
    "                            \"negative_keywords_tan_gs_db\",\n",
    "                            \"negative_keywords_tan_ham_ad\",\n",
    "                            \"negative_keywords_tan_hou_tx\",\n",
    "                            \"negative_keywords_tan_kar_db\",\n",
    "                            \"negative_keywords_tan_lul_qa\",\n",
    "                            \"negative_keywords_tan_mank_db\",\n",
    "                            \"negative_keywords_tan_mee_db\",\n",
    "                            \"negative_keywords_tan_new_nj\",\n",
    "                            \"negative_keywords_tan_rol_sh\",\n",
    "                            \"negative_keywords_tan_rse_wa\",\n",
    "                            \"negative_keywords_tan_sc_ca\",\n",
    "                            \"negative_keywords_tan_sc_sh\",\n",
    "                            \"negative_keywords_tan_sil_db\",\n",
    "                            \"negative_keywords_tan_taj_db\",\n",
    "                            \"negative_keywords_tif_chi_il\",\n",
    "                            \"negative_keywords_tif_eas_nj\",\n",
    "                            \"negative_keywords_tif_hac_nj\",\n",
    "                            \"negative_keywords_tif_nor_il\",\n",
    "                            \"negative_keywords_tif_par_nj\",\n",
    "                            \"negative_keywords_tif_red_nj\",\n",
    "                            \"negative_keywords_tif_ric_va\",\n",
    "                            \"negative_keywords_tif_sho_nj\",\n",
    "                            \"negative_keywords_tif_sko_il\",\n",
    "                            \"negative_keywords_tif_vie_va\",\n",
    "                            \"negative_keywords_vbj_fri_tx\"]\n",
    "\n",
    "\n",
    "for df_name in negative_keyword_df_list:\n",
    "    try:\n",
    "        combined_df_negative_keywords = pd.concat([combined_df_negative_keywords, eval(df_name)], ignore_index=True)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "combined_df_negative_keywords.reset_index(drop=True, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "32a895bb-23f1-4923-910c-7794f1938596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:37:19.777694Z",
     "iopub.status.busy": "2025-06-12T00:37:19.777403Z",
     "iopub.status.idle": "2025-06-12T00:37:19.831638Z",
     "shell.execute_reply": "2025-06-12T00:37:19.831153Z",
     "shell.execute_reply.started": "2025-06-12T00:37:19.777675Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_negative_keywords.to_excel(\"temp/combined_df_negative_keywords_current.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc476e52-84fc-4cd2-a417-bec28a2c265a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Combined Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628459eb-80fc-4cd8-ba2e-3f08a705a193",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Read Data\n",
    "combined_df_negative_keywords = pd.read_excel('temp/combined_df_negative_keywords_current.xlsx')\n",
    "combined_df_positive_keywords = pd.read_excel('temp/combined_df_positive_keywords_current.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "b4a6be92-2ae5-44f4-8c04-69818e639f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:38:09.484339Z",
     "iopub.status.busy": "2025-06-12T00:38:09.484036Z",
     "iopub.status.idle": "2025-06-12T00:38:09.488457Z",
     "shell.execute_reply": "2025-06-12T00:38:09.487805Z",
     "shell.execute_reply.started": "2025-06-12T00:38:09.484318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords_combined_df = pd.concat([combined_df_positive_keywords, combined_df_negative_keywords], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "b2afa18d-b495-4167-bbf7-73054c70ed03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:40:41.117134Z",
     "iopub.status.busy": "2025-06-12T00:40:41.116734Z",
     "iopub.status.idle": "2025-06-12T00:40:41.236310Z",
     "shell.execute_reply": "2025-06-12T00:40:41.235677Z",
     "shell.execute_reply.started": "2025-06-12T00:40:41.117105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords_combined_df.to_excel('recent_keywords_filtered/combined_keywords.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "4fc90fc7-0e0f-47f0-a6a7-820f1a732e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:40:53.689451Z",
     "iopub.status.busy": "2025-06-12T00:40:53.689028Z",
     "iopub.status.idle": "2025-06-12T00:40:53.738120Z",
     "shell.execute_reply": "2025-06-12T00:40:53.737484Z",
     "shell.execute_reply.started": "2025-06-12T00:40:53.689419Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_combined_df.to_parquet('recent_keywords_filtered/combined_keywords.parquet',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576236a-7ab1-4e8c-82ce-4e3b173a23a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782e43d-4c63-4bb4-828b-a369f425f5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "644bcd54-a425-4cfd-8a3f-885950e84f43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_filter = combined_keywords_working_df[\n",
    "                                            (combined_keywords_working_df['Store Name'] == 'Malabar Gold & Diamonds - Silicon Oasis Central') & \n",
    "                                            (combined_keywords_working_df['Type'] == 'keywords') & \n",
    "                                            (combined_keywords_working_df['Sentiment'] == 'negative')\n",
    "                                        ]\n",
    "\n",
    "cell_content = test_filter['Product Design']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d972d3f1-bbd5-4f9c-819b-09141c89d719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    No relevant negative keywords\n",
       "Name: Product Design, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "cell_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b319ddc3-4333-4d36-9d25-e5ca8012c597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_response, input_token, output_token = combine_keywords(cell_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "591e0fcc-ef26-4459-a7c5-4839b8858e36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"Great Experience\": 33,\\n    \"Excellent Service\": 12,\\n    \"Good Experience\": 12,\\n    \"Knowledgeable Staff\": 3,\\n    \"Welcoming Staff\": 3,\\n    \"Pleasant\": 5,\\n    \"Smooth\": 3,\\n    \"Wonderful\": 3,\\n    \"Amazing\": 3,\\n    \"Seamless\": 1\\n}\\n```'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0364c618-36dd-4b46-8961-50625e9f24d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Cleaning up the string to remove ```json and ```\n",
    "api_cleaned = api_response.replace('```json', '').replace('```', '').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1518f226-fbfb-41dc-b3c0-f414296c3381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"Great Experience\": 33,\\n    \"Excellent Service\": 12,\\n    \"Good Experience\": 12,\\n    \"Knowledgeable Staff\": 3,\\n    \"Welcoming Staff\": 3,\\n    \"Pleasant\": 5,\\n    \"Smooth\": 3,\\n    \"Wonderful\": 3,\\n    \"Amazing\": 3,\\n    \"Seamless\": 1\\n}'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2ad86577-3b7c-4683-ae4c-4038a23c1198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Great Experience': 33,\n",
       " 'Excellent Service': 12,\n",
       " 'Good Experience': 12,\n",
       " 'Knowledgeable Staff': 3,\n",
       " 'Welcoming Staff': 3,\n",
       " 'Pleasant': 5,\n",
       " 'Smooth': 3,\n",
       " 'Wonderful': 3,\n",
       " 'Amazing': 3,\n",
       " 'Seamless': 1}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dict = json.loads(api_cleaned)\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "609d32cd-c7f3-4e98-9379-4256665941fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(columns=['Store Experience'])\n",
    "# Convert the dictionary to a JSON string\n",
    "# json_string = json.dumps(response_dict)\n",
    "# Convert the dictionary to a string without curly braces\n",
    "formatted_string = ', '.join([f\"{key}: {value}\" for key, value in response_dict.items()])\n",
    "\n",
    "# Storing the formatted string in the 'Store Experience' column\n",
    "temp_df.at[0, 'Store Experience'] = formatted_string\n",
    "\n",
    "#Storing the dictionary in a specific cell (for example, first row, 'Store Experience' column)\n",
    "#temp_df.at[0, 'Store Experience'] = json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5a0f8c27-ceda-4415-9e71-0343d7ef69ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great Experience: 33, Excellent Service: 12, Good Experience: 12, Knowledgeable Staff: 3, Welcoming Staff: 3, Pleasant: 5, Smooth: 3, Wonderful: 3, Amazing: 3, Seamless: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                              Store Experience\n",
       "0  Great Experience: 33, Excellent Service: 12, Good Experience: 12, Knowledgeable Staff: 3, Welcoming Staff: 3, Pleasant: 5, Smooth: 3, Wonderful: 3, Amazing: 3, Seamless: 1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd2def-5140-4a14-9954-2bb0d2e1fa9c",
   "metadata": {},
   "source": [
    "## Approved for Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e41c4ff5-f400-48ee-b895-a656c9b02d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store_names = ['Malabar Gold & Diamonds - Silicon Oasis Central', 'Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)']\n",
    "type_list = combined_keywords_working_df['Type'].unique().tolist()\n",
    "sentiment_list = combined_keywords_working_df['Sentiment'].unique().tolist()\n",
    "columns_poc = keywords_combined_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6e0b023a-d074-40f5-8fe5-d786c24fe6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(columns=columns_poc)\n",
    "temp_df\n",
    "row_index = 0\n",
    "\n",
    "for store in store_names:\n",
    "    for type_n in type_list:\n",
    "        for sentiment in sentiment_list:\n",
    "            if type_n == 'phrases':\n",
    "                filter_df_poc = combined_keywords_working_df[\n",
    "                                                                (combined_keywords_working_df['Store Name'] == store) & \n",
    "                                                                (combined_keywords_working_df['Type'] == type_n) & \n",
    "                                                                (combined_keywords_working_df['Sentiment'] == sentiment)\n",
    "                                                            ]\n",
    "\n",
    "                for topic in columns_to_concatenate:\n",
    "                    cell_content_poc = filter_df_poc[topic]\n",
    "                    api_response, input_token, output_token = combine_phrases(cell_content_poc)\n",
    "                    \n",
    "                    #Cleaning up the string to remove ```json and ```\n",
    "                    api_cleaned = api_response.replace('```json', '').replace('```', '').strip()\n",
    "                    response_dict = json.loads(api_cleaned)\n",
    "                    formatted_string = ', '.join([f\"{key}: {value}\" for key, value in response_dict.items()])\n",
    "                    #Storing the formatted string in the 'Store Experience' column\n",
    "                    temp_df.at[row_index, 'Store Name'] = store\n",
    "                    temp_df.at[row_index, 'Sentiment'] = sentiment\n",
    "                    temp_df.at[row_index, 'Type'] = type_n\n",
    "                    temp_df.at[row_index, topic] = formatted_string\n",
    "                    \n",
    "                row_index+=1\n",
    "            \n",
    "\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf4777-017e-417f-9098-f954b5f26a1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Approved for Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460659b-bd2c-4aaa-910c-085b5419e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store_names = ['Malabar Gold & Diamonds - Silicon Oasis Central', 'Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)']\n",
    "type_list = combined_keywords_working_df['Type'].unique().tolist()\n",
    "sentiment_list = combined_keywords_working_df['Sentiment'].unique().tolist()\n",
    "columns_poc = keywords_combined_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "84b2ae2d-aec6-40d7-b15a-03342fb13ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(columns=columns_poc)\n",
    "temp_df\n",
    "row_index = 0\n",
    "\n",
    "for store in store_names:\n",
    "    for type_n in type_list:\n",
    "        for sentiment in sentiment_list:\n",
    "            if type_n == 'phrases':\n",
    "                filter_df_poc = combined_keywords_working_df[\n",
    "                                                                (combined_keywords_working_df['Store Name'] == store) & \n",
    "                                                                (combined_keywords_working_df['Type'] == type_n) & \n",
    "                                                                (combined_keywords_working_df['Sentiment'] == sentiment)\n",
    "                                                            ]\n",
    "\n",
    "                for topic in columns_to_concatenate:\n",
    "                    cell_content_poc = filter_df_poc[topic]\n",
    "                    api_response, input_token, output_token = combine_phrases(cell_content_poc)\n",
    "                    \n",
    "                    #Cleaning up the string to remove ```json and ```\n",
    "                    api_cleaned = api_response.replace('```json', '').replace('```', '').strip()\n",
    "                    try:\n",
    "                        response_dict = json.loads(api_cleaned)\n",
    "                        formatted_string = ', '.join([f\"{key}: {value}\" for key, value in response_dict.items()])\n",
    "                        #Storing the formatted string in the 'Store Experience' column\n",
    "                        temp_df.at[row_index, 'Store Name'] = store\n",
    "                        temp_df.at[row_index, 'Sentiment'] = sentiment\n",
    "                        temp_df.at[row_index, 'Type'] = type_n\n",
    "                        temp_df.at[row_index, topic] = formatted_string\n",
    "                    except Exception as e:\n",
    "                        print(f\"{e} in {store}, {sentiment},{type_n},{formatted_string}\")\n",
    "                    \n",
    "                row_index+=1\n",
    "            \n",
    "            else:\n",
    "                filter_df_poc = combined_keywords_working_df[\n",
    "                                                                (combined_keywords_working_df['Store Name'] == store) & \n",
    "                                                                (combined_keywords_working_df['Type'] == type_n) & \n",
    "                                                                (combined_keywords_working_df['Sentiment'] == sentiment)\n",
    "                                                            ]\n",
    "\n",
    "                for topic in columns_to_concatenate:\n",
    "                    cell_content_poc = filter_df_poc[topic]\n",
    "                    api_response, input_token, output_token = combine_keywords(cell_content_poc)\n",
    "                    \n",
    "                    #Cleaning up the string to remove ```json and ```\n",
    "                    api_cleaned = api_response.replace('```json', '').replace('```', '').strip()\n",
    "                    try:\n",
    "                        response_dict = json.loads(api_cleaned)\n",
    "                        formatted_string = ', '.join([f\"{key}: {value}\" for key, value in response_dict.items()])\n",
    "                        #Storing the formatted string in the 'Store Experience' column\n",
    "                        temp_df.at[row_index, 'Store Name'] = store\n",
    "                        temp_df.at[row_index, 'Sentiment'] = sentiment\n",
    "                        temp_df.at[row_index, 'Type'] = type_n\n",
    "                        temp_df.at[row_index, topic] = formatted_string\n",
    "                    except Exception as e:\n",
    "                        print(f\"{e} in {store}, {sentiment},{type_n},{topic},{api_cleaned}\")\n",
    "                row_index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "90356852-52e3-40a8-ac56-decb954726e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Customer Confidence</th>\n",
       "      <th>Store Experience</th>\n",
       "      <th>Store Staff</th>\n",
       "      <th>Product Design</th>\n",
       "      <th>Product Variety</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Making Charge</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Quality</th>\n",
       "      <th>Jewellery Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Trust: 12, Knowledgeable: 3, Professional: 2, Transparent: 2, Understanding: 1, Supportive: 1</td>\n",
       "      <td>Great Experience: 33, Excellent Service: 12, Good Experience: 12, Knowledgeable Staff: 3, Welcoming Staff: 3, Pleasant: 5, Smooth: 3, Wonderful: 3, Amazing: 3, Seamless: 1</td>\n",
       "      <td>helpful: 105, friendly: 24, knowledgeable: 15, polite: 20, professional: 18, patient: 10, great service: 3, attentive: 2</td>\n",
       "      <td>unique designs: 5, good design: 8, beautiful collections: 3, exquisite collection: 2, wonderful collection: 2, great designs: 3, best designs: 2, amazing designs: 2, elegant designs: 1, new designs: 1</td>\n",
       "      <td>collection: 87, variety: 4, selection: 3, range: 3, designs: 1, options: 2</td>\n",
       "      <td>discount: 16, deal: 2, rate: 2, offer: 1, price: 1</td>\n",
       "      <td>reduced: 3, discounted: 2, making charges: 2, negotiate: 1, maximum reduction: 1</td>\n",
       "      <td>good price: 11, best price: 7, reasonable price: 3, great prices: 2, affordable: 1, cost effective: 1, attractive price: 1</td>\n",
       "      <td>good quality: 5, quality: 4, quality service and product: 1, top notch: 1, super quality: 1, quality gold: 1, quality is fantabulous: 1</td>\n",
       "      <td>Exchange: 4, Best Price: 2, Favorable Rates: 2, Transparent: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>Unprofessional: 1, Cut Off: 1, Not to Visit: 1, Never Trusted: 1, Least Interest: 1, Not Bothered: 1, I Don't Care: 1</td>\n",
       "      <td>unhelpful: 3, wait: 2, rude: 1, dissatisfied: 1, nonsense: 1, irritating: 1, disappointing: 1, wasted: 1</td>\n",
       "      <td>rude: 3, unhelpful: 2, ignored: 2, dissatisfied: 1, hard time: 1, wait: 1, smirk: 1, unbothered: 1, leisurely: 1</td>\n",
       "      <td>No relevant negative keywords: 94</td>\n",
       "      <td>Product Variety: 94</td>\n",
       "      <td>no-discount: 1, refused: 1, mercy: 1</td>\n",
       "      <td>high making charges: 1, overpay: 1, paying double: 1, charged 15%: 1, embarrassing: 1</td>\n",
       "      <td>Price Review: 1, Discount: 1, Higher Priced: 2, Budget: 1, Pocket Size: 1, Unnecessary Add: 1</td>\n",
       "      <td>Product Quality: 94</td>\n",
       "      <td>unprofessional: 1, cut off: 1, profit: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Trusted place to buy: 2, Completely transparent: 2, Trustworthy shopping experience: 1, Well trusted: 1, True blessing: 1, My first go-to choice: 1, Knowledgeable and well-behaved: 1, Knowledgeable and helpful: 1, Professional and always have good styles: 1, Guided the entire process: 1, Trustworthy brand: 1, Always trust &amp; buy: 1</td>\n",
       "      <td>great experience: 30, very good customer service: 13, helpful and attentive: 8, friendly and helpful staff: 3, best experience: 3, good store to visit: 1, amazing place for purchasing jewelry: 1</td>\n",
       "      <td>very helpful: 29, excellent service: 13, great service: 10, very professional: 7, very patient: 4, very friendly: 2, very attentive: 1</td>\n",
       "      <td>excellent choice of designs: 2, lovely designs: 1, simple yet elegant bracelet: 1, best and unique designs: 2, ideal design: 1, helpful for showing designs: 1, good brief on the designs: 1, great eye for design: 1, perfect designs: 1, stunning collection: 1</td>\n",
       "      <td>lots of collections: 2, best options: 2, superb collections in diamonds: 1, good bangle collection and earrings also nice collection: 1, live at the collections shown: 1, beautiful collections: 1, great selection: 1, various product range: 1, huge selection: 1, variety of selections: 1</td>\n",
       "      <td>discount on making charges: 3, good discount: 3, discount on purchased item: 1, small discount at the end: 1, best deal: 1, good rate: 1</td>\n",
       "      <td>reduce making charge as much as possible: 1, reduction in making charges: 1, explaining the making charges: 1, less making cost: 1, opportunity to negotiate the making charges: 1, proper making charges: 1</td>\n",
       "      <td>Value for money: 1, Best rates: 2, Good rate: 1, Fair prices: 1, Different price ranges: 1, Great price: 1, Good price: 1, Better prices: 1, Within our budget: 1</td>\n",
       "      <td>quality of their gold was impressive: 1, good quality items: 1, quality service and quality product: 1, quality is fantabulous: 1, quality of their jewelry: 1, quality products: 1, quality of their pieces: 1, quality and style: 1, quality and nice pricing: 1, quality ended up: 1</td>\n",
       "      <td>Helped us with the exchange: 1, Whole process smooth and transparent: 1, Good rate for exchange: 1, Most favorable exchange rates: 2, Took my old jewellery for exchange: 1, Shafeeq was super helpful in getting us the best deal: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malabar Gold &amp; Diamonds - Silicon Oasis Central</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>not paying back the certificate amount: 2, making a profit from the 4% cut-off: 1, used to buy gold bars from Malabar as a trusted source but that's the end of it: 1, given me the reason not to visit any of their stores in future: 1, never trusted it until I faced the same: 1, he doesn't know how to deal with customers: 1, he doesn't know how to respect someone's requirements and budget: 1, purposefully, he quoted higher priced products despite having products in my budget: 1</td>\n",
       "      <td>gave me such a hard time: 1, will not buy anything from here again: 1, could not speak with any manager: 1, had to wait for 40 minutes to have a salesman service: 1, not comfortable shopping at an outlet: 1, resizing time period: 1, waited and wasted: 1, none turned out: 1</td>\n",
       "      <td>gave me such a hard time: 1, extremely dissatisfied with the service provided: 1, did not want to help me at all: 1, were so rude and unhelpful: 1, had to wait for 40 minutes to have a salesman service: 1, couldn't see us: 1, wasting our time: 1, not bothered about customers: 1, I don't care attitude: 1, refused to call the manager: 1</td>\n",
       "      <td>No relevant negative phrases: 95</td>\n",
       "      <td>Try to add more collection in bangles and chains: 1</td>\n",
       "      <td>didn't want to review the price: 1, to give any kind of discount: 1, offered me 50 AED discount on making charge: 1, had to refuse and leave: 1</td>\n",
       "      <td>making charges are high: 1, being charged 15% of making charge was quite embarrassing: 1, had to pay only 3% in another well-known jewellery: 1, don't really understand the complicated design which he meant: 1, really cheating the customers: 1</td>\n",
       "      <td>didn't want to review the price at all: 1, to give any kind of discount on the new item: 1, quoted higher priced products: 1, in spite of having product in my budget: 1, judged based on your pocket size: 1, unnecessarily add charges for card payments: 1, certification charges on Swiss coins are also up to 25% higher than competitors: 1</td>\n",
       "      <td>No relevant negative phrases: 95</td>\n",
       "      <td>don't pay you the certificate amount back: 1, took me a week to change a necklace: 1, manager was not helping: 1, didn't want to review the price: 1, exchange was not going to happen: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)</td>\n",
       "      <td>Positive</td>\n",
       "      <td>keywords</td>\n",
       "      <td>trust: 30, reliable: 5, genuine: 4, confidence: 2, transparency: 1</td>\n",
       "      <td>great experience: 52, good experience: 44, wonderful experience: 15, best experience: 18, excellent service: 23, helpful staff: 23, friendly staff: 9, amazing experience: 9, nice experience: 8</td>\n",
       "      <td>good service: 394, helpful: 68, excellent service: 120, best service: 80, friendly: 15, patient: 9, communicative: 3</td>\n",
       "      <td>design: 20, beautiful designs: 14, unique designs: 6, latest designs: 6, good design: 8, amazing designs: 4, designs: 14, nice design: 2, best design: 2, chain design: 1</td>\n",
       "      <td>variety: 20, range: 10, collection: 19, designs: 4, options: 3</td>\n",
       "      <td>best discount: 42, great deal: 33, good discount: 26, best deal: 13, good deal: 5, special discount: 9, nice discount: 3, maximum discount: 1</td>\n",
       "      <td>reasonable: 14, less: 6, low: 2, nominal: 1, discount: 1</td>\n",
       "      <td>best price: 37, reasonable price: 10, value for money: 5, good price: 13, competitive rate: 3, affordable price: 4, fair price: 2, best rate: 2</td>\n",
       "      <td>quality: 6, good quality: 10, excellent quality: 3, high quality: 2, best quality: 1, top-notch: 1</td>\n",
       "      <td>Exchange: 18, Good: 2, Service: 2, Comfortable: 1, Price: 1, Policy: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)</td>\n",
       "      <td>negative</td>\n",
       "      <td>keywords</td>\n",
       "      <td>disappointed: 3, lied: 1, no trust: 1, denied: 1, insulted: 1, pathetic: 1, delayed: 1, deceitful: 1, shattered: 1, cheated: 1, never recommending: 1</td>\n",
       "      <td>unfriendly: 4, poor service: 3, rude: 2, unprofessional: 1, understaffed: 1, aggressive: 1, lazy: 1, long queue: 1, worst experience: 1, disappointed: 1</td>\n",
       "      <td>unfriendly: 4, rude: 3, unprofessional: 1, aggressive: 1, understaffed: 1, lazy: 1, hesitant: 1, gossiping: 1, arrogant: 1, disappointed: 1</td>\n",
       "      <td>No relevant negative keywords: 118</td>\n",
       "      <td>Limited Options: 2, Slight Improvement: 1, Not Bad: 1</td>\n",
       "      <td>no discount: 2, expected discounts: 1, more discount/offer: 1, reasonable making charges: 1, denied: 1</td>\n",
       "      <td>Profit: 3</td>\n",
       "      <td>expensive: 3, high: 2, additional cost: 1, financial loss: 2, betrayed: 1, cheated: 1</td>\n",
       "      <td>lost: 1, fall off: 1</td>\n",
       "      <td>denied coupon: 1, poor quality: 1, additional cost: 1, rejected full refund: 1, broke easily: 1, can't exchange: 1, not recommend: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)</td>\n",
       "      <td>Positive</td>\n",
       "      <td>phrases</td>\n",
       "      <td>trusted purchase: 3, highly recommended: 3, truly trustworthy: 3, trust in the brand: 2, trusted outlet: 1, trust of Malbar: 1, confidence in purchase: 2, most trusted and valuable brand: 1, trusted brand for a long time: 1</td>\n",
       "      <td>excellent customer service: 9, very good experience: 6, great shopping experience: 5, wonderful experience: 5, pleasant experience: 7, best service: 4, very helpful: 4, very patient: 4, amazing experience: 4, highly recommend: 3</td>\n",
       "      <td>thank you for your service: 10, great customer service: 12, wonderful service: 7, very helpful: 10, good customer service: 9, excellent service: 4, best service: 3</td>\n",
       "      <td>Excellent design: 9, Variety of designs: 4, Great designs: 4, Amazing designs: 2, Beautiful designs: 2, Best design: 5, Very good designs: 2, Wonderful designs: 2, Wide range of collection: 2, Good pattern gold: 1</td>\n",
       "      <td>variety of collections: 7, wide range of collection: 5, great variety of designs: 3, variety of options: 3, wide variety: 3, lots of varieties: 3, lot of collections: 2, various collections: 2, plethora of variety: 1, different varieties of gold: 1</td>\n",
       "      <td>gave us the best deal: 5, gave best discount: 5, discount on making: 8, best discounts: 5, gave us a good discount: 4, reasonable discount on making: 2, offered good discounts: 2, helped a lot with the discounts and pricing: 1, maximum discount: 1, good variety and discount on making: 1</td>\n",
       "      <td>reasonable making charges: 10, less making charges: 3, low charges: 1, nominal making charges: 1, special making charges and discount: 1, making charges are very very reasonable: 1, making charges also very less: 1, less mc 2.99%: 1, reducing the making charges: 1, negotiate on making charges: 1</td>\n",
       "      <td>best rates: 5, best price and service: 2, within our budget: 2, very good rate: 2, competitive rates: 1, excellent pricing: 1, favorable charges: 1, value for money: 1, helped with pricing: 1, great jewelry with best rate: 1</td>\n",
       "      <td>highly recommended jewelry destination for quality and service: 6, quality of the product: 3, good quality gold: 3, quality product: 2, quality and purity gold: 1, excellent quality of pure gold: 1, quality of jewelry at Malabar Gold Shop is top-notch: 1, best place to buy gold jewellery for quality and design: 1, quality of the gold is top-notch: 1, high-quality jewelry: 1</td>\n",
       "      <td>assisted us so well: 1, provided us with the right price: 1, gave the best exchange rate: 1, helped us a lot during the exchange: 1, clear about the estimate and exchange offer: 1, very good experience while exchanging: 1, patiently assisted us with a good price: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)</td>\n",
       "      <td>negative</td>\n",
       "      <td>phrases</td>\n",
       "      <td>Lied to us and shattered trust: 2, No trust in this brand: 1, Denied the use of the coupon: 1, Customers will be insulted: 1, Very disappointed: 1, Payment was delayed: 1, System fault: 1, Feel betrayed: 1, Huge loss: 1, Not providing promised bonus money: 1</td>\n",
       "      <td>poor customer service: 5, long wait times: 3, unhelpful staff: 3, rude store manager: 1, disappointed with brand: 1, not recommending brand: 1</td>\n",
       "      <td>constantly asking them to attend us: 2, service is worst: 1, made us run from one person to another: 1, no more response: 1, wait wait in aggressive way: 1, manager did not care to listen: 1, passing customer to each other: 1, not caring for the customers: 1, didn't explain and show the product properly: 1, talking in their own language: 1, worst experience with Sanjesh: 1, very arrogant and rude: 1, doesn't have basic manners: 1, let their name down by having such people: 1, never recommending this brand anymore: 1</td>\n",
       "      <td>stones won't fall off easily: 1, ruby from the ring is lost: 1, fixing free of cost: 1</td>\n",
       "      <td>Find very few options in ear tops and earrings: 1, Choices of your products need slight improvement: 1, Need more varieties as before: 1</td>\n",
       "      <td>expected discounts more: 1, could provide more discount/offer to the customers: 1, couldn't get the discount as expected: 1, blatantly denied the use of the coupon: 1, what is the use of the gift voucher if customers will be insulted like that: 1</td>\n",
       "      <td>demanded extra money which he never informed us before: 1, putting big margin in making charges: 1, making charges were a bit higher: 1</td>\n",
       "      <td>Price is very high: 1, Very expensive shop: 1, Bharath was genuine but expensive: 1, Selling the item on high margin: 1, Have to bear 71 DHS additional cost: 1, Deceitful scheme: 1</td>\n",
       "      <td>stones won't fall off easily: 1, ruby from the ring is lost: 1</td>\n",
       "      <td>manager blatantly denied the use of the coupon: 1, item is not strong enough: 1, rejected full refund and replacement: 1, have to bear 71 DHS additional cost: 1, fighting with customer for 71 DHS: 1, exchange only in Dubai: 1, can't exchange in India: 1, clearly asked her before I buy: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Store Name  \\\n",
       "0                      Malabar Gold & Diamonds - Silicon Oasis Central   \n",
       "1                      Malabar Gold & Diamonds - Silicon Oasis Central   \n",
       "2                      Malabar Gold & Diamonds - Silicon Oasis Central   \n",
       "3                      Malabar Gold & Diamonds - Silicon Oasis Central   \n",
       "4  Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)   \n",
       "5  Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)   \n",
       "6  Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)   \n",
       "7  Malabar Gold and Diamonds - Al Fahidi Street - Bur Dubai (Branch 1)   \n",
       "\n",
       "  Sentiment      Type  \\\n",
       "0  Positive  keywords   \n",
       "1  negative  keywords   \n",
       "2  Positive   phrases   \n",
       "3  negative   phrases   \n",
       "4  Positive  keywords   \n",
       "5  negative  keywords   \n",
       "6  Positive   phrases   \n",
       "7  negative   phrases   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Customer Confidence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                     Trust: 12, Knowledgeable: 3, Professional: 2, Transparent: 2, Understanding: 1, Supportive: 1   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                             Unprofessional: 1, Cut Off: 1, Not to Visit: 1, Never Trusted: 1, Least Interest: 1, Not Bothered: 1, I Don't Care: 1   \n",
       "2                                                                                                                                                      Trusted place to buy: 2, Completely transparent: 2, Trustworthy shopping experience: 1, Well trusted: 1, True blessing: 1, My first go-to choice: 1, Knowledgeable and well-behaved: 1, Knowledgeable and helpful: 1, Professional and always have good styles: 1, Guided the entire process: 1, Trustworthy brand: 1, Always trust & buy: 1   \n",
       "3  not paying back the certificate amount: 2, making a profit from the 4% cut-off: 1, used to buy gold bars from Malabar as a trusted source but that's the end of it: 1, given me the reason not to visit any of their stores in future: 1, never trusted it until I faced the same: 1, he doesn't know how to deal with customers: 1, he doesn't know how to respect someone's requirements and budget: 1, purposefully, he quoted higher priced products despite having products in my budget: 1   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                trust: 30, reliable: 5, genuine: 4, confidence: 2, transparency: 1   \n",
       "5                                                                                                                                                                                                                                                                                                                                             disappointed: 3, lied: 1, no trust: 1, denied: 1, insulted: 1, pathetic: 1, delayed: 1, deceitful: 1, shattered: 1, cheated: 1, never recommending: 1   \n",
       "6                                                                                                                                                                                                                                                                   trusted purchase: 3, highly recommended: 3, truly trustworthy: 3, trust in the brand: 2, trusted outlet: 1, trust of Malbar: 1, confidence in purchase: 2, most trusted and valuable brand: 1, trusted brand for a long time: 1   \n",
       "7                                                                                                                                                                                                                                Lied to us and shattered trust: 2, No trust in this brand: 1, Denied the use of the coupon: 1, Customers will be insulted: 1, Very disappointed: 1, Payment was delayed: 1, System fault: 1, Feel betrayed: 1, Huge loss: 1, Not providing promised bonus money: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                    Store Experience  \\\n",
       "0                                                                                                        Great Experience: 33, Excellent Service: 12, Good Experience: 12, Knowledgeable Staff: 3, Welcoming Staff: 3, Pleasant: 5, Smooth: 3, Wonderful: 3, Amazing: 3, Seamless: 1   \n",
       "1                                                                                                                                                                           unhelpful: 3, wait: 2, rude: 1, dissatisfied: 1, nonsense: 1, irritating: 1, disappointing: 1, wasted: 1   \n",
       "2                                                                                 great experience: 30, very good customer service: 13, helpful and attentive: 8, friendly and helpful staff: 3, best experience: 3, good store to visit: 1, amazing place for purchasing jewelry: 1   \n",
       "3  gave me such a hard time: 1, will not buy anything from here again: 1, could not speak with any manager: 1, had to wait for 40 minutes to have a salesman service: 1, not comfortable shopping at an outlet: 1, resizing time period: 1, waited and wasted: 1, none turned out: 1   \n",
       "4                                                                                   great experience: 52, good experience: 44, wonderful experience: 15, best experience: 18, excellent service: 23, helpful staff: 23, friendly staff: 9, amazing experience: 9, nice experience: 8   \n",
       "5                                                                                                                           unfriendly: 4, poor service: 3, rude: 2, unprofessional: 1, understaffed: 1, aggressive: 1, lazy: 1, long queue: 1, worst experience: 1, disappointed: 1   \n",
       "6                                               excellent customer service: 9, very good experience: 6, great shopping experience: 5, wonderful experience: 5, pleasant experience: 7, best service: 4, very helpful: 4, very patient: 4, amazing experience: 4, highly recommend: 3   \n",
       "7                                                                                                                                     poor customer service: 5, long wait times: 3, unhelpful staff: 3, rude store manager: 1, disappointed with brand: 1, not recommending brand: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Store Staff  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                   helpful: 105, friendly: 24, knowledgeable: 15, polite: 20, professional: 18, patient: 10, great service: 3, attentive: 2   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                           rude: 3, unhelpful: 2, ignored: 2, dissatisfied: 1, hard time: 1, wait: 1, smirk: 1, unbothered: 1, leisurely: 1   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                     very helpful: 29, excellent service: 13, great service: 10, very professional: 7, very patient: 4, very friendly: 2, very attentive: 1   \n",
       "3                                                                                                                                                                                           gave me such a hard time: 1, extremely dissatisfied with the service provided: 1, did not want to help me at all: 1, were so rude and unhelpful: 1, had to wait for 40 minutes to have a salesman service: 1, couldn't see us: 1, wasting our time: 1, not bothered about customers: 1, I don't care attitude: 1, refused to call the manager: 1   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                       good service: 394, helpful: 68, excellent service: 120, best service: 80, friendly: 15, patient: 9, communicative: 3   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                unfriendly: 4, rude: 3, unprofessional: 1, aggressive: 1, understaffed: 1, lazy: 1, hesitant: 1, gossiping: 1, arrogant: 1, disappointed: 1   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                        thank you for your service: 10, great customer service: 12, wonderful service: 7, very helpful: 10, good customer service: 9, excellent service: 4, best service: 3   \n",
       "7  constantly asking them to attend us: 2, service is worst: 1, made us run from one person to another: 1, no more response: 1, wait wait in aggressive way: 1, manager did not care to listen: 1, passing customer to each other: 1, not caring for the customers: 1, didn't explain and show the product properly: 1, talking in their own language: 1, worst experience with Sanjesh: 1, very arrogant and rude: 1, doesn't have basic manners: 1, let their name down by having such people: 1, never recommending this brand anymore: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                      Product Design  \\\n",
       "0                                                           unique designs: 5, good design: 8, beautiful collections: 3, exquisite collection: 2, wonderful collection: 2, great designs: 3, best designs: 2, amazing designs: 2, elegant designs: 1, new designs: 1   \n",
       "1                                                                                                                                                                                                                                  No relevant negative keywords: 94   \n",
       "2  excellent choice of designs: 2, lovely designs: 1, simple yet elegant bracelet: 1, best and unique designs: 2, ideal design: 1, helpful for showing designs: 1, good brief on the designs: 1, great eye for design: 1, perfect designs: 1, stunning collection: 1   \n",
       "3                                                                                                                                                                                                                                   No relevant negative phrases: 95   \n",
       "4                                                                                          design: 20, beautiful designs: 14, unique designs: 6, latest designs: 6, good design: 8, amazing designs: 4, designs: 14, nice design: 2, best design: 2, chain design: 1   \n",
       "5                                                                                                                                                                                                                                 No relevant negative keywords: 118   \n",
       "6                                              Excellent design: 9, Variety of designs: 4, Great designs: 4, Amazing designs: 2, Beautiful designs: 2, Best design: 5, Very good designs: 2, Wonderful designs: 2, Wide range of collection: 2, Good pattern gold: 1   \n",
       "7                                                                                                                                                                             stones won't fall off easily: 1, ruby from the ring is lost: 1, fixing free of cost: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                  Product Variety  \\\n",
       "0                                                                                                                                                                                                                      collection: 87, variety: 4, selection: 3, range: 3, designs: 1, options: 2   \n",
       "1                                                                                                                                                                                                                                                                             Product Variety: 94   \n",
       "2  lots of collections: 2, best options: 2, superb collections in diamonds: 1, good bangle collection and earrings also nice collection: 1, live at the collections shown: 1, beautiful collections: 1, great selection: 1, various product range: 1, huge selection: 1, variety of selections: 1   \n",
       "3                                                                                                                                                                                                                                             Try to add more collection in bangles and chains: 1   \n",
       "4                                                                                                                                                                                                                                  variety: 20, range: 10, collection: 19, designs: 4, options: 3   \n",
       "5                                                                                                                                                                                                                                           Limited Options: 2, Slight Improvement: 1, Not Bad: 1   \n",
       "6                                        variety of collections: 7, wide range of collection: 5, great variety of designs: 3, variety of options: 3, wide variety: 3, lots of varieties: 3, lot of collections: 2, various collections: 2, plethora of variety: 1, different varieties of gold: 1   \n",
       "7                                                                                                                                                        Find very few options in ear tops and earrings: 1, Choices of your products need slight improvement: 1, Need more varieties as before: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                          Discount  \\\n",
       "0                                                                                                                                                                                                                                               discount: 16, deal: 2, rate: 2, offer: 1, price: 1   \n",
       "1                                                                                                                                                                                                                                                             no-discount: 1, refused: 1, mercy: 1   \n",
       "2                                                                                                                                                         discount on making charges: 3, good discount: 3, discount on purchased item: 1, small discount at the end: 1, best deal: 1, good rate: 1   \n",
       "3                                                                                                                                                  didn't want to review the price: 1, to give any kind of discount: 1, offered me 50 AED discount on making charge: 1, had to refuse and leave: 1   \n",
       "4                                                                                                                                                    best discount: 42, great deal: 33, good discount: 26, best deal: 13, good deal: 5, special discount: 9, nice discount: 3, maximum discount: 1   \n",
       "5                                                                                                                                                                                           no discount: 2, expected discounts: 1, more discount/offer: 1, reasonable making charges: 1, denied: 1   \n",
       "6  gave us the best deal: 5, gave best discount: 5, discount on making: 8, best discounts: 5, gave us a good discount: 4, reasonable discount on making: 2, offered good discounts: 2, helped a lot with the discounts and pricing: 1, maximum discount: 1, good variety and discount on making: 1   \n",
       "7                                           expected discounts more: 1, could provide more discount/offer to the customers: 1, couldn't get the discount as expected: 1, blatantly denied the use of the coupon: 1, what is the use of the gift voucher if customers will be insulted like that: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                              Making Charge  \\\n",
       "0                                                                                                                                                                                                                          reduced: 3, discounted: 2, making charges: 2, negotiate: 1, maximum reduction: 1   \n",
       "1                                                                                                                                                                                                                     high making charges: 1, overpay: 1, paying double: 1, charged 15%: 1, embarrassing: 1   \n",
       "2                                                                                              reduce making charge as much as possible: 1, reduction in making charges: 1, explaining the making charges: 1, less making cost: 1, opportunity to negotiate the making charges: 1, proper making charges: 1   \n",
       "3                                                       making charges are high: 1, being charged 15% of making charge was quite embarrassing: 1, had to pay only 3% in another well-known jewellery: 1, don't really understand the complicated design which he meant: 1, really cheating the customers: 1   \n",
       "4                                                                                                                                                                                                                                                  reasonable: 14, less: 6, low: 2, nominal: 1, discount: 1   \n",
       "5                                                                                                                                                                                                                                                                                                 Profit: 3   \n",
       "6  reasonable making charges: 10, less making charges: 3, low charges: 1, nominal making charges: 1, special making charges and discount: 1, making charges are very very reasonable: 1, making charges also very less: 1, less mc 2.99%: 1, reducing the making charges: 1, negotiate on making charges: 1   \n",
       "7                                                                                                                                                                   demanded extra money which he never informed us before: 1, putting big margin in making charges: 1, making charges were a bit higher: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                               Price  \\\n",
       "0                                                                                                                                                                                                                         good price: 11, best price: 7, reasonable price: 3, great prices: 2, affordable: 1, cost effective: 1, attractive price: 1   \n",
       "1                                                                                                                                                                                                                                                      Price Review: 1, Discount: 1, Higher Priced: 2, Budget: 1, Pocket Size: 1, Unnecessary Add: 1   \n",
       "2                                                                                                                                                                                  Value for money: 1, Best rates: 2, Good rate: 1, Fair prices: 1, Different price ranges: 1, Great price: 1, Good price: 1, Better prices: 1, Within our budget: 1   \n",
       "3  didn't want to review the price at all: 1, to give any kind of discount on the new item: 1, quoted higher priced products: 1, in spite of having product in my budget: 1, judged based on your pocket size: 1, unnecessarily add charges for card payments: 1, certification charges on Swiss coins are also up to 25% higher than competitors: 1   \n",
       "4                                                                                                                                                                                                    best price: 37, reasonable price: 10, value for money: 5, good price: 13, competitive rate: 3, affordable price: 4, fair price: 2, best rate: 2   \n",
       "5                                                                                                                                                                                                                                                              expensive: 3, high: 2, additional cost: 1, financial loss: 2, betrayed: 1, cheated: 1   \n",
       "6                                                                                                                   best rates: 5, best price and service: 2, within our budget: 2, very good rate: 2, competitive rates: 1, excellent pricing: 1, favorable charges: 1, value for money: 1, helped with pricing: 1, great jewelry with best rate: 1   \n",
       "7                                                                                                                                                               Price is very high: 1, Very expensive shop: 1, Bharath was genuine but expensive: 1, Selling the item on high margin: 1, Have to bear 71 DHS additional cost: 1, Deceitful scheme: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                            Product Quality  \\\n",
       "0                                                                                                                                                                                                                                                   good quality: 5, quality: 4, quality service and product: 1, top notch: 1, super quality: 1, quality gold: 1, quality is fantabulous: 1   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                       Product Quality: 94   \n",
       "2                                                                                                   quality of their gold was impressive: 1, good quality items: 1, quality service and quality product: 1, quality is fantabulous: 1, quality of their jewelry: 1, quality products: 1, quality of their pieces: 1, quality and style: 1, quality and nice pricing: 1, quality ended up: 1   \n",
       "3                                                                                                                                                                                                                                                                                                                                                          No relevant negative phrases: 95   \n",
       "4                                                                                                                                                                                                                                                                                        quality: 6, good quality: 10, excellent quality: 3, high quality: 2, best quality: 1, top-notch: 1   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                      lost: 1, fall off: 1   \n",
       "6  highly recommended jewelry destination for quality and service: 6, quality of the product: 3, good quality gold: 3, quality product: 2, quality and purity gold: 1, excellent quality of pure gold: 1, quality of jewelry at Malabar Gold Shop is top-notch: 1, best place to buy gold jewellery for quality and design: 1, quality of the gold is top-notch: 1, high-quality jewelry: 1   \n",
       "7                                                                                                                                                                                                                                                                                                                            stones won't fall off easily: 1, ruby from the ring is lost: 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                 Jewellery Exchange  \n",
       "0                                                                                                                                                                                                                                    Exchange: 4, Best Price: 2, Favorable Rates: 2, Transparent: 1  \n",
       "1                                                                                                                                                                                                                                                          unprofessional: 1, cut off: 1, profit: 1  \n",
       "2                                                             Helped us with the exchange: 1, Whole process smooth and transparent: 1, Good rate for exchange: 1, Most favorable exchange rates: 2, Took my old jewellery for exchange: 1, Shafeeq was super helpful in getting us the best deal: 1  \n",
       "3                                                                                                         don't pay you the certificate amount back: 1, took me a week to change a necklace: 1, manager was not helping: 1, didn't want to review the price: 1, exchange was not going to happen: 1  \n",
       "4                                                                                                                                                                                                                            Exchange: 18, Good: 2, Service: 2, Comfortable: 1, Price: 1, Policy: 1  \n",
       "5                                                                                                                                                              denied coupon: 1, poor quality: 1, additional cost: 1, rejected full refund: 1, broke easily: 1, can't exchange: 1, not recommend: 1  \n",
       "6                         assisted us so well: 1, provided us with the right price: 1, gave the best exchange rate: 1, helped us a lot during the exchange: 1, clear about the estimate and exchange offer: 1, very good experience while exchanging: 1, patiently assisted us with a good price: 1  \n",
       "7  manager blatantly denied the use of the coupon: 1, item is not strong enough: 1, rejected full refund and replacement: 1, have to bear 71 DHS additional cost: 1, fighting with customer for 71 DHS: 1, exchange only in Dubai: 1, can't exchange in India: 1, clearly asked her before I buy: 1  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd85e5-f659-4a43-bbf8-afe16e9a7b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
